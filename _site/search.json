[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Local Climatologies",
    "section": "",
    "text": "Daily and monthly averages and records of NOAA CO-OPS weather and\ntide observations at different locations along the U.S. East Coast"
  },
  {
    "objectID": "index.html#active-sites-updated-daily",
    "href": "index.html#active-sites-updated-daily",
    "title": "Local Climatologies",
    "section": "Active Sites (updated daily)",
    "text": "Active Sites (updated daily)\n\n\n\n\n\n\n\n\nBeaufort, NC\n\n\n\n\n\n\n\n\n\n\n\n\n\nVirginia Key, FL\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#archived-sites-updated-less-frequently",
    "href": "index.html#archived-sites-updated-less-frequently",
    "title": "Local Climatologies",
    "section": "Archived Sites (updated less frequently)",
    "text": "Archived Sites (updated less frequently)\n\n\n\n\n\n\n\n\nLewes, DE\n\n\n\n\n\n\n\n\n\n\n\nPass Christian, MS\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#shout-out",
    "href": "index.html#shout-out",
    "title": "Local Climatologies",
    "section": "Shout Out",
    "text": "Shout Out\nThis project is inspired by Brian McNoldy at the University of Miami, whose long-standing Climatology of Virginia Key, FL site never ceased to provide insightful weather perspectives during my time at the Rosenstiel School of Marine, Atmospheric, and Earth Science."
  },
  {
    "objectID": "content/stations/virginiakey/index.html",
    "href": "content/stations/virginiakey/index.html",
    "title": "Virginia Key, FL",
    "section": "",
    "text": "Monday, October 21, 2024\n\n\n\n\n\n Virginia Key is a small barrier island in southeast Florida with a tropical monsoon climate characterized by hot, humid summers and warm, dry winters. It is located east of Miami, south of Miami Beach, and north of Key Biscayne in Biscayne Bay. The NOAA weather station has been installed on a pier at the University of Miami Rosenstiel School of Marine, Atmospheric, and Earth Science since February 1994."
  },
  {
    "objectID": "content/stations/virginiakey/index.html#row",
    "href": "content/stations/virginiakey/index.html#row",
    "title": "Virginia Key, FL",
    "section": "Row",
    "text": "Row\n\n\nAir TemperatureWater LevelWater Temperature\n\n\n\n\n\n\n\n\nDate\nDaily Average\nRecord High Daily Average\nRecord High Daily Average Year\nRecord Low Daily Average\nRecord Low Daily Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\n01-Jan\n71.9\n78.7\n2016\n54.4\n2001\n75.3\n63.3\n2001\n80.2\n2016\n68.6\n77.2\n2016\n45.5\n2001\n26\n\n\n02-Jan\n72.2\n77.8\n2022\n56.6\n2010\n75.4\n64.2\n2010\n79.7\n2016\n69.0\n76.3\n2017\n49.1\n2010\n26\n\n\n03-Jan\n70.4\n78.0\n2015\n51.7\n2012\n74.4\n57.0\n2012\n79.2\n2019\n66.4\n77.0\n2015\n46.4\n2012\n26\n\n\n04-Jan\n68.7\n77.9\n2015\n51.6\n2018\n73.0\n58.7\n2010\n81.7\n2020\n64.4\n76.8\n2015\n43.7\n2018\n25\n\n\n05-Jan\n67.6\n77.3\n2015\n51.0\n2010\n72.3\n55.6\n1999\n80.2\n2019\n62.9\n75.9\n2007\n44.2\n2010\n26\n\n\n06-Jan\n68.4\n76.8\n2015\n48.4\n2010\n73.4\n55.7\n2010\n78.3\n2015\n63.4\n75.4\n2007\n41.0\n2010\n26\n\n\n07-Jan\n67.7\n77.4\n2007\n53.0\n2010\n72.9\n59.7\n2014\n81.0\n2017\n62.6\n76.6\n2007\n45.5\n2010\n26\n\n\n08-Jan\n67.3\n76.8\n2007\n49.0\n1996\n72.1\n54.5\n1996\n79.2\n2007\n62.4\n75.4\n2013\n43.5\n1996\n24\n\n\n09-Jan\n68.5\n77.1\n2013\n50.0\n1996\n72.7\n59.7\n1996\n78.6\n2016\n64.3\n76.3\n2013\n40.3\n1996\n26\n\n\n10-Jan\n68.3\n76.9\n2014\n54.6\n2001\n73.5\n65.3\n2001\n79.0\n2022\n63.1\n75.4\n2013\n43.9\n2001\n24\n\n\n11-Jan\n69.8\n76.6\n2020\n59.6\n2004\n73.8\n68.7\n2001\n79.0\n2020\n65.7\n74.8\n2013\n49.3\n2004\n24\n\n\n12-Jan\n70.4\n77.4\n2020\n52.5\n2010\n73.7\n60.1\n2010\n79.0\n2024\n67.1\n76.1\n2020\n44.9\n2010\n26\n\n\n13-Jan\n69.6\n76.3\n2020\n53.6\n1996\n73.7\n59.5\n1996\n78.4\n2024\n65.5\n75.2\n2020\n46.4\n2011\n26\n\n\n14-Jan\n68.3\n76.7\n2020\n54.8\n2023\n73.0\n60.6\n2023\n78.4\n2014\n63.6\n75.0\n2020\n49.1\n2023\n26\n\n\n15-Jan\n68.7\n76.0\n2020\n55.2\n2023\n73.1\n64.6\n2006\n78.6\n2024\n64.3\n74.3\n2013\n45.9\n2023\n27\n\n\n16-Jan\n68.9\n76.0\n2020\n58.4\n2014\n73.2\n63.5\n2014\n80.4\n1997\n64.6\n74.5\n2020\n53.2\n2014\n27\n\n\n17-Jan\n67.9\n74.8\n2007\n55.4\n1997\n72.6\n61.9\n1997\n77.7\n2007\n63.3\n73.6\n1999\n48.9\n1997\n27\n\n\n18-Jan\n67.7\n75.8\n2007\n50.0\n1997\n72.2\n55.8\n1997\n77.7\n2015\n63.1\n74.8\n2007\n44.1\n1997\n26\n\n\n19-Jan\n68.0\n74.5\n2020\n48.3\n1997\n72.8\n55.2\n1997\n78.4\n2011\n63.3\n73.0\n2001\n41.4\n1997\n27\n\n\n20-Jan\n68.1\n74.1\n2017\n57.8\n1997\n73.3\n65.7\n1997\n80.2\n2017\n62.9\n70.5\n2015\n49.8\n1997\n26\n\n\n21-Jan\n68.2\n75.4\n2002\n54.8\n2001\n72.6\n63.5\n2001\n77.9\n2023\n63.8\n73.9\n1999\n46.0\n2001\n26\n\n\n22-Jan\n68.7\n76.4\n2017\n52.6\n2020\n72.8\n58.3\n2001\n78.4\n2010\n64.6\n75.0\n2017\n42.1\n2020\n26\n\n\n23-Jan\n69.3\n76.8\n1999\n52.2\n2001\n73.7\n61.7\n2001\n81.5\n2023\n64.9\n75.7\n1999\n42.6\n2001\n25\n\n\n24-Jan\n68.7\n74.8\n2002\n55.0\n2005\n73.3\n65.1\n2005\n77.9\n2017\n64.0\n73.6\n2002\n44.8\n2005\n24\n\n\n25-Jan\n67.3\n76.2\n2023\n56.2\n2000\n72.5\n63.3\n2000\n78.4\n2023\n62.1\n74.3\n2024\n49.1\n2000\n25\n\n\n26-Jan\n68.6\n76.1\n2024\n54.0\n2000\n73.4\n59.7\n2000\n81.3\n2023\n63.8\n74.7\n2024\n48.2\n2000\n25\n\n\n27-Jan\n69.7\n76.8\n2024\n53.8\n2000\n73.8\n63.7\n2000\n80.1\n2021\n65.6\n75.2\n2024\n43.9\n2000\n25\n\n\n28-Jan\n68.7\n75.4\n2002\n58.0\n2019\n72.8\n63.1\n2019\n80.8\n2024\n64.7\n74.5\n2002\n52.2\n2011\n26\n\n\n29-Jan\n67.8\n75.8\n2002\n57.8\n2022\n71.9\n64.8\n2017\n78.4\n2018\n63.7\n74.7\n2002\n48.4\n2022\n27\n\n\n30-Jan\n68.6\n76.4\n2023\n54.1\n2022\n72.8\n64.0\n2022\n78.1\n2023\n64.5\n75.0\n2002\n44.2\n2022\n26\n\n\n31-Jan\n68.7\n77.1\n2002\n58.4\n1995\n73.0\n62.8\n1995\n80.1\n2002\n64.3\n75.4\n2023\n53.2\n2022\n25\n\n\n01-Feb\n69.3\n77.1\n2023\n58.6\n1995\n73.3\n64.9\n1995\n78.4\n2023\n65.4\n75.7\n2023\n52.2\n1995\n25\n\n\n02-Feb\n70.3\n77.3\n2002\n57.4\n1994\n74.1\n61.3\n1994\n84.4\n2002\n66.5\n73.9\n1996\n53.1\n2021\n25\n\n\n03-Feb\n70.1\n77.7\n2002\n59.1\n2021\n74.2\n66.6\n2021\n84.9\n2002\n65.9\n75.7\n2014\n51.6\n2021\n26\n\n\n04-Feb\n69.8\n76.7\n2014\n50.2\n1996\n73.5\n58.3\n1996\n80.6\n2002\n66.1\n75.7\n2014\n42.1\n1996\n26\n\n\n05-Feb\n68.6\n75.0\n1997\n50.0\n1996\n73.3\n62.1\n1996\n79.5\n2018\n64.0\n73.9\n1997\n37.8\n1996\n24\n\n\n06-Feb\n69.6\n77.9\n2014\n58.2\n1996\n73.8\n62.6\n1995\n81.7\n2014\n65.4\n75.2\n2020\n49.6\n1996\n25\n\n\n07-Feb\n70.0\n76.8\n2002\n57.0\n1998\n73.5\n61.3\n1998\n81.1\n2004\n66.4\n74.1\n1997\n52.7\n1998\n25\n\n\n08-Feb\n69.5\n75.6\n2013\n57.9\n1998\n73.5\n64.2\n1998\n80.1\n2013\n65.4\n74.3\n2018\n48.7\n1995\n24\n\n\n09-Feb\n69.8\n77.0\n2017\n52.0\n1995\n73.4\n62.6\n1995\n83.8\n2017\n66.2\n74.5\n1994\n41.4\n1995\n26\n\n\n10-Feb\n70.7\n76.4\n1994\n60.0\n2016\n74.9\n63.7\n2016\n79.7\n1997\n66.5\n75.2\n1994\n52.2\n2010\n25\n\n\n11-Feb\n69.9\n77.2\n2023\n54.0\n2010\n73.8\n62.2\n2010\n78.8\n2023\n66.0\n75.7\n1994\n45.8\n2010\n24\n\n\n12-Feb\n69.6\n77.2\n2020\n54.8\n2012\n74.1\n60.4\n2012\n82.9\n2002\n65.1\n75.9\n2018\n49.1\n2012\n27\n\n\n13-Feb\n69.6\n77.5\n2020\n56.5\n1996\n74.5\n64.8\n1996\n84.4\n2002\n64.7\n75.7\n2020\n48.2\n1996\n26\n\n\n14-Feb\n68.9\n78.4\n2021\n52.6\n2010\n73.1\n59.6\n2010\n80.1\n2021\n64.7\n76.6\n2021\n45.5\n2010\n26\n\n\n15-Feb\n70.8\n78.6\n2021\n61.4\n2010\n74.7\n68.6\n2010\n79.7\n2017\n66.9\n77.4\n2021\n53.6\n2015\n27\n\n\n16-Feb\n70.7\n76.1\n2023\n56.8\n2007\n74.4\n61.3\n2007\n81.7\n2002\n67.0\n74.5\n2023\n49.5\n1996\n27\n\n\n17-Feb\n69.6\n77.8\n2001\n47.9\n1996\n73.7\n57.0\n1996\n82.8\n2001\n65.4\n74.7\n1998\n38.8\n1996\n28\n\n\n18-Feb\n69.6\n78.5\n2021\n54.2\n1996\n73.8\n63.0\n2004\n80.2\n2021\n65.4\n76.8\n2021\n44.6\n1996\n27\n\n\n19-Feb\n70.9\n78.4\n2020\n53.4\n2015\n74.4\n58.3\n2015\n81.0\n2017\n67.4\n77.2\n2020\n46.0\n2007\n27\n\n\n20-Feb\n71.5\n77.7\n2020\n53.8\n2015\n74.9\n64.2\n2015\n79.7\n2020\n68.0\n75.7\n2020\n43.5\n2015\n26\n\n\n21-Feb\n71.7\n76.9\n2014\n65.0\n2024\n74.9\n71.6\n2015\n80.2\n2020\n68.5\n76.1\n2018\n58.3\n1999\n24\n\n\n22-Feb\n72.0\n77.0\n2003\n57.3\n1999\n75.3\n62.4\n1999\n79.0\n2003\n68.8\n75.0\n1997\n52.2\n1999\n27\n\n\n23-Feb\n72.3\n77.9\n2023\n61.4\n1999\n75.8\n69.6\n1999\n79.2\n2023\n68.8\n76.6\n2023\n53.2\n1999\n27\n\n\n24-Feb\n72.8\n77.8\n2023\n65.1\n1998\n76.2\n71.6\n2007\n80.1\n2014\n69.3\n76.3\n2023\n55.6\n2002\n26\n\n\n25-Feb\n72.4\n77.8\n2014\n64.1\n1999\n76.3\n70.9\n1999\n82.8\n2014\n68.6\n75.0\n2022\n57.2\n1999\n27\n\n\n26-Feb\n72.3\n77.6\n2013\n55.1\n2010\n76.0\n63.3\n2010\n81.3\n2002\n68.5\n76.1\n2013\n46.9\n2010\n28\n\n\n27-Feb\n72.1\n77.9\n2021\n60.8\n2016\n75.5\n68.7\n2004\n79.3\n2007\n68.7\n76.6\n2021\n52.2\n2016\n27\n\n\n28-Feb\n72.1\n77.9\n2021\n58.7\n2010\n75.5\n66.7\n2010\n80.6\n2023\n68.8\n76.6\n2021\n49.5\n2004\n27\n\n\n29-Feb\n70.9\n75.3\n2012\n62.6\n2020\n73.9\n70.2\n2020\n77.2\n2012\n67.9\n73.4\n2012\n54.9\n2020\n7\n\n\n01-Mar\n72.2\n78.0\n2021\n59.0\n2010\n75.7\n67.5\n2010\n80.6\n2011\n68.7\n76.8\n2021\n50.4\n2010\n27\n\n\n02-Mar\n72.4\n80.2\n2003\n61.0\n2013\n76.0\n66.0\n2013\n85.6\n2018\n68.8\n76.1\n2003\n55.9\n2013\n27\n\n\n03-Mar\n71.6\n78.9\n2007\n57.2\n2013\n74.9\n62.2\n2013\n82.0\n2021\n68.2\n77.0\n2023\n52.3\n2013\n26\n\n\n04-Mar\n70.8\n79.9\n2023\n55.2\n2013\n75.1\n63.9\n2013\n83.3\n2023\n66.4\n77.5\n2003\n46.4\n2013\n26\n\n\n05-Mar\n70.8\n78.6\n2020\n55.2\n2010\n74.4\n64.6\n2010\n81.7\n2020\n67.3\n77.2\n2003\n45.7\n2010\n26\n\n\n06-Mar\n71.6\n79.4\n2003\n59.2\n2010\n75.5\n66.2\n2010\n82.4\n2020\n67.7\n77.7\n2003\n52.2\n2010\n26\n\n\n07-Mar\n71.5\n80.6\n2003\n59.1\n2013\n75.4\n67.3\n2013\n84.6\n2023\n67.7\n78.4\n2003\n50.9\n2013\n26\n\n\n08-Mar\n70.8\n78.1\n2022\n61.0\n2001\n74.4\n68.5\n2001\n81.5\n2023\n67.3\n77.0\n2022\n53.6\n2001\n26\n\n\n09-Mar\n70.7\n80.0\n2003\n56.5\n1996\n74.0\n64.6\n1996\n84.2\n2003\n67.4\n77.4\n2024\n48.4\n1996\n27\n\n\n10-Mar\n71.5\n80.2\n2024\n57.1\n1996\n74.8\n60.8\n1996\n84.9\n2024\n68.2\n77.4\n2022\n53.4\n1996\n27\n\n\n11-Mar\n70.7\n78.9\n2022\n55.1\n1996\n74.2\n57.7\n1996\n82.8\n2023\n67.1\n77.4\n2022\n50.0\n1998\n27\n\n\n12-Mar\n71.9\n78.6\n2003\n58.4\n1998\n75.4\n64.4\n1998\n84.6\n2022\n68.3\n77.0\n2003\n52.3\n1998\n26\n\n\n13-Mar\n71.5\n79.6\n2023\n60.1\n1998\n74.7\n68.9\n1996\n83.5\n2023\n68.2\n78.4\n2003\n51.3\n1998\n27\n\n\n14-Mar\n71.9\n76.9\n2003\n64.0\n2013\n75.3\n70.3\n2013\n80.6\n2003\n68.6\n75.6\n2015\n57.7\n2013\n27\n\n\n15-Mar\n71.3\n77.1\n2001\n62.6\n2018\n74.9\n68.5\n2017\n79.9\n2016\n67.8\n75.7\n2001\n54.3\n2018\n26\n\n\n16-Mar\n72.1\n78.7\n2001\n61.6\n1999\n75.3\n68.9\n2010\n80.8\n2001\n68.9\n76.6\n2001\n52.0\n1999\n27\n\n\n17-Mar\n73.0\n78.2\n2024\n63.0\n2010\n76.1\n66.6\n2010\n80.6\n2003\n70.0\n76.3\n2001\n59.2\n2017\n27\n\n\n18-Mar\n73.6\n80.8\n2024\n63.2\n2010\n76.6\n68.4\n2010\n84.7\n2024\n70.5\n76.8\n2024\n57.9\n2010\n27\n\n\n19-Mar\n72.7\n81.2\n2003\n61.4\n2010\n76.7\n67.3\n2010\n83.3\n2003\n68.7\n79.0\n2003\n55.4\n2010\n27\n\n\n20-Mar\n72.5\n80.9\n2003\n63.4\n1996\n76.2\n68.9\n1996\n82.6\n2003\n68.7\n79.3\n2003\n57.9\n1996\n27\n\n\n21-Mar\n72.0\n81.6\n2003\n58.0\n1996\n75.8\n64.6\n1996\n83.8\n2003\n68.2\n79.5\n2003\n51.4\n1996\n28\n\n\n22-Mar\n71.8\n82.8\n2003\n61.4\n1996\n75.8\n66.6\n1998\n87.1\n2003\n67.8\n78.6\n2003\n55.0\n1996\n28\n\n\n23-Mar\n72.3\n78.9\n2014\n62.2\n1996\n76.4\n70.7\n1996\n84.9\n2015\n68.2\n75.7\n2022\n53.6\n1996\n28\n\n\n24-Mar\n73.1\n80.0\n2022\n66.6\n2010\n76.4\n71.4\n1996\n82.6\n2013\n69.9\n78.6\n2022\n61.0\n2010\n27\n\n\n25-Mar\n73.6\n79.6\n2020\n61.8\n2006\n76.9\n68.5\n2006\n83.7\n2020\n70.3\n77.4\n1994\n55.0\n2006\n27\n\n\n26-Mar\n73.1\n79.2\n2005\n61.2\n2013\n76.2\n69.1\n2013\n80.8\n2005\n69.9\n77.5\n2005\n53.4\n2013\n28\n\n\n27-Mar\n73.5\n79.1\n1994\n58.0\n2013\n76.6\n66.7\n2013\n83.5\n2015\n70.4\n77.7\n1994\n49.3\n2013\n28\n\n\n28-Mar\n74.2\n79.8\n1994\n63.3\n2013\n76.9\n69.4\n2013\n84.0\n2024\n71.4\n79.2\n1994\n57.2\n2013\n27\n\n\n29-Mar\n73.8\n78.0\n2021\n65.9\n2015\n77.7\n71.1\n2013\n82.8\n1994\n69.9\n76.3\n2020\n59.7\n2015\n25\n\n\n30-Mar\n73.6\n79.2\n2021\n66.1\n2010\n76.7\n70.0\n2013\n81.5\n2003\n70.4\n77.9\n2021\n58.3\n2010\n27\n\n\n31-Mar\n75.3\n80.9\n2020\n64.2\n2010\n78.4\n69.6\n2010\n86.2\n2020\n72.1\n77.0\n2022\n58.8\n2010\n25\n\n\n01-Apr\n75.0\n79.7\n2016\n67.3\n2010\n78.3\n72.7\n2010\n86.4\n2020\n71.6\n77.9\n2016\n61.9\n2010\n26\n\n\n02-Apr\n73.3\n80.9\n2016\n63.8\n1996\n77.0\n70.3\n1996\n83.3\n2016\n69.7\n78.6\n2016\n57.2\n1996\n25\n\n\n03-Apr\n74.2\n80.2\n2009\n65.1\n2005\n76.8\n70.9\n2005\n82.9\n2009\n71.6\n77.5\n2009\n59.2\n2005\n26\n\n\n04-Apr\n74.8\n79.2\n1998\n66.6\n2005\n77.5\n71.8\n2021\n82.9\n1998\n72.1\n78.1\n2023\n60.3\n2005\n26\n\n\n05-Apr\n74.4\n80.2\n2022\n65.7\n2000\n77.6\n71.1\n2000\n84.2\n2012\n71.2\n79.0\n2022\n60.3\n2000\n26\n\n\n06-Apr\n74.7\n81.2\n2022\n67.7\n2000\n78.0\n72.1\n2000\n85.5\n2009\n71.4\n79.9\n2022\n61.3\n2013\n27\n\n\n07-Apr\n75.3\n82.8\n2022\n66.6\n2009\n77.6\n72.9\n2009\n85.6\n2022\n73.0\n79.9\n2022\n60.4\n2009\n25\n\n\n08-Apr\n74.1\n79.9\n2020\n61.2\n2009\n77.1\n66.6\n2009\n82.4\n2020\n71.0\n77.4\n2020\n55.8\n2009\n27\n\n\n09-Apr\n75.1\n82.5\n2020\n66.0\n2009\n78.7\n72.0\n2009\n90.5\n2020\n71.6\n77.0\n1998\n60.1\n2009\n27\n\n\n10-Apr\n74.3\n84.2\n2020\n66.0\n2022\n77.5\n72.1\n2000\n91.8\n2020\n71.0\n77.4\n2015\n58.3\n2022\n28\n\n\n11-Apr\n74.7\n78.8\n1999\n65.2\n1998\n77.6\n69.1\n1998\n84.6\n1999\n71.8\n77.5\n2015\n61.2\n1998\n27\n\n\n12-Apr\n75.3\n80.9\n2020\n67.3\n1998\n78.4\n72.3\n1996\n88.3\n1999\n72.2\n79.0\n2020\n60.3\n1998\n26\n\n\n13-Apr\n75.5\n81.7\n2020\n69.2\n2003\n78.2\n71.1\n1998\n82.6\n2020\n72.9\n80.8\n2020\n64.0\n2003\n26\n\n\n14-Apr\n75.6\n81.8\n2020\n66.0\n2004\n78.0\n70.7\n2004\n82.9\n2020\n73.2\n80.6\n2020\n61.2\n2004\n26\n\n\n15-Apr\n76.3\n82.6\n2020\n64.6\n2004\n79.4\n72.0\n2004\n85.8\n2009\n73.2\n80.6\n2020\n57.2\n2004\n28\n\n\n16-Apr\n75.4\n81.0\n2020\n64.0\n2007\n78.8\n72.5\n2007\n86.7\n2001\n72.1\n78.3\n2015\n55.4\n2007\n29\n\n\n17-Apr\n75.7\n81.3\n2021\n66.6\n2005\n79.2\n74.1\n1996\n85.8\n2001\n72.1\n78.6\n2015\n59.2\n2005\n28\n\n\n18-Apr\n75.0\n80.5\n2015\n65.0\n1999\n78.0\n70.5\n1999\n83.8\n2020\n72.0\n78.6\n2015\n59.4\n1999\n28\n\n\n19-Apr\n75.2\n80.4\n2020\n65.0\n1997\n78.1\n72.0\n2001\n86.0\n2021\n72.2\n78.8\n2013\n57.0\n1997\n29\n\n\n20-Apr\n75.7\n85.6\n2020\n70.4\n1999\n78.6\n73.4\n2001\n89.6\n2020\n72.7\n81.5\n2020\n64.2\n1997\n29\n\n\n21-Apr\n76.3\n85.8\n2020\n71.7\n1997\n79.2\n73.9\n2005\n91.9\n2020\n73.3\n79.7\n2020\n65.7\n2014\n29\n\n\n22-Apr\n75.9\n80.2\n2002\n70.9\n2009\n79.1\n75.6\n2004\n83.8\n2002\n72.6\n76.8\n1995\n65.3\n2009\n28\n\n\n23-Apr\n76.0\n81.8\n2002\n70.1\n1998\n79.0\n74.7\n2007\n87.4\n2002\n72.9\n79.7\n2020\n63.0\n2000\n28\n\n\n24-Apr\n76.0\n81.9\n2018\n68.2\n2012\n79.4\n74.1\n2012\n86.4\n2018\n72.7\n77.7\n2021\n62.4\n2012\n27\n\n\n25-Apr\n76.7\n83.8\n2021\n67.1\n2012\n79.7\n73.0\n2012\n88.3\n2021\n73.7\n79.3\n2021\n61.2\n2012\n27\n\n\n26-Apr\n76.3\n85.1\n2015\n72.1\n2003\n79.4\n74.7\n2012\n91.2\n2015\n73.3\n79.0\n2015\n64.9\n2003\n27\n\n\n27-Apr\n77.2\n83.6\n2015\n71.2\n2000\n79.8\n74.8\n2001\n89.2\n2006\n74.5\n79.0\n2011\n66.6\n2000\n27\n\n\n28-Apr\n76.8\n80.6\n2015\n73.0\n2010\n79.5\n74.8\n2001\n86.0\n2015\n74.1\n79.0\n2011\n67.5\n2000\n27\n\n\n29-Apr\n76.9\n82.0\n2023\n73.0\n2001\n79.5\n74.5\n2001\n85.5\n1999\n74.4\n79.7\n2023\n70.0\n2000\n27\n\n\n30-Apr\n76.5\n81.0\n2014\n72.8\n2012\n79.3\n74.7\n2001\n84.6\n1999\n73.6\n79.7\n2014\n68.4\n2013\n26\n\n\n01-May\n76.4\n80.7\n2014\n67.9\n1999\n79.4\n75.2\n2001\n84.4\n1998\n73.4\n79.7\n2014\n60.3\n1999\n27\n\n\n02-May\n76.9\n80.8\n2014\n70.6\n1999\n79.7\n75.4\n2001\n85.1\n2023\n74.2\n79.3\n2014\n62.8\n1999\n26\n\n\n03-May\n77.2\n81.5\n1997\n72.0\n2001\n79.7\n75.7\n2001\n83.8\n2023\n74.7\n80.6\n2021\n68.0\n1999\n27\n\n\n04-May\n77.1\n81.8\n2021\n73.0\n1998\n80.3\n75.9\n2000\n85.3\n2013\n73.9\n80.8\n2021\n66.7\n1998\n27\n\n\n05-May\n77.5\n81.8\n2021\n73.7\n2015\n80.2\n75.7\n2000\n85.1\n1995\n74.8\n80.6\n2021\n69.4\n2013\n28\n\n\n06-May\n77.6\n83.1\n2022\n71.6\n2013\n80.7\n76.5\n2000\n87.1\n2020\n74.5\n79.9\n2003\n65.8\n2013\n27\n\n\n07-May\n77.1\n83.2\n2022\n71.0\n2016\n80.0\n75.9\n2005\n89.4\n2021\n74.1\n79.3\n2003\n65.5\n2016\n27\n\n\n08-May\n77.9\n82.9\n1998\n73.3\n2001\n80.5\n75.9\n2001\n88.0\n2022\n75.4\n79.5\n2003\n68.2\n2013\n26\n\n\n09-May\n77.9\n82.6\n1998\n72.6\n2001\n80.8\n74.1\n2001\n89.2\n1998\n75.0\n79.2\n2003\n67.6\n2007\n27\n\n\n10-May\n78.5\n82.4\n1998\n73.6\n2001\n81.4\n74.8\n2001\n86.5\n1998\n75.7\n79.3\n2003\n70.2\n2013\n26\n\n\n11-May\n78.9\n84.4\n2024\n74.3\n2001\n81.3\n75.0\n2001\n90.5\n2024\n76.5\n80.2\n2003\n68.9\n2022\n27\n\n\n12-May\n78.5\n83.0\n2003\n74.1\n1999\n81.1\n77.7\n2005\n85.6\n2003\n76.0\n80.4\n2003\n68.9\n1999\n28\n\n\n13-May\n78.7\n82.0\n2021\n74.1\n2006\n81.3\n76.8\n2005\n87.4\n2021\n76.0\n80.4\n2024\n69.8\n2006\n28\n\n\n14-May\n78.9\n83.0\n2024\n76.2\n2018\n81.4\n78.1\n2013\n85.5\n1999\n76.3\n82.2\n2024\n72.1\n1997\n27\n\n\n15-May\n78.5\n87.2\n2024\n75.2\n2011\n81.5\n76.5\n2001\n91.9\n2024\n75.5\n82.6\n2024\n69.4\n2011\n28\n\n\n16-May\n78.8\n86.4\n2024\n74.4\n2006\n81.7\n77.5\n2013\n91.9\n1995\n76.0\n82.8\n2024\n68.5\n2006\n28\n\n\n17-May\n78.7\n83.8\n1995\n74.6\n2014\n81.6\n78.1\n2004\n86.5\n1995\n75.7\n81.5\n2003\n69.3\n2014\n26\n\n\n18-May\n78.5\n84.3\n2024\n74.6\n2009\n81.3\n77.9\n1998\n86.2\n2024\n75.7\n82.4\n2024\n67.6\n2020\n27\n\n\n19-May\n79.0\n86.4\n2024\n74.1\n2009\n81.4\n77.4\n2009\n90.9\n2024\n76.6\n81.9\n2024\n70.7\n2009\n27\n\n\n20-May\n79.0\n85.7\n2024\n75.4\n2012\n82.1\n78.1\n2000\n91.2\n2024\n76.0\n80.2\n2017\n70.5\n2012\n25\n\n\n21-May\n78.8\n83.7\n2022\n73.2\n1994\n81.3\n77.5\n2000\n85.6\n2024\n76.4\n82.8\n2022\n67.6\n1994\n27\n\n\n22-May\n79.5\n83.1\n2022\n73.1\n1994\n82.1\n77.5\n2002\n88.3\n1995\n76.8\n82.2\n2022\n66.9\n1994\n26\n\n\n23-May\n79.1\n81.9\n2013\n75.1\n1994\n81.7\n78.1\n2021\n85.5\n2013\n76.4\n80.1\n2022\n70.9\n1994\n26\n\n\n24-May\n79.2\n82.0\n2024\n75.8\n2007\n81.9\n78.1\n2007\n86.2\n2005\n76.4\n80.8\n2015\n72.5\n2023\n27\n\n\n25-May\n79.2\n83.2\n2024\n75.1\n2007\n81.7\n77.4\n2007\n86.4\n2017\n76.8\n81.3\n2024\n72.7\n2007\n26\n\n\n26-May\n79.4\n83.6\n2024\n74.9\n2010\n81.6\n77.4\n2007\n87.1\n2024\n77.1\n81.1\n1998\n69.3\n2010\n27\n\n\n27-May\n80.0\n84.5\n2024\n76.6\n1997\n82.5\n78.1\n2007\n86.4\n2017\n77.5\n82.6\n2024\n70.0\n1997\n27\n\n\n28-May\n79.8\n83.8\n2017\n76.8\n2016\n82.5\n78.6\n2007\n88.7\n2017\n77.0\n81.1\n2020\n71.6\n1997\n27\n\n\n29-May\n79.4\n82.6\n2000\n76.2\n2013\n82.5\n78.6\n2007\n88.0\n2023\n76.4\n80.6\n2020\n71.1\n2022\n27\n\n\n30-May\n79.9\n84.6\n2024\n75.9\n1994\n82.6\n78.6\n2007\n87.3\n2024\n77.3\n83.1\n2017\n71.2\n1994\n27\n\n\n31-May\n80.2\n83.6\n2024\n76.6\n2013\n82.5\n77.7\n2007\n85.8\n2009\n77.8\n82.0\n2017\n71.1\n2009\n26\n\n\n01-Jun\n79.9\n83.0\n2003\n74.6\n2007\n82.7\n77.7\n2007\n88.0\n2003\n77.1\n81.5\n2017\n71.4\n2007\n27\n\n\n02-Jun\n80.0\n83.8\n1998\n77.1\n2009\n83.2\n80.1\n1996\n89.2\n1998\n76.8\n81.1\n2016\n72.1\n2005\n26\n\n\n03-Jun\n80.1\n83.0\n2003\n76.6\n2022\n82.9\n79.3\n1996\n86.9\n1998\n77.2\n81.5\n2003\n72.1\n2010\n26\n\n\n04-Jun\n80.2\n84.4\n2012\n77.6\n2023\n83.3\n79.9\n2014\n88.9\n2012\n77.2\n82.0\n2016\n72.3\n2023\n26\n\n\n05-Jun\n81.0\n84.7\n2012\n76.0\n2009\n84.0\n81.0\n1999\n88.9\n2018\n78.0\n82.2\n1998\n68.1\n2009\n26\n\n\n06-Jun\n80.9\n84.8\n1998\n78.0\n2023\n84.1\n81.1\n2011\n87.3\n2010\n77.8\n83.1\n1998\n72.8\n2009\n25\n\n\n07-Jun\n80.8\n85.0\n1998\n76.6\n2017\n84.0\n81.5\n2007\n89.2\n2010\n77.6\n83.3\n2020\n70.3\n2017\n26\n\n\n08-Jun\n80.6\n84.5\n1994\n76.4\n1999\n83.8\n79.9\n1999\n87.1\n1994\n77.4\n82.0\n2020\n72.9\n1999\n27\n\n\n09-Jun\n80.9\n83.6\n1995\n77.4\n1997\n84.0\n80.8\n1997\n86.5\n1995\n77.9\n82.2\n2020\n74.1\n1997\n26\n\n\n10-Jun\n80.9\n84.3\n2024\n76.6\n2000\n83.9\n80.6\n2000\n87.4\n2016\n77.9\n82.2\n2024\n71.1\n1994\n26\n\n\n11-Jun\n80.9\n84.4\n2010\n76.3\n2000\n83.9\n80.6\n2000\n87.6\n2018\n77.8\n82.0\n2010\n72.0\n2000\n25\n\n\n12-Jun\n81.0\n84.1\n2022\n76.2\n1997\n83.7\n81.1\n2012\n86.2\n2010\n78.4\n82.4\n2015\n69.4\n2014\n25\n\n\n13-Jun\n81.8\n85.6\n1998\n77.0\n1996\n84.3\n80.6\n1996\n89.8\n2021\n79.2\n82.9\n2010\n73.4\n1996\n26\n\n\n14-Jun\n81.6\n85.4\n2010\n78.8\n2020\n84.8\n81.3\n1996\n90.9\n1998\n78.4\n83.8\n2010\n71.6\n2012\n27\n\n\n15-Jun\n81.5\n86.4\n2010\n76.6\n2012\n84.6\n81.0\n2002\n87.8\n2010\n78.4\n84.9\n2010\n68.7\n2012\n27\n\n\n16-Jun\n81.6\n87.2\n2023\n78.2\n2021\n84.9\n82.2\n1996\n91.4\n2023\n78.3\n83.3\n1998\n72.3\n2021\n26\n\n\n17-Jun\n81.4\n85.2\n1998\n78.1\n2007\n84.4\n81.7\n2012\n88.9\n2016\n78.5\n83.8\n1998\n73.9\n2007\n25\n\n\n18-Jun\n81.7\n85.1\n1998\n77.6\n1995\n84.4\n81.7\n1995\n89.2\n2016\n78.9\n84.0\n1998\n73.6\n1995\n24\n\n\n19-Jun\n81.3\n84.9\n1998\n76.9\n1999\n84.5\n80.2\n1999\n88.7\n2022\n78.1\n84.0\n1998\n72.0\n2014\n27\n\n\n20-Jun\n81.6\n85.2\n1998\n76.2\n1995\n84.7\n79.9\n2012\n89.6\n1994\n78.5\n83.8\n1998\n70.3\n1995\n26\n\n\n21-Jun\n81.3\n85.2\n2021\n75.1\n1995\n84.8\n80.4\n1995\n90.7\n2009\n77.8\n84.4\n2021\n69.8\n1995\n28\n\n\n22-Jun\n81.6\n87.6\n2009\n77.2\n2012\n85.0\n80.6\n2012\n94.3\n2009\n78.2\n82.9\n2015\n71.8\n1997\n27\n\n\n23-Jun\n81.6\n84.6\n2004\n77.2\n2003\n84.5\n79.9\n2003\n88.3\n1996\n78.6\n83.7\n2004\n72.4\n2009\n25\n\n\n24-Jun\n81.7\n85.1\n2020\n77.8\n2002\n84.7\n82.6\n1999\n88.0\n2018\n78.7\n84.0\n2004\n72.5\n2002\n27\n\n\n25-Jun\n82.2\n85.6\n2020\n78.7\n2006\n84.7\n80.8\n2006\n86.9\n2020\n79.7\n84.2\n2020\n75.4\n2002\n25\n\n\n26-Jun\n82.1\n85.6\n2020\n76.6\n2002\n85.0\n81.1\n2002\n86.7\n2023\n79.3\n84.6\n2020\n72.0\n2002\n25\n\n\n27-Jun\n82.4\n85.1\n2020\n78.7\n2003\n85.1\n82.2\n2003\n88.0\n2022\n79.8\n84.2\n2020\n75.0\n1998\n25\n\n\n28-Jun\n82.3\n84.8\n2020\n79.4\n2007\n84.9\n81.9\n2007\n87.3\n2024\n79.7\n83.8\n2010\n75.7\n2003\n27\n\n\n29-Jun\n82.3\n85.2\n2020\n78.7\n2007\n85.2\n82.0\n2007\n88.5\n2023\n79.4\n83.8\n2020\n74.7\n2013\n28\n\n\n30-Jun\n82.2\n85.9\n2015\n78.6\n1995\n85.4\n82.9\n2002\n89.4\n2014\n78.9\n83.7\n2022\n72.3\n1995\n28\n\n\n01-Jul\n82.3\n84.9\n1998\n76.6\n2002\n85.7\n81.7\n2002\n88.7\n1997\n79.0\n83.7\n2022\n71.4\n2002\n28\n\n\n02-Jul\n82.3\n85.4\n1998\n77.4\n1999\n85.4\n81.1\n1999\n87.8\n1997\n79.1\n83.5\n2020\n72.9\n2002\n28\n\n\n03-Jul\n82.6\n85.8\n2020\n77.2\n1999\n85.6\n80.6\n1999\n88.7\n1996\n79.5\n84.0\n2020\n71.1\n2007\n28\n\n\n04-Jul\n82.7\n85.6\n1998\n79.9\n2007\n85.5\n83.3\n1999\n90.1\n1998\n79.9\n83.8\n2016\n73.4\n1997\n28\n\n\n05-Jul\n83.0\n86.9\n2023\n79.5\n1999\n85.5\n82.9\n1999\n89.1\n2023\n80.5\n84.7\n2023\n76.1\n1999\n27\n\n\n06-Jul\n82.6\n85.4\n1998\n78.2\n2006\n85.3\n82.2\n2006\n89.1\n2009\n79.9\n84.0\n1998\n74.3\n2006\n27\n\n\n07-Jul\n83.2\n85.9\n2009\n78.6\n2011\n85.6\n81.9\n2011\n89.2\n2023\n80.9\n83.8\n2005\n75.2\n2011\n27\n\n\n08-Jul\n83.1\n86.6\n2024\n78.6\n2002\n85.6\n82.2\n2002\n89.6\n2023\n80.6\n85.3\n2024\n74.5\n2005\n28\n\n\n09-Jul\n82.9\n86.3\n2020\n79.1\n2002\n85.6\n82.6\n2013\n90.0\n2020\n80.2\n83.3\n2004\n73.4\n2014\n27\n\n\n10-Jul\n82.6\n86.6\n2023\n77.4\n2002\n85.8\n80.8\n2002\n91.4\n1996\n79.4\n84.0\n2007\n73.6\n2006\n28\n\n\n11-Jul\n82.6\n87.2\n2023\n78.4\n2012\n85.7\n82.8\n2012\n90.3\n1998\n79.5\n84.9\n2023\n73.6\n2024\n28\n\n\n12-Jul\n82.5\n87.8\n2023\n77.9\n2021\n85.5\n82.8\n2012\n89.6\n2023\n79.4\n86.0\n2023\n70.3\n2021\n28\n\n\n13-Jul\n82.8\n87.2\n2023\n77.6\n2013\n85.5\n82.9\n2006\n88.7\n2022\n80.2\n86.0\n2023\n72.0\n2013\n27\n\n\n14-Jul\n82.8\n85.1\n2024\n77.9\n2013\n85.7\n83.1\n2013\n88.9\n2023\n79.9\n84.0\n2016\n71.4\n2015\n27\n\n\n15-Jul\n82.3\n85.0\n2009\n77.5\n2012\n85.7\n82.0\n2012\n89.4\n2000\n78.9\n83.7\n2009\n73.0\n2012\n28\n\n\n16-Jul\n82.4\n84.9\n2018\n78.8\n2012\n85.5\n81.7\n2013\n88.9\n2023\n79.4\n83.5\n1998\n74.7\n2000\n27\n\n\n17-Jul\n82.6\n85.1\n2024\n76.1\n2013\n85.9\n80.8\n2013\n89.2\n2011\n79.4\n83.8\n1998\n71.4\n2013\n27\n\n\n18-Jul\n83.1\n86.6\n2022\n77.0\n2013\n85.8\n82.0\n2013\n89.4\n2004\n80.4\n85.3\n2022\n72.1\n2013\n28\n\n\n19-Jul\n83.4\n86.6\n2022\n80.0\n1997\n85.7\n83.5\n2006\n88.2\n2018\n81.1\n85.3\n2022\n75.0\n1997\n28\n\n\n20-Jul\n82.9\n86.7\n2022\n78.2\n2006\n85.7\n82.4\n2004\n88.0\n2023\n80.1\n85.8\n2022\n72.9\n2006\n28\n\n\n21-Jul\n82.8\n88.7\n2018\n78.7\n2006\n86.0\n82.0\n2006\n93.2\n2018\n79.7\n85.3\n2022\n70.9\n2017\n27\n\n\n22-Jul\n82.8\n88.7\n2023\n78.6\n2006\n86.2\n82.4\n2006\n92.8\n2023\n79.4\n84.6\n2023\n74.1\n2012\n27\n\n\n23-Jul\n83.3\n87.8\n2023\n80.2\n2010\n86.0\n83.8\n2012\n90.9\n2023\n80.6\n84.7\n2023\n73.6\n2018\n27\n\n\n24-Jul\n83.7\n87.2\n2015\n80.2\n2018\n86.3\n83.1\n2003\n92.3\n2015\n81.1\n84.9\n2023\n74.1\n2018\n28\n\n\n25-Jul\n83.6\n86.9\n2023\n80.2\n2015\n86.2\n84.7\n1996\n88.9\n2013\n81.0\n84.9\n2023\n74.3\n2015\n27\n\n\n26-Jul\n83.0\n85.2\n2017\n79.6\n1995\n86.1\n84.0\n2015\n88.5\n2018\n79.9\n83.3\n2011\n74.1\n1995\n26\n\n\n27-Jul\n83.3\n85.9\n2017\n78.8\n2004\n85.9\n82.8\n1995\n88.2\n2015\n80.8\n84.4\n2017\n73.0\n2004\n28\n\n\n28-Jul\n83.3\n86.4\n2014\n78.7\n1995\n86.1\n82.8\n2004\n89.4\n2014\n80.5\n85.3\n2022\n74.5\n1995\n28\n\n\n29-Jul\n83.2\n86.2\n1999\n79.5\n1994\n86.1\n83.5\n2000\n90.0\n1999\n80.1\n84.7\n2023\n75.2\n1994\n28\n\n\n30-Jul\n83.6\n85.4\n2010\n80.8\n1995\n86.3\n84.2\n1995\n89.2\n2017\n80.9\n84.0\n2002\n76.3\n2014\n27\n\n\n31-Jul\n83.8\n86.6\n2022\n80.2\n2017\n86.3\n84.4\n1996\n88.0\n2024\n81.4\n85.5\n2022\n74.7\n2017\n28\n\n\n01-Aug\n83.0\n86.6\n2024\n79.3\n2017\n86.1\n83.3\n1995\n88.2\n2023\n80.0\n85.5\n2024\n73.0\n2017\n28\n\n\n02-Aug\n83.2\n85.4\n2010\n80.2\n2000\n86.2\n83.8\n2003\n88.9\n2023\n80.1\n83.8\n2010\n74.8\n2016\n27\n\n\n03-Aug\n82.5\n86.2\n2017\n78.4\n1995\n85.9\n81.5\n2004\n88.0\n2020\n79.1\n84.7\n2017\n73.6\n1995\n27\n\n\n04-Aug\n83.1\n86.1\n2017\n77.4\n1995\n86.0\n82.4\n1995\n88.0\n2023\n80.2\n84.7\n2017\n72.5\n1995\n26\n\n\n05-Aug\n83.6\n86.6\n2023\n80.8\n1994\n86.5\n83.8\n1995\n89.1\n2023\n80.7\n85.1\n2011\n75.0\n2014\n27\n\n\n06-Aug\n83.1\n87.2\n2023\n80.4\n2005\n86.4\n84.0\n1995\n89.8\n2020\n79.7\n85.6\n2023\n73.6\n2005\n27\n\n\n07-Aug\n83.7\n87.6\n2023\n79.2\n2004\n86.2\n81.9\n2004\n89.4\n2024\n81.3\n86.0\n2023\n75.0\n2011\n27\n\n\n08-Aug\n82.9\n87.2\n2023\n78.7\n2006\n86.0\n84.4\n1995\n89.1\n2023\n79.7\n85.3\n2023\n72.5\n2006\n27\n\n\n09-Aug\n83.1\n87.2\n2023\n78.6\n2010\n86.2\n82.6\n2010\n89.4\n2023\n80.1\n85.8\n2022\n73.6\n2016\n26\n\n\n10-Aug\n83.2\n86.8\n2022\n78.8\n2012\n86.2\n83.1\n2012\n90.0\n2023\n80.2\n85.6\n2022\n71.8\n2018\n28\n\n\n11-Aug\n83.3\n86.3\n2022\n80.3\n1994\n86.2\n84.0\n1994\n90.0\n2023\n80.3\n85.3\n2022\n74.8\n2015\n27\n\n\n12-Aug\n83.4\n86.1\n2022\n78.2\n1994\n86.4\n82.4\n1994\n88.2\n2023\n80.4\n84.9\n2022\n74.1\n1994\n26\n\n\n13-Aug\n83.9\n86.4\n2023\n81.0\n1994\n86.8\n84.0\n1994\n89.8\n1995\n81.0\n84.7\n2023\n75.4\n2006\n28\n\n\n14-Aug\n83.3\n87.4\n2024\n79.7\n2021\n86.6\n84.6\n1999\n89.2\n2024\n80.0\n85.6\n2023\n73.0\n2006\n28\n\n\n15-Aug\n83.3\n87.0\n2017\n79.7\n2009\n86.7\n83.7\n2013\n90.7\n1995\n79.8\n83.7\n2016\n74.1\n2024\n28\n\n\n16-Aug\n83.8\n86.7\n2017\n81.5\n2006\n86.3\n84.2\n1994\n90.3\n2017\n81.2\n84.0\n1998\n77.3\n2009\n26\n\n\n17-Aug\n84.1\n87.6\n2022\n80.6\n1999\n86.5\n84.2\n2000\n90.7\n2022\n81.6\n85.1\n2017\n75.4\n1999\n26\n\n\n18-Aug\n83.5\n87.0\n2022\n80.1\n1996\n86.3\n82.9\n1999\n89.8\n2020\n80.7\n84.9\n2021\n74.7\n1996\n27\n\n\n19-Aug\n83.6\n88.5\n2022\n80.6\n2003\n86.2\n84.4\n2003\n91.0\n2022\n80.9\n86.0\n2022\n76.1\n2011\n27\n\n\n20-Aug\n83.4\n87.8\n2022\n77.9\n2003\n86.1\n82.2\n2003\n89.2\n2022\n80.6\n86.4\n2022\n73.6\n2003\n26\n\n\n21-Aug\n83.6\n86.0\n2016\n78.4\n1997\n86.3\n84.0\n1999\n88.7\n2022\n80.8\n84.0\n2018\n69.8\n1997\n27\n\n\n22-Aug\n83.5\n86.2\n2020\n78.9\n1999\n86.3\n83.3\n1996\n88.9\n2024\n80.8\n84.9\n2020\n73.4\n1999\n28\n\n\n23-Aug\n83.3\n87.2\n2022\n76.1\n1996\n86.0\n82.8\n1995\n88.7\n2022\n80.6\n85.8\n2022\n69.4\n1996\n28\n\n\n24-Aug\n83.0\n87.4\n2022\n78.2\n1995\n86.2\n82.9\n1995\n88.9\n2015\n79.8\n86.2\n2022\n73.4\n1997\n29\n\n\n25-Aug\n82.7\n87.4\n2022\n79.4\n2018\n86.3\n83.3\n1994\n92.1\n1998\n79.0\n85.6\n2022\n72.5\n2018\n28\n\n\n26-Aug\n82.2\n87.7\n2022\n78.5\n2000\n86.0\n82.4\n1996\n90.7\n2011\n78.4\n86.0\n2022\n73.0\n2000\n29\n\n\n27-Aug\n82.6\n85.3\n2011\n79.0\n2000\n85.7\n81.5\n2000\n90.5\n2011\n79.6\n84.0\n1998\n75.7\n2012\n28\n\n\n28-Aug\n82.7\n85.4\n1998\n77.0\n1994\n85.8\n82.2\n1994\n87.9\n2009\n79.7\n84.0\n2006\n71.8\n1994\n28\n\n\n29-Aug\n83.3\n86.2\n2004\n79.2\n1994\n86.4\n83.1\n1994\n90.7\n1999\n80.2\n84.6\n2014\n74.8\n2016\n29\n\n\n30-Aug\n83.0\n87.1\n2022\n79.4\n2016\n85.9\n83.3\n2006\n88.7\n2022\n80.1\n85.5\n2022\n74.1\n2016\n28\n\n\n31-Aug\n83.2\n86.2\n2017\n80.4\n2000\n86.2\n83.8\n2024\n89.8\n2022\n80.1\n85.1\n2017\n74.5\n2021\n27\n\n\n01-Sep\n83.2\n85.6\n2022\n80.6\n2006\n86.1\n83.8\n2003\n88.9\n2023\n80.2\n84.0\n2014\n75.6\n2023\n27\n\n\n02-Sep\n82.8\n86.4\n2020\n79.8\n2003\n85.9\n82.6\n2003\n89.2\n2022\n79.8\n85.3\n2020\n73.4\n2017\n28\n\n\n03-Sep\n82.8\n86.6\n1998\n78.2\n2018\n85.9\n82.8\n2012\n88.9\n2007\n79.8\n85.1\n1998\n73.2\n2018\n29\n\n\n04-Sep\n82.7\n87.8\n2022\n77.6\n2004\n85.8\n80.2\n2004\n91.6\n1996\n79.7\n86.9\n2022\n74.5\n2006\n29\n\n\n05-Sep\n82.4\n86.8\n2022\n77.6\n1997\n85.6\n81.3\n1997\n88.9\n2022\n79.2\n84.7\n2022\n73.9\n1997\n29\n\n\n06-Sep\n82.4\n88.4\n2022\n78.7\n1997\n85.5\n82.9\n1997\n89.8\n2022\n79.4\n86.9\n2022\n74.5\n1997\n28\n\n\n07-Sep\n82.2\n87.7\n2022\n78.5\n1999\n85.4\n82.6\n2018\n90.3\n2022\n79.1\n85.1\n2022\n73.2\n1999\n28\n\n\n08-Sep\n82.3\n86.1\n2024\n79.2\n1996\n85.8\n83.7\n2013\n89.2\n2003\n78.9\n84.9\n2024\n73.8\n2017\n28\n\n\n09-Sep\n82.5\n87.2\n2022\n78.2\n1996\n85.6\n82.0\n2001\n91.9\n2021\n79.5\n84.7\n2015\n71.6\n2017\n27\n\n\n10-Sep\n82.5\n89.4\n2022\n79.4\n2001\n85.5\n82.8\n2017\n90.7\n2022\n79.5\n88.0\n2022\n73.4\n2005\n27\n\n\n11-Sep\n82.4\n88.8\n2022\n77.2\n2002\n85.5\n83.5\n2001\n92.1\n2022\n79.3\n85.5\n2022\n70.5\n2002\n26\n\n\n12-Sep\n82.3\n88.0\n2022\n78.2\n2001\n85.3\n81.3\n2001\n92.5\n2022\n79.3\n83.5\n2022\n73.8\n1994\n27\n\n\n13-Sep\n82.4\n86.1\n2023\n77.8\n2014\n85.7\n82.2\n1994\n91.9\n2022\n79.1\n83.1\n2004\n72.0\n2014\n27\n\n\n14-Sep\n82.9\n86.0\n2024\n78.4\n2001\n85.8\n82.9\n1994\n91.5\n2009\n80.1\n83.3\n2002\n73.6\n2001\n28\n\n\n15-Sep\n82.6\n84.4\n2022\n79.0\n1994\n85.6\n83.1\n1998\n89.8\n2022\n79.7\n83.1\n2020\n74.3\n1994\n27\n\n\n16-Sep\n82.2\n85.6\n2024\n76.1\n2001\n85.3\n80.2\n2001\n90.3\n2022\n79.2\n83.5\n2020\n72.0\n2001\n28\n\n\n17-Sep\n82.2\n84.6\n2020\n78.8\n2015\n85.2\n82.8\n1998\n89.8\n2022\n79.3\n82.9\n2009\n74.1\n2000\n29\n\n\n18-Sep\n82.4\n85.0\n2018\n79.1\n2013\n85.5\n82.4\n2013\n89.2\n2022\n79.3\n83.8\n2018\n73.6\n2012\n29\n\n\n19-Sep\n82.1\n86.1\n2022\n78.0\n1997\n86.0\n82.8\n2001\n91.6\n2015\n78.1\n83.1\n2018\n72.3\n1997\n28\n\n\n20-Sep\n82.2\n85.2\n2022\n78.8\n2014\n85.6\n82.6\n1994\n90.7\n2015\n78.8\n82.6\n2003\n73.6\n2014\n29\n\n\n21-Sep\n82.1\n87.0\n2022\n79.6\n1994\n85.0\n82.4\n1994\n91.0\n2022\n79.1\n83.1\n2022\n75.4\n2010\n29\n\n\n22-Sep\n82.0\n86.4\n2022\n78.1\n2012\n85.2\n82.2\n2012\n91.4\n2022\n78.8\n82.8\n2006\n73.9\n1995\n28\n\n\n23-Sep\n81.7\n88.4\n2022\n77.6\n2014\n84.6\n81.3\n2014\n92.7\n2022\n78.8\n84.0\n2022\n73.9\n2014\n29\n\n\n24-Sep\n81.9\n86.2\n2022\n77.8\n1999\n84.8\n80.6\n1999\n89.4\n2022\n79.0\n82.9\n2022\n74.1\n2023\n29\n\n\n25-Sep\n81.6\n87.9\n2022\n77.6\n2007\n84.6\n80.8\n2004\n90.5\n2022\n78.6\n85.3\n2022\n72.0\n2023\n28\n\n\n26-Sep\n82.0\n85.0\n2018\n77.2\n2007\n84.8\n81.3\n2007\n89.1\n2013\n79.3\n83.7\n2018\n73.0\n2007\n28\n\n\n27-Sep\n81.8\n85.1\n2024\n78.6\n2007\n84.9\n82.6\n2007\n88.0\n2013\n78.7\n84.0\n2018\n73.9\n2016\n28\n\n\n28-Sep\n81.5\n85.8\n2024\n76.3\n2001\n84.5\n80.8\n2001\n87.8\n2009\n78.4\n83.8\n2024\n71.8\n1994\n28\n\n\n29-Sep\n81.2\n85.0\n2024\n74.3\n2001\n84.3\n77.4\n2001\n89.5\n2009\n78.1\n83.5\n2024\n71.2\n2001\n28\n\n\n30-Sep\n81.3\n85.3\n2024\n76.6\n2001\n84.6\n80.8\n2001\n90.5\n2015\n78.0\n83.7\n2024\n72.3\n2001\n28\n\n\n01-Oct\n81.2\n84.8\n1998\n76.9\n2001\n84.6\n81.0\n2007\n91.0\n2015\n77.8\n82.9\n2017\n72.3\n2001\n28\n\n\n02-Oct\n80.8\n84.3\n2015\n75.4\n2001\n84.1\n79.7\n2001\n90.0\n2015\n77.6\n81.3\n1996\n71.1\n2001\n27\n\n\n03-Oct\n81.1\n84.2\n1995\n77.8\n2001\n84.2\n81.7\n2001\n87.8\n2014\n78.0\n83.1\n1995\n73.9\n2001\n27\n\n\n04-Oct\n81.1\n85.0\n2020\n77.1\n1996\n84.1\n80.6\n1996\n88.5\n2014\n78.1\n83.7\n2020\n73.6\n1996\n27\n\n\n05-Oct\n81.2\n84.0\n2009\n76.6\n2014\n84.2\n81.5\n2010\n87.8\n2000\n78.2\n82.8\n2009\n71.6\n2014\n26\n\n\n06-Oct\n81.3\n83.6\n1998\n77.9\n2010\n83.9\n81.0\n2010\n86.9\n2013\n78.6\n82.4\n1998\n74.8\n1996\n26\n\n\n07-Oct\n80.8\n84.6\n2020\n75.5\n2010\n83.8\n81.0\n2010\n86.8\n2009\n77.8\n83.7\n2020\n70.0\n2010\n26\n\n\n08-Oct\n81.2\n84.8\n2009\n76.4\n2010\n84.0\n81.0\n2011\n88.2\n2016\n78.4\n83.0\n2009\n71.6\n2010\n26\n\n\n09-Oct\n81.0\n84.9\n2005\n76.2\n2000\n84.0\n80.2\n2000\n89.1\n2005\n77.9\n83.7\n2009\n72.3\n2000\n25\n\n\n10-Oct\n80.9\n84.4\n2009\n75.4\n2000\n83.6\n77.0\n2000\n88.0\n2015\n78.2\n83.4\n2009\n73.2\n2010\n26\n\n\n11-Oct\n81.1\n84.1\n2009\n77.3\n2000\n83.7\n79.0\n2000\n86.2\n2006\n78.4\n82.6\n2009\n73.4\n2021\n25\n\n\n12-Oct\n81.0\n86.0\n2023\n77.8\n2004\n83.6\n80.1\n2004\n87.4\n2023\n78.4\n84.6\n2023\n74.3\n2024\n25\n\n\n13-Oct\n80.8\n86.8\n2023\n78.0\n2000\n83.7\n80.1\n2000\n89.8\n2023\n77.8\n83.7\n2023\n72.9\n2015\n25\n\n\n14-Oct\n80.8\n84.5\n2003\n77.6\n1999\n83.4\n80.8\n2000\n88.0\n2003\n78.1\n81.0\n2003\n73.6\n1999\n26\n\n\n15-Oct\n80.4\n83.2\n2018\n76.0\n2000\n83.4\n80.6\n2006\n86.7\n2023\n77.4\n81.5\n2018\n70.2\n2000\n24\n\n\n16-Oct\n79.2\n83.4\n2017\n72.2\n2004\n82.9\n77.5\n2004\n88.3\n2021\n75.5\n82.0\n2018\n66.9\n2004\n25\n\n\n17-Oct\n78.8\n82.9\n2021\n69.8\n2023\n82.1\n76.1\n2023\n87.6\n2021\n75.4\n80.4\n1998\n63.5\n2023\n27\n\n\n18-Oct\n78.5\n83.2\n2018\n64.9\n2009\n81.4\n70.1\n2009\n84.0\n2007\n75.7\n82.4\n2018\n59.7\n2009\n26\n\n\n19-Oct\n78.8\n83.0\n2007\n68.6\n2009\n81.9\n77.8\n2009\n84.0\n2007\n75.7\n82.0\n2007\n59.4\n2009\n26\n\n\n20-Oct\n78.8\n82.4\n1998\n72.4\n1996\n82.0\n77.5\n2011\n85.6\n2018\n75.7\n81.3\n1998\n66.4\n1996\n26\n\n\n21-Oct\n79.0\n82.5\n2013\n70.2\n2011\n82.0\n75.2\n2011\n86.0\n2018\n75.9\n81.3\n2013\n65.1\n2011\n25\n\n\n22-Oct\n79.1\n83.1\n2017\n72.2\n2011\n81.9\n76.8\n1999\n84.0\n1998\n76.3\n82.2\n2017\n65.1\n2011\n25\n\n\n23-Oct\n78.9\n82.6\n2005\n72.8\n1999\n82.2\n78.3\n1998\n87.1\n2013\n75.7\n81.5\n2007\n66.7\n1999\n25\n\n\n24-Oct\n77.9\n82.0\n2001\n68.9\n2006\n81.2\n75.9\n2006\n84.9\n2001\n74.5\n79.5\n2007\n61.9\n2006\n25\n\n\n25-Oct\n77.3\n81.5\n2002\n64.6\n2005\n80.7\n70.0\n2005\n84.7\n2021\n73.8\n80.1\n2002\n59.2\n2005\n26\n\n\n26-Oct\n77.5\n83.3\n2021\n64.6\n2005\n80.9\n71.6\n2005\n87.3\n2021\n74.2\n79.7\n2010\n57.7\n2005\n24\n\n\n27-Oct\n78.4\n82.8\n2020\n69.4\n2001\n81.2\n75.6\n2001\n85.5\n2021\n75.7\n81.7\n2020\n62.4\n2005\n24\n\n\n28-Oct\n77.8\n82.8\n2020\n67.9\n2001\n80.9\n74.8\n2001\n85.6\n1995\n74.7\n81.9\n2020\n61.0\n2001\n25\n\n\n29-Oct\n77.5\n82.8\n2020\n68.2\n2012\n80.5\n73.4\n2012\n84.0\n2021\n74.4\n81.9\n2020\n62.8\n2017\n26\n\n\n30-Oct\n77.4\n82.4\n2002\n65.6\n2017\n80.3\n71.8\n2017\n84.4\n2020\n74.6\n80.9\n2009\n59.4\n2017\n26\n\n\n31-Oct\n77.6\n81.2\n2015\n69.2\n2012\n80.4\n75.2\n2012\n85.6\n2021\n74.8\n80.1\n2015\n62.8\n2017\n25\n\n\n01-Nov\n77.9\n82.0\n2020\n67.6\n2014\n80.7\n75.7\n2012\n84.4\n2023\n75.0\n80.6\n2020\n58.5\n2014\n26\n\n\n02-Nov\n76.9\n81.8\n2015\n61.4\n2014\n80.1\n69.1\n2014\n84.2\n2013\n73.7\n80.6\n2015\n53.8\n2014\n25\n\n\n03-Nov\n76.3\n80.7\n2015\n67.4\n1999\n79.6\n72.1\n1999\n83.2\n2009\n72.9\n78.8\n2015\n60.8\n2014\n25\n\n\n04-Nov\n76.7\n81.2\n2018\n68.2\n1999\n79.7\n74.3\n1999\n82.9\n2015\n73.7\n79.7\n2018\n62.2\n1999\n25\n\n\n05-Nov\n76.3\n81.2\n2015\n67.8\n2010\n79.7\n74.7\n2010\n82.8\n2023\n73.0\n80.6\n2015\n61.0\n2010\n25\n\n\n06-Nov\n76.1\n81.0\n2018\n62.2\n2010\n79.4\n66.9\n2010\n85.6\n2002\n72.8\n79.5\n2018\n57.6\n2010\n25\n\n\n07-Nov\n75.2\n81.9\n2015\n64.1\n2010\n78.9\n72.1\n2010\n83.3\n2003\n71.5\n81.0\n2015\n56.1\n2010\n24\n\n\n08-Nov\n75.3\n81.8\n2015\n63.8\n2012\n78.8\n68.0\n2012\n83.8\n1995\n71.7\n80.8\n2015\n59.5\n2012\n24\n\n\n09-Nov\n74.8\n81.8\n2015\n66.1\n1997\n78.6\n72.3\n1997\n83.3\n2003\n71.1\n80.4\n2015\n59.9\n1997\n26\n\n\n10-Nov\n76.1\n80.8\n2015\n66.6\n1996\n79.5\n74.7\n1996\n83.3\n2015\n72.8\n79.0\n2023\n58.6\n1996\n26\n\n\n11-Nov\n76.2\n81.0\n2023\n68.2\n1996\n79.5\n73.8\n2011\n82.9\n2015\n73.0\n80.1\n2023\n60.6\n1996\n27\n\n\n12-Nov\n76.0\n81.8\n2015\n67.5\n2009\n79.1\n74.0\n2009\n83.5\n2015\n72.9\n80.1\n2015\n61.0\n2009\n26\n\n\n13-Nov\n75.6\n81.1\n2015\n66.5\n2009\n78.9\n74.8\n2009\n82.9\n2015\n72.4\n79.2\n2015\n58.2\n2009\n27\n\n\n14-Nov\n75.1\n81.7\n2020\n67.0\n1995\n78.7\n72.9\n1995\n83.3\n2020\n71.5\n80.1\n2020\n61.0\n1995\n27\n\n\n15-Nov\n74.5\n81.5\n2020\n61.8\n1995\n78.2\n69.1\n1995\n83.8\n2018\n70.8\n80.2\n2020\n54.5\n1995\n27\n\n\n16-Nov\n74.2\n80.2\n2020\n64.4\n1995\n77.7\n72.1\n2007\n81.9\n2020\n70.6\n78.6\n2020\n56.1\n1995\n26\n\n\n17-Nov\n74.7\n79.4\n2015\n66.9\n2007\n78.2\n73.2\n1995\n83.1\n2010\n71.2\n78.1\n2015\n60.3\n2007\n26\n\n\n18-Nov\n75.0\n80.6\n2015\n69.5\n2014\n78.2\n75.4\n1994\n81.9\n2015\n71.8\n79.2\n2015\n58.8\n2014\n26\n\n\n19-Nov\n74.3\n80.4\n2015\n64.6\n2014\n78.0\n72.0\n2006\n81.9\n2013\n70.7\n79.3\n2015\n56.8\n2014\n27\n\n\n20-Nov\n74.1\n79.7\n1998\n61.7\n2006\n77.5\n65.1\n2006\n81.9\n2018\n70.6\n78.4\n1998\n58.3\n2006\n27\n\n\n21-Nov\n74.0\n78.9\n1998\n57.4\n2006\n77.4\n62.2\n2006\n81.5\n2017\n70.7\n77.4\n1998\n52.5\n2006\n26\n\n\n22-Nov\n73.9\n79.2\n1998\n58.8\n2006\n77.6\n67.8\n2006\n85.3\n2021\n70.2\n78.4\n1998\n49.8\n2006\n26\n\n\n23-Nov\n73.7\n78.9\n1998\n62.5\n2006\n77.3\n69.1\n2005\n81.7\n2020\n70.2\n78.1\n1998\n53.4\n2006\n26\n\n\n24-Nov\n73.9\n79.2\n2014\n65.6\n2006\n77.6\n73.6\n2006\n81.3\n2018\n70.2\n77.4\n2014\n57.7\n2006\n25\n\n\n25-Nov\n74.3\n79.5\n2014\n66.9\n2012\n77.4\n74.3\n2012\n80.6\n2018\n71.3\n78.6\n2014\n59.5\n2012\n26\n\n\n26-Nov\n74.2\n78.8\n2023\n66.3\n1995\n78.0\n74.1\n1995\n82.4\n2018\n70.4\n76.6\n2023\n58.5\n1995\n26\n\n\n27-Nov\n73.2\n78.2\n2010\n64.4\n2009\n77.2\n70.9\n2009\n83.3\n2010\n69.1\n76.6\n2007\n56.7\n1996\n26\n\n\n28-Nov\n72.5\n78.4\n1994\n60.0\n2018\n76.4\n66.7\n2018\n80.4\n2003\n68.6\n77.4\n1994\n52.5\n2013\n26\n\n\n29-Nov\n72.9\n78.5\n1994\n62.5\n2018\n76.7\n71.8\n2018\n79.5\n1994\n69.0\n77.5\n1994\n53.2\n2018\n26\n\n\n30-Nov\n73.9\n78.8\n1994\n65.8\n2003\n77.2\n72.7\n2003\n80.2\n1994\n70.6\n77.5\n1994\n58.8\n2003\n22\n\n\n01-Dec\n73.7\n78.7\n2023\n63.3\n1999\n77.2\n69.6\n2020\n80.4\n2023\n70.3\n77.2\n2006\n56.5\n2011\n23\n\n\n02-Dec\n73.1\n79.2\n2023\n62.2\n1999\n76.9\n69.6\n1999\n81.1\n2018\n69.4\n77.4\n2023\n54.9\n1999\n24\n\n\n03-Dec\n73.9\n78.8\n2023\n64.0\n2010\n77.4\n71.8\n1999\n81.3\n2023\n70.5\n77.4\n1994\n55.6\n2010\n24\n\n\n04-Dec\n74.1\n79.6\n1994\n64.4\n2000\n77.1\n72.3\n2000\n81.3\n2023\n71.1\n78.3\n1994\n56.5\n2000\n25\n\n\n05-Dec\n73.7\n78.4\n2016\n66.8\n2000\n77.1\n72.5\n2000\n81.3\n2023\n70.3\n77.4\n2016\n60.3\n2018\n25\n\n\n06-Dec\n72.3\n78.8\n2016\n56.9\n2010\n76.0\n64.9\n2010\n80.2\n1994\n68.6\n77.5\n2016\n48.9\n2010\n25\n\n\n07-Dec\n71.9\n79.2\n1994\n52.2\n2010\n76.1\n59.4\n2010\n80.6\n1994\n67.8\n77.7\n1994\n45.1\n2010\n26\n\n\n08-Dec\n72.4\n78.6\n2017\n54.0\n2010\n76.2\n63.3\n2010\n82.4\n2021\n68.5\n77.0\n2017\n44.8\n2010\n26\n\n\n09-Dec\n72.8\n78.4\n1994\n57.4\n2010\n75.8\n59.9\n2010\n80.1\n2021\n69.8\n77.5\n1994\n51.3\n2020\n26\n\n\n10-Dec\n72.0\n78.8\n2009\n57.6\n2017\n75.8\n64.9\n2017\n83.0\n2009\n68.2\n76.8\n1994\n50.2\n2017\n26\n\n\n11-Dec\n71.8\n79.0\n2021\n60.4\n2018\n75.6\n65.8\n2018\n80.6\n1994\n68.0\n77.7\n2021\n52.5\n2017\n26\n\n\n12-Dec\n72.0\n78.8\n2021\n60.5\n2004\n75.7\n66.9\n2004\n81.5\n2021\n68.3\n76.5\n2002\n54.1\n2004\n26\n\n\n13-Dec\n72.8\n78.8\n2021\n53.7\n2010\n76.2\n62.6\n2010\n82.9\n2020\n69.3\n77.5\n2021\n44.8\n2010\n26\n\n\n14-Dec\n72.4\n78.0\n2015\n62.2\n2017\n76.3\n68.9\n2017\n80.1\n2009\n68.5\n76.5\n2001\n55.6\n2017\n25\n\n\n15-Dec\n71.0\n78.4\n2009\n52.6\n2010\n75.1\n61.7\n2010\n80.4\n2016\n67.0\n77.0\n2009\n43.5\n2010\n25\n\n\n16-Dec\n71.8\n78.4\n2015\n60.6\n2010\n75.4\n64.6\n1998\n79.7\n2009\n68.2\n77.0\n2015\n51.6\n2010\n25\n\n\n17-Dec\n71.9\n79.1\n2015\n63.2\n1997\n76.1\n70.2\n1998\n82.2\n2020\n67.7\n78.1\n2015\n55.8\n1997\n25\n\n\n18-Dec\n71.2\n78.8\n2016\n54.7\n2003\n75.6\n62.1\n2003\n82.8\n2012\n66.8\n77.4\n2016\n47.3\n2003\n26\n\n\n19-Dec\n70.5\n78.9\n2016\n59.9\n2003\n74.8\n64.6\n2003\n79.9\n2016\n66.2\n77.9\n2016\n48.9\n1996\n26\n\n\n20-Dec\n69.2\n78.3\n2016\n50.6\n1996\n72.8\n57.0\n1996\n80.4\n2021\n65.6\n77.4\n2016\n44.2\n1996\n26\n\n\n21-Dec\n68.8\n77.6\n2013\n57.6\n2009\n73.5\n63.0\n2009\n79.3\n2020\n64.1\n76.3\n2013\n49.3\n2003\n25\n\n\n22-Dec\n69.8\n78.4\n2013\n57.2\n2012\n73.6\n64.0\n1995\n80.4\n2017\n66.0\n77.4\n2013\n49.5\n2012\n26\n\n\n23-Dec\n71.4\n79.0\n2015\n58.8\n1995\n74.7\n62.2\n1995\n79.9\n2015\n68.1\n78.1\n2015\n55.4\n1995\n26\n\n\n24-Dec\n71.7\n79.2\n2015\n51.8\n1995\n74.9\n57.9\n1995\n80.1\n2015\n68.5\n78.3\n2015\n45.7\n1995\n25\n\n\n25-Dec\n70.5\n79.0\n2015\n49.4\n1995\n74.5\n57.7\n1995\n79.7\n2015\n66.5\n78.3\n2015\n41.0\n1995\n26\n\n\n26-Dec\n69.4\n78.6\n2015\n54.7\n1995\n73.8\n61.7\n1995\n80.8\n2023\n65.0\n77.2\n2015\n47.5\n2010\n24\n\n\n27-Dec\n67.7\n78.4\n2015\n48.8\n2010\n72.5\n55.4\n2010\n80.2\n2021\n62.9\n77.5\n2015\n42.1\n2010\n25\n\n\n28-Dec\n69.3\n79.0\n2015\n52.2\n2010\n73.0\n57.7\n1995\n80.1\n2015\n65.6\n77.9\n2015\n42.4\n2010\n25\n\n\n29-Dec\n70.5\n79.4\n2015\n58.7\n2009\n74.4\n67.1\n2010\n80.6\n2015\n66.6\n78.3\n2015\n50.1\n2009\n25\n\n\n30-Dec\n69.5\n79.5\n2015\n54.8\n2000\n73.1\n59.5\n2000\n80.6\n2013\n65.9\n78.4\n2015\n50.0\n2000\n25\n\n\n31-Dec\n70.8\n79.2\n2015\n49.9\n2000\n74.4\n55.6\n2000\n80.1\n2015\n67.2\n78.3\n2015\n44.2\n2000\n24\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\nDate\nDaily Average\nRecord High Daily Average\nRecord High Daily Average Year\nRecord Low Daily Average\nRecord Low Daily Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\n01-Jan\n-1.13\n-0.67\n2022\n-1.78\n1998\n0.01\n-0.65\n2004\n0.81\n2022\n-2.27\n-1.79\n2024\n-3.16\n1998\n29\n\n\n02-Jan\n-1.15\n-0.68\n2022\n-1.58\n2011\n-0.02\n-0.64\n2012\n0.9\n2018\n-2.27\n-1.52\n2024\n-2.84\n2006\n29\n\n\n03-Jan\n-1.13\n-0.36\n2018\n-1.79\n2011\n-0.01\n-0.78\n2012\n1.2\n2018\n-2.25\n-1.34\n2024\n-3.04\n2011\n29\n\n\n04-Jan\n-1.16\n-0.65\n2018\n-1.7\n2002\n-0.04\n-0.6\n2004\n0.85\n2022\n-2.29\n-1.58\n2024\n-2.87\n2002\n29\n\n\n05-Jan\n-1.17\n-0.52\n2014\n-1.61\n2004\n-0.06\n-0.59\n2012\n0.9\n2014\n-2.28\n-1.39\n2024\n-2.8\n2011\n29\n\n\n06-Jan\n-1.13\n-0.39\n2016\n-1.64\n2004\n-0.0\n-0.6\n1998\n0.7\n2014\n-2.26\n-1.37\n2016\n-2.71\n2004\n29\n\n\n07-Jan\n-1.14\n-0.38\n2016\n-1.72\n2004\n-0.01\n-0.65\n2004\n0.68\n2016\n-2.28\n-1.44\n2016\n-2.79\n2002\n29\n\n\n08-Jan\n-1.12\n-0.33\n2016\n-1.71\n2002\n0.01\n-0.62\n2002\n0.86\n2016\n-2.24\n-1.51\n2016\n-2.8\n2002\n27\n\n\n09-Jan\n-1.09\n-0.18\n2016\n-1.67\n2002\n0.04\n-0.57\n2009\n1.17\n2016\n-2.23\n-1.4\n2022\n-2.97\n2005\n29\n\n\n10-Jan\n-1.13\n-0.2\n2016\n-1.67\n2002\n0.02\n-0.56\n2007\n1.11\n2016\n-2.28\n-1.52\n2016\n-3.14\n2001\n28\n\n\n11-Jan\n-1.08\n-0.41\n2016\n-1.66\n2002\n0.05\n-0.64\n2006\n1.03\n2016\n-2.2\n-1.27\n2022\n-2.84\n1998\n28\n\n\n12-Jan\n-1.09\n-0.33\n2022\n-1.61\n2002\n0.03\n-0.75\n2011\n0.97\n2016\n-2.21\n-1.2\n2022\n-2.84\n2002\n28\n\n\n13-Jan\n-1.1\n-0.2\n2022\n-1.69\n2011\n0.05\n-0.92\n2011\n0.91\n2016\n-2.24\n-1.19\n2022\n-2.75\n2002\n29\n\n\n14-Jan\n-1.13\n-0.17\n2022\n-1.7\n2012\n-0.03\n-0.82\n2011\n0.96\n2016\n-2.24\n-1.2\n2022\n-2.84\n2012\n28\n\n\n15-Jan\n-1.1\n-0.23\n2016\n-1.74\n2012\n-0.0\n-0.68\n2012\n1.12\n2016\n-2.2\n-1.3\n2022\n-2.81\n2012\n28\n\n\n16-Jan\n-1.08\n-0.1\n2022\n-1.69\n2012\n0.01\n-0.7\n2012\n0.96\n2022\n-2.17\n-1.16\n2022\n-2.67\n2002\n28\n\n\n17-Jan\n-1.14\n-0.48\n2015\n-1.7\n2009\n-0.03\n-0.78\n2009\n0.81\n2016\n-2.25\n-1.61\n2015\n-2.68\n2007\n29\n\n\n18-Jan\n-1.16\n-0.43\n2015\n-1.58\n2002\n-0.05\n-0.7\n2002\n0.8\n2015\n-2.27\n-1.67\n2015\n-2.77\n2003\n29\n\n\n19-Jan\n-1.16\n-0.59\n2015\n-1.93\n2003\n-0.04\n-0.77\n2002\n0.76\n2015\n-2.29\n-1.73\n2013\n-3.14\n2003\n29\n\n\n20-Jan\n-1.16\n-0.55\n2015\n-1.86\n2003\n-0.02\n-0.92\n2002\n0.94\n2015\n-2.3\n-1.68\n2013\n-3.11\n2003\n29\n\n\n21-Jan\n-1.14\n-0.51\n2015\n-2.02\n2001\n0.02\n-1.04\n2009\n1.08\n2015\n-2.3\n-1.72\n2013\n-3.04\n2001\n29\n\n\n22-Jan\n-1.08\n-0.51\n2015\n-1.88\n2001\n0.07\n-1.02\n2002\n0.99\n2015\n-2.24\n-1.67\n2017\n-2.96\n2001\n29\n\n\n23-Jan\n-1.09\n-0.21\n2020\n-1.86\n2001\n0.06\n-0.9\n2009\n1.13\n2020\n-2.25\n-1.56\n2020\n-2.97\n2001\n28\n\n\n24-Jan\n-1.12\n0.02\n2020\n-1.83\n2003\n0.01\n-0.82\n2006\n1.31\n2020\n-2.25\n-1.28\n2020\n-2.88\n2003\n27\n\n\n25-Jan\n-1.15\n-0.37\n2022\n-1.74\n2003\n-0.02\n-0.74\n2003\n0.78\n2022\n-2.28\n-1.52\n2022\n-2.75\n2003\n27\n\n\n26-Jan\n-1.12\n-0.49\n2022\n-1.74\n2011\n0.0\n-0.58\n2006\n0.68\n2020\n-2.25\n-1.59\n2022\n-2.98\n2011\n29\n\n\n27-Jan\n-1.12\n-0.45\n2020\n-1.9\n2011\n-0.0\n-0.87\n2011\n0.77\n2020\n-2.23\n-1.6\n2016\n-2.93\n2011\n28\n\n\n28-Jan\n-1.12\n-0.28\n2016\n-1.85\n2011\n-0.01\n-0.82\n2011\n0.85\n2016\n-2.23\n-1.41\n2016\n-2.98\n2002\n29\n\n\n29-Jan\n-1.1\n-0.44\n2022\n-1.84\n2011\n0.01\n-0.81\n2011\n0.89\n2022\n-2.21\n-1.58\n2020\n-2.94\n2002\n29\n\n\n30-Jan\n-1.09\n-0.47\n2022\n-1.86\n2011\n0.04\n-0.84\n2011\n0.97\n2022\n-2.21\n-1.47\n2016\n-2.89\n2002\n29\n\n\n31-Jan\n-1.08\n-0.37\n2022\n-1.69\n2011\n0.04\n-0.69\n2009\n1.26\n2022\n-2.19\n-1.2\n2016\n-2.81\n2011\n29\n\n\n01-Feb\n-1.01\n-0.29\n2022\n-1.75\n2001\n0.11\n-0.85\n2001\n1.12\n2022\n-2.14\n-1.31\n2016\n-2.82\n2002\n28\n\n\n02-Feb\n-1.04\n-0.31\n1998\n-1.9\n2001\n0.05\n-1.02\n2001\n1.12\n2022\n-2.13\n-1.38\n2016\n-2.92\n2003\n29\n\n\n03-Feb\n-1.07\n-0.43\n2024\n-1.88\n2001\n0.05\n-0.91\n2001\n0.91\n2022\n-2.18\n-1.24\n2024\n-2.86\n2003\n29\n\n\n04-Feb\n-1.11\n-0.38\n2024\n-1.81\n2001\n-0.02\n-0.75\n2009\n0.55\n2022\n-2.21\n-1.3\n2024\n-2.87\n2001\n29\n\n\n05-Feb\n-1.1\n-0.15\n2024\n-1.77\n2009\n-0.0\n-0.93\n2009\n0.93\n2023\n-2.2\n-1.15\n2024\n-2.96\n2001\n29\n\n\n06-Feb\n-1.09\n-0.38\n2024\n-1.71\n2001\n0.01\n-0.75\n2003\n0.88\n2005\n-2.2\n-1.5\n2024\n-3.06\n2001\n29\n\n\n07-Feb\n-1.08\n-0.34\n2024\n-1.65\n2003\n0.03\n-0.76\n2006\n0.86\n2005\n-2.19\n-1.48\n2024\n-2.97\n2001\n29\n\n\n08-Feb\n-1.11\n-0.31\n2024\n-1.81\n2003\n0.03\n-1.03\n2003\n1.14\n2005\n-2.24\n-1.53\n2022\n-3.06\n2001\n28\n\n\n09-Feb\n-1.09\n-0.33\n2024\n-1.7\n2011\n0.03\n-0.86\n2011\n1.03\n2024\n-2.22\n-1.46\n2022\n-2.94\n2001\n28\n\n\n10-Feb\n-1.09\n-0.43\n2024\n-1.8\n2003\n0.04\n-0.85\n2003\n1.04\n2024\n-2.22\n-1.34\n2022\n-2.98\n2001\n29\n\n\n11-Feb\n-1.11\n-0.45\n2024\n-1.73\n2001\n0.01\n-0.99\n2003\n1.01\n2024\n-2.24\n-1.38\n2022\n-3.0\n2001\n29\n\n\n12-Feb\n-1.13\n-0.51\n2014\n-1.77\n2003\n-0.02\n-0.84\n2003\n0.9\n2024\n-2.25\n-1.36\n2015\n-2.76\n2001\n28\n\n\n13-Feb\n-1.18\n-0.46\n2014\n-1.91\n2003\n-0.07\n-0.97\n2003\n0.66\n2024\n-2.29\n-1.55\n2014\n-2.85\n2003\n28\n\n\n14-Feb\n-1.24\n-0.59\n2014\n-1.78\n2003\n-0.14\n-0.76\n2001\n0.56\n2014\n-2.34\n-1.75\n2014\n-2.88\n2003\n28\n\n\n15-Feb\n-1.21\n-0.53\n2014\n-1.75\n2008\n-0.11\n-0.75\n2001\n0.64\n2014\n-2.3\n-1.71\n2014\n-2.76\n1996\n28\n\n\n16-Feb\n-1.19\n-0.5\n2015\n-1.61\n2008\n-0.1\n-0.66\n2008\n0.71\n2015\n-2.28\n-1.72\n2015\n-3.01\n1996\n28\n\n\n17-Feb\n-1.19\n-0.5\n2022\n-1.76\n1996\n-0.08\n-0.79\n2009\n0.84\n2015\n-2.3\n-1.64\n2022\n-3.34\n1996\n28\n\n\n18-Feb\n-1.17\n-0.66\n2015\n-1.59\n2003\n-0.05\n-0.71\n2009\n0.86\n2015\n-2.28\n-1.79\n2024\n-2.98\n1996\n28\n\n\n19-Feb\n-1.19\n-0.76\n1999\n-1.61\n2006\n-0.06\n-0.8\n1998\n0.63\n2019\n-2.33\n-1.88\n2017\n-2.98\n2011\n28\n\n\n20-Feb\n-1.21\n-0.67\n2019\n-1.62\n2006\n-0.08\n-0.76\n2006\n0.86\n2019\n-2.33\n-1.87\n2021\n-2.88\n2011\n27\n\n\n21-Feb\n-1.18\n-0.64\n2015\n-1.67\n1996\n-0.06\n-0.81\n1998\n0.83\n2015\n-2.31\n-1.53\n2021\n-2.99\n1996\n28\n\n\n22-Feb\n-1.13\n-0.55\n2020\n-1.71\n2006\n0.01\n-0.81\n2006\n0.84\n2020\n-2.27\n-1.63\n2017\n-2.87\n2011\n28\n\n\n23-Feb\n-1.18\n-0.22\n2020\n-1.83\n2006\n-0.05\n-0.78\n2006\n0.92\n2020\n-2.31\n-1.38\n2020\n-2.87\n2006\n27\n\n\n24-Feb\n-1.19\n-0.19\n2020\n-1.84\n2003\n-0.09\n-0.78\n2003\n0.99\n2020\n-2.29\n-1.37\n2020\n-2.9\n2003\n26\n\n\n25-Feb\n-1.19\n-0.5\n2020\n-1.87\n2003\n-0.06\n-0.97\n1996\n0.59\n2020\n-2.32\n-1.59\n2020\n-2.82\n2003\n27\n\n\n26-Feb\n-1.16\n-0.57\n2020\n-1.84\n1996\n-0.04\n-0.97\n1996\n0.72\n2002\n-2.29\n-1.67\n2020\n-2.74\n2006\n28\n\n\n27-Feb\n-1.14\n-0.57\n2014\n-1.82\n1996\n-0.02\n-1.01\n1996\n0.8\n2014\n-2.27\n-1.58\n2019\n-2.77\n2006\n27\n\n\n28-Feb\n-1.18\n-0.55\n2014\n-2.02\n2008\n-0.07\n-1.31\n2008\n0.93\n2014\n-2.28\n-1.62\n2019\n-2.74\n2008\n27\n\n\n29-Feb\n-1.33\n-1.04\n2020\n-1.78\n2008\n-0.5\n-1.12\n2008\n-0.12\n2020\n-2.15\n-1.8\n2004\n-2.44\n2008\n8\n\n\n01-Mar\n-1.15\n-0.68\n2022\n-1.74\n2008\n-0.01\n-1.03\n2008\n0.72\n2022\n-2.28\n-1.78\n2020\n-2.67\n2006\n28\n\n\n02-Mar\n-1.13\n-0.65\n2022\n-1.65\n2008\n0.0\n-0.98\n2008\n0.77\n2018\n-2.27\n-1.75\n2020\n-2.66\n2006\n28\n\n\n03-Mar\n-1.15\n-0.52\n2022\n-1.6\n2009\n-0.04\n-0.73\n2008\n0.84\n2022\n-2.26\n-1.66\n2023\n-2.72\n2010\n28\n\n\n04-Mar\n-1.15\n-0.47\n2018\n-1.65\n1997\n-0.05\n-0.69\n1997\n0.93\n2018\n-2.26\n-1.56\n2023\n-3.06\n2002\n28\n\n\n05-Mar\n-1.15\n-0.28\n2018\n-1.85\n2001\n-0.05\n-0.75\n2001\n1.0\n2018\n-2.24\n-1.56\n2018\n-2.95\n2001\n28\n\n\n06-Mar\n-1.14\n-0.19\n2018\n-1.59\n2001\n-0.02\n-0.52\n2005\n1.01\n2018\n-2.26\n-1.39\n2018\n-2.86\n2001\n28\n\n\n07-Mar\n-1.1\n-0.26\n2018\n-1.55\n2004\n0.03\n-0.7\n2006\n0.83\n2018\n-2.24\n-1.36\n2018\n-2.85\n2001\n28\n\n\n08-Mar\n-1.1\n-0.41\n2018\n-1.95\n1996\n0.02\n-0.79\n1996\n0.76\n2016\n-2.23\n-1.32\n2018\n-3.11\n1996\n28\n\n\n09-Mar\n-1.05\n-0.35\n2023\n-1.77\n1996\n0.1\n-0.63\n1996\n0.95\n2020\n-2.21\n-1.36\n2018\n-3.07\n2008\n29\n\n\n10-Mar\n-1.07\n-0.25\n2023\n-1.62\n2002\n0.1\n-0.72\n2002\n0.94\n2023\n-2.23\n-1.38\n2018\n-2.94\n2008\n29\n\n\n11-Mar\n-1.07\n-0.25\n2023\n-1.55\n2008\n0.07\n-0.65\n2011\n1.14\n2013\n-2.21\n-1.37\n2018\n-2.8\n2008\n29\n\n\n12-Mar\n-1.09\n-0.13\n2023\n-1.55\n2003\n0.05\n-0.68\n2011\n1.15\n2013\n-2.23\n-1.17\n2023\n-2.73\n2008\n29\n\n\n13-Mar\n-1.08\n-0.16\n2023\n-1.69\n2008\n0.02\n-0.74\n2003\n0.98\n2023\n-2.18\n-1.31\n2023\n-2.81\n2008\n29\n\n\n14-Mar\n-1.1\n-0.27\n2023\n-1.61\n2008\n-0.02\n-0.65\n2003\n0.86\n2023\n-2.19\n-1.39\n2023\n-2.72\n2005\n29\n\n\n15-Mar\n-1.13\n-0.44\n2023\n-1.62\n2002\n-0.06\n-0.57\n2002\n0.62\n2023\n-2.2\n-1.5\n2023\n-2.67\n2002\n29\n\n\n16-Mar\n-1.12\n-0.38\n2023\n-1.68\n2002\n-0.04\n-0.62\n2001\n0.59\n2023\n-2.2\n-1.35\n2023\n-2.77\n2000\n29\n\n\n17-Mar\n-1.09\n-0.41\n2023\n-1.64\n2000\n-0.02\n-0.8\n2001\n0.82\n2023\n-2.16\n-1.63\n2023\n-2.82\n2000\n29\n\n\n18-Mar\n-1.05\n-0.39\n2019\n-1.59\n2000\n0.06\n-0.74\n2001\n0.94\n2019\n-2.16\n-1.68\n2023\n-2.83\n2000\n29\n\n\n19-Mar\n-1.01\n-0.19\n2019\n-1.4\n2000\n0.11\n-0.59\n2005\n1.36\n2019\n-2.14\n-1.52\n2024\n-2.85\n1996\n29\n\n\n20-Mar\n-1.04\n-0.06\n2019\n-1.6\n1996\n0.09\n-0.45\n2005\n1.5\n2019\n-2.17\n-1.6\n2024\n-2.91\n1996\n29\n\n\n21-Mar\n-1.07\n-0.12\n2019\n-1.72\n1996\n0.07\n-0.5\n1998\n1.45\n2019\n-2.21\n-1.54\n2013\n-3.02\n1996\n29\n\n\n22-Mar\n-1.05\n-0.22\n2019\n-1.68\n1996\n0.08\n-0.52\n2002\n1.35\n2019\n-2.19\n-1.39\n2021\n-2.99\n2011\n29\n\n\n23-Mar\n-1.04\n-0.28\n2019\n-1.64\n1996\n0.08\n-0.55\n1996\n1.21\n2019\n-2.16\n-1.26\n2021\n-2.95\n2011\n29\n\n\n24-Mar\n-1.02\n-0.44\n2021\n-1.64\n1999\n0.07\n-0.61\n1999\n0.85\n2019\n-2.12\n-1.36\n2021\n-2.68\n2011\n29\n\n\n25-Mar\n-1.03\n-0.43\n2024\n-1.65\n1999\n0.07\n-0.67\n1996\n0.85\n2019\n-2.14\n-1.56\n2024\n-2.68\n1999\n29\n\n\n26-Mar\n-1.07\n-0.41\n2024\n-1.78\n1996\n-0.0\n-0.84\n1996\n0.7\n2024\n-2.14\n-1.51\n2019\n-2.72\n1996\n29\n\n\n27-Mar\n-1.04\n-0.43\n2019\n-1.86\n1996\n0.07\n-1.16\n1996\n0.75\n2024\n-2.15\n-1.41\n2019\n-2.65\n2001\n29\n\n\n28-Mar\n-1.07\n-0.39\n2019\n-2.0\n1996\n0.03\n-1.18\n1996\n0.66\n2018\n-2.16\n-1.19\n2019\n-2.83\n1996\n28\n\n\n29-Mar\n-1.09\n-0.09\n2019\n-1.79\n1996\n0.01\n-1.06\n1996\n0.79\n2018\n-2.19\n-0.89\n2019\n-2.89\n1998\n28\n\n\n30-Mar\n-1.11\n-0.1\n2019\n-1.55\n1996\n-0.0\n-0.7\n2008\n0.79\n2019\n-2.22\n-0.99\n2019\n-2.82\n2010\n28\n\n\n31-Mar\n-1.12\n-0.35\n2019\n-1.62\n2003\n-0.02\n-0.57\n2000\n0.76\n2018\n-2.22\n-1.29\n2019\n-3.0\n2010\n28\n\n\n01-Apr\n-1.13\n-0.38\n2019\n-1.52\n1999\n-0.02\n-0.49\n2001\n0.7\n2018\n-2.23\n-1.31\n2019\n-2.75\n2010\n28\n\n\n02-Apr\n-1.11\n-0.38\n2019\n-1.63\n2001\n-0.02\n-0.7\n2001\n0.64\n2018\n-2.21\n-1.4\n2019\n-2.76\n1998\n28\n\n\n03-Apr\n-1.1\n-0.49\n2019\n-1.72\n1999\n-0.01\n-0.61\n1998\n0.56\n2018\n-2.19\n-1.52\n2019\n-2.83\n1999\n28\n\n\n04-Apr\n-1.04\n-0.38\n2019\n-1.6\n1999\n0.08\n-0.54\n1999\n0.74\n2019\n-2.16\n-1.51\n2019\n-2.66\n1999\n29\n\n\n05-Apr\n-1.0\n-0.29\n2019\n-1.52\n2011\n0.12\n-0.46\n1999\n0.9\n2019\n-2.13\n-1.47\n2019\n-2.68\n2000\n29\n\n\n06-Apr\n-0.99\n-0.49\n2020\n-1.58\n2011\n0.16\n-0.49\n2011\n0.93\n2020\n-2.15\n-1.64\n2018\n-2.67\n2011\n29\n\n\n07-Apr\n-1.01\n-0.49\n2020\n-1.5\n2001\n0.15\n-0.42\n1999\n1.04\n2020\n-2.18\n-1.66\n2022\n-2.84\n2001\n29\n\n\n08-Apr\n-1.02\n-0.45\n2023\n-1.58\n2001\n0.15\n-0.51\n2003\n0.94\n2020\n-2.19\n-1.6\n2002\n-2.92\n2001\n29\n\n\n09-Apr\n-1.03\n-0.44\n2023\n-1.42\n2001\n0.13\n-0.47\n2014\n0.94\n2024\n-2.19\n-1.69\n2002\n-2.85\n2001\n29\n\n\n10-Apr\n-1.02\n-0.17\n2023\n-1.4\n1998\n0.1\n-0.41\n2010\n1.02\n2023\n-2.14\n-1.37\n2023\n-2.66\n2009\n29\n\n\n11-Apr\n-0.99\n-0.01\n2023\n-1.68\n2009\n0.09\n-0.45\n2009\n1.06\n2023\n-2.08\n-1.08\n2023\n-2.91\n2009\n29\n\n\n12-Apr\n-1.0\n-0.01\n2023\n-1.53\n2009\n0.1\n-0.41\n2007\n1.07\n2023\n-2.11\n-1.09\n2023\n-2.65\n2009\n28\n\n\n13-Apr\n-1.05\n-0.18\n2023\n-1.49\n2009\n0.06\n-0.43\n2007\n0.95\n2023\n-2.16\n-1.31\n2023\n-2.66\n2004\n29\n\n\n14-Apr\n-1.04\n-0.33\n2023\n-1.69\n2004\n0.03\n-0.72\n2004\n0.7\n2023\n-2.12\n-1.37\n2023\n-2.66\n2004\n29\n\n\n15-Apr\n-1.0\n-0.45\n2023\n-1.52\n2004\n0.1\n-0.43\n2001\n0.85\n2022\n-2.1\n-1.45\n2016\n-2.65\n2004\n29\n\n\n16-Apr\n-1.03\n-0.53\n2023\n-1.46\n1998\n0.11\n-0.69\n2009\n1.0\n2003\n-2.16\n-1.51\n2016\n-2.76\n1996\n29\n\n\n17-Apr\n-0.99\n-0.47\n2016\n-1.47\n1998\n0.16\n-0.56\n2009\n1.0\n2003\n-2.15\n-1.36\n2005\n-2.73\n1996\n29\n\n\n18-Apr\n-0.96\n-0.36\n2016\n-1.54\n1998\n0.18\n-0.59\n1998\n0.9\n2023\n-2.1\n-1.38\n2016\n-2.81\n2011\n29\n\n\n19-Apr\n-0.97\n-0.35\n2016\n-1.53\n1998\n0.19\n-0.57\n1998\n1.02\n2023\n-2.12\n-1.43\n2016\n-2.8\n2011\n29\n\n\n20-Apr\n-0.99\n-0.43\n2016\n-1.58\n1998\n0.14\n-0.65\n1998\n0.99\n2023\n-2.12\n-1.41\n2017\n-2.91\n2011\n29\n\n\n21-Apr\n-0.98\n-0.41\n2016\n-1.46\n1998\n0.13\n-0.47\n1998\n0.93\n2023\n-2.1\n-1.46\n2017\n-2.69\n2011\n29\n\n\n22-Apr\n-0.98\n-0.34\n2014\n-1.76\n2004\n0.13\n-0.72\n2004\n0.77\n2023\n-2.08\n-1.4\n2014\n-2.81\n2004\n29\n\n\n23-Apr\n-0.98\n-0.34\n2014\n-1.81\n2004\n0.12\n-0.81\n2004\n0.79\n2014\n-2.08\n-1.47\n2014\n-2.81\n2004\n29\n\n\n24-Apr\n-0.96\n-0.31\n2017\n-1.72\n2004\n0.15\n-0.85\n2004\n1.01\n2017\n-2.06\n-1.56\n2022\n-2.84\n2001\n28\n\n\n25-Apr\n-0.93\n-0.35\n2021\n-1.6\n2004\n0.19\n-0.79\n2004\n1.1\n2021\n-2.06\n-1.48\n2023\n-2.84\n1998\n28\n\n\n26-Apr\n-0.95\n-0.35\n2021\n-1.54\n2004\n0.19\n-0.78\n2004\n1.2\n2021\n-2.09\n-1.62\n2023\n-2.81\n1998\n28\n\n\n27-Apr\n-0.96\n-0.44\n2021\n-1.5\n2004\n0.15\n-0.74\n2004\n1.12\n2021\n-2.07\n-1.3\n2023\n-2.89\n1998\n28\n\n\n28-Apr\n-0.98\n-0.41\n2014\n-1.61\n2009\n0.15\n-0.57\n2004\n1.05\n2014\n-2.11\n-1.17\n2023\n-2.88\n2009\n27\n\n\n29-Apr\n-0.96\n-0.32\n2023\n-1.51\n2009\n0.14\n-0.41\n2004\n1.07\n2014\n-2.05\n-1.12\n2023\n-2.68\n2009\n28\n\n\n30-Apr\n-0.94\n-0.38\n2023\n-1.44\n2009\n0.18\n-0.39\n2011\n0.8\n2014\n-2.05\n-1.33\n2023\n-2.58\n2009\n28\n\n\n01-May\n-0.94\n-0.53\n2023\n-1.42\n2009\n0.16\n-0.38\n2009\n0.57\n2014\n-2.04\n-1.46\n2023\n-2.62\n1998\n28\n\n\n02-May\n-0.9\n-0.53\n2014\n-1.35\n1996\n0.22\n-0.28\n1998\n0.63\n2008\n-2.01\n-1.55\n2023\n-2.68\n1996\n27\n\n\n03-May\n-0.91\n-0.43\n2013\n-1.42\n2010\n0.23\n-0.43\n1998\n0.82\n2016\n-2.06\n-1.52\n2013\n-2.69\n1996\n28\n\n\n04-May\n-0.94\n-0.35\n2016\n-1.51\n2010\n0.23\n-0.67\n2010\n1.22\n2016\n-2.11\n-1.52\n2006\n-2.73\n1996\n28\n\n\n05-May\n-0.98\n-0.3\n2016\n-1.44\n2011\n0.21\n-0.55\n2010\n1.33\n2016\n-2.16\n-1.53\n2014\n-2.81\n2000\n29\n\n\n06-May\n-1.01\n-0.41\n2016\n-1.44\n1996\n0.18\n-0.61\n2002\n1.15\n2016\n-2.2\n-1.49\n2014\n-2.79\n2000\n29\n\n\n07-May\n-0.99\n-0.48\n2016\n-1.5\n2002\n0.2\n-0.68\n2002\n1.1\n2016\n-2.18\n-1.4\n2014\n-2.74\n2004\n28\n\n\n08-May\n-0.97\n-0.5\n2007\n-1.47\n2002\n0.19\n-0.57\n2002\n0.93\n2016\n-2.13\n-1.34\n2022\n-2.64\n2004\n27\n\n\n09-May\n-1.0\n-0.4\n2007\n-1.5\n2009\n0.14\n-0.51\n2003\n0.72\n2020\n-2.13\n-1.15\n2022\n-2.69\n2009\n28\n\n\n10-May\n-1.0\n-0.24\n2022\n-1.53\n2009\n0.09\n-0.52\n2003\n0.58\n2020\n-2.08\n-1.02\n2022\n-2.73\n2009\n27\n\n\n11-May\n-0.98\n-0.05\n2022\n-1.47\n2009\n0.1\n-0.42\n2003\n0.85\n2022\n-2.06\n-0.96\n2022\n-2.59\n2009\n29\n\n\n12-May\n-0.94\n0.43\n2022\n-1.37\n2002\n0.15\n-0.3\n2004\n1.52\n2022\n-2.04\n-0.66\n2022\n-2.54\n2002\n29\n\n\n13-May\n-0.94\n0.21\n2022\n-1.44\n2002\n0.17\n-0.4\n2004\n1.45\n2022\n-2.05\n-1.02\n2022\n-2.65\n2002\n28\n\n\n14-May\n-0.95\n0.01\n2022\n-1.47\n2004\n0.17\n-0.5\n2004\n1.4\n2022\n-2.07\n-1.3\n2020\n-2.64\n2010\n28\n\n\n15-May\n-0.97\n-0.1\n2022\n-1.48\n2002\n0.18\n-0.44\n2009\n1.44\n2022\n-2.13\n-1.41\n2020\n-2.74\n1999\n29\n\n\n16-May\n-0.94\n-0.21\n2022\n-1.55\n1996\n0.21\n-0.39\n2004\n1.39\n2022\n-2.1\n-1.41\n2024\n-2.82\n2003\n29\n\n\n17-May\n-0.96\n-0.46\n2024\n-1.5\n1996\n0.19\n-0.37\n2002\n1.03\n2022\n-2.11\n-1.3\n2024\n-2.85\n2003\n29\n\n\n18-May\n-0.96\n-0.34\n2024\n-1.58\n1996\n0.17\n-0.4\n1996\n0.85\n2022\n-2.1\n-1.26\n2024\n-2.76\n1996\n29\n\n\n19-May\n-0.96\n-0.44\n2024\n-1.46\n1996\n0.17\n-0.39\n1997\n0.86\n2022\n-2.09\n-1.4\n2021\n-2.63\n1996\n29\n\n\n20-May\n-0.96\n-0.4\n2024\n-1.6\n1997\n0.16\n-0.49\n1997\n0.87\n2022\n-2.09\n-1.46\n2021\n-2.7\n1997\n29\n\n\n21-May\n-0.95\n-0.26\n2024\n-1.51\n1997\n0.17\n-0.38\n2008\n0.88\n2024\n-2.06\n-1.39\n2024\n-2.72\n1997\n28\n\n\n22-May\n-0.9\n-0.18\n2007\n-1.33\n1997\n0.23\n-0.32\n2008\n0.86\n2024\n-2.03\n-1.15\n2007\n-2.65\n1997\n28\n\n\n23-May\n-0.91\n-0.21\n2007\n-1.34\n1997\n0.23\n-0.39\n2000\n0.96\n2024\n-2.05\n-1.12\n2007\n-2.66\n1997\n29\n\n\n24-May\n-0.91\n-0.3\n2024\n-1.34\n1997\n0.24\n-0.39\n2000\n0.97\n2024\n-2.06\n-1.21\n2007\n-2.66\n1997\n29\n\n\n25-May\n-0.93\n-0.23\n2023\n-1.38\n1996\n0.21\n-0.59\n1996\n0.94\n2024\n-2.07\n-1.15\n2023\n-2.6\n1997\n29\n\n\n26-May\n-0.93\n-0.18\n2023\n-1.36\n1997\n0.21\n-0.54\n2004\n0.96\n2002\n-2.07\n-1.02\n2023\n-2.6\n2021\n29\n\n\n27-May\n-0.93\n-0.12\n2023\n-1.4\n2004\n0.18\n-0.62\n2004\n0.89\n2002\n-2.04\n-0.85\n2023\n-2.55\n1998\n29\n\n\n28-May\n-0.96\n-0.22\n2023\n-1.59\n2003\n0.14\n-0.63\n2003\n0.84\n2002\n-2.06\n-1.03\n2023\n-2.55\n1998\n29\n\n\n29-May\n-0.93\n0.01\n2023\n-1.5\n2003\n0.16\n-0.48\n2011\n0.84\n2023\n-2.03\n-0.82\n2023\n-2.53\n2003\n28\n\n\n30-May\n-0.93\n-0.01\n2023\n-1.51\n2011\n0.17\n-0.46\n2011\n0.99\n2023\n-2.04\n-1.01\n2023\n-2.55\n2011\n28\n\n\n31-May\n-0.97\n-0.23\n2023\n-1.61\n2011\n0.17\n-0.54\n2011\n0.83\n2023\n-2.11\n-1.3\n2023\n-2.68\n2011\n29\n\n\n01-Jun\n-0.95\n-0.33\n2023\n-1.61\n2011\n0.2\n-0.53\n2011\n0.82\n2023\n-2.1\n-1.47\n2023\n-2.69\n2011\n29\n\n\n02-Jun\n-0.96\n-0.29\n2023\n-1.6\n2011\n0.21\n-0.42\n2011\n1.06\n2023\n-2.13\n-1.59\n2014\n-2.8\n2008\n28\n\n\n03-Jun\n-0.96\n-0.11\n2023\n-1.48\n2003\n0.22\n-0.45\n2003\n1.29\n2023\n-2.14\n-1.45\n2022\n-2.9\n2008\n28\n\n\n04-Jun\n-0.96\n-0.04\n2023\n-1.5\n2003\n0.22\n-0.49\n1999\n1.38\n2023\n-2.14\n-1.39\n2022\n-2.92\n2008\n28\n\n\n05-Jun\n-0.93\n-0.13\n2023\n-1.57\n2008\n0.21\n-0.57\n2003\n1.28\n2023\n-2.08\n-1.34\n2022\n-2.95\n2008\n28\n\n\n06-Jun\n-0.95\n-0.15\n2023\n-1.49\n2008\n0.2\n-0.52\n2003\n1.27\n2023\n-2.09\n-1.43\n2022\n-2.85\n2008\n28\n\n\n07-Jun\n-0.96\n-0.09\n2023\n-1.43\n1998\n0.15\n-0.5\n2006\n1.25\n2023\n-2.07\n-1.43\n2023\n-2.61\n2008\n28\n\n\n08-Jun\n-0.96\n-0.12\n2023\n-1.52\n1998\n0.14\n-0.52\n2003\n1.2\n2023\n-2.07\n-1.45\n2023\n-2.62\n1998\n28\n\n\n09-Jun\n-0.93\n-0.25\n2023\n-1.64\n1998\n0.16\n-0.56\n1998\n0.94\n2023\n-2.02\n-1.44\n2023\n-2.72\n1998\n28\n\n\n10-Jun\n-0.89\n-0.35\n2023\n-1.42\n2006\n0.21\n-0.31\n2013\n0.78\n2023\n-2.0\n-1.45\n1997\n-2.54\n2006\n27\n\n\n11-Jun\n-0.93\n-0.51\n2023\n-1.52\n1996\n0.2\n-0.49\n1996\n0.63\n2007\n-2.07\n-1.48\n1997\n-2.78\n2006\n27\n\n\n12-Jun\n-0.94\n-0.55\n2020\n-1.53\n1996\n0.2\n-0.45\n1996\n0.81\n2007\n-2.08\n-1.44\n2020\n-2.74\n2006\n27\n\n\n13-Jun\n-1.01\n-0.4\n2020\n-1.71\n2006\n0.13\n-0.63\n2001\n0.67\n2007\n-2.14\n-1.26\n2020\n-2.94\n2006\n29\n\n\n14-Jun\n-1.0\n-0.39\n2020\n-1.83\n2006\n0.14\n-0.68\n2001\n0.78\n2007\n-2.14\n-1.27\n2020\n-2.99\n2006\n29\n\n\n15-Jun\n-1.01\n-0.42\n2020\n-1.73\n2006\n0.12\n-0.69\n2001\n0.98\n2007\n-2.14\n-1.32\n2020\n-2.91\n2006\n29\n\n\n16-Jun\n-1.04\n-0.51\n2020\n-1.64\n1996\n0.09\n-0.56\n1996\n0.78\n2007\n-2.17\n-1.45\n2020\n-2.82\n2003\n29\n\n\n17-Jun\n-1.01\n-0.41\n2024\n-1.63\n1996\n0.11\n-0.56\n1996\n0.77\n2022\n-2.14\n-1.36\n2024\n-2.69\n1996\n29\n\n\n18-Jun\n-0.99\n-0.36\n2012\n-1.66\n1996\n0.12\n-0.66\n1996\n0.8\n2022\n-2.11\n-1.45\n2012\n-2.66\n1996\n29\n\n\n19-Jun\n-1.02\n-0.33\n2012\n-1.76\n1996\n0.09\n-0.77\n1996\n0.83\n2012\n-2.14\n-1.48\n2012\n-2.75\n1996\n29\n\n\n20-Jun\n-1.03\n-0.43\n2022\n-1.74\n1996\n0.1\n-0.74\n1996\n0.67\n2022\n-2.16\n-1.52\n2012\n-2.81\n1998\n29\n\n\n21-Jun\n-1.04\n-0.43\n2012\n-1.72\n1996\n0.08\n-0.88\n1996\n0.73\n2012\n-2.15\n-1.53\n2022\n-2.81\n2001\n28\n\n\n22-Jun\n-1.02\n-0.44\n2022\n-1.59\n1996\n0.13\n-0.76\n1996\n0.81\n2009\n-2.16\n-1.47\n2022\n-2.73\n2001\n29\n\n\n23-Jun\n-0.98\n-0.4\n2022\n-1.47\n2004\n0.15\n-0.56\n1996\n0.76\n2024\n-2.11\n-1.44\n2023\n-2.75\n2021\n28\n\n\n24-Jun\n-0.98\n-0.4\n2012\n-1.46\n2004\n0.15\n-0.56\n2004\n0.79\n2024\n-2.1\n-1.42\n2022\n-2.68\n2021\n28\n\n\n25-Jun\n-0.99\n-0.39\n2012\n-1.56\n1996\n0.12\n-0.64\n1996\n0.72\n2024\n-2.09\n-1.32\n2023\n-2.56\n2021\n29\n\n\n26-Jun\n-0.98\n-0.49\n2012\n-1.43\n2004\n0.13\n-0.55\n2004\n0.72\n2024\n-2.08\n-1.46\n2023\n-2.47\n1998\n28\n\n\n27-Jun\n-1.0\n-0.54\n2024\n-1.49\n1996\n0.09\n-0.5\n2004\n0.64\n2024\n-2.09\n-1.52\n2023\n-2.56\n1996\n29\n\n\n28-Jun\n-1.02\n-0.63\n2012\n-1.47\n2004\n0.08\n-0.39\n2004\n0.59\n2017\n-2.12\n-1.63\n2023\n-2.54\n2004\n29\n\n\n29-Jun\n-1.05\n-0.53\n2023\n-1.47\n2008\n0.06\n-0.34\n2008\n0.55\n2023\n-2.16\n-1.61\n2023\n-2.65\n2004\n29\n\n\n30-Jun\n-1.04\n-0.59\n2019\n-1.51\n2003\n0.08\n-0.44\n2003\n0.65\n2019\n-2.16\n-1.67\n2014\n-2.69\n2004\n29\n\n\n01-Jul\n-1.04\n-0.54\n2024\n-1.54\n2003\n0.11\n-0.43\n2003\n0.64\n2024\n-2.2\n-1.58\n2014\n-2.85\n2004\n29\n\n\n02-Jul\n-1.05\n-0.43\n2014\n-1.58\n1998\n0.1\n-0.72\n1998\n0.81\n2019\n-2.21\n-1.35\n2014\n-2.85\n2004\n29\n\n\n03-Jul\n-1.04\n-0.43\n2014\n-1.61\n1998\n0.12\n-0.73\n1998\n0.87\n2019\n-2.19\n-1.38\n2014\n-2.74\n2004\n29\n\n\n04-Jul\n-1.01\n-0.5\n2019\n-1.58\n2005\n0.14\n-0.52\n2005\n0.89\n2019\n-2.16\n-1.48\n2018\n-2.67\n2004\n29\n\n\n05-Jul\n-0.97\n-0.53\n2024\n-1.46\n2005\n0.14\n-0.46\n2002\n0.69\n2024\n-2.07\n-1.6\n2018\n-2.56\n2005\n28\n\n\n06-Jul\n-0.98\n-0.56\n2024\n-1.32\n1998\n0.12\n-0.34\n2006\n0.6\n2024\n-2.07\n-1.69\n2021\n-2.5\n1996\n28\n\n\n07-Jul\n-0.98\n-0.48\n2024\n-1.53\n1996\n0.1\n-0.44\n2006\n0.66\n2020\n-2.07\n-1.61\n2024\n-2.63\n1996\n28\n\n\n08-Jul\n-1.02\n-0.54\n2019\n-1.72\n1998\n0.08\n-0.57\n1998\n0.68\n2019\n-2.11\n-1.62\n2020\n-2.88\n1998\n29\n\n\n09-Jul\n-1.02\n-0.46\n2020\n-1.55\n1998\n0.08\n-0.52\n1996\n0.61\n2019\n-2.12\n-1.44\n2020\n-2.76\n1998\n29\n\n\n10-Jul\n-1.04\n-0.54\n2024\n-1.49\n1998\n0.07\n-0.42\n2004\n0.61\n2023\n-2.14\n-1.49\n2024\n-2.76\n1998\n29\n\n\n11-Jul\n-1.03\n-0.51\n2024\n-1.41\n2011\n0.08\n-0.28\n2004\n0.73\n2018\n-2.14\n-1.45\n2024\n-2.64\n2011\n29\n\n\n12-Jul\n-1.0\n-0.35\n2013\n-1.4\n1996\n0.12\n-0.38\n1997\n0.65\n2013\n-2.12\n-1.36\n2013\n-2.63\n1999\n29\n\n\n13-Jul\n-0.99\n-0.42\n2013\n-1.53\n1996\n0.13\n-0.5\n1996\n0.7\n2013\n-2.1\n-1.54\n2013\n-2.56\n1996\n28\n\n\n14-Jul\n-0.97\n-0.53\n2017\n-1.36\n1996\n0.14\n-0.32\n1997\n0.65\n2018\n-2.09\n-1.59\n2024\n-2.5\n2011\n28\n\n\n15-Jul\n-1.0\n-0.64\n2017\n-1.44\n2003\n0.11\n-0.28\n2009\n0.77\n2010\n-2.12\n-1.64\n2024\n-2.66\n2003\n29\n\n\n16-Jul\n-1.02\n-0.49\n2017\n-1.44\n2003\n0.08\n-0.32\n2001\n0.54\n2017\n-2.12\n-1.51\n2017\n-2.6\n2003\n29\n\n\n17-Jul\n-1.03\n-0.58\n2017\n-1.46\n1996\n0.07\n-0.43\n1996\n0.5\n2017\n-2.14\n-1.66\n2017\n-2.48\n1996\n29\n\n\n18-Jul\n-1.07\n-0.7\n2022\n-1.43\n2009\n0.05\n-0.29\n2009\n0.5\n2022\n-2.18\n-1.86\n2021\n-2.59\n2001\n29\n\n\n19-Jul\n-1.06\n-0.72\n2011\n-1.4\n2009\n0.07\n-0.35\n1996\n0.38\n2020\n-2.18\n-1.83\n2011\n-2.63\n2009\n29\n\n\n20-Jul\n-1.03\n-0.63\n2011\n-1.45\n2003\n0.1\n-0.56\n2003\n0.42\n2020\n-2.16\n-1.65\n2011\n-2.62\n2009\n29\n\n\n21-Jul\n-1.01\n-0.6\n2019\n-1.39\n2003\n0.12\n-0.55\n2003\n0.56\n2024\n-2.14\n-1.58\n2019\n-2.64\n2017\n29\n\n\n22-Jul\n-0.97\n-0.5\n2019\n-1.42\n2003\n0.16\n-0.58\n2003\n0.69\n2012\n-2.1\n-1.4\n2019\n-2.48\n2009\n29\n\n\n23-Jul\n-0.95\n-0.48\n2024\n-1.41\n2003\n0.16\n-0.55\n2003\n0.91\n2024\n-2.07\n-1.49\n2019\n-2.58\n2001\n29\n\n\n24-Jul\n-0.97\n-0.57\n2024\n-1.59\n1996\n0.13\n-0.64\n2003\n0.78\n2021\n-2.08\n-1.53\n2019\n-2.57\n1996\n29\n\n\n25-Jul\n-1.01\n-0.57\n2019\n-1.55\n1996\n0.1\n-0.63\n2003\n0.78\n2021\n-2.11\n-1.54\n2019\n-2.58\n1996\n29\n\n\n26-Jul\n-1.02\n-0.62\n2021\n-1.56\n2003\n0.09\n-0.63\n2003\n0.64\n2017\n-2.13\n-1.56\n2019\n-2.58\n2004\n29\n\n\n27-Jul\n-1.03\n-0.56\n2008\n-1.6\n2003\n0.08\n-0.52\n2003\n0.62\n2017\n-2.13\n-1.67\n2019\n-2.69\n2003\n29\n\n\n28-Jul\n-1.02\n-0.54\n2017\n-1.55\n2001\n0.09\n-0.57\n2001\n0.67\n2000\n-2.12\n-1.66\n2017\n-2.7\n1996\n29\n\n\n29-Jul\n-0.99\n-0.33\n2019\n-1.53\n2001\n0.13\n-0.55\n2001\n0.91\n2019\n-2.11\n-1.52\n2017\n-2.7\n2004\n29\n\n\n30-Jul\n-0.96\n-0.24\n2019\n-1.47\n2005\n0.18\n-0.53\n2005\n1.1\n2019\n-2.1\n-1.53\n2017\n-2.64\n1996\n29\n\n\n31-Jul\n-0.94\n-0.19\n2019\n-1.58\n2009\n0.2\n-0.67\n2009\n1.21\n2019\n-2.08\n-1.52\n2021\n-2.53\n1996\n29\n\n\n01-Aug\n-0.92\n-0.15\n2019\n-1.51\n2009\n0.22\n-0.6\n1998\n1.39\n2019\n-2.05\n-1.54\n2002\n-2.53\n2004\n29\n\n\n02-Aug\n-0.89\n-0.1\n2019\n-1.45\n1998\n0.25\n-0.61\n1998\n1.43\n2019\n-2.02\n-1.46\n2002\n-2.48\n2004\n29\n\n\n03-Aug\n-0.85\n-0.11\n2019\n-1.33\n1998\n0.28\n-0.38\n2006\n1.41\n2019\n-1.98\n-1.53\n2022\n-2.4\n1996\n28\n\n\n04-Aug\n-0.88\n-0.17\n2019\n-1.41\n1998\n0.23\n-0.43\n1998\n1.19\n2019\n-1.99\n-1.53\n2019\n-2.51\n1996\n29\n\n\n05-Aug\n-0.93\n-0.18\n2019\n-1.36\n1998\n0.17\n-0.32\n2001\n1.16\n2019\n-2.03\n-1.52\n2019\n-2.44\n1998\n29\n\n\n06-Aug\n-0.95\n-0.22\n2019\n-1.39\n2001\n0.15\n-0.39\n2001\n1.08\n2019\n-2.04\n-1.52\n2019\n-2.51\n1998\n29\n\n\n07-Aug\n-0.97\n-0.45\n2019\n-1.36\n2001\n0.12\n-0.43\n1996\n0.76\n2019\n-2.05\n-1.6\n2020\n-2.49\n2003\n29\n\n\n08-Aug\n-0.96\n-0.52\n2019\n-1.52\n1996\n0.14\n-0.59\n1996\n0.76\n2002\n-2.05\n-1.59\n2020\n-2.55\n2003\n29\n\n\n09-Aug\n-0.94\n-0.48\n2019\n-1.49\n1996\n0.16\n-0.57\n2004\n0.86\n2002\n-2.05\n-1.58\n2019\n-2.55\n2006\n29\n\n\n10-Aug\n-0.96\n-0.39\n2002\n-1.39\n1996\n0.14\n-0.41\n1996\n1.03\n2002\n-2.06\n-1.49\n2019\n-2.45\n2006\n29\n\n\n11-Aug\n-0.97\n-0.39\n2002\n-1.52\n1996\n0.12\n-0.51\n2016\n0.97\n2002\n-2.06\n-1.45\n2019\n-2.62\n2003\n28\n\n\n12-Aug\n-0.98\n-0.42\n2019\n-1.56\n1996\n0.13\n-0.53\n1996\n0.8\n2002\n-2.08\n-1.56\n2019\n-2.65\n2003\n28\n\n\n13-Aug\n-0.98\n-0.32\n2019\n-1.52\n1996\n0.13\n-0.5\n2016\n0.9\n2019\n-2.09\n-1.54\n2019\n-2.58\n1996\n29\n\n\n14-Aug\n-0.99\n-0.41\n2019\n-1.6\n1996\n0.11\n-0.58\n1996\n0.75\n2019\n-2.09\n-1.52\n2020\n-2.62\n1996\n29\n\n\n15-Aug\n-0.97\n-0.43\n2019\n-1.61\n1996\n0.13\n-0.62\n1996\n0.71\n2019\n-2.07\n-1.58\n2019\n-2.6\n1996\n29\n\n\n16-Aug\n-0.98\n-0.53\n2022\n-1.58\n1996\n0.14\n-0.52\n1996\n0.69\n2022\n-2.09\n-1.7\n2023\n-2.63\n1996\n29\n\n\n17-Aug\n-0.97\n-0.48\n2022\n-1.41\n1996\n0.15\n-0.36\n1999\n0.74\n2020\n-2.08\n-1.61\n2022\n-2.52\n2001\n29\n\n\n18-Aug\n-0.9\n-0.17\n2020\n-1.36\n2018\n0.26\n-0.41\n2018\n1.26\n2008\n-2.05\n-1.49\n2022\n-2.48\n2001\n29\n\n\n19-Aug\n-0.87\n-0.23\n2020\n-1.35\n2010\n0.27\n-0.39\n2010\n1.2\n2020\n-2.02\n-1.43\n2019\n-2.5\n2017\n29\n\n\n20-Aug\n-0.85\n-0.22\n2020\n-1.21\n2010\n0.27\n-0.32\n2018\n1.18\n2020\n-1.98\n-1.48\n2019\n-2.47\n2001\n29\n\n\n21-Aug\n-0.86\n-0.24\n2020\n-1.29\n2004\n0.25\n-0.41\n1999\n1.14\n2020\n-1.97\n-1.43\n2022\n-2.42\n2017\n28\n\n\n22-Aug\n-0.85\n-0.17\n2020\n-1.39\n2004\n0.25\n-0.36\n2003\n1.21\n2020\n-1.95\n-1.35\n2023\n-2.46\n2004\n28\n\n\n23-Aug\n-0.83\n-0.2\n2020\n-1.48\n2004\n0.27\n-0.48\n2004\n1.09\n2020\n-1.93\n-1.44\n2014\n-2.48\n2004\n29\n\n\n24-Aug\n-0.8\n-0.21\n2020\n-1.49\n2004\n0.3\n-0.4\n2004\n1.01\n2020\n-1.9\n-1.28\n2023\n-2.58\n2004\n29\n\n\n25-Aug\n-0.77\n-0.03\n2014\n-1.53\n2004\n0.32\n-0.47\n2004\n1.1\n2014\n-1.87\n-1.16\n2014\n-2.59\n2004\n29\n\n\n26-Aug\n-0.72\n0.01\n2014\n-1.39\n2004\n0.4\n-0.34\n2001\n1.16\n2012\n-1.85\n-1.09\n2014\n-2.55\n2004\n29\n\n\n27-Aug\n-0.73\n-0.09\n2014\n-1.42\n2004\n0.4\n-0.48\n2001\n1.16\n2011\n-1.85\n-1.24\n2014\n-2.65\n2004\n29\n\n\n28-Aug\n-0.74\n-0.11\n2014\n-1.31\n2001\n0.38\n-0.3\n2001\n1.19\n2011\n-1.86\n-1.14\n2014\n-2.61\n1996\n29\n\n\n29-Aug\n-0.69\n-0.16\n2014\n-1.23\n2005\n0.45\n-0.37\n2005\n1.28\n2019\n-1.83\n-1.23\n2014\n-2.68\n1996\n29\n\n\n30-Aug\n-0.68\n-0.09\n2019\n-1.26\n2004\n0.46\n-0.12\n2009\n1.46\n2019\n-1.83\n-1.39\n2014\n-2.57\n2004\n29\n\n\n31-Aug\n-0.72\n-0.09\n2008\n-1.14\n2004\n0.41\n-0.23\n2006\n1.4\n2019\n-1.86\n-1.4\n2008\n-2.49\n1996\n29\n\n\n01-Sep\n-0.72\n-0.14\n2019\n-1.22\n2003\n0.4\n-0.26\n2006\n1.34\n2019\n-1.85\n-1.3\n2002\n-2.48\n2003\n29\n\n\n02-Sep\n-0.72\n0.04\n2019\n-1.28\n1996\n0.4\n-0.33\n2006\n1.59\n2019\n-1.83\n-1.27\n2002\n-2.43\n1996\n29\n\n\n03-Sep\n-0.68\n0.39\n2019\n-1.27\n2003\n0.43\n-0.2\n2003\n1.83\n2019\n-1.79\n-1.04\n2019\n-2.35\n1996\n29\n\n\n04-Sep\n-0.62\n0.38\n2019\n-1.18\n2003\n0.49\n-0.11\n2003\n1.75\n2019\n-1.73\n-1.0\n2019\n-2.25\n2003\n29\n\n\n05-Sep\n-0.58\n0.12\n2019\n-1.16\n2003\n0.52\n-0.13\n2003\n1.29\n2019\n-1.68\n-0.91\n2008\n-2.47\n1998\n29\n\n\n06-Sep\n-0.62\n-0.03\n2019\n-1.25\n2003\n0.49\n-0.15\n2001\n1.12\n2019\n-1.73\n-1.14\n2008\n-2.47\n1998\n29\n\n\n07-Sep\n-0.62\n-0.18\n2019\n-1.17\n2004\n0.49\n-0.42\n2004\n1.25\n2002\n-1.73\n-1.21\n2019\n-2.32\n1998\n29\n\n\n08-Sep\n-0.6\n-0.1\n2024\n-1.35\n2004\n0.51\n-0.65\n2004\n1.11\n2002\n-1.72\n-0.94\n2008\n-2.38\n2003\n29\n\n\n09-Sep\n-0.57\n0.39\n2017\n-1.27\n2004\n0.56\n-0.5\n2004\n2.1\n2017\n-1.7\n-0.62\n2008\n-2.34\n1998\n29\n\n\n10-Sep\n-0.54\n1.9\n2017\n-1.4\n2004\n0.61\n-0.59\n2004\n3.63\n2017\n-1.69\n0.16\n2017\n-2.39\n1998\n28\n\n\n11-Sep\n-0.63\n-0.11\n2024\n-1.28\n2001\n0.48\n-0.3\n2001\n1.26\n2018\n-1.75\n-0.94\n2024\n-2.31\n1998\n29\n\n\n12-Sep\n-0.61\n-0.03\n2024\n-1.13\n2001\n0.5\n-0.1\n2004\n1.24\n2018\n-1.72\n-0.86\n2024\n-2.22\n2014\n29\n\n\n13-Sep\n-0.57\n-0.02\n2019\n-1.04\n2015\n0.54\n0.03\n2015\n1.27\n2022\n-1.69\n-1.0\n2024\n-2.11\n2015\n29\n\n\n14-Sep\n-0.51\n0.16\n1999\n-0.98\n2002\n0.62\n-0.04\n2002\n1.3\n1999\n-1.64\n-0.97\n1999\n-2.2\n2001\n29\n\n\n15-Sep\n-0.52\n0.34\n1999\n-1.1\n2002\n0.61\n-0.17\n2002\n1.33\n1999\n-1.64\n-0.65\n1999\n-2.29\n2001\n29\n\n\n16-Sep\n-0.5\n0.24\n1999\n-1.05\n1996\n0.62\n-0.1\n2002\n1.4\n2020\n-1.62\n-0.64\n1999\n-2.19\n1997\n29\n\n\n17-Sep\n-0.49\n0.22\n2024\n-1.25\n1996\n0.66\n-0.2\n1996\n1.7\n2024\n-1.63\n-0.77\n1999\n-2.3\n1996\n29\n\n\n18-Sep\n-0.49\n0.33\n2024\n-1.39\n1996\n0.67\n-0.36\n1996\n1.87\n2024\n-1.64\n-0.96\n2022\n-2.42\n1996\n29\n\n\n19-Sep\n-0.48\n0.31\n2024\n-1.38\n1996\n0.67\n-0.36\n1996\n1.96\n2024\n-1.63\n-0.9\n2022\n-2.48\n1997\n29\n\n\n20-Sep\n-0.45\n0.34\n2024\n-1.39\n1996\n0.68\n-0.38\n1996\n1.93\n2005\n-1.59\n-0.84\n2022\n-2.42\n2012\n29\n\n\n21-Sep\n-0.46\n0.34\n2020\n-1.3\n1996\n0.65\n-0.23\n1996\n1.91\n2020\n-1.56\n-0.86\n2019\n-2.36\n1996\n29\n\n\n22-Sep\n-0.47\n0.7\n2020\n-1.31\n1996\n0.62\n-0.24\n1996\n1.95\n2020\n-1.55\n-0.56\n2020\n-2.39\n1996\n29\n\n\n23-Sep\n-0.46\n0.59\n2020\n-1.15\n1996\n0.62\n0.06\n1998\n1.78\n2020\n-1.54\n-0.61\n2020\n-2.36\n1996\n29\n\n\n24-Sep\n-0.43\n0.48\n2020\n-1.0\n2006\n0.67\n-0.01\n1997\n1.57\n2020\n-1.53\n-0.61\n2020\n-2.26\n1996\n29\n\n\n25-Sep\n-0.37\n0.37\n2008\n-1.01\n1996\n0.75\n0.0\n2006\n1.52\n2008\n-1.5\n-0.58\n2024\n-2.36\n1996\n28\n\n\n26-Sep\n-0.39\n0.48\n2024\n-1.03\n2006\n0.74\n-0.16\n2001\n1.74\n2015\n-1.52\n-0.41\n2024\n-2.29\n1996\n29\n\n\n27-Sep\n-0.41\n0.31\n2022\n-1.08\n1998\n0.74\n-0.23\n1998\n1.83\n2015\n-1.55\n-0.95\n2008\n-2.35\n1996\n29\n\n\n28-Sep\n-0.44\n0.28\n2022\n-1.22\n1997\n0.7\n-0.37\n1998\n1.72\n2015\n-1.58\n-0.79\n2017\n-2.37\n1996\n29\n\n\n29-Sep\n-0.47\n0.25\n2020\n-1.34\n1997\n0.68\n-0.32\n1997\n1.82\n2019\n-1.62\n-0.89\n2020\n-2.37\n1997\n29\n\n\n30-Sep\n-0.44\n0.28\n2019\n-1.24\n1997\n0.71\n-0.26\n1997\n1.86\n2019\n-1.59\n-0.91\n2021\n-2.35\n2004\n29\n\n\n01-Oct\n-0.41\n0.41\n2019\n-1.18\n1996\n0.73\n-0.21\n1998\n1.96\n2019\n-1.56\n-0.92\n2022\n-2.31\n1996\n29\n\n\n02-Oct\n-0.39\n0.46\n2022\n-1.14\n2004\n0.72\n-0.04\n2004\n1.72\n2023\n-1.5\n-0.68\n2022\n-2.24\n2004\n28\n\n\n03-Oct\n-0.36\n0.47\n2023\n-1.29\n2012\n0.75\n-0.25\n2012\n1.74\n2023\n-1.47\n-0.74\n2017\n-2.34\n1998\n28\n\n\n04-Oct\n-0.34\n0.54\n2023\n-1.36\n2012\n0.76\n-0.38\n2012\n1.83\n2017\n-1.44\n-0.62\n2023\n-2.47\n1998\n27\n\n\n05-Oct\n-0.31\n0.72\n2017\n-1.24\n2012\n0.79\n-0.31\n2012\n2.08\n2017\n-1.41\n-0.61\n2023\n-2.46\n1998\n28\n\n\n06-Oct\n-0.31\n0.38\n2017\n-1.15\n2012\n0.8\n-0.28\n2012\n1.76\n2017\n-1.42\n-0.58\n2023\n-2.57\n1998\n28\n\n\n07-Oct\n-0.26\n0.27\n2023\n-0.99\n2012\n0.86\n-0.24\n2012\n1.63\n2017\n-1.39\n-0.54\n2023\n-2.44\n1998\n28\n\n\n08-Oct\n-0.32\n0.51\n2015\n-1.03\n1998\n0.83\n-0.05\n2012\n1.51\n2022\n-1.47\n-0.47\n2015\n-2.51\n1998\n27\n\n\n09-Oct\n-0.36\n0.4\n2015\n-0.97\n1998\n0.77\n-0.19\n2012\n1.58\n2022\n-1.49\n-0.59\n2023\n-2.33\n1998\n27\n\n\n10-Oct\n-0.36\n0.34\n2023\n-1.2\n1998\n0.76\n-0.03\n1996\n1.62\n2022\n-1.48\n-0.53\n2023\n-2.42\n1998\n27\n\n\n11-Oct\n-0.35\n0.46\n2019\n-1.02\n1998\n0.77\n0.1\n2009\n1.51\n2019\n-1.47\n-0.6\n2019\n-2.14\n1998\n27\n\n\n12-Oct\n-0.33\n0.62\n2019\n-1.16\n1998\n0.8\n-0.1\n1998\n1.76\n2019\n-1.45\n-0.52\n2019\n-2.2\n1998\n27\n\n\n13-Oct\n-0.28\n0.67\n2019\n-1.02\n1998\n0.84\n-0.04\n1998\n1.83\n2019\n-1.4\n-0.5\n2019\n-2.0\n1998\n28\n\n\n14-Oct\n-0.3\n0.52\n2019\n-0.91\n2018\n0.83\n0.03\n1998\n1.82\n2016\n-1.44\n-0.64\n2019\n-2.0\n2001\n28\n\n\n15-Oct\n-0.22\n0.79\n1999\n-0.92\n2018\n0.96\n0.02\n1998\n2.37\n1999\n-1.4\n-0.78\n1999\n-2.07\n2001\n28\n\n\n16-Oct\n-0.27\n0.27\n2016\n-0.98\n1998\n0.9\n-0.01\n1998\n1.8\n2016\n-1.43\n-0.74\n2022\n-2.12\n2004\n28\n\n\n17-Oct\n-0.31\n0.16\n2022\n-0.83\n1998\n0.83\n0.03\n2003\n1.78\n2016\n-1.46\n-0.59\n2022\n-2.19\n2004\n27\n\n\n18-Oct\n-0.33\n0.22\n2019\n-0.8\n2004\n0.81\n0.08\n2018\n1.69\n2020\n-1.47\n-0.56\n2022\n-2.05\n2004\n27\n\n\n19-Oct\n-0.33\n0.38\n2020\n-0.89\n2004\n0.8\n0.14\n2003\n1.94\n2020\n-1.45\n-0.76\n2022\n-2.04\n2004\n27\n\n\n20-Oct\n-0.36\n0.3\n2020\n-1.05\n2011\n0.75\n-0.24\n2011\n1.75\n2020\n-1.47\n-0.79\n2015\n-2.12\n2004\n28\n\n\n21-Oct\n-0.39\n0.36\n2020\n-1.06\n2011\n0.71\n-0.12\n2011\n1.65\n2020\n-1.48\n-0.9\n2015\n-2.07\n1998\n27\n\n\n22-Oct\n-0.4\n0.28\n2020\n-0.98\n1998\n0.69\n0.14\n1998\n1.41\n2020\n-1.49\n-0.85\n2020\n-2.1\n1998\n27\n\n\n23-Oct\n-0.41\n0.16\n2022\n-0.88\n2010\n0.69\n0.23\n2005\n1.27\n2022\n-1.5\n-0.84\n2020\n-2.05\n2007\n27\n\n\n24-Oct\n-0.36\n0.22\n2005\n-0.95\n2002\n0.83\n0.14\n2002\n2.55\n2005\n-1.54\n-0.83\n2020\n-2.11\n2007\n27\n\n\n25-Oct\n-0.44\n0.16\n2023\n-1.22\n2005\n0.72\n-0.53\n2005\n1.54\n2015\n-1.59\n-0.98\n2020\n-2.28\n2007\n27\n\n\n26-Oct\n-0.42\n0.32\n2023\n-1.14\n2010\n0.74\n-0.04\n2010\n1.65\n2023\n-1.57\n-0.84\n2012\n-2.51\n2007\n26\n\n\n27-Oct\n-0.4\n0.45\n2012\n-1.39\n2010\n0.79\n-0.36\n2010\n1.71\n2023\n-1.59\n-0.81\n2012\n-2.47\n2007\n25\n\n\n28-Oct\n-0.47\n0.64\n2012\n-1.59\n2010\n0.7\n-0.56\n2010\n1.93\n2012\n-1.64\n-0.66\n2012\n-2.62\n2010\n26\n\n\n29-Oct\n-0.49\n0.58\n2012\n-1.43\n2010\n0.66\n-0.39\n2010\n1.8\n2012\n-1.64\n-0.64\n2012\n-2.47\n2010\n27\n\n\n30-Oct\n-0.49\n0.45\n2012\n-1.11\n2010\n0.64\n-0.16\n2010\n1.62\n2023\n-1.63\n-0.7\n2012\n-2.15\n2011\n27\n\n\n31-Oct\n-0.47\n0.12\n2022\n-1.11\n2010\n0.65\n-0.1\n2010\n1.46\n2023\n-1.59\n-1.04\n2007\n-2.11\n2010\n27\n\n\n01-Nov\n-0.49\n0.27\n2007\n-1.25\n2010\n0.63\n-0.14\n2010\n1.31\n2023\n-1.61\n-0.71\n2007\n-2.36\n2010\n27\n\n\n02-Nov\n-0.49\n0.27\n2023\n-1.16\n2010\n0.61\n-0.07\n2004\n1.32\n2023\n-1.59\n-0.78\n2023\n-2.27\n2010\n27\n\n\n03-Nov\n-0.48\n0.35\n2023\n-0.98\n2010\n0.64\n-0.14\n2004\n1.31\n2023\n-1.61\n-0.61\n2023\n-2.26\n2010\n27\n\n\n04-Nov\n-0.44\n0.39\n2023\n-0.95\n2018\n0.72\n-0.11\n2004\n1.52\n1998\n-1.6\n-0.49\n2023\n-2.24\n1998\n27\n\n\n05-Nov\n-0.37\n0.55\n2023\n-0.9\n2018\n0.78\n0.19\n1996\n1.58\n2021\n-1.53\n-0.28\n2023\n-2.34\n1998\n27\n\n\n06-Nov\n-0.42\n0.64\n2023\n-1.12\n2010\n0.72\n0.1\n2004\n1.62\n2022\n-1.56\n-0.11\n2023\n-2.56\n2010\n27\n\n\n07-Nov\n-0.47\n0.44\n2023\n-1.19\n2002\n0.68\n0.06\n2005\n1.38\n2022\n-1.61\n-0.38\n2023\n-2.7\n2002\n27\n\n\n08-Nov\n-0.39\n0.57\n2020\n-1.01\n2002\n0.77\n0.0\n2005\n1.59\n2020\n-1.55\n-0.44\n2020\n-2.3\n2002\n27\n\n\n09-Nov\n-0.35\n0.78\n2020\n-0.98\n2002\n0.8\n0.12\n2005\n2.06\n2022\n-1.49\n-0.37\n2020\n-2.14\n2002\n28\n\n\n10-Nov\n-0.37\n0.88\n2022\n-0.97\n2006\n0.77\n0.05\n1998\n2.14\n2022\n-1.5\n-0.38\n2022\n-2.04\n1996\n27\n\n\n11-Nov\n-0.42\n0.51\n2022\n-1.16\n1998\n0.74\n-0.16\n1998\n1.62\n2022\n-1.58\n-0.6\n2022\n-2.25\n1996\n28\n\n\n12-Nov\n-0.45\n0.44\n2019\n-1.34\n1998\n0.72\n-0.49\n1998\n1.72\n2019\n-1.61\n-0.83\n2019\n-2.2\n1998\n28\n\n\n13-Nov\n-0.47\n0.33\n2019\n-1.14\n1998\n0.7\n-0.27\n1998\n1.6\n2016\n-1.64\n-0.93\n2019\n-2.21\n1997\n28\n\n\n14-Nov\n-0.5\n0.35\n2019\n-1.04\n1998\n0.69\n-0.07\n2002\n1.67\n2019\n-1.68\n-0.88\n2022\n-2.47\n1997\n28\n\n\n15-Nov\n-0.49\n0.36\n2023\n-1.35\n1997\n0.68\n-0.14\n1998\n1.76\n2023\n-1.66\n-0.93\n2010\n-2.83\n1997\n28\n\n\n16-Nov\n-0.49\n0.44\n2023\n-1.4\n1997\n0.68\n-0.14\n2007\n1.72\n2023\n-1.65\n-0.85\n2023\n-2.8\n1997\n28\n\n\n17-Nov\n-0.55\n0.28\n2019\n-1.53\n1997\n0.59\n-0.22\n2005\n1.51\n2019\n-1.69\n-0.91\n2022\n-2.86\n1997\n28\n\n\n18-Nov\n-0.57\n0.51\n2019\n-1.44\n1997\n0.55\n-0.31\n2002\n1.63\n2019\n-1.68\n-0.62\n2019\n-2.64\n1997\n28\n\n\n19-Nov\n-0.6\n0.58\n2019\n-1.46\n1997\n0.5\n-0.39\n1997\n1.7\n2019\n-1.71\n-0.54\n2019\n-2.54\n1997\n28\n\n\n20-Nov\n-0.56\n0.3\n2019\n-1.28\n1998\n0.55\n-0.3\n1997\n1.41\n2019\n-1.68\n-0.8\n2019\n-2.37\n1998\n28\n\n\n21-Nov\n-0.57\n0.3\n2019\n-1.33\n1998\n0.55\n-0.28\n1997\n1.54\n2022\n-1.7\n-0.82\n2019\n-2.47\n2006\n28\n\n\n22-Nov\n-0.59\n0.23\n2019\n-1.55\n1998\n0.56\n-0.48\n1998\n1.57\n2019\n-1.74\n-0.89\n2012\n-2.62\n1998\n28\n\n\n23-Nov\n-0.61\n0.17\n2019\n-1.54\n1998\n0.54\n-0.56\n1998\n1.54\n2019\n-1.77\n-0.98\n2012\n-2.54\n2007\n28\n\n\n24-Nov\n-0.63\n0.11\n2019\n-1.58\n1998\n0.56\n-0.55\n1998\n1.51\n2019\n-1.82\n-0.96\n2021\n-2.62\n1998\n28\n\n\n25-Nov\n-0.62\n-0.06\n2012\n-1.38\n1997\n0.55\n-0.5\n1997\n1.46\n2019\n-1.8\n-0.82\n2013\n-2.52\n2007\n28\n\n\n26-Nov\n-0.69\n-0.09\n2023\n-1.42\n1998\n0.48\n-0.52\n2005\n1.39\n2023\n-1.86\n-0.93\n2021\n-2.5\n2007\n28\n\n\n27-Nov\n-0.77\n-0.11\n2023\n-1.47\n2007\n0.37\n-0.58\n1998\n1.26\n2023\n-1.92\n-1.07\n2021\n-2.78\n2007\n28\n\n\n28-Nov\n-0.8\n-0.21\n2021\n-1.44\n2007\n0.33\n-0.4\n1998\n1.08\n2023\n-1.92\n-1.13\n2021\n-2.62\n2007\n28\n\n\n29-Nov\n-0.77\n-0.15\n2022\n-1.42\n2007\n0.37\n-0.34\n2007\n1.09\n2023\n-1.91\n-1.33\n2022\n-2.49\n2007\n28\n\n\n30-Nov\n-0.74\n-0.05\n2023\n-1.4\n2005\n0.4\n-0.2\n2005\n1.12\n2023\n-1.87\n-1.12\n2022\n-2.64\n1998\n27\n\n\n01-Dec\n-0.82\n-0.03\n2023\n-1.44\n1997\n0.31\n-0.38\n2004\n1.02\n2023\n-1.95\n-1.08\n2023\n-2.74\n2005\n27\n\n\n02-Dec\n-0.9\n-0.2\n2022\n-1.52\n2007\n0.24\n-0.63\n2007\n1.16\n2013\n-2.03\n-1.22\n2023\n-2.85\n1998\n28\n\n\n03-Dec\n-0.92\n-0.24\n2013\n-1.59\n2007\n0.22\n-0.72\n2007\n1.27\n2013\n-2.07\n-1.19\n2023\n-2.82\n2006\n28\n\n\n04-Dec\n-0.88\n-0.3\n2023\n-1.41\n2006\n0.25\n-0.5\n1996\n1.2\n2013\n-2.01\n-1.14\n2023\n-2.78\n1998\n28\n\n\n05-Dec\n-0.86\n-0.12\n2022\n-1.39\n1998\n0.27\n-0.58\n2004\n1.15\n2022\n-2.0\n-1.13\n2015\n-2.88\n1998\n28\n\n\n06-Dec\n-0.91\n-0.21\n2022\n-1.44\n1998\n0.23\n-0.48\n2004\n0.97\n2022\n-2.04\n-1.16\n2015\n-2.78\n1998\n28\n\n\n07-Dec\n-0.95\n-0.2\n2015\n-1.54\n1997\n0.18\n-0.56\n2004\n0.89\n2022\n-2.08\n-1.22\n2015\n-2.73\n2002\n28\n\n\n08-Dec\n-0.9\n-0.12\n2015\n-1.49\n1997\n0.23\n-0.43\n2007\n1.02\n2015\n-2.04\n-1.18\n2023\n-2.6\n2004\n28\n\n\n09-Dec\n-0.89\n-0.02\n2015\n-1.46\n1998\n0.26\n-0.47\n1998\n1.14\n2015\n-2.03\n-1.19\n2015\n-2.69\n1996\n28\n\n\n10-Dec\n-0.87\n-0.06\n2014\n-1.44\n2007\n0.28\n-0.55\n1998\n1.07\n2014\n-2.01\n-1.18\n2014\n-2.82\n1996\n28\n\n\n11-Dec\n-0.88\n0.03\n2014\n-1.49\n2007\n0.28\n-0.52\n1998\n1.06\n2014\n-2.03\n-0.99\n2014\n-2.64\n2008\n28\n\n\n12-Dec\n-0.9\n-0.08\n2014\n-1.58\n2004\n0.27\n-0.58\n1998\n1.0\n2016\n-2.06\n-1.05\n2014\n-3.05\n2004\n28\n\n\n13-Dec\n-0.9\n0.2\n2022\n-1.71\n2004\n0.27\n-0.57\n1998\n1.15\n2022\n-2.08\n-0.76\n2022\n-3.11\n2004\n28\n\n\n14-Dec\n-0.86\n0.24\n2022\n-1.51\n2004\n0.3\n-0.43\n2010\n1.05\n2023\n-2.02\n-0.57\n2022\n-2.93\n2004\n28\n\n\n15-Dec\n-0.88\n-0.01\n2023\n-1.61\n2004\n0.28\n-0.48\n1999\n1.33\n2023\n-2.05\n-0.93\n2022\n-3.14\n2004\n27\n\n\n16-Dec\n-0.89\n0.48\n2023\n-1.4\n1997\n0.27\n-0.36\n1999\n2.05\n2023\n-2.05\n-1.09\n2023\n-2.76\n1997\n27\n\n\n17-Dec\n-0.88\n0.35\n2023\n-1.34\n2007\n0.24\n-0.36\n2007\n1.76\n2023\n-2.01\n-1.07\n2023\n-2.38\n2008\n27\n\n\n18-Dec\n-0.93\n-0.1\n2023\n-1.52\n2005\n0.18\n-0.48\n2005\n1.04\n2023\n-2.04\n-1.24\n2023\n-2.55\n2005\n28\n\n\n19-Dec\n-0.98\n-0.33\n2023\n-1.49\n2000\n0.14\n-0.47\n2005\n0.82\n2023\n-2.09\n-1.47\n2022\n-2.68\n2003\n28\n\n\n20-Dec\n-0.99\n-0.33\n2023\n-1.51\n2003\n0.13\n-0.51\n2000\n0.9\n2023\n-2.1\n-1.51\n2019\n-2.84\n2003\n28\n\n\n21-Dec\n-0.94\n-0.25\n2022\n-1.51\n2003\n0.19\n-0.43\n2008\n1.11\n2022\n-2.08\n-1.38\n2023\n-2.9\n2003\n27\n\n\n22-Dec\n-0.95\n-0.15\n2022\n-1.53\n2010\n0.19\n-0.49\n1997\n1.25\n2022\n-2.09\n-1.35\n2009\n-2.84\n1999\n28\n\n\n23-Dec\n-0.94\n-0.27\n2023\n-1.5\n1997\n0.2\n-0.7\n1997\n1.2\n2022\n-2.09\n-1.13\n2009\n-2.77\n1999\n28\n\n\n24-Dec\n-0.91\n-0.15\n2023\n-1.41\n1999\n0.27\n-0.4\n1997\n1.13\n2022\n-2.08\n-1.0\n2009\n-2.93\n1999\n27\n\n\n25-Dec\n-0.95\n-0.14\n2023\n-1.47\n1997\n0.22\n-0.54\n1997\n1.11\n2023\n-2.12\n-1.27\n2021\n-2.91\n2011\n28\n\n\n26-Dec\n-0.97\n-0.33\n2022\n-1.49\n2005\n0.2\n-0.48\n2008\n1.17\n2022\n-2.14\n-1.44\n2021\n-2.64\n2003\n26\n\n\n27-Dec\n-1.0\n-0.23\n2019\n-1.64\n2005\n0.13\n-0.62\n2005\n1.07\n2019\n-2.12\n-1.53\n2019\n-2.66\n2005\n27\n\n\n28-Dec\n-1.02\n-0.28\n2019\n-1.61\n2008\n0.12\n-0.64\n2008\n0.96\n2019\n-2.15\n-1.52\n2019\n-2.71\n1997\n27\n\n\n29-Dec\n-1.0\n-0.45\n2019\n-1.66\n2008\n0.12\n-0.67\n2008\n0.69\n2019\n-2.13\n-1.59\n2019\n-2.65\n2005\n27\n\n\n30-Dec\n-1.07\n-0.47\n2019\n-1.54\n1996\n0.06\n-0.61\n1996\n0.57\n2019\n-2.2\n-1.52\n2019\n-2.77\n2005\n28\n\n\n31-Dec\n-1.08\n-0.65\n2022\n-1.58\n1997\n0.04\n-0.61\n1996\n0.6\n2021\n-2.2\n-1.68\n2019\n-2.82\n1997\n28\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\nDate\nDaily Average\nRecord High Daily Average\nRecord High Daily Average Year\nRecord Low Daily Average\nRecord Low Daily Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\n01-Jan\n72.7\n80.4\n2022\n66.4\n2011\n73.9\n67.8\n2011\n81.1\n2022\n71.4\n79.7\n2022\n63.9\n2001\n27\n\n\n02-Jan\n73.2\n80.2\n2022\n66.8\n2011\n74.4\n68.0\n2011\n81.0\n2022\n71.9\n79.5\n2022\n64.4\n2001\n27\n\n\n03-Jan\n73.3\n80.7\n2017\n67.3\n2011\n74.6\n68.9\n2011\n81.5\n2017\n72.1\n79.9\n2017\n65.5\n2001\n27\n\n\n04-Jan\n72.9\n81.2\n2017\n67.6\n2002\n74.3\n69.1\n2011\n81.9\n2017\n71.5\n80.6\n2017\n64.5\n2010\n27\n\n\n05-Jan\n72.6\n81.4\n2017\n66.2\n2001\n74.0\n68.5\n2001\n82.2\n2017\n71.1\n80.6\n2017\n63.6\n2010\n27\n\n\n06-Jan\n72.2\n81.7\n2017\n64.8\n2001\n73.4\n66.2\n2001\n82.6\n2017\n70.9\n80.8\n2017\n61.7\n2010\n27\n\n\n07-Jan\n72.2\n81.5\n2017\n65.9\n2010\n73.6\n67.1\n2002\n82.2\n2017\n70.8\n80.8\n2017\n61.7\n2010\n26\n\n\n08-Jan\n72.0\n78.8\n2017\n66.2\n2002\n73.5\n67.8\n2011\n80.6\n2017\n70.5\n77.9\n2022\n62.5\n2010\n26\n\n\n09-Jan\n71.6\n78.2\n2022\n64.5\n1996\n73.0\n66.6\n1996\n79.0\n2017\n70.3\n77.5\n2022\n60.9\n2010\n27\n\n\n10-Jan\n71.7\n78.2\n2022\n65.0\n1996\n73.2\n67.3\n1996\n79.2\n2022\n70.3\n77.2\n2022\n61.2\n2010\n26\n\n\n11-Jan\n71.7\n78.2\n2022\n64.0\n2010\n73.1\n68.0\n2010\n79.0\n2022\n70.3\n77.5\n2022\n60.1\n2010\n26\n\n\n12-Jan\n71.8\n77.2\n2022\n65.9\n2010\n73.2\n68.9\n2001\n78.4\n2017\n70.5\n76.6\n2022\n62.2\n2010\n26\n\n\n13-Jan\n71.9\n77.4\n2017\n65.6\n1996\n73.2\n68.0\n1996\n79.2\n2017\n70.6\n75.9\n2022\n62.3\n2010\n26\n\n\n14-Jan\n71.7\n77.8\n2017\n66.2\n1996\n73.1\n67.6\n2011\n79.7\n2017\n70.3\n75.9\n2017\n62.2\n2010\n26\n\n\n15-Jan\n71.2\n78.0\n2017\n66.9\n2011\n72.6\n68.7\n2006\n79.9\n2017\n69.8\n76.1\n2017\n63.9\n2010\n27\n\n\n16-Jan\n71.3\n78.0\n2017\n66.8\n2011\n72.7\n68.0\n2011\n79.5\n2017\n69.8\n76.5\n2017\n65.0\n2010\n27\n\n\n17-Jan\n71.2\n77.4\n2017\n66.4\n2012\n72.5\n67.5\n2012\n78.4\n2017\n69.8\n76.5\n2017\n65.3\n2012\n26\n\n\n18-Jan\n70.8\n78.6\n2017\n66.7\n1997\n72.2\n68.2\n2012\n79.9\n2017\n69.3\n77.2\n2017\n64.0\n1997\n26\n\n\n19-Jan\n70.9\n79.8\n2017\n64.9\n2003\n72.3\n67.1\n2003\n81.1\n2017\n69.5\n78.6\n2017\n62.8\n2003\n27\n\n\n20-Jan\n71.1\n80.4\n2017\n65.0\n2003\n72.5\n66.9\n2003\n81.5\n2017\n69.7\n79.2\n2017\n63.0\n1997\n26\n\n\n21-Jan\n71.0\n80.4\n2017\n65.5\n2003\n72.4\n67.6\n2014\n81.1\n2017\n69.7\n79.7\n2017\n63.0\n2003\n26\n\n\n22-Jan\n71.2\n80.6\n2017\n65.9\n2003\n72.6\n67.8\n2003\n81.3\n2017\n69.8\n79.9\n2017\n64.0\n2003\n26\n\n\n23-Jan\n71.1\n79.9\n2017\n65.1\n2001\n72.5\n66.7\n2001\n80.8\n2017\n69.7\n79.0\n2017\n63.5\n2001\n25\n\n\n24-Jan\n70.9\n78.8\n2017\n64.0\n2003\n72.4\n66.7\n2003\n79.9\n2017\n69.4\n77.7\n2017\n61.2\n2003\n24\n\n\n25-Jan\n70.8\n79.2\n2017\n64.2\n2003\n72.2\n66.2\n2003\n80.1\n2017\n69.4\n78.3\n2017\n62.2\n2003\n25\n\n\n26-Jan\n71.2\n79.6\n2017\n65.3\n2001\n72.5\n67.5\n2001\n80.6\n2017\n69.8\n78.6\n2017\n63.0\n2003\n25\n\n\n27-Jan\n71.2\n80.0\n2017\n65.0\n2005\n72.5\n66.2\n2005\n80.8\n2017\n70.0\n79.2\n2017\n63.5\n2000\n25\n\n\n28-Jan\n71.2\n79.1\n2017\n65.2\n2001\n72.5\n66.4\n2001\n80.2\n2017\n70.0\n77.9\n2017\n64.0\n2001\n26\n\n\n29-Jan\n71.2\n77.4\n2017\n65.6\n2001\n72.7\n66.9\n2001\n79.0\n2017\n69.8\n75.7\n2002\n63.5\n2005\n27\n\n\n30-Jan\n71.1\n76.8\n2002\n65.3\n2005\n72.4\n66.7\n2005\n77.7\n2002\n69.8\n75.9\n2002\n63.9\n2005\n26\n\n\n31-Jan\n71.5\n76.5\n2002\n65.8\n2005\n72.8\n67.5\n2005\n77.7\n2017\n70.1\n75.6\n2002\n64.0\n2005\n25\n\n\n01-Feb\n71.5\n76.8\n2017\n66.7\n2005\n72.7\n68.5\n2005\n78.4\n2017\n70.3\n76.1\n2002\n64.9\n2005\n26\n\n\n02-Feb\n71.7\n77.6\n2017\n66.8\n2005\n72.9\n68.4\n1995\n79.0\n2017\n70.4\n76.3\n2017\n65.1\n2005\n25\n\n\n03-Feb\n72.2\n78.6\n2017\n67.1\n1995\n73.4\n68.7\n1995\n80.1\n2017\n71.0\n77.2\n2017\n65.5\n1995\n25\n\n\n04-Feb\n72.2\n79.8\n2017\n66.2\n2005\n73.4\n67.5\n2005\n81.1\n2017\n71.0\n78.4\n2017\n64.8\n2005\n25\n\n\n05-Feb\n71.8\n80.4\n2017\n65.3\n2005\n72.9\n67.6\n2005\n81.5\n2017\n70.7\n79.2\n2017\n63.0\n2005\n23\n\n\n06-Feb\n72.0\n80.8\n2017\n65.9\n1996\n73.1\n66.9\n1996\n81.5\n2017\n70.9\n80.1\n2017\n64.9\n1995\n25\n\n\n07-Feb\n72.3\n81.0\n2017\n65.9\n2005\n73.4\n67.1\n2005\n82.0\n2017\n71.1\n80.1\n2017\n64.2\n1996\n25\n\n\n08-Feb\n72.4\n81.8\n2017\n66.1\n2005\n73.5\n67.8\n2005\n82.9\n2017\n71.2\n80.8\n2017\n64.2\n1996\n25\n\n\n09-Feb\n72.4\n82.2\n2017\n65.8\n1995\n73.5\n67.6\n1995\n83.1\n2017\n71.4\n81.3\n2017\n63.9\n1995\n26\n\n\n10-Feb\n72.8\n81.6\n2017\n66.4\n2005\n73.9\n67.6\n2005\n82.4\n2017\n71.6\n80.8\n2017\n64.8\n1995\n25\n\n\n11-Feb\n72.8\n80.2\n2017\n64.4\n2005\n74.0\n66.7\n2005\n81.1\n2017\n71.5\n79.3\n2017\n62.2\n2005\n24\n\n\n12-Feb\n72.8\n80.2\n2017\n63.6\n2005\n74.2\n66.4\n2005\n81.0\n2017\n71.4\n79.5\n2017\n60.8\n2005\n27\n\n\n13-Feb\n73.2\n80.2\n2017\n64.2\n2005\n74.5\n66.4\n2005\n81.5\n2001\n71.8\n79.5\n2017\n62.1\n2005\n25\n\n\n14-Feb\n72.9\n81.0\n2017\n63.2\n2005\n74.1\n64.8\n2005\n81.9\n2017\n71.8\n80.1\n2017\n61.5\n2005\n25\n\n\n15-Feb\n72.8\n81.1\n2017\n64.4\n2005\n73.9\n66.0\n2005\n81.7\n2017\n71.7\n80.4\n2017\n62.8\n2005\n26\n\n\n16-Feb\n73.0\n81.0\n2021\n65.1\n2005\n74.2\n66.4\n2005\n81.7\n2017\n71.8\n80.2\n2021\n63.7\n2005\n26\n\n\n17-Feb\n72.8\n81.1\n2021\n66.2\n2010\n74.0\n67.8\n2005\n81.7\n2021\n71.6\n80.4\n2021\n63.3\n1996\n27\n\n\n18-Feb\n72.9\n81.0\n2021\n66.3\n1996\n74.1\n68.5\n2010\n82.0\n2021\n71.8\n80.1\n2021\n63.3\n1996\n26\n\n\n19-Feb\n73.0\n81.5\n2021\n66.1\n1996\n74.3\n68.0\n2010\n82.4\n2021\n71.7\n80.6\n2021\n64.0\n1996\n27\n\n\n20-Feb\n73.1\n81.6\n2017\n66.5\n1996\n74.4\n68.2\n1996\n82.4\n2017\n71.9\n80.8\n2017\n63.3\n2015\n27\n\n\n21-Feb\n73.1\n80.8\n2017\n67.0\n2015\n74.3\n68.7\n2005\n81.3\n2017\n71.9\n80.2\n2017\n64.9\n2015\n26\n\n\n22-Feb\n73.2\n77.7\n2023\n67.8\n2015\n74.6\n69.1\n2015\n78.4\n2023\n71.9\n77.0\n2023\n66.4\n2010\n26\n\n\n23-Feb\n73.9\n78.3\n2023\n68.6\n2015\n75.0\n70.0\n2015\n79.2\n2023\n72.9\n77.4\n2023\n67.1\n2015\n25\n\n\n24-Feb\n74.1\n78.4\n2023\n70.4\n1999\n75.2\n72.0\n2000\n79.3\n2014\n73.0\n77.7\n2023\n67.6\n1999\n24\n\n\n25-Feb\n74.7\n80.0\n1994\n70.5\n1999\n76.0\n72.3\n1999\n83.5\n1994\n73.5\n77.9\n2023\n68.7\n1999\n25\n\n\n26-Feb\n74.6\n79.6\n2021\n66.8\n2010\n75.6\n68.2\n2010\n80.8\n2021\n73.6\n78.4\n2023\n65.5\n2010\n26\n\n\n27-Feb\n74.7\n80.0\n2021\n66.8\n2010\n75.7\n67.8\n2010\n81.0\n2021\n73.6\n79.0\n2021\n65.8\n2010\n26\n\n\n28-Feb\n74.4\n80.0\n2021\n65.9\n2010\n75.6\n67.3\n2010\n81.0\n2021\n73.2\n79.0\n2021\n64.6\n2010\n26\n\n\n29-Feb\n73.2\n77.0\n2012\n69.6\n2004\n74.5\n70.2\n2004\n77.7\n2012\n72.0\n76.3\n2012\n68.9\n2004\n7\n\n\n01-Mar\n74.3\n80.5\n2021\n65.8\n2010\n75.6\n67.6\n2010\n81.5\n2021\n73.0\n79.5\n2021\n61.9\n1999\n26\n\n\n02-Mar\n74.4\n81.1\n2021\n66.4\n2010\n75.5\n67.5\n2010\n82.0\n2021\n73.3\n80.2\n2021\n65.3\n2010\n26\n\n\n03-Mar\n74.3\n81.1\n2021\n65.8\n2010\n75.4\n66.9\n2010\n81.7\n2021\n73.1\n80.4\n2021\n64.6\n2010\n25\n\n\n04-Mar\n74.0\n79.4\n2021\n65.3\n2010\n75.3\n66.9\n2010\n80.6\n2003\n72.7\n78.4\n2021\n63.7\n2010\n25\n\n\n05-Mar\n73.8\n79.9\n2003\n64.8\n2010\n75.2\n66.7\n2010\n81.1\n2003\n72.4\n78.8\n2003\n63.0\n2010\n25\n\n\n06-Mar\n74.0\n80.4\n2003\n65.0\n2010\n75.2\n66.9\n2010\n81.7\n2003\n72.8\n79.2\n2003\n63.0\n2010\n25\n\n\n07-Mar\n73.7\n81.4\n2003\n66.0\n2010\n75.0\n68.0\n2010\n82.2\n2003\n72.5\n80.6\n2003\n64.0\n2010\n25\n\n\n08-Mar\n73.8\n81.8\n2003\n66.8\n2010\n75.1\n68.4\n2010\n82.9\n2003\n72.6\n80.8\n2003\n65.3\n2010\n25\n\n\n09-Mar\n73.6\n82.2\n2003\n67.6\n2010\n74.7\n68.7\n2010\n83.1\n2003\n72.4\n81.3\n2003\n66.6\n2010\n26\n\n\n10-Mar\n73.7\n81.4\n2003\n68.0\n1996\n74.8\n69.4\n1996\n81.9\n2003\n72.5\n81.0\n2003\n66.6\n1996\n26\n\n\n11-Mar\n73.5\n81.2\n2003\n66.2\n1996\n74.8\n68.9\n1996\n82.2\n2003\n72.3\n80.1\n2003\n63.5\n1996\n26\n\n\n12-Mar\n73.7\n81.6\n2003\n66.6\n1996\n74.9\n68.4\n1996\n82.6\n2003\n72.6\n80.6\n2003\n64.8\n1996\n25\n\n\n13-Mar\n74.0\n82.2\n2003\n67.9\n1998\n75.1\n69.4\n1998\n83.3\n2003\n72.8\n81.1\n2003\n66.4\n1996\n26\n\n\n14-Mar\n74.1\n82.4\n2003\n68.9\n1996\n75.3\n70.7\n1996\n83.5\n2003\n73.0\n81.3\n2003\n67.1\n1996\n26\n\n\n15-Mar\n74.5\n82.0\n2003\n69.4\n2013\n75.8\n71.2\n2010\n82.9\n2003\n73.2\n81.0\n2003\n67.5\n2013\n26\n\n\n16-Mar\n74.8\n81.5\n2003\n69.2\n2010\n76.0\n70.3\n2010\n82.6\n2003\n73.6\n80.4\n2003\n68.2\n2010\n26\n\n\n17-Mar\n75.2\n80.8\n2003\n69.1\n2010\n76.3\n69.8\n2010\n81.7\n2003\n74.1\n79.9\n2003\n68.4\n2010\n26\n\n\n18-Mar\n75.7\n80.4\n2024\n68.3\n2010\n76.8\n69.3\n2010\n81.3\n2003\n74.6\n79.7\n2024\n67.3\n2010\n26\n\n\n19-Mar\n76.0\n80.8\n2003\n68.1\n2010\n77.1\n69.6\n2010\n82.2\n2003\n74.8\n79.5\n2003\n66.6\n2010\n26\n\n\n20-Mar\n76.0\n81.9\n2003\n69.4\n2010\n77.2\n70.7\n2010\n83.3\n2003\n74.8\n80.6\n2003\n68.0\n2010\n26\n\n\n21-Mar\n76.0\n82.6\n2003\n69.0\n1996\n77.2\n70.7\n1996\n83.5\n2003\n74.8\n81.7\n2003\n67.3\n1996\n27\n\n\n22-Mar\n75.5\n82.4\n2003\n68.1\n1996\n76.7\n69.3\n1996\n83.8\n2003\n74.4\n81.0\n2003\n66.9\n1996\n27\n\n\n23-Mar\n75.6\n80.8\n1994\n67.6\n1996\n76.9\n69.3\n1996\n84.2\n1994\n74.2\n79.3\n2003\n65.8\n1996\n27\n\n\n24-Mar\n75.9\n82.0\n1994\n68.4\n1996\n77.2\n69.4\n1996\n85.8\n1994\n74.7\n79.5\n2015\n67.3\n1996\n27\n\n\n25-Mar\n76.1\n80.8\n2015\n69.2\n1996\n77.3\n70.5\n1996\n81.9\n2015\n74.9\n79.7\n2015\n68.0\n1996\n27\n\n\n26-Mar\n76.2\n81.4\n2021\n71.2\n1996\n77.4\n72.3\n2009\n82.8\n2021\n74.9\n80.2\n2015\n69.8\n1996\n27\n\n\n27-Mar\n76.3\n82.0\n2021\n70.4\n2013\n77.5\n72.5\n2013\n83.5\n2021\n75.2\n81.0\n2020\n68.2\n2013\n27\n\n\n28-Mar\n76.6\n82.3\n2021\n70.1\n2013\n77.8\n72.0\n2013\n83.5\n2021\n75.4\n81.1\n2021\n68.2\n2013\n27\n\n\n29-Mar\n76.8\n82.7\n2021\n70.6\n2013\n78.1\n72.0\n2013\n86.4\n1994\n75.5\n81.7\n2021\n69.1\n2013\n27\n\n\n30-Mar\n76.8\n82.8\n2021\n70.4\n2013\n77.9\n71.4\n2013\n83.7\n2021\n75.6\n81.9\n2021\n69.3\n2013\n27\n\n\n31-Mar\n77.1\n83.2\n2021\n70.7\n2010\n78.2\n72.0\n2013\n84.2\n2021\n75.9\n82.2\n2021\n69.3\n2010\n26\n\n\n01-Apr\n77.2\n83.7\n2021\n69.4\n2003\n78.3\n71.2\n2003\n84.6\n2021\n76.0\n82.8\n2021\n67.6\n2003\n27\n\n\n02-Apr\n77.2\n81.9\n2016\n70.8\n2003\n78.5\n72.3\n2003\n83.1\n2016\n76.0\n80.8\n2016\n69.3\n2003\n28\n\n\n03-Apr\n77.3\n83.4\n2017\n71.4\n2003\n78.8\n72.5\n2003\n90.0\n2017\n75.8\n80.1\n2020\n70.3\n2003\n28\n\n\n04-Apr\n77.6\n82.2\n2017\n71.8\n2004\n78.7\n73.2\n2004\n83.5\n2017\n76.4\n80.8\n2017\n70.5\n2004\n28\n\n\n05-Apr\n77.6\n81.3\n2020\n72.0\n2004\n78.7\n73.4\n2004\n82.4\n2023\n76.4\n80.6\n2020\n70.5\n2004\n27\n\n\n06-Apr\n77.6\n81.5\n2020\n72.8\n2004\n78.8\n74.3\n2004\n82.6\n2020\n76.4\n80.4\n2020\n71.4\n2004\n27\n\n\n07-Apr\n77.8\n81.8\n2020\n73.4\n2004\n79.0\n74.5\n2004\n83.3\n2020\n76.6\n80.8\n2022\n72.3\n2004\n26\n\n\n08-Apr\n77.8\n82.6\n2020\n74.2\n2004\n78.9\n75.4\n2004\n83.7\n2020\n76.6\n81.5\n2020\n73.0\n2004\n27\n\n\n09-Apr\n77.9\n83.0\n2020\n74.8\n2009\n79.0\n75.9\n1996\n84.0\n2020\n76.8\n82.0\n2020\n73.6\n2009\n27\n\n\n10-Apr\n77.8\n83.5\n2020\n73.6\n2000\n79.0\n74.5\n2000\n84.4\n2020\n76.6\n82.6\n2020\n72.7\n2000\n27\n\n\n11-Apr\n77.7\n83.5\n2020\n73.4\n2000\n78.8\n74.7\n2000\n84.2\n2020\n76.6\n82.8\n2020\n72.1\n2000\n27\n\n\n12-Apr\n77.7\n83.1\n2020\n72.4\n1998\n78.9\n74.5\n1996\n84.4\n2011\n76.5\n82.4\n2020\n70.2\n1998\n26\n\n\n13-Apr\n77.9\n83.8\n2020\n72.1\n1998\n79.2\n73.4\n1998\n84.7\n2020\n76.5\n82.9\n2020\n70.7\n1998\n27\n\n\n14-Apr\n78.2\n84.6\n2020\n72.0\n1998\n79.5\n72.9\n1998\n85.8\n2020\n76.9\n83.5\n2020\n71.1\n1998\n27\n\n\n15-Apr\n78.6\n85.2\n2020\n72.5\n1998\n79.8\n73.6\n1998\n86.4\n2020\n77.5\n84.0\n2020\n71.4\n1998\n26\n\n\n16-Apr\n78.7\n85.7\n2020\n73.0\n2004\n79.9\n74.3\n2004\n86.7\n2020\n77.5\n84.7\n2020\n71.8\n2004\n28\n\n\n17-Apr\n78.7\n84.9\n2020\n72.8\n2004\n80.0\n74.5\n2004\n86.7\n2020\n77.4\n83.1\n2020\n71.1\n2004\n28\n\n\n18-Apr\n78.9\n85.4\n2020\n72.6\n2004\n80.2\n74.3\n2010\n88.2\n1994\n77.5\n84.2\n2020\n70.5\n2004\n27\n\n\n19-Apr\n78.5\n85.6\n2020\n72.6\n2004\n79.8\n74.3\n2004\n87.1\n2020\n77.3\n84.2\n2020\n70.9\n2004\n28\n\n\n20-Apr\n78.7\n85.7\n2020\n73.4\n2004\n79.8\n74.8\n2004\n86.5\n2020\n77.6\n84.9\n2020\n72.0\n2004\n28\n\n\n21-Apr\n78.9\n85.8\n2020\n73.5\n2004\n79.9\n74.5\n2004\n86.9\n2020\n77.8\n84.6\n2020\n72.5\n2001\n28\n\n\n22-Apr\n79.0\n84.5\n2020\n74.2\n2004\n80.1\n75.4\n2004\n86.2\n2020\n77.8\n82.8\n2020\n72.9\n2004\n28\n\n\n23-Apr\n79.1\n83.8\n2020\n75.3\n2012\n80.2\n76.1\n2012\n85.1\n2020\n77.9\n82.6\n2020\n73.9\n2001\n28\n\n\n24-Apr\n79.1\n84.8\n2020\n73.8\n2012\n80.4\n75.0\n2012\n85.8\n2020\n77.8\n83.7\n2020\n72.5\n2012\n27\n\n\n25-Apr\n79.5\n84.3\n2020\n73.6\n2012\n80.7\n74.7\n2012\n85.1\n2020\n78.3\n83.5\n2020\n72.5\n2012\n26\n\n\n26-Apr\n79.8\n83.9\n2020\n74.1\n2012\n81.0\n75.2\n2012\n85.3\n2015\n78.5\n83.1\n2020\n73.0\n2012\n26\n\n\n27-Apr\n79.7\n84.6\n2015\n75.1\n2012\n80.9\n75.9\n2012\n85.8\n2015\n78.6\n83.3\n2015\n74.3\n2012\n26\n\n\n28-Apr\n79.8\n84.2\n2015\n75.4\n2012\n80.8\n75.7\n2012\n84.7\n2011\n78.7\n83.8\n2015\n75.0\n2009\n26\n\n\n29-Apr\n79.7\n83.4\n2011\n74.6\n2012\n80.7\n75.2\n2012\n84.4\n2011\n78.6\n82.4\n2011\n73.9\n2001\n26\n\n\n30-Apr\n79.5\n83.9\n2021\n74.2\n2001\n80.5\n75.0\n2001\n84.9\n2021\n78.6\n82.9\n2021\n73.4\n2001\n26\n\n\n01-May\n79.4\n85.1\n2021\n74.1\n2001\n80.6\n75.0\n2001\n86.4\n2021\n78.2\n83.7\n2021\n73.2\n2001\n27\n\n\n02-May\n79.9\n85.7\n2021\n74.1\n2001\n81.1\n75.0\n2001\n86.7\n2021\n78.8\n84.7\n2021\n73.2\n2001\n25\n\n\n03-May\n80.3\n85.8\n2021\n74.8\n2001\n81.6\n76.3\n2001\n86.9\n2021\n79.0\n84.6\n2021\n73.4\n2001\n25\n\n\n04-May\n80.7\n86.2\n2021\n75.8\n2001\n82.0\n77.4\n2001\n87.6\n2021\n79.4\n84.7\n2021\n74.1\n2001\n26\n\n\n05-May\n80.8\n86.8\n2021\n76.4\n2015\n82.2\n77.2\n2015\n88.2\n2021\n79.5\n85.3\n2021\n74.7\n2001\n27\n\n\n06-May\n80.9\n87.7\n2021\n76.4\n2001\n82.2\n78.1\n2001\n89.2\n2021\n79.5\n86.2\n2021\n74.8\n2001\n27\n\n\n07-May\n80.7\n86.6\n2021\n76.0\n2001\n82.1\n78.1\n2001\n88.0\n2021\n79.3\n85.1\n2021\n73.9\n2001\n26\n\n\n08-May\n81.1\n85.2\n2021\n75.2\n2001\n82.4\n76.5\n2001\n86.5\n2021\n79.9\n83.8\n2021\n73.8\n2001\n26\n\n\n09-May\n81.4\n84.6\n2010\n74.3\n2001\n82.7\n75.6\n2001\n86.5\n2010\n80.1\n83.3\n2003\n73.0\n2001\n26\n\n\n10-May\n81.7\n84.8\n2003\n74.6\n2001\n83.0\n75.4\n2001\n86.4\n2021\n80.5\n83.5\n2003\n73.8\n2001\n25\n\n\n11-May\n81.9\n85.6\n2021\n74.6\n2001\n83.1\n75.4\n2001\n87.3\n2021\n80.7\n84.2\n2003\n73.9\n2001\n27\n\n\n12-May\n81.8\n86.2\n2021\n75.1\n2001\n83.0\n76.3\n2001\n87.4\n2003\n80.7\n85.1\n2021\n73.9\n2001\n28\n\n\n13-May\n81.9\n86.7\n2021\n76.2\n2001\n83.2\n77.5\n2001\n87.8\n2003\n80.7\n85.6\n2021\n74.8\n2001\n28\n\n\n14-May\n82.2\n85.9\n2021\n77.2\n2001\n83.4\n78.6\n2001\n87.1\n2021\n80.9\n84.7\n2021\n75.7\n2004\n27\n\n\n15-May\n82.2\n85.4\n1995\n78.2\n2001\n83.4\n79.5\n2001\n86.9\n1995\n81.0\n84.4\n2024\n76.5\n2004\n27\n\n\n16-May\n82.1\n85.8\n2003\n78.8\n2001\n83.2\n80.2\n2001\n87.4\n1995\n80.9\n85.1\n2024\n77.4\n2001\n28\n\n\n17-May\n82.2\n86.2\n1995\n78.6\n2014\n83.2\n79.7\n2006\n87.8\n1995\n81.1\n84.6\n1995\n77.4\n2014\n27\n\n\n18-May\n82.2\n86.8\n2024\n77.2\n2014\n83.3\n78.8\n2014\n88.0\n2024\n81.1\n85.5\n2024\n75.7\n2014\n27\n\n\n19-May\n82.4\n87.6\n2024\n78.0\n2014\n83.4\n79.3\n2014\n88.9\n2024\n81.3\n86.4\n2024\n76.8\n2014\n27\n\n\n20-May\n82.5\n87.3\n2024\n78.2\n2014\n83.6\n79.7\n2014\n88.2\n2024\n81.4\n86.4\n2024\n76.8\n2014\n26\n\n\n21-May\n82.7\n86.8\n2024\n78.8\n2014\n83.8\n79.5\n2018\n87.8\n2024\n81.5\n85.8\n2024\n77.4\n2014\n26\n\n\n22-May\n82.8\n86.8\n2024\n78.9\n2018\n83.9\n79.3\n2018\n88.2\n2024\n81.7\n85.5\n2024\n77.9\n2014\n26\n\n\n23-May\n82.7\n86.2\n2024\n79.6\n2002\n83.9\n80.8\n2002\n87.6\n2024\n81.6\n84.9\n1997\n78.3\n2002\n26\n\n\n24-May\n82.7\n86.6\n2024\n79.6\n2002\n84.0\n81.3\n2002\n87.8\n2024\n81.4\n85.3\n2024\n77.9\n2002\n27\n\n\n25-May\n82.8\n87.0\n2024\n79.0\n2002\n84.0\n80.1\n2002\n88.0\n2024\n81.6\n86.0\n2024\n77.9\n2002\n26\n\n\n26-May\n82.8\n87.4\n2024\n79.0\n2002\n83.9\n80.4\n2002\n88.3\n2024\n81.7\n86.4\n2024\n77.5\n2002\n27\n\n\n27-May\n83.2\n88.0\n2024\n79.1\n2018\n84.4\n79.9\n2018\n88.9\n2024\n82.0\n87.1\n2024\n78.3\n2002\n27\n\n\n28-May\n83.5\n88.1\n2024\n79.0\n2018\n84.6\n79.5\n2018\n88.7\n2024\n82.5\n87.4\n2024\n78.4\n2018\n27\n\n\n29-May\n83.6\n88.4\n2024\n78.7\n2013\n84.6\n79.7\n2013\n89.4\n2024\n82.5\n87.3\n2024\n77.7\n2013\n27\n\n\n30-May\n83.6\n88.6\n2024\n78.2\n2013\n84.8\n79.3\n2013\n89.6\n2024\n82.5\n87.6\n2024\n77.2\n2013\n27\n\n\n31-May\n83.9\n87.4\n2024\n79.2\n2013\n85.0\n80.2\n2013\n88.3\n2024\n82.8\n86.5\n2024\n78.3\n2013\n28\n\n\n01-Jun\n83.8\n87.0\n2020\n80.4\n2013\n84.9\n81.5\n2013\n88.5\n2020\n82.7\n86.2\n2017\n79.3\n2013\n28\n\n\n02-Jun\n83.7\n86.2\n2017\n80.0\n1996\n84.8\n81.9\n1996\n87.3\n2004\n82.6\n85.6\n2017\n78.1\n1996\n27\n\n\n03-Jun\n83.8\n86.2\n2004\n80.2\n1996\n84.8\n81.3\n1996\n87.4\n2004\n82.7\n85.1\n2020\n79.2\n1996\n26\n\n\n04-Jun\n83.8\n86.1\n2002\n80.0\n2014\n84.8\n80.4\n2014\n87.4\n2021\n82.8\n84.9\n2002\n79.5\n2014\n26\n\n\n05-Jun\n84.2\n86.8\n1998\n80.9\n2014\n85.3\n82.0\n2013\n88.5\n2021\n83.0\n85.6\n1998\n79.3\n2014\n26\n\n\n06-Jun\n84.4\n87.9\n2010\n81.8\n2013\n85.4\n82.9\n2013\n89.1\n2010\n83.5\n86.9\n1998\n80.8\n2013\n26\n\n\n07-Jun\n84.7\n88.3\n1998\n82.0\n2017\n85.7\n82.8\n2017\n89.2\n1998\n83.7\n87.4\n1998\n81.1\n2013\n26\n\n\n08-Jun\n84.5\n88.5\n1998\n81.4\n1999\n85.5\n81.9\n1999\n89.2\n1998\n83.6\n87.8\n1998\n80.8\n2017\n27\n\n\n09-Jun\n84.6\n87.5\n2024\n81.5\n1997\n85.7\n82.0\n2017\n88.9\n2021\n83.5\n86.7\n2024\n80.2\n1997\n27\n\n\n10-Jun\n84.6\n87.7\n2024\n81.0\n1997\n85.6\n81.7\n1997\n88.7\n2010\n83.5\n86.9\n2024\n80.2\n1997\n26\n\n\n11-Jun\n84.6\n88.2\n2020\n81.6\n1997\n85.6\n82.6\n1997\n89.2\n2010\n83.5\n87.4\n2020\n80.6\n1997\n26\n\n\n12-Jun\n84.6\n87.9\n2021\n82.0\n1997\n85.6\n82.4\n1997\n89.2\n2010\n83.6\n87.1\n2021\n81.0\n2000\n26\n\n\n13-Jun\n85.0\n88.2\n2021\n82.2\n2002\n86.2\n82.6\n2002\n89.8\n2010\n83.9\n87.3\n1998\n81.1\n1997\n28\n\n\n14-Jun\n85.4\n88.7\n2010\n81.6\n2002\n86.5\n82.2\n2002\n90.3\n2010\n84.3\n87.1\n2010\n81.0\n2002\n28\n\n\n15-Jun\n85.6\n89.2\n2010\n80.7\n2002\n86.7\n81.5\n2002\n90.3\n2010\n84.6\n88.0\n2010\n79.9\n2002\n28\n\n\n16-Jun\n85.7\n89.6\n2010\n81.0\n2002\n86.8\n82.4\n2002\n91.0\n2010\n84.6\n88.3\n2010\n79.5\n2002\n27\n\n\n17-Jun\n85.8\n90.4\n2010\n82.2\n2002\n86.9\n83.3\n2002\n91.4\n2010\n84.7\n89.4\n2010\n81.1\n2002\n27\n\n\n18-Jun\n85.9\n89.9\n2010\n82.6\n2012\n87.0\n83.5\n1995\n90.7\n2010\n84.9\n89.1\n2010\n81.1\n2012\n26\n\n\n19-Jun\n85.8\n89.7\n1998\n82.0\n2012\n87.0\n82.9\n2012\n90.9\n1998\n84.6\n88.5\n1998\n81.0\n2012\n28\n\n\n20-Jun\n85.9\n89.9\n1998\n80.8\n2012\n87.0\n81.5\n2012\n90.9\n1998\n84.7\n88.9\n1998\n80.1\n2012\n27\n\n\n21-Jun\n85.7\n90.1\n1998\n80.7\n1995\n86.8\n81.5\n1995\n90.9\n1998\n84.6\n89.2\n1998\n79.9\n1995\n28\n\n\n22-Jun\n85.6\n90.2\n1998\n80.2\n1995\n86.7\n81.1\n1995\n90.9\n1998\n84.6\n89.4\n1998\n79.2\n1995\n28\n\n\n23-Jun\n85.8\n89.4\n2021\n80.6\n2012\n86.9\n81.1\n2012\n90.9\n2021\n84.6\n88.7\n1998\n80.1\n1995\n27\n\n\n24-Jun\n85.8\n89.2\n2020\n81.0\n2012\n86.9\n81.5\n2012\n90.7\n2020\n84.7\n88.3\n1998\n80.4\n1995\n27\n\n\n25-Jun\n86.1\n90.2\n2020\n81.6\n2012\n87.1\n82.4\n2012\n91.2\n2020\n85.1\n89.2\n2020\n80.8\n2012\n25\n\n\n26-Jun\n86.0\n90.3\n2020\n81.9\n2012\n87.0\n82.4\n2002\n91.2\n2020\n85.0\n89.4\n2020\n81.0\n2012\n25\n\n\n27-Jun\n86.2\n90.1\n2020\n82.4\n2002\n87.2\n82.9\n2002\n90.9\n2020\n85.1\n89.2\n2020\n81.5\n2012\n26\n\n\n28-Jun\n86.2\n89.6\n2020\n82.8\n2002\n87.2\n83.3\n2002\n90.5\n2020\n85.2\n88.7\n2020\n82.2\n2002\n28\n\n\n29-Jun\n86.4\n90.1\n2020\n83.4\n2002\n87.5\n84.4\n2002\n91.4\n2020\n85.3\n88.7\n2020\n82.0\n2001\n28\n\n\n30-Jun\n86.4\n90.3\n2020\n83.3\n2002\n87.6\n83.8\n2002\n92.1\n1997\n85.3\n88.7\n2020\n82.8\n2002\n28\n\n\n01-Jul\n86.5\n90.4\n2020\n83.6\n1999\n87.6\n84.2\n1999\n92.3\n2020\n85.3\n88.5\n2020\n82.4\n1996\n27\n\n\n02-Jul\n86.4\n90.4\n2020\n82.8\n1999\n87.5\n83.5\n1999\n92.5\n2020\n85.3\n88.2\n2020\n82.2\n1999\n28\n\n\n03-Jul\n86.6\n90.2\n2020\n82.0\n1999\n87.8\n82.8\n1999\n92.1\n2020\n85.4\n88.3\n2020\n81.3\n1999\n28\n\n\n04-Jul\n86.8\n90.4\n2020\n82.0\n1999\n88.0\n82.9\n1999\n92.3\n2020\n85.6\n88.7\n2023\n81.1\n1999\n28\n\n\n05-Jul\n87.0\n90.4\n2023\n83.2\n1999\n88.0\n84.2\n1999\n91.4\n2020\n85.9\n89.4\n2023\n82.2\n1999\n27\n\n\n06-Jul\n87.1\n90.4\n2023\n84.4\n2011\n88.1\n85.1\n2011\n91.2\n2023\n86.0\n89.6\n2023\n83.1\n2013\n26\n\n\n07-Jul\n87.0\n90.2\n2020\n82.9\n2011\n88.0\n83.8\n2011\n91.4\n2020\n85.9\n89.2\n2023\n82.0\n2011\n27\n\n\n08-Jul\n87.2\n90.4\n2020\n82.8\n2011\n88.3\n83.8\n2011\n91.4\n2020\n86.1\n89.4\n2020\n81.7\n2011\n28\n\n\n09-Jul\n87.2\n90.4\n2020\n83.6\n2011\n88.4\n84.4\n2011\n91.4\n2020\n86.1\n89.4\n2020\n82.8\n2006\n28\n\n\n10-Jul\n87.2\n90.6\n2016\n83.2\n2002\n88.3\n84.0\n2002\n91.6\n1996\n86.1\n89.8\n2016\n82.4\n2002\n28\n\n\n11-Jul\n87.0\n90.3\n2016\n82.8\n2002\n88.0\n83.5\n2002\n91.2\n2016\n85.9\n89.4\n2016\n82.0\n2002\n28\n\n\n12-Jul\n87.0\n90.8\n2023\n83.4\n2002\n88.2\n84.7\n2002\n91.9\n2023\n85.9\n89.6\n2016\n82.0\n2002\n28\n\n\n13-Jul\n87.1\n90.9\n2016\n83.4\n2006\n88.2\n84.0\n2006\n92.1\n2016\n86.1\n89.8\n2016\n82.9\n2006\n27\n\n\n14-Jul\n87.3\n90.7\n2023\n83.8\n2006\n88.4\n84.7\n2006\n92.5\n2023\n86.2\n89.4\n2016\n82.9\n2006\n27\n\n\n15-Jul\n87.4\n90.5\n2023\n83.5\n2001\n88.4\n84.2\n2001\n91.8\n2020\n86.4\n89.2\n2023\n82.8\n2001\n28\n\n\n16-Jul\n87.2\n90.4\n2023\n83.3\n2013\n88.1\n84.2\n2013\n91.6\n2023\n86.3\n89.2\n2023\n82.4\n2001\n27\n\n\n17-Jul\n87.1\n89.8\n2023\n81.7\n2013\n88.1\n82.4\n2013\n91.0\n2009\n86.1\n89.1\n2023\n81.0\n2013\n27\n\n\n18-Jul\n87.2\n90.2\n2009\n80.9\n2013\n88.2\n81.3\n2013\n91.4\n2009\n86.1\n89.1\n2018\n80.6\n2013\n28\n\n\n19-Jul\n87.3\n90.2\n2009\n81.8\n2013\n88.4\n83.3\n2013\n91.2\n2009\n86.2\n89.1\n2009\n80.2\n2013\n28\n\n\n20-Jul\n87.4\n89.8\n2018\n82.8\n2013\n88.4\n83.8\n2013\n91.4\n2021\n86.3\n89.2\n2018\n81.9\n2013\n28\n\n\n21-Jul\n87.4\n90.0\n2021\n83.6\n2013\n88.4\n84.9\n2013\n91.9\n2021\n86.3\n89.2\n2023\n82.4\n2013\n27\n\n\n22-Jul\n87.3\n90.5\n2021\n84.0\n2006\n88.4\n84.6\n2006\n92.8\n2021\n86.2\n88.7\n2023\n82.6\n2013\n26\n\n\n23-Jul\n87.3\n90.2\n2023\n83.5\n2001\n88.3\n84.2\n2001\n91.9\n2021\n86.3\n89.4\n2023\n82.8\n2001\n27\n\n\n24-Jul\n87.4\n90.4\n2023\n83.0\n2001\n88.5\n84.0\n2001\n91.2\n2011\n86.3\n89.6\n2023\n81.9\n2001\n28\n\n\n25-Jul\n87.4\n90.5\n2023\n84.4\n2001\n88.4\n85.6\n2001\n91.2\n2011\n86.4\n90.0\n2023\n83.1\n2001\n27\n\n\n26-Jul\n87.4\n90.2\n2021\n85.0\n2001\n88.4\n86.0\n2001\n91.2\n2021\n86.4\n89.1\n2021\n84.0\n2001\n26\n\n\n27-Jul\n87.5\n91.0\n2021\n84.4\n1995\n88.5\n85.1\n1995\n91.9\n2021\n86.5\n90.0\n2021\n83.8\n1995\n28\n\n\n28-Jul\n87.7\n91.5\n2021\n83.4\n1995\n88.6\n83.8\n1995\n92.5\n2021\n86.7\n90.5\n2021\n82.9\n1995\n28\n\n\n29-Jul\n87.7\n91.8\n2021\n82.6\n1995\n88.7\n83.7\n1995\n92.5\n2021\n86.7\n91.2\n2021\n81.5\n1995\n28\n\n\n30-Jul\n87.8\n91.7\n2021\n82.6\n1995\n88.8\n83.1\n1995\n92.5\n2016\n86.8\n90.9\n2021\n82.2\n1995\n28\n\n\n31-Jul\n87.8\n92.0\n2021\n82.8\n1995\n89.0\n83.8\n1995\n93.0\n2021\n86.7\n91.0\n2021\n81.9\n1995\n28\n\n\n01-Aug\n87.7\n92.2\n2021\n84.0\n1995\n88.8\n85.5\n2017\n93.2\n2021\n86.7\n91.2\n2021\n82.2\n1995\n28\n\n\n02-Aug\n87.5\n91.9\n2021\n82.5\n1995\n88.4\n83.3\n1995\n92.8\n2021\n86.5\n91.0\n2021\n81.7\n1995\n27\n\n\n03-Aug\n87.1\n90.2\n1998\n81.5\n1995\n88.0\n82.0\n1995\n91.4\n2021\n86.2\n89.4\n1998\n81.0\n1995\n26\n\n\n04-Aug\n87.0\n90.2\n1998\n81.2\n1995\n88.0\n82.4\n1995\n90.7\n1998\n86.1\n89.6\n1998\n80.1\n1995\n26\n\n\n05-Aug\n87.2\n90.0\n2021\n81.6\n1995\n88.2\n82.9\n1995\n91.8\n2021\n86.3\n89.2\n1998\n80.4\n1995\n26\n\n\n06-Aug\n87.3\n91.0\n2021\n83.1\n1995\n88.3\n84.4\n1995\n92.7\n2021\n86.3\n89.2\n2021\n81.7\n1995\n27\n\n\n07-Aug\n87.3\n90.9\n2021\n83.2\n2004\n88.4\n83.7\n2004\n92.7\n2021\n86.3\n89.1\n2021\n82.6\n2004\n28\n\n\n08-Aug\n87.4\n91.1\n2021\n83.5\n2004\n88.4\n84.6\n2004\n92.8\n2021\n86.3\n89.4\n2021\n82.4\n2004\n28\n\n\n09-Aug\n87.4\n91.0\n2023\n84.6\n2004\n88.4\n85.6\n2004\n92.1\n2021\n86.4\n90.0\n2023\n83.5\n2004\n28\n\n\n10-Aug\n87.4\n91.5\n2023\n84.2\n2002\n88.4\n85.1\n2002\n92.5\n2023\n86.4\n90.5\n2023\n83.3\n2002\n28\n\n\n11-Aug\n87.5\n91.8\n2023\n83.6\n2002\n88.5\n84.2\n2002\n93.2\n2023\n86.5\n90.5\n2023\n83.1\n2002\n27\n\n\n12-Aug\n87.7\n91.8\n2023\n84.0\n1994\n88.7\n85.1\n1994\n92.8\n2023\n86.7\n90.9\n2023\n82.9\n1994\n26\n\n\n13-Aug\n87.8\n90.8\n2020\n83.1\n1994\n88.8\n84.2\n1994\n91.9\n2020\n86.9\n89.8\n2020\n81.9\n1994\n28\n\n\n14-Aug\n87.9\n91.1\n2020\n83.2\n1994\n88.9\n84.0\n1994\n92.1\n2020\n87.0\n90.1\n2020\n82.4\n1994\n28\n\n\n15-Aug\n87.9\n91.4\n2020\n84.0\n1994\n88.9\n85.3\n1994\n92.7\n2020\n87.0\n90.1\n2020\n82.8\n1994\n27\n\n\n16-Aug\n87.9\n91.1\n2020\n85.1\n1994\n88.9\n86.4\n1994\n93.0\n2020\n86.8\n89.6\n2017\n83.7\n1994\n26\n\n\n17-Aug\n87.9\n91.4\n2020\n85.8\n2000\n89.0\n86.7\n2000\n93.0\n2020\n86.9\n89.8\n2017\n84.7\n2003\n26\n\n\n18-Aug\n87.9\n91.2\n2020\n85.6\n2000\n88.8\n86.2\n1999\n92.7\n2020\n86.9\n89.8\n2020\n84.9\n2000\n27\n\n\n19-Aug\n87.9\n90.4\n2010\n85.4\n1999\n88.9\n85.8\n1999\n91.8\n2010\n86.9\n88.9\n2010\n84.6\n2003\n28\n\n\n20-Aug\n87.7\n90.9\n2010\n84.5\n2003\n88.7\n85.3\n1996\n92.3\n2010\n86.7\n89.6\n2010\n83.7\n2003\n27\n\n\n21-Aug\n87.5\n90.8\n2021\n83.4\n2003\n88.5\n84.0\n2003\n92.8\n2021\n86.6\n89.4\n2010\n82.9\n2003\n27\n\n\n22-Aug\n87.5\n91.4\n2021\n84.0\n1996\n88.5\n84.4\n1996\n92.8\n2021\n86.5\n90.1\n2021\n82.9\n2003\n26\n\n\n23-Aug\n87.4\n91.8\n2021\n83.6\n1996\n88.4\n84.2\n1999\n92.8\n2021\n86.5\n90.7\n2021\n82.8\n1996\n27\n\n\n24-Aug\n87.3\n91.1\n2021\n83.2\n1996\n88.2\n83.8\n1996\n91.9\n2021\n86.4\n90.3\n2021\n82.6\n1996\n28\n\n\n25-Aug\n86.9\n90.1\n2022\n83.2\n1995\n87.8\n83.7\n1995\n91.2\n2021\n85.9\n88.9\n2022\n82.6\n1995\n27\n\n\n26-Aug\n86.5\n90.0\n2022\n82.3\n2012\n87.4\n83.3\n2012\n90.9\n2022\n85.5\n89.1\n2022\n81.3\n2012\n28\n\n\n27-Aug\n86.4\n89.8\n2022\n81.0\n2012\n87.2\n81.3\n2012\n90.5\n2020\n85.5\n89.2\n2022\n80.8\n2012\n28\n\n\n28-Aug\n86.4\n90.2\n2020\n81.8\n2012\n87.3\n83.3\n2012\n91.4\n2020\n85.5\n88.9\n2020\n80.4\n2012\n28\n\n\n29-Aug\n86.5\n91.0\n2020\n83.2\n2012\n87.5\n84.6\n2012\n92.3\n2020\n85.5\n89.8\n2020\n81.9\n2012\n28\n\n\n30-Aug\n86.5\n91.3\n2020\n84.1\n2006\n87.4\n84.9\n2000\n92.3\n2020\n85.5\n90.3\n2020\n82.8\n2012\n28\n\n\n31-Aug\n86.5\n91.3\n2020\n83.3\n2006\n87.4\n84.4\n2000\n92.5\n2020\n85.6\n90.1\n2020\n82.2\n2006\n27\n\n\n01-Sep\n86.8\n91.6\n2020\n84.1\n2006\n87.7\n85.1\n2006\n92.7\n2020\n85.8\n90.5\n2020\n83.1\n2006\n27\n\n\n02-Sep\n86.8\n90.9\n2020\n84.3\n1995\n87.7\n84.9\n2003\n91.8\n2020\n85.9\n90.1\n2020\n82.8\n1995\n27\n\n\n03-Sep\n86.6\n90.8\n2020\n83.3\n2018\n87.5\n84.6\n2018\n91.8\n2020\n85.7\n89.8\n2020\n82.0\n2018\n28\n\n\n04-Sep\n86.4\n90.6\n2020\n82.2\n2004\n87.4\n84.2\n2006\n91.6\n2020\n85.5\n89.6\n2020\n79.9\n2004\n28\n\n\n05-Sep\n86.4\n90.3\n2020\n79.6\n2004\n87.3\n80.2\n2004\n91.0\n2020\n85.5\n89.6\n2020\n79.0\n2004\n28\n\n\n06-Sep\n86.5\n90.0\n2021\n79.9\n2004\n87.4\n81.1\n2004\n91.0\n2021\n85.6\n88.9\n2021\n78.8\n2004\n26\n\n\n07-Sep\n86.3\n90.0\n2021\n80.6\n2004\n87.2\n81.0\n2004\n91.0\n2022\n85.5\n89.2\n2021\n80.1\n2004\n27\n\n\n08-Sep\n86.3\n90.2\n2021\n81.2\n2004\n87.2\n82.4\n2004\n90.7\n2021\n85.4\n89.6\n2021\n80.1\n2004\n27\n\n\n09-Sep\n86.3\n90.3\n2021\n82.6\n2004\n87.2\n84.2\n2004\n91.2\n2021\n85.4\n89.4\n2021\n81.0\n2004\n26\n\n\n10-Sep\n86.0\n90.5\n2021\n81.9\n2017\n86.9\n83.8\n2017\n91.4\n2021\n85.1\n89.6\n2021\n80.1\n2017\n26\n\n\n11-Sep\n86.1\n91.0\n2021\n80.8\n2017\n87.0\n81.9\n2017\n92.1\n2021\n85.2\n90.0\n2021\n79.7\n2017\n25\n\n\n12-Sep\n85.9\n90.4\n2021\n81.8\n2017\n86.8\n83.1\n2017\n91.0\n2021\n85.1\n89.8\n2021\n80.6\n2017\n26\n\n\n13-Sep\n85.8\n89.4\n2022\n82.8\n1994\n86.6\n83.8\n1994\n90.1\n2022\n84.9\n88.7\n2022\n81.7\n1994\n26\n\n\n14-Sep\n85.7\n89.2\n2021\n81.4\n1994\n86.6\n81.9\n1994\n90.1\n2016\n84.8\n88.2\n2021\n80.8\n2001\n27\n\n\n15-Sep\n85.6\n90.0\n2021\n81.2\n2001\n86.5\n81.9\n2001\n91.0\n2021\n84.8\n88.9\n2021\n80.4\n1994\n26\n\n\n16-Sep\n85.7\n90.6\n2016\n81.7\n2001\n86.7\n82.6\n1998\n91.8\n2016\n84.7\n89.4\n2016\n80.6\n2001\n27\n\n\n17-Sep\n85.7\n90.8\n2016\n81.5\n2001\n86.7\n82.2\n1998\n91.8\n2016\n84.8\n89.8\n2016\n79.9\n2001\n27\n\n\n18-Sep\n85.8\n90.4\n2016\n82.0\n1998\n86.7\n82.6\n1998\n91.8\n2016\n84.9\n89.1\n2016\n81.5\n1998\n27\n\n\n19-Sep\n85.8\n90.0\n2016\n82.4\n1998\n86.6\n82.9\n1998\n91.2\n2016\n85.0\n89.1\n2021\n81.9\n2001\n26\n\n\n20-Sep\n85.8\n90.4\n2021\n82.8\n2001\n86.7\n83.5\n2001\n91.4\n2021\n84.9\n89.4\n2021\n82.0\n2001\n27\n\n\n21-Sep\n85.6\n90.1\n2016\n82.5\n1999\n86.5\n83.3\n1999\n90.9\n2016\n84.8\n89.4\n2021\n81.7\n1999\n27\n\n\n22-Sep\n85.6\n90.8\n2016\n82.0\n1999\n86.4\n82.9\n1999\n91.4\n2016\n84.8\n90.1\n2016\n81.1\n1999\n26\n\n\n23-Sep\n85.5\n90.8\n2016\n81.8\n2004\n86.3\n82.9\n2004\n91.6\n2016\n84.7\n90.1\n2016\n80.6\n2004\n27\n\n\n24-Sep\n85.4\n90.9\n2016\n81.8\n2004\n86.2\n82.4\n1999\n91.6\n2016\n84.6\n90.3\n2016\n80.8\n2004\n26\n\n\n25-Sep\n85.2\n90.7\n2016\n80.4\n2004\n86.1\n81.5\n1999\n91.6\n2016\n84.4\n89.8\n2016\n79.3\n2004\n26\n\n\n26-Sep\n85.0\n90.5\n2016\n79.5\n2004\n85.8\n80.2\n2004\n91.0\n2016\n84.2\n90.0\n2016\n78.8\n2004\n27\n\n\n27-Sep\n84.9\n89.4\n2016\n80.0\n2004\n85.7\n81.1\n2004\n90.5\n2016\n84.0\n88.3\n2016\n79.0\n2004\n27\n\n\n28-Sep\n84.8\n88.5\n2016\n81.0\n2004\n85.6\n81.9\n2004\n89.2\n2016\n84.0\n87.8\n2016\n80.1\n2004\n26\n\n\n29-Sep\n84.7\n88.9\n2016\n81.4\n2022\n85.5\n81.9\n2022\n89.8\n2016\n84.0\n88.0\n2016\n81.0\n2004\n27\n\n\n30-Sep\n84.7\n89.3\n2016\n80.8\n2022\n85.6\n81.5\n2001\n90.1\n2016\n83.9\n88.5\n2016\n79.9\n2022\n27\n\n\n01-Oct\n84.7\n88.5\n2016\n80.7\n1994\n85.5\n81.3\n1994\n89.4\n2016\n83.9\n87.6\n2016\n79.7\n2001\n27\n\n\n02-Oct\n84.4\n88.4\n2016\n80.3\n2001\n85.3\n81.3\n2001\n89.1\n2016\n83.5\n87.6\n2016\n79.3\n2001\n27\n\n\n03-Oct\n84.1\n88.2\n2016\n79.8\n2001\n84.9\n80.6\n2001\n89.1\n2016\n83.2\n87.4\n2016\n79.0\n2001\n26\n\n\n04-Oct\n83.9\n88.5\n2016\n80.2\n2001\n84.7\n81.3\n2001\n89.2\n2016\n83.1\n87.8\n2016\n79.0\n2001\n26\n\n\n05-Oct\n83.8\n89.0\n2016\n81.0\n2001\n84.7\n81.9\n2001\n89.8\n2016\n82.9\n88.3\n2016\n80.1\n2001\n25\n\n\n06-Oct\n83.7\n87.7\n2016\n79.9\n2010\n84.5\n81.0\n2010\n88.7\n2016\n82.9\n86.7\n2016\n78.8\n2010\n25\n\n\n07-Oct\n83.6\n87.2\n2021\n78.5\n2010\n84.3\n79.5\n2010\n88.2\n2021\n82.8\n86.2\n2009\n77.5\n2010\n26\n\n\n08-Oct\n83.7\n87.6\n2021\n78.7\n2010\n84.5\n79.9\n2010\n88.3\n2009\n82.9\n86.9\n2021\n77.5\n2010\n26\n\n\n09-Oct\n83.6\n87.6\n2016\n79.1\n2010\n84.4\n80.1\n2010\n88.3\n2021\n82.8\n86.9\n2016\n78.1\n2010\n26\n\n\n10-Oct\n83.5\n87.4\n2009\n79.5\n2010\n84.5\n80.6\n2010\n88.2\n2009\n82.6\n86.5\n2009\n78.4\n2010\n26\n\n\n11-Oct\n83.3\n87.3\n2021\n77.8\n2000\n84.1\n78.8\n2000\n88.2\n2021\n82.6\n86.5\n2009\n76.8\n2000\n26\n\n\n12-Oct\n83.3\n87.3\n2020\n78.0\n2000\n84.1\n79.2\n2000\n88.2\n2020\n82.6\n86.4\n2020\n76.8\n2000\n26\n\n\n13-Oct\n83.3\n87.7\n2021\n77.6\n2000\n84.1\n78.6\n2000\n88.7\n2021\n82.5\n86.7\n2021\n76.6\n2000\n26\n\n\n14-Oct\n83.2\n87.9\n2021\n76.9\n2000\n84.2\n78.1\n2000\n88.7\n2021\n82.3\n87.1\n2021\n75.7\n2000\n26\n\n\n15-Oct\n83.0\n87.6\n2021\n77.1\n2000\n83.9\n78.1\n2000\n88.2\n2021\n82.1\n87.1\n2021\n76.1\n2000\n26\n\n\n16-Oct\n82.5\n87.5\n2016\n77.2\n2000\n83.6\n78.4\n2000\n93.0\n2016\n81.5\n86.7\n2021\n76.1\n2000\n25\n\n\n17-Oct\n81.9\n87.6\n2021\n77.6\n2000\n82.7\n78.8\n2000\n88.5\n2021\n81.1\n86.7\n2021\n76.3\n2000\n25\n\n\n18-Oct\n81.4\n86.4\n2021\n78.0\n2000\n82.3\n79.0\n2011\n87.4\n2021\n80.4\n85.5\n2021\n76.6\n2000\n26\n\n\n19-Oct\n81.0\n84.8\n2018\n77.2\n2009\n82.0\n78.6\n2011\n86.0\n2018\n80.1\n83.7\n2021\n74.6\n2009\n25\n\n\n20-Oct\n81.1\n84.8\n2018\n78.0\n2011\n82.0\n79.0\n2011\n86.2\n2018\n80.2\n83.5\n2016\n76.3\n2009\n25\n\n\n21-Oct\n81.3\n85.2\n2018\n77.0\n2011\n82.1\n77.9\n2011\n86.0\n2018\n80.4\n84.4\n2018\n76.1\n2011\n25\n\n\n22-Oct\n81.1\n84.4\n2016\n76.4\n2011\n82.0\n77.5\n2011\n85.6\n2016\n80.2\n83.3\n2016\n75.2\n2011\n25\n\n\n23-Oct\n80.9\n84.0\n2013\n77.2\n2011\n81.8\n78.3\n2011\n84.7\n2013\n80.0\n83.3\n2013\n76.1\n2011\n25\n\n\n24-Oct\n80.6\n84.1\n2021\n77.1\n2000\n81.6\n77.9\n2000\n84.9\n2021\n79.6\n83.3\n2021\n76.3\n2000\n24\n\n\n25-Oct\n80.1\n85.0\n2021\n76.0\n2005\n81.2\n77.5\n2005\n85.6\n2021\n79.0\n84.4\n2021\n74.5\n2005\n24\n\n\n26-Oct\n79.9\n86.0\n2021\n74.0\n2005\n80.9\n75.0\n2005\n87.4\n2021\n79.0\n84.6\n2021\n73.0\n2005\n23\n\n\n27-Oct\n79.9\n86.4\n2021\n73.2\n2005\n80.9\n74.3\n2005\n87.4\n2021\n78.9\n85.5\n2021\n72.1\n2005\n24\n\n\n28-Oct\n79.7\n86.9\n2021\n74.2\n2005\n80.8\n75.6\n2005\n87.8\n2021\n78.7\n86.0\n2021\n72.9\n2005\n24\n\n\n29-Oct\n79.6\n86.1\n2021\n74.8\n2012\n80.7\n75.9\n2001\n86.9\n2021\n78.6\n85.3\n2021\n73.8\n2005\n25\n\n\n30-Oct\n79.5\n85.6\n2020\n73.5\n2012\n80.4\n74.3\n2012\n86.7\n2020\n78.6\n84.6\n2020\n72.7\n2012\n25\n\n\n31-Oct\n79.4\n85.7\n2020\n73.8\n2012\n80.3\n75.2\n2001\n86.5\n2020\n78.4\n84.9\n2020\n71.8\n2012\n24\n\n\n01-Nov\n79.5\n85.0\n2020\n74.6\n2012\n80.5\n75.9\n2001\n85.8\n2020\n78.6\n84.2\n2020\n72.1\n2012\n25\n\n\n02-Nov\n79.5\n83.6\n2020\n74.4\n2014\n80.5\n76.1\n2014\n85.5\n2020\n78.5\n82.8\n2021\n72.5\n2012\n25\n\n\n03-Nov\n79.2\n83.6\n2009\n74.3\n2014\n80.2\n76.3\n2014\n84.3\n2009\n78.2\n82.8\n2009\n72.3\n2014\n24\n\n\n04-Nov\n78.9\n83.2\n2009\n74.4\n2014\n79.8\n76.5\n2001\n83.8\n2009\n77.9\n82.6\n2009\n72.3\n2014\n24\n\n\n05-Nov\n78.7\n82.7\n2016\n73.8\n2014\n79.8\n75.7\n2014\n83.7\n2016\n77.7\n81.7\n2015\n72.0\n2014\n25\n\n\n06-Nov\n78.6\n81.9\n2016\n74.2\n2010\n79.7\n76.1\n2010\n83.8\n1998\n77.4\n81.1\n2016\n72.3\n2010\n24\n\n\n07-Nov\n78.3\n82.3\n2015\n72.6\n2010\n79.4\n75.4\n2014\n83.3\n2015\n77.2\n81.3\n2015\n69.6\n2010\n24\n\n\n08-Nov\n78.2\n82.6\n2015\n73.4\n2010\n79.2\n75.6\n2001\n83.5\n2015\n77.2\n81.7\n2015\n71.1\n2010\n24\n\n\n09-Nov\n77.9\n82.8\n2015\n73.0\n2010\n78.9\n74.8\n2010\n83.8\n2015\n76.8\n81.9\n2015\n71.2\n2010\n25\n\n\n10-Nov\n77.9\n83.2\n2015\n73.1\n2010\n78.9\n74.8\n2010\n84.0\n2015\n76.9\n82.4\n2015\n71.4\n2010\n25\n\n\n11-Nov\n77.7\n83.4\n2015\n73.2\n2012\n78.6\n74.7\n2012\n84.2\n2015\n76.8\n82.6\n2015\n71.8\n2012\n26\n\n\n12-Nov\n77.7\n83.3\n2015\n74.0\n1996\n78.6\n75.0\n2011\n84.0\n2015\n76.8\n82.6\n2015\n72.0\n2012\n26\n\n\n13-Nov\n77.6\n83.4\n2015\n73.6\n1996\n78.6\n74.7\n1996\n84.0\n2015\n76.7\n82.9\n2015\n72.5\n1996\n26\n\n\n14-Nov\n77.6\n83.0\n2018\n73.7\n1996\n78.6\n75.4\n1996\n83.7\n2018\n76.6\n82.2\n2018\n72.0\n1996\n26\n\n\n15-Nov\n77.4\n83.0\n2016\n73.6\n1995\n78.4\n75.2\n1995\n83.7\n2018\n76.4\n82.4\n2016\n72.1\n1995\n26\n\n\n16-Nov\n76.9\n82.6\n2020\n72.6\n1995\n77.8\n74.1\n1996\n83.3\n2016\n76.0\n82.0\n2020\n70.5\n1995\n26\n\n\n17-Nov\n76.8\n82.4\n2020\n72.8\n1996\n78.0\n74.1\n1995\n83.1\n2020\n75.7\n81.7\n2020\n71.4\n1996\n26\n\n\n18-Nov\n76.7\n80.6\n2016\n72.2\n1996\n77.8\n73.4\n1996\n82.0\n2020\n75.6\n79.5\n2016\n71.1\n1996\n26\n\n\n19-Nov\n76.6\n81.0\n2016\n72.6\n1996\n77.8\n73.9\n1996\n82.4\n2016\n75.5\n79.5\n2016\n71.2\n1996\n26\n\n\n20-Nov\n76.8\n81.2\n2016\n73.6\n2004\n77.9\n74.7\n1999\n83.1\n2016\n75.8\n79.3\n2015\n71.6\n1996\n26\n\n\n21-Nov\n76.8\n80.9\n2016\n74.1\n1996\n77.8\n75.2\n2004\n82.6\n2016\n75.8\n79.5\n2021\n72.7\n1996\n26\n\n\n22-Nov\n76.8\n81.4\n2021\n73.1\n2000\n77.9\n75.0\n2010\n83.3\n2016\n75.6\n80.4\n2021\n70.5\n2000\n26\n\n\n23-Nov\n76.6\n80.4\n2021\n72.1\n2000\n77.7\n73.4\n2000\n81.9\n2021\n75.6\n79.0\n2016\n70.7\n2000\n26\n\n\n24-Nov\n76.5\n80.7\n2016\n70.8\n2000\n77.6\n72.0\n2000\n82.4\n1999\n75.4\n79.5\n2016\n69.6\n2000\n26\n\n\n25-Nov\n76.1\n80.7\n2016\n71.4\n2000\n77.0\n72.5\n2000\n81.9\n2016\n75.2\n79.5\n2016\n70.3\n2000\n26\n\n\n26-Nov\n76.0\n81.1\n2016\n71.8\n2012\n77.0\n72.7\n2012\n82.2\n2016\n75.1\n79.9\n2016\n70.3\n1995\n26\n\n\n27-Nov\n76.0\n81.2\n2016\n72.1\n2012\n77.1\n72.9\n2012\n82.4\n2016\n74.9\n80.1\n2016\n71.2\n2012\n25\n\n\n28-Nov\n75.7\n81.0\n2022\n72.3\n2000\n76.9\n73.6\n1996\n82.0\n2016\n74.4\n80.1\n2022\n70.3\n2000\n26\n\n\n29-Nov\n75.5\n80.6\n2022\n72.1\n2014\n76.7\n73.4\n2014\n81.3\n2016\n74.3\n79.9\n2022\n70.7\n1996\n25\n\n\n30-Nov\n75.4\n80.7\n2016\n71.0\n1996\n76.5\n71.8\n1996\n81.5\n2016\n74.3\n79.9\n2016\n70.0\n2014\n24\n\n\n01-Dec\n75.3\n81.5\n2016\n70.4\n1996\n76.4\n71.2\n1996\n82.4\n2016\n74.2\n80.6\n2016\n69.6\n1996\n25\n\n\n02-Dec\n75.2\n82.6\n2016\n71.7\n1996\n76.4\n72.7\n1996\n83.1\n2016\n74.0\n82.0\n2016\n70.0\n1999\n25\n\n\n03-Dec\n75.2\n82.4\n2016\n71.1\n1999\n76.4\n72.7\n1999\n83.1\n2016\n74.1\n81.7\n2016\n69.4\n1999\n25\n\n\n04-Dec\n75.2\n82.0\n2016\n69.4\n1999\n76.1\n70.0\n1999\n82.6\n2016\n74.2\n81.5\n2016\n68.9\n1999\n25\n\n\n05-Dec\n75.2\n82.4\n2016\n69.4\n1999\n76.1\n69.8\n1999\n83.1\n2016\n74.2\n81.7\n2016\n68.9\n1999\n25\n\n\n06-Dec\n75.1\n82.8\n2016\n69.9\n2010\n76.3\n71.1\n1999\n83.7\n2016\n74.0\n82.0\n2016\n68.2\n2010\n25\n\n\n07-Dec\n75.2\n83.9\n2016\n68.2\n2010\n76.3\n70.9\n2010\n84.6\n2016\n74.0\n83.3\n2016\n65.5\n2010\n26\n\n\n08-Dec\n75.2\n84.6\n2016\n67.4\n2010\n76.2\n70.5\n2010\n85.1\n2016\n74.2\n84.0\n2016\n64.4\n2010\n26\n\n\n09-Dec\n75.1\n83.6\n2016\n67.6\n2010\n76.3\n70.0\n2003\n84.6\n2016\n74.0\n82.6\n2016\n64.9\n2010\n26\n\n\n10-Dec\n75.1\n81.8\n2016\n68.7\n2010\n76.2\n70.0\n2003\n82.6\n2016\n73.9\n81.1\n2016\n65.3\n2010\n26\n\n\n11-Dec\n75.1\n81.5\n2021\n68.8\n2003\n76.2\n70.0\n2003\n82.2\n2021\n74.0\n80.8\n2021\n66.9\n2010\n26\n\n\n12-Dec\n74.8\n81.7\n2021\n69.1\n1996\n75.9\n69.8\n1996\n82.6\n2021\n73.7\n80.8\n2021\n67.3\n2010\n26\n\n\n13-Dec\n74.7\n82.6\n2016\n67.6\n2010\n75.8\n70.9\n2010\n83.5\n2016\n73.6\n81.7\n2016\n64.4\n2010\n26\n\n\n14-Dec\n74.6\n83.3\n2016\n66.3\n2010\n75.7\n69.8\n2010\n84.0\n2016\n73.5\n82.6\n2016\n62.8\n2010\n26\n\n\n15-Dec\n74.1\n83.3\n2016\n65.8\n2010\n75.5\n69.3\n2010\n84.0\n2016\n72.6\n82.6\n2016\n62.2\n2010\n25\n\n\n16-Dec\n74.1\n82.8\n2016\n63.7\n2010\n75.2\n65.3\n2010\n83.7\n2016\n73.0\n81.9\n2016\n62.1\n2010\n25\n\n\n17-Dec\n74.1\n82.2\n2016\n65.0\n2010\n75.2\n68.0\n2010\n82.9\n2016\n73.0\n81.5\n2016\n62.1\n2010\n25\n\n\n18-Dec\n74.0\n82.4\n2016\n65.3\n2010\n75.2\n68.0\n2010\n83.1\n2016\n72.8\n81.7\n2016\n62.6\n2010\n26\n\n\n19-Dec\n73.8\n83.1\n2016\n67.1\n2010\n75.1\n68.9\n1997\n83.8\n2016\n72.5\n82.4\n2016\n63.7\n2010\n26\n\n\n20-Dec\n73.3\n83.2\n2016\n67.1\n2003\n74.5\n68.5\n1997\n83.8\n2016\n72.2\n82.6\n2016\n65.1\n2003\n26\n\n\n21-Dec\n72.9\n83.4\n2016\n65.8\n2003\n74.2\n68.7\n2003\n84.0\n2016\n71.6\n82.8\n2016\n63.0\n2003\n25\n\n\n22-Dec\n72.6\n83.0\n2016\n66.8\n2003\n73.9\n69.1\n2004\n83.7\n2016\n71.3\n82.2\n2016\n64.4\n2003\n26\n\n\n23-Dec\n72.7\n83.2\n2016\n67.8\n2010\n74.1\n69.4\n2004\n83.8\n2016\n71.4\n82.6\n2016\n64.9\n2003\n26\n\n\n24-Dec\n72.7\n83.0\n2016\n67.3\n2003\n74.1\n69.1\n2003\n83.7\n2016\n71.4\n82.2\n2016\n65.5\n2003\n25\n\n\n25-Dec\n72.6\n82.8\n2016\n66.4\n2003\n73.9\n67.3\n2003\n83.5\n2016\n71.4\n82.0\n2016\n63.3\n1995\n26\n\n\n26-Dec\n72.4\n82.3\n2016\n66.6\n2010\n73.7\n68.7\n2010\n82.9\n2016\n71.1\n81.7\n2016\n64.0\n1995\n25\n\n\n27-Dec\n72.1\n81.8\n2016\n65.8\n1995\n73.4\n67.8\n1995\n82.6\n2016\n70.8\n81.1\n2016\n63.0\n2010\n26\n\n\n28-Dec\n72.3\n82.2\n2016\n65.2\n2010\n73.7\n67.1\n1995\n82.9\n2016\n71.0\n81.5\n2016\n62.2\n2010\n26\n\n\n29-Dec\n72.4\n82.6\n2016\n66.6\n1995\n73.8\n69.4\n2003\n83.3\n2016\n71.0\n81.9\n2016\n62.2\n2010\n26\n\n\n30-Dec\n72.4\n81.9\n2016\n66.4\n2010\n73.8\n68.4\n2010\n83.1\n2016\n71.1\n80.8\n2016\n64.4\n2010\n26\n\n\n31-Dec\n72.4\n80.5\n2021\n66.1\n2010\n73.6\n67.8\n2010\n81.7\n2021\n71.2\n79.3\n2021\n64.4\n2010\n26\n\n\n\n\n\n\n        \n\n\n\n\n\n\nAir TemperatureWater LevelWater Temperature\n\n\n\n\n\n\n\n\nMonth\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\nJan\n68.9\n74.3\n1994\n63.0\n2001\n76.1\n73.0\n2011\n78.7\n2016\n56.1\n71.6\n1994\n48.3\n1997\n23\n\n\nFeb\n70.7\n74.9\n2018\n62.7\n2010\n76.2\n73.8\n2010\n78.6\n2021\n59.9\n71.8\n2003\n47.9\n1996\n23\n\n\nMar\n72.3\n77.6\n2003\n66.1\n2010\n78.5\n74.2\n2010\n82.8\n2003\n63.6\n72.0\n1997\n55.1\n1996\n24\n\n\nApr\n75.5\n79.5\n2002\n71.4\n2005\n80.5\n75.9\n2005\n85.8\n2020\n68.4\n77.1\n2002\n61.2\n2009\n24\n\n\nMay\n78.5\n81.9\n2024\n74.8\n2001\n82.3\n79.4\n2007\n87.2\n2024\n73.8\n77.1\n2003\n67.9\n1999\n22\n\n\nJun\n81.2\n83.6\n2010\n78.7\n2002\n84.4\n82.0\n2002\n87.6\n2009\n77.4\n80.8\n2004\n74.6\n2007\n21\n\n\nJul\n82.9\n85.0\n2023\n81.0\n2013\n85.8\n84.2\n2012\n88.7\n2018\n79.1\n82.3\n2022\n76.1\n2013\n26\n\n\nAug\n83.2\n85.9\n2022\n81.8\n1996\n85.7\n84.0\n2003\n88.5\n2022\n79.5\n83.6\n2022\n76.1\n1996\n25\n\n\nSep\n82.2\n86.4\n2022\n80.6\n2001\n85.3\n82.8\n1997\n89.4\n2022\n78.6\n83.8\n2022\n74.3\n2001\n25\n\n\nOct\n79.6\n81.2\n2020\n77.6\n2000\n83.5\n80.0\n1997\n86.8\n2023\n73.2\n78.5\n1997\n64.6\n2005\n23\n\n\nNov\n74.9\n78.6\n2015\n71.4\n2012\n79.8\n76.9\n2012\n82.0\n2020\n66.0\n74.4\n2020\n57.4\n2006\n23\n\n\nDec\n71.4\n76.9\n2015\n62.1\n2010\n77.4\n72.5\n2010\n79.6\n1994\n59.6\n70.5\n2015\n48.8\n2010\n24\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\nMonth\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\nJan\n-1.12\n-0.53\n2022\n-1.56\n2002\n-0.71\n-1.33\n2009\n0.02\n2020\n-1.51\n-0.8\n2022\n-2.02\n2001\n26\n\n\nFeb\n-1.14\n-0.7\n2024\n-1.63\n2003\n-0.72\n-1.29\n2011\n-0.15\n2024\n-1.51\n-1.11\n2015\n-2.02\n2008\n26\n\n\nMar\n-1.09\n-0.5\n2019\n-1.47\n1996\n-0.7\n-1.15\n2008\n-0.06\n2019\n-1.45\n-0.96\n2019\n-2.0\n1996\n27\n\n\nApr\n-1.0\n-0.5\n2023\n-1.37\n2001\n-0.66\n-1.19\n2001\n-0.01\n2023\n-1.36\n-0.88\n2017\n-1.81\n2004\n27\n\n\nMay\n-0.95\n-0.51\n2022\n-1.33\n1996\n-0.6\n-1.1\n2004\n0.43\n2022\n-1.27\n-0.79\n2024\n-1.61\n2011\n27\n\n\nJun\n-0.99\n-0.5\n2023\n-1.4\n1996\n-0.69\n-1.13\n2001\n-0.04\n2023\n-1.3\n-0.81\n2024\n-1.83\n2006\n27\n\n\nJul\n-1.01\n-0.69\n2019\n-1.33\n1996\n-0.68\n-1.04\n1996\n-0.19\n2019\n-1.34\n-1.09\n2019\n-1.72\n1998\n28\n\n\nAug\n-0.87\n-0.42\n2019\n-1.27\n1996\n-0.44\n-0.99\n2001\n0.01\n2014\n-1.24\n-0.76\n2019\n-1.61\n1996\n29\n\n\nSep\n-0.53\n-0.02\n2019\n-1.05\n1996\n0.01\n-0.67\n1996\n1.9\n2017\n-0.97\n-0.52\n2008\n-1.4\n2004\n29\n\n\nOct\n-0.37\n0.18\n2023\n-1.07\n1997\n0.12\n-1.01\n1997\n0.79\n1999\n-0.83\n-0.1\n2023\n-1.59\n2010\n26\n\n\nNov\n-0.55\n0.09\n2023\n-1.2\n1997\n-0.02\n-0.7\n1997\n0.88\n2022\n-1.0\n-0.28\n2022\n-1.58\n1998\n27\n\n\nDec\n-0.93\n-0.3\n2022\n-1.34\n2008\n-0.49\n-1.03\n2008\n0.48\n2023\n-1.31\n-0.65\n2022\n-1.71\n2004\n27\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\nMonth\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\nJan\n71.7\n78.9\n2017\n67.5\n2001\n75.5\n70.5\n2011\n81.7\n2017\n67.9\n75.9\n2017\n64.0\n2003\n24\n\n\nFeb\n73.0\n80.3\n2017\n67.7\n2005\n76.9\n73.6\n2010\n82.2\n2017\n69.2\n76.8\n2017\n63.2\n2005\n21\n\n\nMar\n75.0\n80.0\n2003\n69.2\n2010\n79.2\n73.3\n2010\n83.2\n2021\n71.0\n75.4\n1997\n64.8\n2010\n25\n\n\nApr\n78.4\n83.4\n2020\n75.1\n2004\n81.8\n78.4\n2010\n85.8\n2020\n74.7\n81.1\n2020\n69.4\n2003\n25\n\n\nMay\n82.0\n84.8\n2024\n78.6\n2001\n85.1\n82.5\n2018\n88.6\n2024\n78.1\n80.4\n1994\n74.1\n2001\n24\n\n\nJun\n85.2\n87.6\n2010\n83.3\n2002\n87.8\n84.8\n1999\n90.4\n2010\n82.3\n85.2\n2004\n80.0\n2014\n24\n\n\nJul\n87.2\n89.5\n2023\n84.5\n2013\n89.2\n86.4\n2013\n92.0\n2021\n84.6\n87.4\n2016\n80.9\n2013\n26\n\n\nAug\n87.3\n90.1\n2021\n85.4\n1995\n89.4\n87.2\n2000\n92.2\n2021\n84.3\n87.2\n2021\n81.0\n2012\n26\n\n\nSep\n85.7\n89.5\n2021\n82.7\n2004\n88.0\n84.4\n2006\n91.6\n2020\n83.1\n87.1\n2021\n79.5\n2004\n25\n\n\nOct\n82.2\n85.9\n2021\n79.6\n2000\n85.5\n82.7\n2004\n89.0\n2016\n78.2\n83.4\n2021\n73.2\n2005\n23\n\n\nNov\n77.3\n81.5\n2016\n74.6\n2012\n80.5\n76.3\n1997\n85.0\n2020\n74.2\n80.0\n2016\n70.8\n2000\n24\n\n\nDec\n73.9\n82.5\n2016\n68.2\n2010\n77.5\n73.0\n2003\n84.6\n2016\n70.1\n79.6\n2016\n63.7\n2010\n24"
  },
  {
    "objectID": "content/stations/virginiakey/index.html#row-1",
    "href": "content/stations/virginiakey/index.html#row-1",
    "title": "Virginia Key, FL",
    "section": "Row",
    "text": "Row\n\n\nAir TemperatureWater LevelWater Temperature\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n\n\n\n\nAir TemperatureWater LevelWater Temperature"
  },
  {
    "objectID": "content/stations/virginiakey/index.html#row-.height50",
    "href": "content/stations/virginiakey/index.html#row-.height50",
    "title": "````",
    "section": "Row {.height=50%}",
    "text": "Row {.height=50%}\n\nvar = 'Air Temperature'\ndict(\n  icon = \"thermometer-snow\",\n  color = colsdict['RecordLow'],\n  value = getval(var, 'Record Low', 'daily')\n)\n\n{'icon': 'thermometer-snow', 'color': '#74a0ef', 'value': '72.3 °F'}\n\n\n\ndict(\n  icon = \"thermometer-low\",\n  color = colsdict['AvgLow'],\n  value = getval(var, 'Average Low', 'daily')\n)\n\n{'icon': 'thermometer-low', 'color': '#a2bff4', 'value': '77.4 °F'}\n\n\n\ndict(\n  icon = \"thermometer-half\",\n  color = colsdict['HighestLow'],\n  value = getval(var, 'Highest Low', 'daily')\n)\n\n{'icon': 'thermometer-half', 'color': '#d1dffa', 'value': '82.0 °F'}\n\n\n\ndict(\n  icon = \"thermometer-half\",\n  color = colsdict['LowestHigh'],\n  value = getval(var, 'Lowest High', 'daily')\n)\n\n{'icon': 'thermometer-half', 'color': '#e6aeae', 'value': '79.9 °F'}\n\n\n\ndict(\n  icon = \"thermometer-high\",\n  color = colsdict['AvgHigh'],\n  value = getval(var, 'Average High', 'daily')\n)\n\n{'icon': 'thermometer-high', 'color': '#dc8d8d', 'value': '83.4 °F'}\n\n\n\ndict(\n  icon = \"thermometer-sun\",\n  color = colsdict['RecordHigh'],\n  value = getval(var, 'Record High', 'daily')\n)\n\n{'icon': 'thermometer-sun', 'color': '#d26c6c', 'value': '88.9 °F'}"
  },
  {
    "objectID": "content/stations/virginiakey/index.html#row-2",
    "href": "content/stations/virginiakey/index.html#row-2",
    "title": "````",
    "section": "Row",
    "text": "Row\n\ntoday = datetime.today().strftime('%d-%b')\nMarkdown(\"**Welcome!** Today is {}.\"\n    .format(datetime.today().strftime(\"%A, %B %d, %Y\")))\n\nWelcome! Today is Tuesday, June 11, 2024."
  },
  {
    "objectID": "content/stations/virginiakey/index.html#row-3",
    "href": "content/stations/virginiakey/index.html#row-3",
    "title": "````",
    "section": "Row",
    "text": "Row\n\nColumn\n\nRow\n\nvar = 'Air Temperature'\ndict(\n  icon = \"thermometer-sun\",\n  color = colsdict['RecordHigh'],\n  value = getval(var, 'Record High', 'daily')\n)\n\n{'icon': 'thermometer-sun', 'color': '#d26c6c', 'value': '87.6 °F'}\n\n\n\n\nRow\n\ndict(\n  icon = \"thermometer-high\",\n  color = colsdict['AvgHigh'],\n  value = getval(var, 'Average High', 'daily')\n)\n\n{'icon': 'thermometer-high', 'color': '#dc8d8d', 'value': '83.9 °F'}\n\n\n\n\nRow\n\ndict(\n  icon = \"thermometer-half\",\n  color = colsdict['LowestHigh'],\n  value = getval(var, 'Lowest High', 'daily')\n)\n\n{'icon': 'thermometer-half', 'color': '#e6aeae', 'value': '80.6 °F'}\n\n\n\n\nRow\n\ndict(\n  icon = \"thermometer-half\",\n  color = colsdict['HighestLow'],\n  value = getval(var, 'Highest Low', 'daily')\n)\n\n{'icon': 'thermometer-half', 'color': '#d1dffa', 'value': '82.0 °F'}\n\n\n\n\nRow\n\ndict(\n  icon = \"thermometer-snow\",\n  color = colsdict['RecordLow'],\n  value = getval(var, 'Record Low', 'daily')\n)\n\n{'icon': 'thermometer-snow', 'color': '#74a0ef', 'value': '72.0 °F'}\n\n\n\n\n\nColumn\n\ndisplay(Markdown('::: {.panel-tabset}'))\n\nfor var in daily_stats.variable.values:\n    display(Markdown(f'\\n## {var}\\n\\n'))\n    daily_climo(data=daily_stats, var=var, scheme='cb')\n    display(Markdown(' '))\n\ndisplay(Markdown(':::'))\n\nAir TemperatureWater Temperature\n\n\n                                                \n\n\n                                                \n\n\n\n\n\ndisplay(Markdown('::: {.panel-tabset}'))\n\nfor var in daily_stats.variable.values:\n    display(Markdown(f'\\n## {var}\\n\\n'))\n    display(Markdown('Plot'))\n    display(Markdown(' '))\n\ndisplay(Markdown(':::'))\n\nAir TemperatureWater Temperature\n\n\nPlot\n\n\nPlot"
  },
  {
    "objectID": "content/stations/virginiakey/index.html#tabset-2-1",
    "href": "content/stations/virginiakey/index.html#tabset-2-1",
    "title": "Climatology",
    "section": "Row",
    "text": "Row\n\nDaily Stats\n\n\n\nAir TemperatureWater Temperature\n\n\n                                                \n\n\n                                                \n\n\n\n\n\n\n    \n    \n        \n    \n\n\nMonthly Stats\n\n\n\n\n\nAir\n\nTemperature\n\n                                                \n\nWater\n\nTemperature"
  },
  {
    "objectID": "content/stations/virginiakey/index.html#row-9",
    "href": "content/stations/virginiakey/index.html#row-9",
    "title": "````",
    "section": "Row",
    "text": "Row\n\ndisplay(Markdown('::: {..column-screen}'))\ndisplay(Markdown('::: {.panel-tabset}'))\n\nfor var in daily_stats.variable.values:\n    display(Markdown(f'\\n## {var}\\n\\n'))\n    display_table(daily_stats, var)\n    display(Markdown(' '))\n\ndisplay(Markdown(':::'))\ndisplay(Markdown(':::'))\n\n\nAir TemperatureWater Temperature\n\n\n                                                \n\n\n                                                \n\n\n\n\n\n\ndisplay(Markdown('::: {.panel-tabset}'))\n\nfor var in daily_stats.variable.values:\n    display(Markdown(f'\\n## {var}\\n\\n'))\n    display_table(monthly_stats, var)\n    display(Markdown(' '))\n\ndisplay(Markdown(':::'))\n\nAir TemperatureWater Temperature\n\n\n                                                \n\n\n                                                \n\n\n\n\n````"
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "How are these statistics calculated?",
    "section": "",
    "text": "All data from the beginning of each time series to the present are retrieved from the NOAA CO-OPS Tides and Currents data portal using a noaa-coops utility and saved to file to avoid having to repeatedly re-download the historical data. Subsequent data updates retrieve from the most recently saved timestamp onward and append these new data to the saved historical record.\nSix-minute data are used whenever possible and hourly data otherwise.\nAny observations flagged by NOAA as being suspect for any reason (flag &gt; 0) are discarded. Examples of flagged data are a minimum or maximum value or a rate of change exceeding an acceptable tolerance. A day is allowed to have up to three hours of missing data to be counted in the daily climatologies, and a month is allowed up to two days of missing data to be counted in the monthly climatologies. Climatological statistics are calculated as follows.",
    "crumbs": [
      "Home",
      "Overview",
      "How are these statistics calculated?"
    ]
  },
  {
    "objectID": "NOAA-CO-OPS-Climatology.html",
    "href": "NOAA-CO-OPS-Climatology.html",
    "title": "Climatology",
    "section": "",
    "text": "from noaa_coops import Station\nimport datetime as dt\nimport pandas as pd\nimport xarray as xr\nimport numpy as np\nimport calendar\nimport yaml\nimport os\n\n\n\nclass Data:\n    def __init__(self, stationname, stationid, units='metric', timezone='gmt',\n                datum='MHHW', hr_threshold=3, day_threshold=2,\n                redownload=False, verbose=True):\n        \"\"\"Data class for downloading, formatting, and saving to file\n        historical atmospheric (air temperature, barometric pressure, wind) and\n        oceanographic (water temperature, water level) data from NOAA CO-OPS\n        coastal tide stations.\n        WARNING: This may take a while to initiate depending on the amount of\n        data to be retrieved.\n        \n        Inputs:\n            stationname: str, desired name of station. Does not need to be the\n                CO-OPS name; it is used only for saving data to file.\n            stationid: str, NOAA CO-OPS tide station number from which to\n                retrieve data\n            units: str, either 'metric' or 'english', indicating the units to\n                download data in. Defaults to 'metric'.\n            timezone: str, one of either 'gmt' for Greenwich Mean Time, 'lst'\n                for local standard time, or 'lst_ldt' for adjusted local\n                standard/daylight savings time. Defaults to 'gmt'.\n            datum: str, tidal datum for water level data. Options: 'STND',\n                'MHHW', 'MHW', 'MTL', 'MSL', 'MLW', 'MLLW', 'NAVD'. Defaults to\n                'MHHW'.\n            hr_threshold: int, maximum number of hours of data that can be\n                missing in a given day in order for that day to be included in\n                the historical record. Default is 3.\n            day_threshold: int, maximum number of days of data that can be\n                missing in a given month in order for that month to be included\n                in the historical record. Default is 2.\n            redownload: Bool, if True, historical data will be redownloaded and\n                the class instance will be re-initiated. Defaults to False.\n                WARNING: This may take a while to run depending on the amount\n                of data being retrieved.\n            verbose: Bool, print statuses to screen. Defaults to True.\n        \"\"\"\n        \n        self.name = stationname\n        self.dirname = self.camel(stationname)\n        self.id = stationid\n        self.unit_system = units.lower()\n        self.tz = timezone.lower()\n        self.datum = datum.upper()\n        self.hr_threshold = hr_threshold\n        self.day_threshold = day_threshold\n        self.verbose = verbose\n        self.variables = []\n        today = self._format_date(pd.to_datetime('today'))\n        \n        # Check for valid arguments\n        self._valid_units(self.unit_system)\n        self._valid_tz(self.tz)\n        self._valid_datum(self.datum)\n        \n        # Set out directory as a station subdirectory within the home directory\n        HOMEDIR = os.getcwd()\n        self.outdir = os.path.join(HOMEDIR, self.dirname)\n\n        # =====================================================================\n        # If 'redownload' argument is True OR if the directory station name\n        # subdirectory does not exist within 'outdir', then create that\n        # subdirectory and download historical data.\n        if not os.path.exists(self.outdir) or redownload:\n            if not os.path.exists(self.outdir):\n                if self.verbose:\n                    print('Creating new directory for this station.')\n                os.makedirs(self.outdir)\n        \n            # Download all data and save to file\n            self.download_data(start_date=None, end_date=None)\n            outFile = os.path.join(self.outdir,\n                                   'observational_data_record.csv.gz')\n            self.data.to_csv(outFile, compression='infer')\n            if self.verbose:\n                print(f\"Observational data written to file '{outFile}'.\")\n\n            # Store units\n            deg = u'\\N{DEGREE SIGN}'\n            self.unit_options = dict({\n                'Air Temperature': {'metric': deg+'C', 'english': deg+'F'},\n                'Barometric Pressure': {'metric': 'mb', 'english': 'mb'},\n                'Wind Speed': {'metric': 'm/s', 'english': 'kn'},\n                'Wind Gust': {'metric': 'm/s', 'english': 'kn'},\n                'Wind Direction': {'metric': 'deg', 'english': 'deg'},\n                'Water Temperature': {'metric': deg+'C', 'english': deg+'F'},\n                'Water Level': {'metric': 'm', 'english': 'ft'}\n            })\n            self.units = {k:v[self.unit_system] \\\n                          for k, v in self.unit_options.items() \\\n                          if k in self.variables}\n            \n            # Save class variables\n            self.meta = dict({\n                'stationname': self.name,\n                'stationid': self.id,\n                'dirname': self.dirname,\n                'unit_system': self.unit_system,\n                'tz': self.tz,\n                'datum': self.datum,\n                'hr_threshold': self.hr_threshold,\n                'day_threshold': self.day_threshold,\n                'variables': self.variables,\n                'units': self.units})\n            with open(os.path.join(self.outdir, 'metadata.yml'), 'w') as fp:\n                yaml.dump(self.meta, fp) \n                    \n            # Create and save statistics dictionaries\n            self.filtered_hours = \\\n                pd.concat([self._filter_hours(\n                                self.data[var],\n                                hr_threshold=self.meta['hr_threshold'])\n                           for var in self.variables], axis=1)\n            self.filtered_hours = self._DOY(self.filtered_hours)\n            self.filtered_days = \\\n                pd.concat([self._filter_days(\n                                self.data[var],\n                                hr_threshold=self.meta['hr_threshold'],\n                                day_threshold=self.meta['day_threshold'])\n                           for var in self.variables], axis=1)\n            self.filtered_days = self._DOY(self.filtered_days)\n            # Daily stats\n            self.daily_records = self.daily_stats()\n            statsOutFile = os.path.join(self.outdir, 'statistics-daily.nc')\n            self.daily_records.to_netcdf(statsOutFile, mode='w')\n            if self.verbose:\n                print(f\"Observational daily statistics written to '{statsOutFile}'\")\n            # Monthly stats\n            self.monthly_records = self.monthly_stats()\n            statsOutFile = os.path.join(self.outdir, 'statistics-monthly.nc')\n            self.monthly_records.to_netcdf(statsOutFile, mode='w')\n            if self.verbose:\n                print(f\"Observational monthly statistics written to '{statsOutFile}'\")\n\n        # =====================================================================\n        # If historical data for this station already exists:\n        else:\n            # Load the metadata from file\n            if self.verbose:\n                print('Loading metadata from file')\n            with open(os.path.join(self.outdir, 'metadata.yml')) as m:\n                self.meta = yaml.safe_load(m)\n            self._load_from_yaml(self.meta)\n            \n            # Load the historical data from file\n            if self.verbose:\n                print('Loading historical data from file')\n            dataInFile = os.path.join(self.outdir,\n                                    'observational_data_record.csv.gz')\n            self.data = pd.read_csv(dataInFile, index_col=f'time_{self.tz}',\n                                        parse_dates=True, compression='infer')\n                \n            # Load daily statistics from file\n            if self.verbose:\n                print('Loading daily statistics from file')\n            statsInFile = os.path.join(self.outdir, 'statistics-daily.nc')\n            with xr.open_dataset(statsInFile) as dds:\n                self.daily_records = dds.load()\n            \n            # Load monthly statistics from file\n            if self.verbose:\n                print('Loading monthly statistics from file')\n            statsInFile = os.path.join(self.outdir, 'statistics-monthly.nc')\n            with xr.open_dataset(statsInFile) as mds:\n                self.monthly_records = mds.load()\n            \n            # Clean and format\n            self.filtered_hours = \\\n                pd.concat([self._filter_hours(\n                                self.data[var],\n                                hr_threshold=self.meta['hr_threshold'])\n                           for var in self.variables], axis=1)\n            self.filtered_hours = self._DOY(self.filtered_hours)\n            self.filtered_days = \\\n                pd.concat([self._filter_days(\n                                self.data[var],\n                                hr_threshold=self.meta['hr_threshold'],\n                                day_threshold=self.meta['day_threshold'])\n                           for var in self.variables], axis=1)\n            self.filtered_days = self._DOY(self.filtered_days)\n        if self.verbose:\n            print('Done!')\n\n    # =========================================================================\n    def download_data(self, start_date=None, end_date=None):\n        \"\"\"Download data from NOAA CO-OPS\"\"\"\n        if self.verbose:\n            print('Downloading historic data')\n        \n        # NOAA CO-OPS API\n        self.station = Station(id=self.id)\n\n        # List of data variables to combine at the end\n        datasets = []\n\n        # If no 'end_date' is passed, download through current day\n        if not end_date:\n            end_date = self._format_date(\n                            pd.to_datetime('today') + pd.Timedelta(days=1))\n\n        # Air temperature\n        if 'Air Temperature' in self.station.data_inventory:\n            self.variables.append('Air Temperature')\n            if not start_date:\n                start_date = self._format_date(\n                    self.station.data_inventory['Air Temperature']['start_date'])\n            self._load_atemp(start_date=start_date, end_date=end_date)\n            self.air_temp['atemp_flag'] = self.air_temp['atemp_flag'].str\\\n                                              .split(',', expand=True)\\\n                                              .astype(int)\\\n                                              .sum(axis=1)\n            self.air_temp.loc[self.air_temp['atemp_flag']&gt;0, 'atemp'] = np.nan\n            datasets.append(self.air_temp['atemp'])\n\n        # Water temperature\n        if 'Water Temperature' in self.station.data_inventory:\n            self.variables.append('Water Temperature')\n            if not start_date:\n                start_date = self._format_date(\n                    self.station.data_inventory['Water Temperature']['start_date'])\n            self._load_water_temp(start_date=start_date, end_date=end_date)\n            self.water_temp['wtemp_flag'] = self.water_temp['wtemp_flag'].str\\\n                                                .split(',', expand=True)\\\n                                                .astype(int)\\\n                                                .sum(axis=1)\n            self.water_temp.loc[self.water_temp['wtemp_flag']&gt;0, 'wtemp'] = np.nan\n            datasets.append(self.water_temp['wtemp'])\n\n        # Water level (tides)\n        if 'Verified 6-Minute Water Level' in self.station.data_inventory:\n            self.variables.append('Water Level')\n            if not start_date:\n                start_date = self._format_date(\n                    self.station.data_inventory['Verified 6-Minute Water Level']['start_date'])\n            self._load_water_level(start_date=start_date, end_date=end_date)\n            self.water_levels['wlevel_flag'] = self.water_levels['wlevel_flag']\\\n                                                   .str.split(',', expand=True)\\\n                                                   .astype(int).sum(axis=1)\n            self.water_levels.loc[self.water_levels['wlevel_flag'] &gt; 0, 'wlevel'] = np.nan\n            datasets.append(self.water_levels['wlevel'])\n\n        # # Barometric pressure\n        # if 'Barometric Pressure' in self.station.data_inventory:\n        #     self.variables.append('Barometric Pressure')\n        #     if not start_date:\n        #         start_date = self._format_date(\n        #             self.station.data_inventory['Barometric Pressure']['start_date'])\n        #     self._load_atm_pres(start_date=start_date, end_date=end_date)\n        #     self.pressure['apres_flag'] = self.pressure['apres_flag'].str\\\n        #                                       .split(',', expand=True)\\\n        #                                       .astype(int).sum(axis=1)\n        #     self.pressure.loc[self.pressure['apres_flag']&gt;0, 'apres'] = np.nan\n        #     datasets.append(self.pressure['apres'])\n\n        # # Wind\n        # if 'Wind' in self.station.data_inventory:\n        #     self.variables.extend(['Wind Speed', 'Wind Gust'])\n        #     if not start_date:\n        #         start_date = self._format_date(\n        #             self.station.data_inventory['Wind']['start_date'])\n        #     self._load_wind(start_date=start_date, end_date=end_date)\n        #     self.wind['windflag'] = self.wind['wind_flag'].str\\\n        #                                 .split(',', expand=True).astype(int)\\\n        #                                 .sum(axis=1)\n        #     self.wind.loc[self.wind['wind_flag'] &gt; 0, ['windspeed', 'windgust']] = np.nan\n        #     datasets.append(self.wind[['windspeed', 'windgust']])\n\n        # Merge into single dataframe\n        if self.verbose:\n            print('Compiling data')\n        self.data = pd.concat(datasets, axis=1)\n        self.data.index.name = f'time_{self.tz}'\n        self.data.columns = [i for i in self.variables]\n\n    def update_data(self, start_date=None, end_date=None):\n        \"\"\"Download data from NOAA CO-OPS\"\"\"\n        if self.verbose:\n            print('Downloading latest data')\n\n        # NOAA CO-OPS API\n        self.station = Station(id=self.id)\n\n        # List of data variables to combine at the end\n        datasets = []\n        \n        # If no 'start_date' is passed, pick up from the last observation time\n        if not start_date:\n            start_date = self._format_date(self.data.index.max())\n            \n        # If no 'end_date' is passed, download through end of current date\n        if not end_date:\n            end_date = self._format_date(\n                            pd.to_datetime('today') + pd.Timedelta(days=1))\n        \n        # Air temperature\n        if 'Air Temperature' in self.variables:\n            self._load_atemp(start_date=start_date, end_date=end_date)\n            datasets.append(self.air_temp['atemp'])\n\n        # Water temperature\n        if 'Water Temperature' in self.variables:\n            self._load_water_temp(start_date=start_date, end_date=end_date)\n            datasets.append(self.water_temp['wtemp'])\n\n        # Water level (tides)\n        if 'Water Level' in self.variables:\n            self._load_water_level(start_date=start_date, end_date=end_date)\n            datasets.append(self.water_levels['wlevel'])\n\n        # Barometric pressure\n        if 'Barometric Pressure' in self.variables:\n            self._load_atm_pres(start_date=start_date, end_date=end_date)\n            datasets.append(self.pressure['apres'])\n\n        # Wind\n        if 'Wind Speed' in self.variables:\n            self._load_wind(start_date=start_date, end_date=end_date)\n            datasets.append(self.wind[['windspeed', 'windgust']])\n\n        # Merge into single dataframe\n        data = pd.concat(datasets, axis=1)\n        if sum(~data.index.isin(self.data.index)) == 0:\n            print('No new data available.')\n        else:\n            data.index.name = f'time_{self.tz}'\n            data.columns = [i for i in self.variables]\n            data = pd.concat([self.data,\n                              data[data.index.isin(self.data.index) == False]],\n                             axis=0)\n            self.data = data\n            self.filtered_hours = \\\n                pd.concat([self._filter_hours(\n                                self.data[var],\n                                hr_threshold=self.meta['hr_threshold'])\n                           for var in self.variables], axis=1)\n            self.filtered_hours = self._DOY(self.filtered_hours)\n            self.filtered_days = \\\n                pd.concat([self._filter_days(\n                                self.data[var],\n                                hr_threshold=self.meta['hr_threshold'],\n                                day_threshold=self.meta['day_threshold'])\n                           for var in self.variables], axis=1)\n            self.filtered_days = self._DOY(self.filtered_days)\n            statsOutFile = os.path.join(self.outdir,\n                                        'observational_data_record.csv.gz')\n            self.data.to_csv(statsOutFile, compression='infer')\n            if self.verbose:\n                print(f\"Updated observational data written to file '{statsOutFile}'.\")\n                print(\"Done! Run Data.update_stats() to update statistics.\")\n    \n    def update_stats(self):    \n        \"\"\"Calculate new statistics and update if any changes\"\"\"\n        # Daily stats\n        _new_daily_stats = self.daily_stats()\n        if _new_daily_stats.equals(self.daily_records):\n            if self.verbose:\n                print('No new daily records set.')\n        else:\n            if self.verbose:\n                print(\"\"\"Daily stats differ. Updating and saving to file. If new records have been set,\n                they will be printed below.\\n\"\"\")\n                self._compare(old=self.daily_records, new=_new_daily_stats)\n            self.daily_records = _new_daily_stats\n            # Write to file\n            statsOutFile = os.path.join(self.outdir, 'statistics-daily.nc')\n            self.daily_records.to_netcdf(statsOutFile, mode='w')\n            if self.verbose:\n                print(f\"\\nUpdated daily observational statistics written to '{statsOutFile}\\n'\")\n            print('*'*10)\n\n        # Monthly stats\n        _new_monthly_stats = self.monthly_stats()\n        if _new_monthly_stats.equals(self.monthly_records):\n            if self.verbose:\n                print('No new monthly records set.')\n        else:\n            if self.verbose:\n                print(\"\"\"Monthly stats dicts differ. Updating and saving to file. If new records have\n                been set, they will be printed below.\\n\"\"\")\n                self._compare(old=self.monthly_records,\n                              new=_new_monthly_stats)\n            self.monthly_records = _new_monthly_stats\n            # Write to file\n            statsOutFile = os.path.join(self.outdir, 'statistics-monthly.nc')\n            self.monthly_records.to_netcdf(statsOutFile, mode='w')\n            if self.verbose:\n                print(f\"Updated monthly observational statistics written to '{statsOutFile}'\")\n\n    def _format_date(self, datestr):\n        dtdt = pd.to_datetime(datestr)\n        return dt.datetime.strftime(dtdt, '%Y%m%d')\n    \n    def camel(self, text):\n        \"\"\"Convert 'text' to camel case\"\"\"\n        s = text.replace(',', '').replace(\"-\", \" \").replace(\"_\", \" \")\n        s = s.split()\n        if len(text) == 0:\n            return text\n        return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\n    def _valid_units(self, unit):\n        valid = {'metric', 'english'}\n        if unit.lower() not in valid:\n            raise ValueError(\"units: units must be one of %r.\" % valid)\n    \n    def _valid_tz(self, tz):\n        valid = {'gmt', 'lst', 'lst_ldt'}\n        if tz.lower() not in valid:\n            raise ValueError(\"timezone: timezone must be one of %r.\" % valid)\n\n    def _valid_datum(self, datum):\n        valid = {'STND', 'MHHW', 'MHW', 'MTL', 'MSL', 'MLW', 'MLLW', 'NAVD'}\n        if datum.upper() not in valid:\n            raise ValueError(\"datum: datum must be one of %r.\" % valid)\n\n    def _load_from_yaml(self, blob):\n        for k, v in blob.items():\n            setattr(self, k, v)\n    \n    def get_data(self):\n        return self.data\n        \n    def _load_atemp(self, start_date, end_date):\n        \"\"\"Download air temperature data from NOAA CO-OPS from 'start_date'\n        through current day.\n        \"\"\"\n        if self.verbose:\n            print('Retrieving air temperature data')\n        self.air_temp = self.station.get_data(\n            begin_date=start_date,\n            end_date=end_date,\n            product='air_temperature',\n            units=self.unit_system,\n            time_zone=self.tz)\n        self.air_temp.columns = ['atemp', 'atemp_flag']\n    \n    def _load_wind(self, start_date, end_date):\n        \"\"\"Download wind data from NOAA CO-OPS from 'start_date' through\n        current day.\n        \"\"\"\n        if self.verbose:\n            print('Retrieving wind data')\n        self.wind = self.station.get_data(\n            begin_date=start_date,\n            end_date=end_date,\n            product='wind',\n            units=self.unit_system,\n            time_zone=self.tz)\n        self.wind.columns = ['windspeed', 'winddir_deg', 'winddir',\n                             'windgust', 'wind_flag']\n    \n    def _load_atm_pres(self, start_date, end_date):\n        \"\"\"Download barometric pressure data from NOAA CO-OPS from 'start_date'\n        through current day.\n        \"\"\"\n        if self.verbose:\n            print('Retrieving barometric pressure data')\n        self.pressure = self.station.get_data(\n            begin_date=start_date,\n            end_date=end_date,\n            product='air_pressure',\n            units=self.unit_system,\n            time_zone=self.tz)\n        self.pressure.columns = ['apres', 'apres_flag']\n    \n    def _load_water_temp(self, start_date, end_date):\n        \"\"\"Download water temperature data from NOAA CO-OPS from 'start_date'\n       through current day.\n        \"\"\"\n        if self.verbose:\n            print('Retrieving water temperature data')\n        self.water_temp = self.station.get_data(\n            begin_date=start_date,\n            end_date=end_date,\n            product='water_temperature',\n            units=self.unit_system,\n            time_zone=self.tz)\n        self.water_temp.columns = ['wtemp', 'wtemp_flag']\n\n    def _load_water_level(self, start_date, end_date):\n        \"\"\"Download water level tide data from NOAA CO-OPS from 'start_date'\n        through current day.\n        \"\"\"\n        if self.verbose:\n            print('Retrieving water level tide data')\n        self.water_levels = self.station.get_data(\n            begin_date=start_date,\n            end_date=end_date,\n            product='water_level',\n            datum=self.datum,\n            units=self.unit_system,\n            time_zone=self.tz)\n        self.water_levels.columns = ['wlevel', 's', 'wlevel_flag', 'wlevel_qc']\n\n    def _DOY(self, df):\n        \"\"\"Calculate year day out of 366\"\"\"\n        # Day of year as integer\n        df['YearDay'] = df.index.day_of_year.astype(int)\n        # Years that are NOT leap years\n        leapInd = [not calendar.isleap(i) for i in df.index.year]\n        # mask = (leapInd) & (df['Month'] &gt; 2)\n        mask = (leapInd) & (df.index.month &gt; 2)\n        # Advance by one day everything after February 28 \n        df.loc[mask, 'YearDay'] += 1\n        return df\n\n    def _count_missing_hours(self, group, threshold=3):\n        \"\"\"Return True if the number of hours in a day with missing data is \n        less than or equal to 'threshold' and False otherwise.\n        \"\"\"\n        missing_hours = group.resample('1h').mean().isna().sum()\n        return missing_hours &lt;= threshold\n\n    def _count_missing_days(self, group, threshold=2):\n        \"\"\"Return True if the number of days in a month with missing data \n        is less than or equal to 'theshold' and False otherwise. Two tests \n        are performed: missing data (NaN) and compare to the number of days in\n        the given month.\n        \"\"\"\n        try:\n            days_in_month = pd.Period(group.index[0].strftime(format='%Y-%m-%d')).days_in_month\n            missing_days = group.resample('1D').mean().isna().sum()\n            missing_days_flag = missing_days &lt;= threshold\n            days_in_month_flag = days_in_month - group.resample('1D').mean().size &lt;= threshold\n            return min(missing_days_flag, days_in_month_flag)\n        except IndexError:\n            pass\n\n    def _filter_hours(self, data, hr_threshold=3):\n        \"\"\"Filter data to remove days with more than 'hr_threshold' missing\n        hours of data.\n        \"\"\"\n        # Filter out days missing more than &lt;hr_threshold&gt; hours\n        filtered = data.groupby(pd.Grouper(freq='1D')).filter(\n            lambda x: self._count_missing_hours(group=x, threshold=hr_threshold))\n        return filtered\n\n    def _filter_days(self, data, hr_threshold=3, day_threshold=2):\n        \"\"\"Filter months with more than 'day_threshold' days of missing\n        data by first filtering data to remove days with more than \n        'hr_threshold' missing hours of data.\n        \"\"\"\n        # Filter out days missing more than &lt;hr_threshold&gt; hours\n        filtered = self._filter_hours(data, hr_threshold=hr_threshold)\n        # Filter out months missing more than &lt;day_threshold&gt; days\n        filtered = filtered.groupby(pd.Grouper(freq='1M')).filter(\n            lambda x: self._count_missing_days(group=x, threshold=day_threshold))\n        return filtered\n\n    def daily_highs(self):\n        \"\"\"Daily highs\"\"\"\n        return self.filtered_hours.groupby(\n            pd.Grouper(freq='1D', closed='left', label='left', dropna=True))\\\n              .max(numeric_only=True)\n    \n    def daily_lows(self):\n        \"\"\"Daily lows\"\"\"\n        return self.filtered_hours.groupby(\n            pd.Grouper(freq='1D', closed='left', label='left', dropna=True))\\\n              .min(numeric_only=True)\n\n    def daily_avgs(self, true_average=False):\n        \"\"\"Daily averages by calendar day. If 'true_average' is True, all\n        measurements from each 24-hour day will be used to calculate the\n        average. Otherwise, only the maximum and minimum observations are used.\n        Defaults to False (meteorological standard).\n        \"\"\"\n        if true_average:\n            return self.filtered_hours.groupby(\n                pd.Grouper(freq='1D', closed='left', label='left', dropna=True))\\\n                  .mean(numeric_only=True)\n        else:\n            dailyHighs = self.daily_highs()\n            dailyLows = self.daily_lows()\n            results = (dailyHighs + dailyLows) / 2\n            return results\n\n    def daily_avg(self, true_average=False):\n        \"\"\"Daily averages. If 'true_average' is True, all measurements from\n        each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        dailyAvg = dailyAvgs.groupby('YearDay')\\\n                            .mean(numeric_only=True)\n        dailyAvg.index = dailyAvg.index.astype(int)\n        results = xr.DataArray(dailyAvg, dims=['yearday', 'variable'])\n        results.name = 'Daily Average'\n        return results\n\n    def monthly_highs(self, true_average=False):\n        \"\"\"Monthly highs. If 'true_average' is True, all measurements from each\n        24-hour day will be used to calculate the daily average. Otherwise,\n        only the maximum and minimum observations are used. Defaults to False\n        (meteorological standard).\n        \"\"\"\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        monthHighs = dailyAvgs.groupby(pd.Grouper(freq='M'))\\\n                              .max(numeric_only=True)\n        return monthHighs\n    \n    def monthly_lows(self, true_average=False):\n        \"\"\"Monthly lows. If 'true_average' is True, all measurements from each\n        24-hour day will be used to calculate the daily average. Otherwise,\n        only the maximum and minimum observations are used. Defaults to False\n        (meteorological standard).\n        \"\"\"\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        monthLows = dailyAvgs.groupby(pd.Grouper(freq='M'))\\\n                             .min(numeric_only=True)\n        return monthLows\n    \n    def monthly_avg(self, true_average=False):\n        \"\"\"Monthly averages. If 'true_average' is True, all measurements from\n        each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        monthlyMeans = dailyAvgs.groupby(pd.Grouper(freq='M'))\\\n                                .mean(numeric_only=True)\n        monthlyMeans.drop('YearDay', axis=1, inplace=True)\n        monthlyAvg = monthlyMeans.groupby(monthlyMeans.index.month)\\\n                                 .mean(numeric_only=True)\n        monthlyAvg.index = monthlyAvg.index.astype(int)\n        results = xr.DataArray(monthlyAvg, dims=['month', 'variable'])\n        results.name = 'Monthly Average'\n        return results\n\n    def record_high_daily_avg(self, true_average=False):\n        \"\"\"Record high daily averages. If 'true_average' is True, all\n        measurements from each 24-hour day will be used to calculate the daily\n        average. Otherwise, only the maximum and minimum observations are used.\n        Defaults to False (meteorological standard).\n        \"\"\"\n        # Calculate the records\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        recordHighDailyAvg = \\\n            dailyAvgs.groupby('YearDay').max(numeric_only=True)\n        recordHighDailyAvg.index = recordHighDailyAvg.index.astype(int)\n        # Record years\n        recordHighDailyAvgYear = dailyAvgs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n        recordHighDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n        recordHighDailyAvgYear.index = recordHighDailyAvgYear.index.astype(int)\n        recordHighDailyAvgYear.columns = \\\n            [i+' Year' for i in recordHighDailyAvgYear.columns]\n        # Create xarray\n        results = pd.concat((recordHighDailyAvg, recordHighDailyAvgYear), \n                            axis=1)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Record High Daily Average'\n        return results\n\n    def record_high_monthly_avg(self, true_average=False):\n        \"\"\"Record high monthly averages. If 'true_average' is True, all\n        measurements from each 24-hour day will be used to calculate the daily\n        average. Otherwise, only the maximum and minimum observations are used.\n        Defaults to False (meteorological standard).\n        \"\"\"\n        # Calculate the records\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M'))\\\n                               .mean(numeric_only=True)\n        monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n        recordHighMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month)\\\n                                          .max(numeric_only=True)\n        recordHighMonthlyAvg.index = recordHighMonthlyAvg.index.astype(int)\n        # Record years\n        recordHighMonthlyAvgYear = \\\n            monthlyAvgs.groupby(monthlyAvgs.index.month).apply(\n                lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n        recordHighMonthlyAvgYear.index = \\\n            recordHighMonthlyAvgYear.index.astype(int)\n        recordHighMonthlyAvgYear.columns = \\\n            [i+' Year' for i in recordHighMonthlyAvgYear.columns]\n        # Create xarray\n        results = pd.concat((recordHighMonthlyAvg, recordHighMonthlyAvgYear),\n                             axis=1)\n        results = xr.DataArray(results, dims=['month', 'variable'])\n        results.name = 'Record High Monthly Average'\n        return results\n\n    def record_low_daily_avg(self, true_average=False):\n        \"\"\"Record low daily averages.  If 'true_average' is True, all\n        measurements from each 24-hour day will be used to calculate the\n        average. Otherwise, only the maximum and minimum observations are used.\n        Defaults to False (meteorological standard).\"\"\"\n        # Calculate the records\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        recordLowDailyAvg = \\\n            dailyAvgs.groupby('YearDay').min(numeric_only=True)\n        recordLowDailyAvg.index = recordLowDailyAvg.index.astype(int)\n        # Record years\n        recordLowDailyAvgYear = dailyAvgs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n        recordLowDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n        recordLowDailyAvgYear.index = recordLowDailyAvgYear.index.astype(int)\n        recordLowDailyAvgYear.columns = \\\n            [i+' Year' for i in recordLowDailyAvgYear.columns]\n        # Create xarray\n        results = pd.concat((recordLowDailyAvg, recordLowDailyAvgYear), axis=1)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Record Low Daily Average'\n        return results\n\n    def record_low_monthly_avg(self, true_average=False):\n        \"\"\"Record low monthly averages. If 'true_average' is True, all\n        measurements from each 24-hour day will be used to calculate the daily\n        average. Otherwise, only the maximum and minimum observations are used.\n        Defaults to False (meteorological standard).\n        \"\"\"\n        # Calculate the records\n        dailyAvgs = self.daily_avgs(true_average=true_average)\n        monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M'))\\\n                               .mean(numeric_only=True)\n        monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n        recordLowMonthlyAvg = \\\n            monthlyAvgs.groupby(monthlyAvgs.index.month).min(numeric_only=True)\n        recordLowMonthlyAvg.index = recordLowMonthlyAvg.index.astype(int)\n        # Record years\n        recordLowMonthlyAvgYear = \\\n            monthlyAvgs.groupby(monthlyAvgs.index.month).apply(\n                lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n        recordLowMonthlyAvgYear.index = \\\n            recordLowMonthlyAvgYear.index.astype(int)\n        recordLowMonthlyAvgYear.columns = \\\n            [i+' Year' for i in recordLowMonthlyAvgYear.columns]\n        # Create xarray\n        results = pd.concat((recordLowMonthlyAvg, recordLowMonthlyAvgYear),\n                             axis=1)\n        results = xr.DataArray(results, dims=['month', 'variable'])\n        results.name = 'Record Low Monthly Average'\n        return results\n\n    def avg_daily_high(self):\n        \"\"\"Average daily highs.\"\"\"        \n        dailyHighs = self.daily_highs()\n        results = dailyHighs.groupby('YearDay')\\\n                            .mean(numeric_only=True)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Average Daily High'\n        return results\n\n    def avg_monthly_high(self, true_average=False):\n        \"\"\"Average monthly highs. If 'true_average' is True, all measurements\n        from each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        monthlyHighs = self.monthly_highs(true_average=true_average)\n        monthlyHighs.drop('YearDay', axis=1, inplace=True)\n        avgMonthlyHighs = monthlyHighs.groupby(monthlyHighs.index.month)\\\n                                      .mean(numeric_only=True)\n        results = xr.DataArray(avgMonthlyHighs, dims=['month', 'variable'])\n        results.name = 'Average Monthly High'\n        return results\n\n    def lowest_daily_high(self):\n        \"\"\"Lowest daily highs.\"\"\"\n        # Calculate the record\n        dailyHighs = self.daily_highs()\n        lowestHigh = dailyHighs.groupby('YearDay')\\\n                               .min(numeric_only=True)\n        lowestHigh.index = lowestHigh.index.astype(int)\n        # Record years\n        lowestHighYear = dailyHighs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n        lowestHighYear.drop('YearDay', axis=1, inplace=True)\n        lowestHighYear.index = lowestHighYear.index.astype(int)\n        lowestHighYear.columns = \\\n            [i+' Year' for i in lowestHighYear.columns]\n        # Create xarray\n        results = pd.concat((lowestHigh, lowestHighYear), axis=1)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Lowest Daily High'\n        return results\n\n    def lowest_monthly_high(self, true_average=False):\n        \"\"\"Lowest monthly highs. If 'true_average' is True, all measurements\n        from each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        # Calculate the record\n        monthlyHighs = self.monthly_highs(true_average=true_average)\n        monthlyHighs.drop('YearDay', axis=1, inplace=True)\n        lowMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month)\\\n                                     .min(numeric_only=True)\n        lowMonthlyHigh.index = lowMonthlyHigh.index.astype(int)\n        # Record years\n        lowMonthlyHighYear = \\\n            monthlyHighs.groupby(monthlyHighs.index.month).apply(\n                lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n        lowMonthlyHighYear.index = lowMonthlyHighYear.index.astype(int)\n        lowMonthlyHighYear.columns = \\\n            [i+' Year' for i in lowMonthlyHighYear.columns]\n        # Create xarray\n        results = pd.concat((lowMonthlyHigh, lowMonthlyHighYear), axis=1)\n        results = xr.DataArray(results, dims=['month', 'variable'])\n        results.name = 'Lowest Monthly High'\n        return results\n\n    def record_daily_high(self):\n        \"\"\"Record daily highs.\"\"\"\n        # Calculate the record\n        dailyHighs = self.daily_highs()\n        recordHigh = dailyHighs.groupby('YearDay')\\\n                               .max(numeric_only=True)\n        recordHigh.index = recordHigh.index.astype(int)\n        # Record years\n        recordHighYear = dailyHighs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n        recordHighYear.drop('YearDay', axis=1, inplace=True)\n        recordHighYear.index = recordHighYear.index.astype(int)\n        recordHighYear.columns = \\\n            [i+' Year' for i in recordHighYear.columns]\n        # Create xarray\n        results = pd.concat((recordHigh, recordHighYear), axis=1)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Record Daily High'\n        return results\n\n    def record_monthly_high(self, true_average=False):\n        \"\"\"Record monthly highs. If 'true_average' is True, all measurements\n        from each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        # Calculate the record\n        monthlyHighs = self.monthly_highs(true_average=true_average)\n        monthlyHighs.drop('YearDay', axis=1, inplace=True)\n        recordMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month)\\\n                                        .max(numeric_only=True)\n        recordMonthlyHigh.index = recordMonthlyHigh.index.astype(int)\n        # Record years\n        recordMonthlyHighYear = \\\n            monthlyHighs.groupby(monthlyHighs.index.month).apply(\n                lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n        recordMonthlyHighYear.index = recordMonthlyHighYear.index.astype(int)\n        recordMonthlyHighYear.columns = \\\n            [i+' Year' for i in recordMonthlyHighYear.columns]\n        # Create xarray\n        results = pd.concat((recordMonthlyHigh, recordMonthlyHighYear), axis=1)\n        results = xr.DataArray(results, dims=['month', 'variable'])\n        results.name = 'Record Monthly High'\n        return results\n\n    def avg_daily_low(self):\n        \"\"\"Average daily lows.\"\"\"        \n        dailyLows = self.daily_lows()\n        results = dailyLows.groupby('YearDay')\\\n                           .mean(numeric_only=True)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Average Daily Low'\n        return results\n\n    def avg_monthly_low(self, true_average=False):\n        \"\"\"Average monthly lows. If 'true_average' is True, all measurements\n        from each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        monthlyLows = self.monthly_lows(true_average=true_average)\n        monthlyLows.drop('YearDay', axis=1, inplace=True)\n        avgMonthlyLows = monthlyLows.groupby(monthlyLows.index.month)\\\n                                    .mean(numeric_only=True)\n        results = xr.DataArray(avgMonthlyLows, dims=['month', 'variable'])\n        results.name = 'Average Monthly Low'\n        return results\n\n    def highest_daily_low(self):\n        \"\"\"Highest daily lows.\"\"\"\n        # Calculate the record\n        dailyLows = self.daily_lows()\n        highestLow = dailyLows.groupby('YearDay')\\\n                              .max(numeric_only=True)\n        highestLow.index = highestLow.index.astype(int)\n        # Record years\n        highestLowYear = dailyLows.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n        highestLowYear.drop('YearDay', axis=1, inplace=True)\n        highestLowYear.index = highestLowYear.index.astype(int)\n        highestLowYear.columns = [i+' Year' for i in highestLowYear.columns]\n        # Create xarray\n        results = pd.concat((highestLow, highestLowYear), axis=1)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Highest Daily Low'\n        return results\n\n    def highest_monthly_low(self, true_average=False):\n        \"\"\"Highest monthly lows. If 'true_average' is True, all measurements\n        from each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        # Calculate the record\n        monthlyLows = self.monthly_lows(true_average=true_average)\n        monthlyLows.drop('YearDay', axis=1, inplace=True)\n        highestMonthlyLow = monthlyLows.groupby(monthlyLows.index.month)\\\n                                       .max(numeric_only=True)\n        highestMonthlyLow.index = highestMonthlyLow.index.astype(int)\n        # Record years\n        highestMonthlyLowYear = \\\n            monthlyLows.groupby(monthlyLows.index.month).apply(\n                lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n        highestMonthlyLowYear.index = highestMonthlyLowYear.index.astype(int)\n        highestMonthlyLowYear.columns = \\\n            [i+' Year' for i in highestMonthlyLowYear.columns]\n        # Create xarray\n        results = pd.concat((highestMonthlyLow, highestMonthlyLowYear), axis=1)\n        results = xr.DataArray(results, dims=['month', 'variable'])\n        results.name = 'Highest Monthly Low'\n        return results\n\n    def record_daily_low(self):\n        \"\"\"Record daily lows.\"\"\"\n        # Calculate the record\n        dailyLows = self.daily_lows()\n        recordLow = dailyLows.groupby('YearDay')\\\n                             .min(numeric_only=True)\n        recordLow.index = recordLow.index.astype(int)\n        # Record years\n        recordLowYear = dailyLows.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n        recordLowYear.drop('YearDay', axis=1, inplace=True)\n        recordLowYear.index = recordLowYear.index.astype(int)\n        recordLowYear.columns = [i+' Year' for i in recordLowYear.columns]\n        # Create xarray\n        results = pd.concat((recordLow, recordLowYear), axis=1)\n        results = xr.DataArray(results, dims=['yearday', 'variable'])\n        results.name = 'Record Daily Low'\n        return results\n\n    def record_monthly_low(self, true_average=False):\n        \"\"\"Record monthly lows. If 'true_average' is True, all measurements\n        from each 24-hour day will be used to calculate the daily average.\n        Otherwise, only the maximum and minimum observations are used. Defaults\n        to False (meteorological standard).\n        \"\"\"\n        # Calculate the record\n        monthlyLows = self.monthly_lows(true_average=true_average)\n        monthlyLows.drop('YearDay', axis=1, inplace=True)\n        recordMonthlyLow = monthlyLows.groupby(monthlyLows.index.month)\\\n                                      .min(numeric_only=True)\n        recordMonthlyLow.index = recordMonthlyLow.index.astype(int)\n        # Record years\n        recordMonthlyLowYear = \\\n            monthlyLows.groupby(monthlyLows.index.month).apply(\n                lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n        recordMonthlyLowYear.index = recordMonthlyLowYear.index.astype(int)\n        recordMonthlyLowYear.columns = \\\n            [i+' Year' for i in recordMonthlyLowYear.columns]\n        # Create xarray\n        results = pd.concat((recordMonthlyLow, recordMonthlyLowYear), axis=1)\n        results = xr.DataArray(results, dims=['month', 'variable'])\n        results.name = 'Record Monthly Low'\n        return results\n\n    def number_of_years_byday(self):\n        \"\"\"Number of years in the historical data records by day of year.\"\"\"\n        numYears = pd.concat(\n            [self.filtered_hours[[v, 'YearDay']]\\\n                .dropna().groupby('YearDay').apply(\n                # .groupby('YearDay').apply(\n                    lambda x: len(x.index.year.unique())) \\\n             for v in self.filtered_hours.columns if v != 'YearDay'], axis=1)\n        numYears.columns = [v for v in self.filtered_hours.columns \\\n                            if v != 'YearDay']\n        results = xr.DataArray(numYears, dims=['yearday', 'variable'])\n        results.name = 'Number of Years'\n        return results\n\n    def number_of_years_bymonth(self):\n        \"\"\"Number of years in the historical data records by month.\"\"\"\n        numYears = pd.concat(\n            [self.filtered_days[v]\\\n                 .dropna().groupby(self.filtered_days[v].dropna().index.month).apply(\n                #  .groupby(self.filtered_days[v].index.month).apply(\n                    lambda x: len(x.index.year.unique())) \\\n                for v in self.filtered_days if v != 'YearDay'], axis=1)\n        numYears.columns = [v for v in self.filtered_days.columns \\\n                            if v != 'YearDay']\n        results = xr.DataArray(numYears, dims=['month', 'variable'])\n        results.name = 'Number of Years'\n        return results\n    \n    def generate_yeardays(self):\n        return pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D')\\\n                 .strftime('%d-%b')\n    \n    def daily_stats(self):\n        \"\"\"Create xarray of daily statistics for all science variables\"\"\"\n        daily_records = xr.Dataset(\n            {'Daily Average': self.daily_avg(),\n             'Record High Daily Average': self.record_high_daily_avg(),\n             'Record Low Daily Average': self.record_low_daily_avg(),\n             'Average High': self.avg_daily_high(),\n             'Lowest High': self.lowest_daily_high(),\n             'Record High': self.record_daily_high(),\n             'Average Low': self.avg_daily_low(),\n             'Highest Low': self.highest_daily_low(),\n             'Record Low': self.record_daily_low(),\n             'Years': self.number_of_years_byday()},\n            attrs = {k:v for k, v in self.meta.items() \\\n                     if k not in ['outdir', 'variables', 'units']})\n        \n        # Add data units for each variable to the array as metadata attributes\n        for k, v in self.meta['units'].items():\n            daily_records.attrs[k+' units'] = v\n        \n        # Add time series ranges for each variable to the array as metadata \n        # attributes\n        for var in daily_records.coords['variable'].values:\n            if 'Year' not in var:\n                daily_records.attrs[var+' data range'] = \\\n                    (self.filtered_hours[var].dropna().index.min().strftime('%Y-%m-%d'),\n                     self.filtered_hours[var].dropna().index.max().strftime('%Y-%m-%d'))\n        \n        # Rearrange array coordinates and variables: separate records and \n        # years into smaller arrays\n        day_records = daily_records.sel(variable = [\n            i for i in daily_records.coords['variable'].values \\\n                if 'Year' not in i])\n        day_years = daily_records.sel(variable = [\n            i for i in daily_records.coords['variable'].values if 'Year' in i])\n        \n        # Add \"Year\" to variable names and remove it from coordinate name\n        day_years = day_years.rename_vars(\n            {i:i+' Year' for i in day_years.data_vars})\n        day_years.coords['variable'] = \\\n            [i.removesuffix(' Year') for i in day_years.coords['variable'].values]\n\n        # Merge arrays together\n        daily_records = xr.merge([day_records, day_years])\n        daily_records = daily_records[\n            [item for items in zip(day_records.data_vars, day_years.data_vars) \\\n             for item in items]]\n        daily_records = daily_records.drop_vars(\n            [x for x in daily_records.data_vars \\\n             if daily_records[x].isnull().all()])\n        \n        # Convert years to integers\n        daily_records[[i for i in daily_records.data_vars if \"Year\" in i]] = \\\n            daily_records[\n            [i for i in daily_records.data_vars if \"Year\" in i]].astype(int)\n\n        # Replace yearday with calendar day and rename coordinate\n        daily_records.coords['yearday'] = \\\n            pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D')\\\n              .strftime('%d-%b')\n        daily_records = daily_records.rename({'yearday':'Date'})\n\n        return daily_records\n\n    def monthly_stats(self):\n        \"\"\"Create xarray of monthly statistics for all science variables\"\"\"\n        monthly_records = xr.Dataset(\n            {'Monthly Average': self.monthly_avg(),\n             'Record High Monthly Average': self.record_high_monthly_avg(),\n             'Record Low Monthly Average': self.record_low_monthly_avg(),\n             'Average High': self.avg_monthly_high(),\n             'Lowest High': self.lowest_monthly_high(),\n             'Record High': self.record_monthly_high(),\n             'Average Low': self.avg_monthly_low(),\n             'Highest Low': self.highest_monthly_low(),\n             'Record Low': self.record_monthly_low(),\n             'Years': self.number_of_years_bymonth()},\n            attrs = {k:v for k, v in self.meta.items() \\\n                     if k not in ['outdir', 'variables', 'units']})\n\n        # Add data units for each variable to the array as metadata attributes\n        for k, v in self.meta['units'].items():\n            monthly_records.attrs[k+' units'] = v\n\n        # Add time series ranges for each variable to the array as metadata \n        # attributes\n        for var in monthly_records.coords['variable'].values:\n            if 'Year' not in var:\n                monthly_records.attrs[var+' data range'] = \\\n                    (self.filtered_days[var].dropna().index.min().strftime('%Y-%m-%d'),\n                     self.filtered_days[var].dropna().index.max().strftime('%Y-%m-%d'))\n        \n        # Rearrange array coordinates and variables: separate records and \n        # years into smaller arrays\n        mon_records = monthly_records.sel(variable = [\n            i for i in monthly_records.coords['variable'].values \\\n                if 'Year' not in i])\n        mon_years = monthly_records.sel(variable = [\n            i for i in monthly_records.coords['variable'].values \\\n                if 'Year' in i])\n        \n        # Add \"Year\" to variable names and remove it from coordinate name\n        mon_years = mon_years.rename_vars(\n            {i:i+' Year' for i in mon_years.data_vars})\n        mon_years.coords['variable'] = \\\n            [i.removesuffix(' Year') for i in mon_years.coords['variable'].values]\n\n        # Merge arrays together\n        monthly_records = xr.merge([mon_records, mon_years])\n        monthly_records = monthly_records[\n            [item for items in zip(mon_records.data_vars, mon_years.data_vars) for item in items]]\n        monthly_records = monthly_records.drop_vars(\n            [x for x in monthly_records.data_vars if monthly_records[x].isnull().all()])\n        \n        # Convert years to integers\n        monthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]] = \\\n            monthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]].astype(int)\n\n        # Replace yearday with calendar day and rename coordinate\n        monthly_records.coords['month'] = \\\n            pd.date_range(start='2020-01-01', end='2020-12-31', freq='1m')\\\n              .strftime('%b')\n        monthly_records = monthly_records.rename({'month': 'Month'})\n\n        return monthly_records\n\n    def _compare(self, old, new):\n        \"\"\"Compare 'old' and 'new' records xarrays excluding daily highs, lows,\n        and averages, since these will always change with updated data.\n        \"\"\"\n        # Mask out unchanged records\n        diffs = old != new\n        exclude = ['Daily Average', 'Monthly Average', 'Average High',\n                   'Average Low', 'Years']\n        try:\n            new_records = xr.where(diffs, new, np.nan)\\\n                            .drop_vars(exclude, errors='ignore')\\\n                            .dropna(dim='variable', how='all')\\\n                            .dropna(dim='Date', how='all')\\\n                            .to_dataframe()\n        except ValueError:\n            new_records = xr.where(diffs, new, np.nan)\\\n                            .drop_vars(exclude, errors='ignore')\\\n                            .dropna(dim='variable', how='all')\\\n                            .dropna(dim='Month', how='all')\\\n                            .to_dataframe()\n        \n        # List of records set\n        record_set = new_records.loc[:, new_records.columns.str.endswith('Year')].columns\n        record_set = [i.replace(' Year', '') for i in record_set]\n\n        # Loop through the dataframe of new records to report out the updates\n        # This is a hacky solution that pieces together the various compoents\n        # of the iterrows() output.\n        for row in new_records.iterrows():\n            for record in record_set:\n                if not np.isnan(row[1][record]):\n                    var = row[0][1]\n                    newRecord = row[1][record]\n                    newYear = int(row[1][record+' Year'])\n                    try:\n                        oldRecord = old.sel(variable=var,\n                                            Date=row[0][0])[record].values\n                        oldYear = old.sel(variable=var,\n                                          Date=row[0][0])[record+' Year'].values\n                    except KeyError:\n                        oldRecord = old.sel(variable=var,\n                                            Month=row[0][0])[record].values\n                        oldYear = old.sel(variable=var,\n                                          Month=row[0][0])[record+' Year'].values\n                    units = self.units[var]\n                    print(f\"{record.capitalize()} {var.lower()} set {row[0][0]} {newYear}:\\n\\t\"\\\n                        f\"{newRecord} {units} (previously {oldRecord} {units} in {oldYear})\")\n    \n    def get_daily_stats(self, var=None):\n        \"\"\"Return the daily statistics for variable 'var'\"\"\"\n        try:\n            return self.daily_records.sel(variable=var)\n        except AttributeError:\n            raise AttributeError(\n                \"\"\"Instance of Data has no daily stats yet. Run Data.stats() to\n                calculate stats and try again.\"\"\")\n    \n    def get_monthly_stats(self, var=None):\n        \"\"\"Return the monthly statistics dictionary\"\"\"\n        try:\n            return self.monthly_records.sel(variable=var)\n        except AttributeError:\n            raise AttributeError(\n                \"\"\"Instance of Data has no monthly stats yet. Run Data.stats() to calculate stats and try again.\"\"\")\n\n    def get_daily_stats_table(self, var=None):\n        \"\"\"Return the daily statistics table\"\"\"\n        try:\n            return self.daily_records.sel(variable=var)\\\n                                     .to_dataframe().drop('variable', axis=1)\n        except AttributeError:\n            raise AttributeError(\n                \"\"\"Instance of Data has no daily stats table yet. Run Data.daily_stats() to calculate stats and try again.\"\"\")\n            \n    def get_monthly_stats_table(self, var=None):\n        \"\"\"Return the monthly statistics table\"\"\"\n        try:\n            return self.monthly_records.sel(variable=var)\\\n                                       .to_dataframe().drop('variable', axis=1)\n        except AttributeError:\n            raise AttributeError(\n                \"\"\"Instance of Data has no monthly stats table yet. Run Data.monthly_stats() to calculate stats and try again.\"\"\")\n\n    def _skip_keys(self, d, keys):\n        return {x: d[x] for x in d if x not in keys}\n\n    def set_station(self, station):\n        self.name = station\n        \n    def get_station(self):\n        return self.name\n    \n    def get_stationid(self):\n        return self.id\n    \n    def get_variables(self):\n        return self.variables\n    \n    def __str__(self):\n        return(\n            f\"\"\"Oceanic and atmospheric observations for station '{self.name}'   \n            (station ID {self.id}): {self.station.data_inventory}\"\"\"\n            )\n    \n    def __repr__(self):\n        return(\n            f\"\"\"{type(self).__name__}(stationname='{self.name}', stationid='{self.id}',\n            timezone='{self.tz}', units='{self.units}', datum='{self.datum}', hr_threshold='{self.hr_threshold}', day_threshold='{self.day_threshold}')\"\"\"\n            )\n\n\nvk = Data(stationname='Virginia Key, FL', stationid='8723214')#, redownload=True, units='english', timezone='lst', datum='MHHW')\n\nLoading metadata from file\nLoading historical data from file\nLoading daily statistics from file\nLoading monthly statistics from file\nDone!\n\n\n\nvk.update_data()\nvk.update_stats()\n\nDownloading latest data\nRetrieving air temperature data\nRetrieving water temperature data\nRetrieving water level tide data\nUpdated observational data written to file '/workspaces/climatology/virginiaKeyFl/observational_data_record.csv.gz'.\nDone! Run Data.update_stats() to update statistics.\nNo new daily records set.\nNo new monthly records set.\n\n\n\nprint(\nf\"\"\"This is a test of a very long string with a \nvariable {vk.id} that hopefully prints to the screen properly as I want it to.\"\"\")\n\nThis is a test of a very long string with a \n variable 8723214 that hopefully prints to the screen properly as I want it to.\n\n\n\n\nbm = pd.read_csv(os.path.join(vk.outdir, 'bmcnoldy-data.csv'))\n\n\nbm.columns\n\nIndex(['Date', 'Daily Average', 'Record High Daily Average', 'Year1',\n       'Record Low Daily Average', 'Year2', 'Average High', 'Lowest High',\n       'Year3', 'Record High', 'Year4', 'Average Low', 'Highest Low', 'Year5',\n       'Record Low', 'Year6', 'Years'],\n      dtype='object')\n\n\n\nd = vk.get_daily_stats_table('Water Temperature').drop('29-Feb', axis=0).reset_index()\n\n\nrecords = ['Daily Average', 'Record High Daily Average',\n           'Record Low Daily Average', 'Average High', 'Lowest High',\n           'Record High', 'Average Low', 'Highest Low', 'Record Low']\n\n\nd.equals(bm)\n\nFalse\n\n\n\nd.head()\n\n\n\n\n\n\n\n\nDate\nDaily Average\nRecord High Daily Average\nRecord High Daily Average Year\nRecord Low Daily Average\nRecord Low Daily Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\n0\n01-Jan\n72.7\n80.4\n2022\n66.4\n2011\n73.9\n67.8\n2011\n81.1\n2022\n71.4\n79.7\n2022\n63.9\n2001\n27\n\n\n1\n02-Jan\n73.2\n80.2\n2022\n66.8\n2011\n74.4\n68.0\n2011\n81.0\n2022\n71.9\n79.5\n2022\n64.4\n2001\n27\n\n\n2\n03-Jan\n73.3\n80.7\n2017\n67.3\n2011\n74.6\n68.9\n2011\n81.5\n2017\n72.1\n79.9\n2017\n65.5\n2001\n27\n\n\n3\n04-Jan\n72.9\n81.2\n2017\n67.6\n2001\n74.3\n69.1\n2011\n81.9\n2017\n71.5\n80.6\n2017\n64.5\n2010\n27\n\n\n4\n05-Jan\n72.6\n81.4\n2017\n66.2\n2001\n74.0\n68.5\n2001\n82.2\n2017\n71.1\n80.6\n2017\n63.6\n2010\n27\n\n\n\n\n\n\n\n\nbm.head()\n\n\n\n\n\n\n\n\nDate\nDaily Average\nRecord High Daily Average\nYear1\nRecord Low Daily Average\nYear2\nAverage High\nLowest High\nYear3\nRecord High\nYear4\nAverage Low\nHighest Low\nYear5\nRecord Low\nYear6\nYears\n\n\n\n\n0\n01-Jan\n72.1\n80.4\n2022\n66.3\n2001\n73.4\n69.1\n2001\n81.1\n2022\n70.9\n79.9\n2022\n63.9\n2001\n25\n\n\n1\n02-Jan\n72.0\n80.2\n2022\n67.0\n2001\n73.4\n69.3\n1998\n81.0\n2022\n70.8\n79.5\n2022\n64.4\n2001\n25\n\n\n2\n03-Jan\n72.0\n80.0\n2022\n67.7\n2001\n73.3\n69.8\n1998\n80.2\n2022\n70.7\n79.7\n2022\n65.5\n2001\n25\n\n\n3\n04-Jan\n71.9\n78.7\n2022\n67.1\n2010\n73.2\n70.0\n2012\n79.7\n2022\n70.6\n77.9\n2022\n64.8\n2002\n25\n\n\n4\n05-Jan\n71.8\n78.1\n2022\n65.7\n2001\n73.2\n68.5\n2001\n78.6\n2022\n70.6\n77.4\n2022\n63.7\n2010\n26\n\n\n\n\n\n\n\n\nbm2 = bm.copy()\nbm2.columns = d.columns\n\n\nd.equals(bm)\n\nFalse\n\n\n\nd == bm2\n\n\n\n\n\n\n\n\nDate\nDaily Average\nRecord High Daily Average\nRecord High Daily Average Year\nRecord Low Daily Average\nRecord Low Daily Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\n0\nTrue\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\n1\nTrue\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n3\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n360\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n361\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n362\nTrue\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n363\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n364\nTrue\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\n\n\n\n\n365 rows × 17 columns\n\n\n\n\nnp.round(((d != bm2).sum()/365)*100, 1)\n\nDate                               0.0\nDaily Average                     90.4\nRecord High Daily Average         84.4\nRecord High Daily Average Year    38.4\nRecord Low Daily Average          82.2\nRecord Low Daily Average Year     14.0\nAverage High                      88.2\nLowest High                       20.5\nLowest High Year                  14.0\nRecord High                       49.0\nRecord High Year                  39.5\nAverage Low                       85.5\nHighest Low                       38.4\nHighest Low Year                  33.4\nRecord Low                        21.4\nRecord Low Year                    9.3\nYears                             99.7\ndtype: float64\n\n\n\n\ndef ploy_fit(data, degree=5, print_coefs=False, plot=False):\n    \"\"\"Fit polynomial curve to data\"\"\"\n    # Fit curve to data\n    y = data.values\n    x = np.arange(0, len(y))\n    coef = np.polyfit(x, y, degree)\n    polyfun = np.poly1d(coef)\n    if print_coefs:\n        print(f'Coefficients: {coef}')\n    if plot:\n        fig, ax = plt.subplots(1, 1, figsize=(12,5))\n        ax.plot(data, label=data.name)\n        ax.plot(polyfun(x), color='red', label=f'{degree}D Polynomial')\n        ax.legend(loc='best')\n        plt.show()\n    else:\n        return polyfun(x)\n\n\ndef cos_fit(data, plot=False):\n    \"\"\"Fit cosine curve to data\"\"\"\n    X = np.arange(0, len(data))/len(data)\n\n    # Initial parameter values\n    guess_freq = 1\n    guess_amplitude = 3*np.std(data)/(2**0.5)\n    guess_phase = 0\n    guess_offset = np.mean(data)\n    p0 = [guess_freq, guess_amplitude,\n          guess_phase, guess_offset]\n\n    # Function to fit\n    def my_cos(x, freq, amplitude, phase, offset):\n        return np.cos(x * freq + phase) * amplitude + offset\n\n    # Fit curve to data\n    fit = curve_fit(my_cos, X, data, p0=p0)\n\n    if plot:\n        fig, ax = plt.subplots(1, 1, figsize=(12,5))\n\n        ax.plot(data, label=data.name)\n        ax.plot(fit, color='red', label=f'Cosine fit')\n\n        ax.legend(loc='best')\n        plt.show()\n    else:\n        return my_cos(np.array(X), *fit[0])\n\n\nvar = 'Air Temperature'\ndf = vk.get_stats_table()[var]\nfig, ax = plt.subplots(1,1, figsize=(18,10))\n\nplt.suptitle(f'Daily {var} for {vk.get_station()}'.upper(), fontsize=16)\nplt.title('NOAA CO-OPS Site {}, {} - {}'.upper().format(\n          vk.get_stationid(),\n          vk.data.dropna(axis=0).index.min().strftime('%m/%d/%Y'),\n          vk.data.dropna(axis=0).index.max().strftime('%m/%d/%Y')),\n          fontsize=14)\n\nax.plot(cos_fit(df['Average High']), label='Average high', color='red')\nax.plot(cos_fit(df['Daily Average']), label='Daily average', color='lightgrey')\nax.plot(cos_fit(df['Average Low']), label='Average low', color='purple')\n\nhigh_records = df.loc[df['Record High Year']==pd.to_datetime('today').year, 'Record High']\nax.scatter(df.index, df['Record High'], label='Record high', color='orange', s=2)\nax.scatter(high_records.index, high_records, color='white', s=3)\nax.scatter(df.index, df['Record Low'], label='Record low', color='white', s=2)\n\nax.set_facecolor('black')\nax.legend(loc='upper left')\nax.grid(axis='y', alpha=0.5)\nax.set_ylabel(f'{var} ({vk.units[var]})'.upper())\n# ax.set_ylim(58,97)\nax.yaxis.set_major_locator(ticker.MultipleLocator(10))\nax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\nplt.show()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nInput In [8], in &lt;cell line: 26&gt;()\n     24 ax.set_ylabel(f'{var} ({vk.units[var]})'.upper())\n     25 # ax.set_ylim(58,97)\n---&gt; 26 ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n     27 ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n     28 ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n\nNameError: name 'ticker' is not defined\n\n\n\n\n\n\n\n\n\n\n\nvar = 'Air Temperature'\n\n\n# Color dictionary\n# Mine from https://www.ipcc.ch/site/assets/uploads/2022/09/IPCC_AR6_WGI_VisualStyleGuide_2022.pdf\ncols = dict({\n    'Record High Year': 'black',\n    'Record High': '#811b1e',\n    'Average High': '#e71d25',\n    'Monthly Average': 'grey',\n    'Daily Average': 'grey',\n    'Average Low': '#5292cd',\n    'Record Low': '#0049cf'})\n# McNoldy\n# cols = dict({\n#     'Record High Year': 'white',\n#     'Record High': 'orange',\n#     'Average High': 'red',\n#     'Monthly Average': 'grey',\n#     'Daily Average': 'grey',\n#     'Average Low': 'purple',\n#     'Record Low': 'white'})\n\n\ndef daily_climo(data, var, colors=cols, show=False):\n    \"\"\"Create a daily climatology plot for environmental variable 'var'\n    from 'data'.\n    \n    Inputs:\n        data: dict, climatological stats dictionary from Data class object\n        var: str, one of the available environmental variables in 'data'\n        colors: dict, dictionary of series:color defining color to use for\n            each series (key) in 'data'\n        show: Bool, whether to display plot (True) or return plot object\n           (False, default) \n    \"\"\"\n\n    # Dates for x axis\n    xdates = pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D')\n    df = data[var]\n        \n    # Create figure\n    fig = go.Figure()\n\n    # Add series\n    annotations = []\n    for key, color in colors.items():\n        if 'Year' in key or 'Monthly' in key:\n            continue\n        if 'Average' in key:\n            fig.add_trace(\n            go.Scatter(\n                x=xdates, y=cos_fit(df[key]).round(1),\n                name=key.upper(),\n                marker=dict(size=1, color=color)\n            ))\n            annotations.append(dict(x=0.95, y=cos_fit(df[key])[-1],\n                               xref='paper', xshift=20,\n                               xanchor='left', yanchor='middle',\n                               text='{}'.format(key),\n                               font=dict(family='Arial',\n                                         size=14),\n                               showarrow=False))\n        else:\n            fig.add_trace(\n            go.Scatter(\n                x=xdates, y=df[key],\n                name=key.upper(),\n                mode='markers',\n                marker=dict(size=5, color=color)\n            ))\n            annotations.append(dict(x=0.95, y=df[key][-1],\n                               xref='paper', xshift=20,\n                               xanchor='left', yanchor='middle',\n                               text='{}'.format(key),\n                               font=dict(family='Arial',\n                                         size=14),\n                               showarrow=False))\n\n    # High records this year\n    high_records = df.loc[df['Record High Year']==pd.to_datetime('today').year, 'Record High']\n    high_records.index = pd.to_datetime(high_records.index+'-2020')\n    fig.add_trace(\n    go.Scatter(\n        x=high_records.index, y=high_records.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=7, color='black'),\n        hoverinfo='none',\n    ))\n\n    # Low records this year\n    low_records = df.loc[df['Record Low Year']==pd.to_datetime('today').year, 'Record Low']\n    low_records.index = pd.to_datetime(low_records.index+'-2020')\n    fig.add_trace(\n    go.Scatter(\n        x=low_records.index, y=low_records.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=7, color='black'),\n        hoverinfo='none'\n    ))\n\n#     # Record highs\n#     # High records this year\n#     high_records = df.loc[df['Record High Year']==pd.to_datetime('today').year, 'Record High']\n#     high_records.index = pd.to_datetime(high_records.index+'-2020')\n#     fig.add_trace(\n#     go.Scatter(\n#         x=high_records.index, y=high_records.values,\n#         name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n#         mode='markers',\n#         marker=dict(size=6, color='white'),\n#         hoverinfo='none'\n#     ))\n#     fig.add_trace(\n#     go.Scatter(\n#         x=xdates, y=df['Record High'],\n#         name='Record High'.upper(),\n#         mode='markers',\n#         marker=dict(size=3, color='orange')\n#     ))\n#     # Average highs\n#     fig.add_trace(\n#     go.Scatter(\n#         x=xdates, y=cos_fit(df['Average High']).round(1),\n#         name='Average High'.upper(),\n#         marker=dict(size=3, color='red')\n#     ))\n#     # Daily average\n#     fig.add_trace(\n#     go.Scatter(\n#         x=xdates, y=cos_fit(df['Daily Average']).round(1),\n#         name='Daily Average'.upper(),\n#         marker=dict(size=3, color='grey')\n#     ))\n#     # Average lows\n#     fig.add_trace(\n#     go.Scatter(\n#         x=xdates,\n#         y=cos_fit(df['Average Low']).round(1),\n#         name='Average Low'.upper(),\n#         marker=dict(size=3, color='purple')\n#     ))\n#     # Record lows\n#     fig.add_trace(\n#     go.Scatter(\n#         x=xdates, y=df['Record Low'],\n#         name='Record Low'.upper(),\n#         mode='markers',\n#         marker=dict(size=3, color='white')\n#     ))\n    # Hover box\n    fig.update_traces(\n        # mode = 'markers',    \n        hoverlabel = dict(bordercolor='white')\n    )\n    # Plot settings\n    thisYear = dt.datetime.today().year\n    fig.update_layout(\n        template='plotly_white',\n        # paper_bgcolor='rgba(0,0,0,0)',\n        # plot_bgcolor='rgba(245,245,245,245)',\n        plot_bgcolor='rgba(0,0,0,0)',\n        # height=600, width=1000,\n        title=dict(text='Daily {} Climatology since {}'.format(\n                        var,\n                        vk.filtered_data[var].dropna(axis=0).index.min().strftime('%B %Y')\n                        # vk.filtered_data[var].dropna(axis=0).index.min().strftime('%m/%d/%Y'),\n                        # vk.filtered_data[var].dropna(axis=0).index.max().strftime('%m/%d/%Y')\n                        )+\n                        '&lt;br&gt;&lt;sup&gt;As of {}, &lt;b&gt;{}&lt;/b&gt; daily records have been set in {}. Last year, {} daily records were set in total.&lt;/sup&gt;'.format(\n                        dt.datetime.today().strftime('%A, %b %d, %Y'),\n                        (data[var]==thisYear).sum().sum(),\n                        thisYear,\n                        (data[var]==thisYear-1).sum().sum()),\n                   font=dict(size=24,\n                              # family='PT Sans Narrow'\n                         )),\n        yaxis = dict(title=f'{var} ({vk.units[var]})',\n                     tickfont=dict(size=14),\n                     titlefont=dict(size=14)),\n        xaxis = dict(showgrid=False, showspikes=True,\n                     dtick='M1', tickformat='%b %d',\n                     tickfont=dict(size=14),\n                     fixedrange=True),\n        hovermode='x unified',\n        legend=dict(itemsizing='constant'),\n        hoverlabel=dict(font_size=12,\n                        # font_family=\"Rockwell\"\n                       ),\n        showlegend=False,\n        annotations=annotations,\n        margin=dict(r=22, l=0),\n        dragmode=False\n    )\n    if show:\n        fig.show()\n    else:\n        return fig\n\n\ndef monthly_climo(data, var, colors=cols, show=False):\n    \"\"\"Create a monthly climatology plot for environmental variable 'var'\n    from 'data'.\n    \n    Inputs:\n        data: dict, climatological stats dictionary from Data class object\n        var: str, one of the available environmental variables in 'data'\n        colors: dict, dictionary of series:color defining color to use for\n            each series (key) in 'data'\n        show: Bool, whether to display plot (True) or return plot object\n           (False, default) \n    \"\"\"\n\n    # Dates for x axis\n    xdates = pd.date_range(start='2020-01-01',end='2020-12-31', freq='MS')\n    df = data[var]\n    \n    # Create figure\n    fig = go.Figure()\n\n    # Add series\n    annotations = []\n    for key, color in colors.items():\n        if 'Year' in key or 'Daily' in key:\n            continue\n        if 'Average' in key:\n            fig.add_trace(\n            go.Scatter(\n                x=xdates, y=cos_fit(df[key]).round(1),\n                name=key.upper(),\n                marker=dict(size=1, color=color)\n            ))\n            annotations.append(dict(x=0.93, y=cos_fit(df[key])[-1],\n                               xref='paper', xshift=20,\n                               xanchor='left', yanchor='middle',\n                               text='{}'.format(key),\n                               font=dict(family='Arial',\n                                         size=14),\n                               showarrow=False))\n        else:\n            fig.add_trace(\n            go.Scatter(\n                x=xdates, y=df[key],\n                name=key.upper(),\n                mode='markers',\n                marker=dict(size=5, color=color)\n            ))\n            annotations.append(dict(x=0.93, y=df[key]['Dec'],\n                               xref='paper', xshift=20,\n                               xanchor='left', yanchor='middle',\n                               text='{}'.format(key),\n                               font=dict(family='Arial',\n                                         size=14),\n                               showarrow=False))\n\n    # High records this year\n    high_records = df.loc[df['Record High Year']==pd.to_datetime('today').year, 'Record High']\n    high_records.index = pd.to_datetime(high_records.index+'-2020')\n    fig.add_trace(\n    go.Scatter(\n        x=high_records.index, y=high_records.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=7, color='black'),\n        hoverinfo='none',\n    ))\n\n    # Low records this year\n    low_records = df.loc[df['Record Low Year']==pd.to_datetime('today').year, 'Record Low']\n    low_records.index = pd.to_datetime(low_records.index+'-2020')\n    fig.add_trace(\n    go.Scatter(\n        x=low_records.index, y=low_records.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=7, color='black'),\n        hoverinfo='none'\n    ))\n        \n    # Hover box\n    fig.update_traces(\n        # mode = 'markers',    \n        hoverlabel = dict(bordercolor='white')\n    )\n    # Plot settings\n    thisYear = dt.datetime.today().year\n    fig.update_layout(\n        template='plotly_white',\n        # paper_bgcolor='rgba(245,245,245,245)',\n        # plot_bgcolor='rgba(245,245,245,245)',\n        plot_bgcolor='rgba(0,0,0,0)',\n        #height=600, width=1000,\n        title=dict(text='Monthly {} Climatology since {}'.format(\n                        var,\n                        vk.filtered_data[var].dropna(axis=0).index.min().strftime('%B %Y')\n                        # vk.filtered_data[var].dropna(axis=0).index.min().strftime('%m/%d/%Y'),\n                        # vk.filtered_data[var].dropna(axis=0).index.max().strftime('%m/%d/%Y')\n                        )+\n                        '&lt;br&gt;&lt;sup&gt;As of {}, &lt;b&gt;{}&lt;/b&gt; monthly records have been set in {}. Last year, {} monthly records were set in total.&lt;/sup&gt;'.format(\n                        dt.datetime.today().strftime('%A, %b %d, %Y'),\n                        (data[var]==thisYear).sum().sum(),\n                        thisYear,\n                        (data[var]==thisYear-1).sum().sum()),\n                   font=dict(size=24,\n                              # family='PT Sans Narrow'\n                         )),\n        yaxis = dict(title=f'{var} ({vk.units[var]})',\n                     tickfont=dict(size=14),\n                     titlefont=dict(size=14)),\n        xaxis = dict(showgrid=False, showspikes=True,\n                     dtick='M1', tickformat='%b',\n                     tickfont=dict(size=14),\n                     fixedrange=True),\n        hovermode='x unified',\n        legend=dict(itemsizing='constant'),\n        hoverlabel=dict(font_size=12,\n                        # font_family=\"Rockwell\"\n                       ),\n        showlegend=False,\n        annotations=annotations,\n        margin=dict(r=22, l=0),\n        dragmode=False\n    )\n    fig.update_yaxes(ticksuffix = \"  \")\n    if show:\n        fig.show()\n    else:\n        return fig\n\n\n#daily_climo(vk.get_daily_stats_table(), 'Air Temperature')\n\n\nmonfig = monthly_climo(vk.get_monthly_stats_table(), 'Air Temperature', show=False)\n\n\nplotly.io.write_html(monfig, file=os.path.join(os.getcwd(), '_includes', 'figure-virginiakeyfl-airtemperature-monthly.html'),\n                     auto_open=True, full_html=False, include_plotlyjs='cdn',\n                     config=dict(responsive=True,\n                                 scrollZoom=True,\n                                 displaylogo=False,\n                                 modeBarButtonsToRemove=['lasso', 'select']))\n\n\ndayfig = daily_climo(vk.get_daily_stats_table(), 'Air Temperature', show=False)\n\n\nplotly.io.write_html(dayfig, file=os.path.join(os.getcwd(), '_includes', 'figure-virginiakeyfl-airtemperature-daily.html'),\n                     auto_open=True, full_html=False, include_plotlyjs='cdn',\n                     config=dict(responsive=True,\n                                 scrollZoom=True,\n                                 displaylogo=False,\n                                 modeBarButtonsToRemove=['lasso', 'select']))\n\n\nvk.get_monthly_stats_table('Air Temperature')\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nNumber of Years\n\n\n\n\nJan\n68.7\n72.6\n2013\n63.0\n2001\n76.1\n73.0\n2011\n78.7\n2016\n55.3\n63.5\n2013\n48.3\n1997\n26\n\n\nFeb\n70.7\n74.9\n2018\n62.7\n2010\n76.4\n73.8\n2010\n78.6\n2021\n59.3\n71.8\n2003\n47.9\n1996\n27\n\n\nMar\n72.2\n77.6\n2003\n66.1\n2010\n78.4\n74.2\n2010\n82.8\n2003\n63.4\n72.0\n1997\n55.1\n1996\n27\n\n\nApr\n75.5\n79.5\n2002\n71.4\n2005\n80.5\n75.9\n2005\n85.8\n2020\n68.3\n77.1\n2002\n61.2\n2009\n28\n\n\nMay\n78.4\n80.7\n1995\n74.8\n2001\n82.1\n79.4\n2007\n85.2\n1995\n73.7\n77.1\n2003\n67.9\n1999\n28\n\n\nJun\n81.2\n83.6\n2010\n78.7\n2002\n84.4\n82.0\n2002\n87.6\n2009\n77.4\n80.8\n2004\n74.6\n2007\n27\n\n\nJul\n82.9\n85.0\n2023\n81.0\n2013\n85.7\n84.2\n2012\n88.7\n2018\n79.1\n82.3\n2022\n76.1\n2013\n27\n\n\nAug\n83.2\n85.9\n2022\n81.8\n1994\n85.6\n84.0\n2003\n88.5\n2022\n79.4\n83.6\n2022\n76.1\n1996\n28\n\n\nSep\n82.2\n86.4\n2022\n80.6\n2001\n85.2\n82.8\n1997\n89.4\n2022\n78.5\n83.8\n2022\n74.3\n2001\n28\n\n\nOct\n79.7\n82.6\n2023\n77.5\n2000\n83.6\n81.0\n2010\n86.8\n2023\n73.2\n80.2\n2023\n64.6\n2005\n26\n\n\nNov\n74.9\n78.6\n2015\n71.4\n2012\n79.7\n76.9\n2012\n82.0\n2020\n65.9\n74.4\n2020\n57.4\n2006\n26\n\n\nDec\n71.4\n76.9\n2015\n62.1\n2010\n77.4\n72.5\n2010\n79.6\n1994\n59.4\n70.5\n2015\n48.8\n2010\n25\n\n\n\n\n\n\n\n\nvar = 'Water Temperature'\n\n\ng = vk.filtered_data['Water Temperature'].groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\n\n\ng[g.isna()['Water Temperature']]\n\n(43, 5)\n\n\n\nvk.filtered_data[var].loc['2019-12-31']\n\n\n\n\n\n\n\n\nWater Temperature\nYear\nMonth\nDay\nYearDay\nDOY\n\n\ntime_lst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng2 = vk.data['Water Temperature'].groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\n\n\ng2\n\ntime_lst\n1994-01-31    74.200000\n1994-02-28    74.359346\n1994-03-31    75.420326\n1994-04-30    79.387291\n1994-05-31    82.640816\n                ...    \n2023-06-30    85.444775\n2023-07-31    89.422191\n2023-08-31    88.533938\n2023-09-30    86.722042\n2023-10-31    85.322129\nFreq: M, Name: Water Temperature, Length: 358, dtype: float64\n\n\n\ng2[g2.isna()]\n\ntime_lst\n2006-10-31   NaN\n2006-11-30   NaN\n2006-12-31   NaN\n2007-02-28   NaN\n2007-03-31   NaN\n2007-04-30   NaN\n2007-05-31   NaN\n2007-06-30   NaN\n2007-07-31   NaN\n2007-08-31   NaN\n2007-09-30   NaN\n2007-10-31   NaN\n2007-11-30   NaN\n2007-12-31   NaN\n2008-01-31   NaN\n2008-02-29   NaN\n2008-03-31   NaN\n2008-04-30   NaN\n2008-05-31   NaN\n2008-06-30   NaN\n2008-07-31   NaN\n2008-08-31   NaN\n2008-09-30   NaN\n2008-10-31   NaN\n2008-11-30   NaN\n2008-12-31   NaN\n2009-01-31   NaN\n2009-02-28   NaN\n2017-03-31   NaN\n2019-03-31   NaN\n2019-04-30   NaN\n2019-05-31   NaN\n2019-06-30   NaN\n2019-07-31   NaN\n2019-08-31   NaN\n2019-09-30   NaN\n2019-10-31   NaN\n2019-11-30   NaN\nName: Water Temperature, dtype: float64\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "NOAA CO OPS Climatology"
    ]
  },
  {
    "objectID": "content/stations/virginiakey/index.html#dashboard",
    "href": "content/stations/virginiakey/index.html#dashboard",
    "title": "Virginia Key, FL",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\nAir TemperatureWater LevelWater Temperature\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n\n\n\nAir TemperatureWater LevelWater Temperature"
  },
  {
    "objectID": "content/data.html",
    "href": "content/data.html",
    "title": "What are these data?",
    "section": "",
    "text": "The National Oceanographic and Atmospheric Administration (NOAA) National Ocean Service Center for Operational Oceanographic Products and Services (CO-OPS) operates hundreds of water level observation stations along the United States coasts and Great Lakes. This National Water Level Observation Network (NWLON), part of the Integrating Ocean Observing System (IOOS), provides the data from which official tidal predictions are generated. Most of these observation stations also observe water temperature as well as air temperature, barometric pressure, and wind. All of these data are publically available via the NOAA CO-OPS Tides and Currents data portal.\nThe historical time series vary in length among sites and environmental parameters. Water level sensors often came first, with eather stations added later. Data collected since circa 1995 are generally available in 6-minute observations; prior to that, observations are hourly. Data inventories are provided every site:\n\nBeaufort, North Carolina\nWoods Hole, Massachusetts\nNaples, Florida\nBay St. Louis, Mississippi\nVirginia Key, Florida\nLewes, Delaware\n\nWater level sensors are calibrated and the observations are verified. None of the other variables are verified and should be used with caution.\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Overview",
      "What are these data?"
    ]
  },
  {
    "objectID": "content/demos/NOAA-CO-OPS-data.html",
    "href": "content/demos/NOAA-CO-OPS-data.html",
    "title": "Downloading NOAA CO-OPS Data",
    "section": "",
    "text": "In this notebook, we will download atmospheric and water observations from the National Oceanic and Atmospheric Administration (NOAA) Center for Operational Oceanographic Products and Services (CO-OPS) data portal. The objective is to replicate the Climatology for Virginia Key, FL page created and maintained by Brian McNoldy at the University of Miami Rosenstiel School of Marine, Atmospheric, and Earth Science.\nFor sake of demonstration, we will focus on air and water temperature from Virginia Key, FL. Ultimately, however, there are several variables of interest:\n\nAir temperature\nBarometric pressure\nWater temperature\nWater level (i.e., tides)\nWind speed\n\nThis notebook will simply download the data, store the metadata, and write these to file. The second notebook, NOAA-CO-OPS-records, will filter these data and calculate a set of statistics and records. Part 3, NOAA-CO-OPS-plots, will plot and display the data.\n\nPackages and configurations\nFirst we import the packages we need.\n\nfrom noaa_coops import Station\nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nimport yaml\nimport os\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes soem trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.n\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nNext, we define a number of functions that will come in handy later.\n\nHelper functions\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef get_units(variable, unit_system):\n    \"\"\"Return the desired units for 'variable'\"\"\"\n    unit_options = dict({\n        'Air Temperature': {'metric': 'C', 'english': 'F'},\n        'Barometric Pressure': {'metric': 'mb', 'english': 'mb'},\n        'Wind Speed': {'metric': 'm/s', 'english': 'kn'},\n        'Wind Gust': {'metric': 'm/s', 'english': 'kn'},\n        'Wind Direction': {'metric': 'deg', 'english': 'deg'},\n        'Water Temperature': {'metric': 'C', 'english': 'F'},\n        'Water Level': {'metric': 'm', 'english': 'ft'}\n    })\n    return unit_options[variable][unit_system]\n\ndef format_date(datestr):\n    \"\"\"Format date strings into YYYYMMDD format\"\"\"\n    dtdt = pd.to_datetime(datestr)\n    return dt.datetime.strftime(dtdt, '%Y%m%d')\n\n\n\nDownloading data\n\ndef load_atemp(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download air temperature data from NOAA CO-OPS between 'start_date'\n    and 'end_date' for 'stationid', 'unit_system', and timezone 'tz'\n    provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving air temperature data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Air Temperature']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    air_temp = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='air_temperature',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    air_temp.columns = ['atemp', 'atemp_flag']\n    return air_temp\n\ndef load_wind(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download wind data from NOAA CO-OPS between 'start_date' and\n    'end_date' for 'stationid', 'unit_system', and timezone 'tz' provided\n    in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving wind data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Wind']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    wind = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='wind',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    wind.columns = ['windspeed', 'winddir_deg', 'winddir',\n                    'windgust', 'wind_flag']\n    return wind\n\ndef load_atm_pres(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download barometric pressure data from NOAA CO-OPS between\n    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n    timezone 'tz' provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving barometric pressure data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Barometric Pressure']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    pressure = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='air_pressure',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    pressure.columns = ['apres', 'apres_flag']\n    return pressure\n\ndef load_water_temp(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download water temperature data from NOAA CO-OPS between\n    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n    timezone 'tz' provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving water temperature data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Water Temperature']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    water_temp = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='water_temperature',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    water_temp.columns = ['wtemp', 'wtemp_flag']\n    return water_temp\n\ndef load_water_level(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download water level data from NOAA CO-OPS between 'start_date' and\n    'end_date' for 'stationid', 'unit_system', 'datum', and timezone 'tz'\n    provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving water level tide data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Verified 6-Minute Water Level']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    water_levels = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='water_level',\n        datum=metadata['datum'],\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    water_levels.columns = ['wlevel', 's', 'wlevel_flag', 'wlevel_qc']\n    return water_levels\n\ndef download_data(metadata, start_date=None, end_date=None, verbose=True):\n    \"\"\"Download data from NOAA CO-OPS\"\"\"\n    # List of data variables to combine at the end\n    datasets = []\n            \n    # If no 'end_date' is passed, download through end of current date\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    \n    # Air temperature\n    if 'Air Temperature' in metadata['variables']:\n        air_temp = load_atemp(metadata=metadata, start_date=start_date,\n                              end_date=end_date, verbose=verbose)\n        air_temp['atemp_flag'] = air_temp['atemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        air_temp.loc[air_temp['atemp_flag'] &gt; 0, 'atemp'] = np.nan\n        datasets.append(air_temp['atemp'])\n\n    # Barometric pressure\n    if 'Barometric Pressure' in metadata['variables']:\n        pressure = load_atm_pres(metadata=metadata, start_date=start_date,\n                                 end_date=end_date, verbose=verbose)\n        pressure['apres_flag'] = pressure['apres_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        pressure.loc[pressure['apres_flag'] &gt; 0, 'apres'] = np.nan\n        datasets.append(pressure['apres'])\n\n    # Wind\n    if 'Wind Speed' in metadata['variables']:\n        metadata['variables'].extend(['Wind Gust'])\n        wind = load_wind(metadata=metadata, start_date=start_date,\n                         end_date=end_date, verbose=verbose)\n        wind['windflag'] = wind['wind_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        wind.loc[wind['wind_flag'] &gt; 0, ['windspeed', 'windgust']] = np.nan\n        datasets.append(wind[['windspeed', 'windgust']])\n\n    # Water temperature\n    if 'Water Temperature' in metadata['variables']:\n        water_temp = load_water_temp(metadata=metadata, start_date=start_date,\n                                     end_date=end_date, verbose=verbose)\n        water_temp['wtemp_flag'] = water_temp['wtemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        water_temp.loc[water_temp['wtemp_flag'] &gt; 0, 'wtemp'] = np.nan\n        datasets.append(water_temp['wtemp'])\n\n    # Water level (tides)\n    if 'Verified 6-Minute Water Level' in metadata['variables']:\n        water_levels = load_water_level(metadata=metadata, start_date=start_date,\n                                        end_date=end_date, verbose=verbose)\n        water_levels['wlevel_flag'] = water_levels['wlevel_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        water_levels.loc[water_levels['wlevel_flag'] &gt; 0, 'wlevel'] = np.nan\n        datasets.append(water_levels['wlevel'])\n\n    # Merge into single dataframe and rename columns\n    newdata = pd.concat(datasets, axis=1)\n    newdata.index.name = f'time_{metadata[\"tz\"]}'\n    newdata.columns = [i for i in metadata['variables']]\n    return newdata\n\n\n\n\nLoad / download data\nNow it’s time to load the data. First, specify the station we want to load. This will be used to load saved data or download all data from a new station, if we have not yet retrieved data from this particular stationname.\nstationname is a custom human-readable “City, ST” string for the station, while id is the NOAA-COOPS station ID number.\n\nstationname = 'Virginia Key, FL'\nid = '8723214'\n\nDerive the directory name containing for data from the station name. This is where the data are or will be saved locally.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: /home/climatology/virginiaKeyFl\n\n\nFlag for printing statuses\n\nverbose = True\n\nLet’s see if we already have data from this station saved locally. This will be true if a directory already exists for the station.\nIf the directory outdir does not exist, then no data have been downloaded for this station, so we need to download everything through the present. This requires a few steps:\n\nCreate outdir\nLoad the configuration settings from station-init.yml. This file contains settings such as unit system, time zone, and what variables to retrieve. Using a init file like this makes it easier to keep the same settings across multiple stations. It will be read in as a Python dictionary, which we will call meta and will use to store all relevant metadata for the station.\nDownload the data and record the timestamp of the last observation in the metadata. This will be used later when updating the data.\nWrite the data and metadata to file.\n\nOn the other hand, if data already exist locally, we will load it from file and download new data we do not yet have:\n\nLoad the data and metadata from file\nRetrieve new data\nCombine new data to existing data, update the ‘last_updated’ metadata entry, and write data and metadata to file\n\nThe noaa-coops tool only accepts dates without times, so it is possible to download data we already have. We therefore have to check what we download against what we already have to avoid duplicating data.\nThe most likely (and perhaps only) scenerio is if the data we have for the most recent day is incomplete. For example, assume today is May 5, 2024 and we download data at noon. Also assume the start date is some earlier day, the last time we retrieved data, and this will be automatically determined from the metadata. Specifying an end date 2024-05-01 will retrieve all data available through noon on May 5. In this case, we do not yet have these data, so we concatenate what we do not have to what we do have. However, if we then run the download function again (say, for diagnostic purposes) with the new start date of 2024-05-01 and the end date 2024-05-01, it will again download the data through noon on May 5. But since we already have those data, we do not want to re-concatenate them.\nThis cell may take several seconds or minutes to run, depending on how much data is being downloaded.\n\nif not os.path.exists(outdir):\n    if verbose:\n        print('Creating new directory for this station.')\n    os.makedirs(outdir)\n\n    # Metadata configuration\n    with open('station-init.yml') as d:\n        meta = yaml.safe_load(d)\n    meta['units'] = {k:get_units(k, meta['unit_system']) for k in meta['variables']}\n    meta['outdir'] = outdir\n    meta['stationname'] = stationname\n    meta['stationid'] = id\n\n    # Download all data (set start and end date to None to get all data)\n    if verbose:\n        print('Downloading all data for this station.')\n    data = download_data(metadata=meta, start_date=None, end_date=None)\n    data.to_csv(os.path.join(meta['outdir'], 'observational_data_record.csv.gz'),\n                             compression='infer')\n    print(\"Updated observational data written to file \"\\\n          f\"{os.path.join(meta['outdir'], 'observational_data_record.csv')}.\")\n\n    # Save metadata\n    meta['last_updated'] = str(data.index.max())\n    if verbose:\n        print(f\"Metadata written to file {os.path.join(meta['outdir'], 'metadata.yml')}\")\n    with open(os.path.join(meta['outdir'], 'metadata.yml'), 'w') as fp:\n        yaml.dump(meta, fp)\n    \nelse:\n    # Load the metadata\n    if verbose:\n        print('Loading metadata from file')\n    with open(os.path.join(outdir, 'metadata.yml')) as m:\n        meta = yaml.safe_load(m)\n    \n    # Load the historical data\n    if verbose:\n        print('Loading data from file')\n    data = pd.read_csv(os.path.join(outdir, 'observational_data_record.csv.gz'),\n                       index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n                       compression='infer')\n\n    # Retrieve new data\n    newdata = download_data(metadata=meta, start_date=format_date(meta['last_updated']))\n    if sum(~newdata.index.isin(data.index)) == 0:\n        print('No new data available.')\n    else:\n        data = pd.concat([data,\n                          newdata[newdata.index.isin(data.index) == False]], axis=0)\n        data.to_csv(os.path.join(meta['outdir'], 'observational_data_record.csv.gz'),\n                                 compression='infer')\n        meta['last_updated'] = str(data.index.max())\n        with open(os.path.join(meta['outdir'], 'metadata.yml'), 'w') as fp:\n            yaml.dump(meta, fp)\n        print(\"Updated observational data written to file \"\\\n              f\"{os.path.join(meta['outdir'], 'observational_data_record.csv')}.\")\n\nLoading metadata from file\nLoading data from file\nRetrieving air temperature data\nRetrieving water temperature data\nNo new data available.\n\n\nCheck the data and metadata for sanity:\n\ndata\n\n\n\n\n\n\n\n\nAir Temperature\nWater Temperature\n\n\ntime_lst\n\n\n\n\n\n\n1994-01-28 00:00:00\nNaN\nNaN\n\n\n1994-01-28 00:06:00\nNaN\nNaN\n\n\n1994-01-28 00:12:00\nNaN\nNaN\n\n\n1994-01-28 00:18:00\nNaN\nNaN\n\n\n1994-01-28 00:24:00\nNaN\nNaN\n\n\n...\n...\n...\n\n\n2024-05-25 09:36:00\n83.5\n86.0\n\n\n2024-05-25 09:42:00\n83.5\n86.2\n\n\n2024-05-25 09:48:00\n83.7\n86.2\n\n\n2024-05-25 09:54:00\n83.8\n86.2\n\n\n2024-05-25 10:00:00\n83.7\n86.2\n\n\n\n\n2466580 rows × 2 columns\n\n\n\n\nmeta\n\n{'datum': 'MHHW',\n 'day_threshold': 2,\n 'hr_threshold': 3,\n 'last_updated': '2024-05-25 10:00:00',\n 'outdir': '/home/climatology/virginiaKeyFl',\n 'stationid': '8723214',\n 'stationname': 'Virginia Key, FL',\n 'tz': 'lst',\n 'unit_system': 'english',\n 'units': {'Air Temperature': 'F', 'Water Temperature': 'F'},\n 'variables': ['Air Temperature', 'Water Temperature']}\n\n\n\nlen(data.index.unique()) == data.shape[0]\n\nTrue\n\n\nThe ‘last_updated’ metadata flag matches the last observation in the data record and corresponds to the most recently available observation. Also, every observation time is unique, so there are no duplicated entries. So, everything checks out.\nIn the next part, NOAA-CO-OPS-records, we will clean filter these data and calculate statistics and records.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Overview",
      "Demonstrations",
      "Downloading NOAA CO-OPS Data"
    ]
  },
  {
    "objectID": "content/demos/NOAA-CO-OPS-plots.html",
    "href": "content/demos/NOAA-CO-OPS-plots.html",
    "title": "Plotting Records",
    "section": "",
    "text": "This notebook is the last in a series of three notebooks demonstrating how daily and monthly record highs, lows, and averages are calculated from NOAA CO-OPS weather and tide station data. The notebook follows sequentially from NOAA-CO-OPS-records in which we calculated record highs, lows, and averages from observational data for a particular NOAA CO-OPS weather and tide station. Daily and monthly records were written to netCDF files. Here we visualize these records as plots and as a colored dataframe.\nIn the previous notebook we calculated several records of interest:\n\nDaily and monthly averages\nRecord high daily and monthly averages*\nRecord low daily and monthly averages*\nAverage daily and monthly high\nLowest daily and monthly high*\nRecord daily and monthly high*\nAverage daily and monthly low\nHighest daily and monthly low*\nRecord daily and monthly low*\n\nFor those records marked with an asterisk (*), we also noted the year in which that particular record was set. Now let’s return to these statistics to visualize them.\n\nPackages and configurations\nAs always, we frst import the packages we need. We will use Bokeh to make interactive plots and great_tables to display the data behind the plots in a visually appealing manner.\nTo better visualize the seasonality of daily and monthly averages, average highs, and average lows, we will fit a curve to the calculated averages and plot these curves instead of the actual values. This will be done with curve_fit from SciPy.\n\nfrom datetime import datetime as dt\nfrom scipy.optimize import curve_fit\nfrom great_tables import GT, loc, style\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nimport bokeh.models as bm\nimport pandas as pd\nimport xarray as xr\nimport numpy as np\nimport os\noutput_notebook(hide_banner=True)\n\n\n\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes some trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nLet’s define functions to plot the daily and monthly data. These two plots will be similar in appearance but have some differences (for example, the x axis), so two separate functions will be needed.\nFirst, we’ll need some helper functions. Some of these were used previously, while others are new:\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef round_down(num, divisor):\n    \"\"\"Round num down to the nearest divisor.\n    For example, round_down(45.5, 10) will return 40.\n    \"\"\"\n    return num - (num%divisor)\n\ndef round_up(num, divisor):\n    \"\"\"Round num up to the nearest divisor.\n    For example, round_up(45.5, 10) will return 50.\n    \"\"\"\n    return num + (divisor - (num%divisor))\n\ndef cos_fit(data, plot=False):\n    \"\"\"Fit cosine curve to data\"\"\"\n    X = np.arange(0, len(data))/len(data)\n\n    # Initial parameter values\n    guess_freq = 1\n    guess_amplitude = 3*np.std(data)/(2**0.5)\n    guess_phase = 0\n    guess_offset = np.mean(data)\n    p0 = [guess_freq, guess_amplitude,\n          guess_phase, guess_offset]\n\n    # Function to fit\n    def my_cos(x, freq, amplitude, phase, offset):\n        return np.cos(x * freq + phase) * amplitude + offset\n\n    # Fit curve to data\n    fit = curve_fit(my_cos, X, data, p0=p0)\n\n    if plot:\n        fig, ax = plt.subplots(1, 1, figsize=(12,5))\n\n        ax.plot(data, label=data.name)\n        ax.plot(fit, color='red', label=f'Cosine fit')\n\n        ax.legend(loc='best')\n        plt.show()\n    else:\n        return my_cos(np.array(X), *fit[0])\n    \n\nDefining all of the colors in a dictionary will make it easier to customize everything later and will clean up the plotting codes. Below is a dictionary of three color schemes: “mg” are my chosen colors, “bm” colors are the same color scheme as Brian McNoldy’s figures on his website, and “cb” are colorblind-friendly colors.\n\n# Color dictionary\n# https://www.tutorialrepublic.com/css-reference/css-color-names.php\ncolors = dict(\n    mg=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': '#F5F5F5',\n        'Monthly Average': '#F5F5F5',\n        'Record High Daily Average': '#ff8080',\n        'Record High Daily Average Year': '#ff8080',\n        'Record High Monthly Average': '#ff8080',\n        'Record High Monthly Average Year': '#ff8080',\n        'Record Low Daily Average': '#c1d5f8',\n        'Record Low Daily Average Year': '#c1d5f8',\n        'Record Low Monthly Average': '#c1d5f8',\n        'Record Low Monthly Average Year': '#c1d5f8',\n        'Average High': '#dc8d8d',\n        'Lowest High': '#e6aeae',\n        'Lowest High Year': '#e6aeae',        \n        'Record High': '#d26c6c',\n        'Record High Year': '#d26c6c',\n        'Average Low': '#a2bff4',\n        'Highest Low': '#d1dffa',\n        'Highest Low Year': '#d1dffa',\n        'Record Low': '#74a0ef',\n        'Record Low Year': '#74a0ef',\n        'Years': 'white',\n        'Plot Light Color': '#D3D3D3'}),\n    bm=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': 'gainsboro',\n        'Monthly Average': 'gainsboro',\n        'Record High Daily Average': 'mistyrose',\n        'Record High Daily Average Year': 'mistyrose',\n        'Record High Monthly Average': 'mistyrose',\n        'Record High Monthly Average Year': 'mistyrose',\n        'Record Low Daily Average': 'lavender',\n        'Record Low Daily Average Year': 'lavender',\n        'Record Low Monthly Average': 'lavender',\n        'Record Low Monthly Average Year': 'lavender',\n        'Average High': 'orangered',\n        'Lowest High': 'darkorange',\n        'Lowest High Year': 'darkorange',        \n        'Record High': 'orange',\n        'Record High Year': 'orange',\n        'Average Low': 'mediumpurple',\n        'Highest Low': 'navyblue',\n        'Highest Low Year': 'navyblue',\n        'Record Low': 'lightblue',\n        'Record Low Year': 'lightblue',\n        'Years': 'white',\n        'Plot Light Color': 'white'}),\n    cb=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': '#F5F5F5',\n        'Monthly Average': '#F5F5F5',\n        'Record High Daily Average': '#',\n        'Record High Daily Average Year': '#',\n        'Record High Monthly Average': '#',\n        'Record High Monthly Average Year': '#',\n        'Record Low Daily Average': '#',\n        'Record Low Daily Average Year': '#',\n        'Record Low Monthly Average': '#',\n        'Record Low Monthly Average Year': '#',\n        'Average High': '#dc8d8d',\n        'Lowest High': '#',\n        'Lowest High Year': '#',        \n        'Record High': '#d26c6c',\n        'Record High Year': '#d26c6c',\n        'Average Low': '#a2bff4',\n        'Highest Low': '#',\n        'Highest Low Year': '#',\n        'Record Low': '#74a0ef',\n        'Record Low Year': '#74a0ef',\n        'Years': 'white',\n        'Plot Light Color': 'white'})\n    )\n\nThe plots will be made using Bokeh for interactivity. Consequently, there are many steps involved in building and formatting the plot with the desired functionality. We will plot daily/monthly averages, average highs, and average lows as curves; record highs and record lows as points, and will highlight records set this year for emphasis. The plot will also contain a legend and a hoverbox that displays the values of each series for a given date when one hovers one’s mouse over the plot. The functions below will be used to generate daily and monthly climatology plots, and comments within the functions explain what each step does.\nNote that daily_climo also supports showing flood thresholds when used to plot water level data. THese thresholds need to be retrieved for each site and passed as a dictionary, for example:\n\nfloods = {'Major Flood Threshold': 2.5,\n          'Moderate Flood Threshold': 1.7,\n          'Minor Flood Threshold': 1.3}\n\n\ndef daily_climo(data, var, flood_thresholds=None, scheme='mg'):\n    \"\"\"Create a daily climatology plot for environmental variable 'var'\n    from 'data' using color scheme 'scheme'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        flood_threshold: dict containing flood thresholds to add to water\n            level plot\n        scheme: str specifying which color scheme to use. Options: 'mg'\n            for M. Grossi's, 'bm' for B. McNoldy's, or 'cb' to use a\n            colorblind scheme\n    \"\"\"\n\n    # Dates for x axis\n    df = data.sel(variable=var).to_dataframe().drop('variable', axis=1)\n    df['xdates'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D')\n    df['Average High Curve'] = cos_fit(df['Average High']).round(1)\n    df['Daily Average Curve'] = cos_fit(df['Daily Average']).round(1)\n    df['Average Low Curve'] = cos_fit(df['Average Low']).round(1)\n    \n    # Record this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1)[['Record High Year', 'Record Low Year']].sum().sum()\n    df['High Records'] = df['Record High'].where(df['Record High Year'] == thisYear)\n    df['Low Records'] = df['Record Low'].where(df['Record Low Year'] == thisYear)\n    source = bm.ColumnDataSource(df)\n    \n    # Create a new plot\n    ts_start = dt.strptime(data.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    ts_end = dt.strptime(data.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    p = figure(title='Daily {} records  |  {} - {}\\n'.format(var.lower(), ts_start, ts_end).upper()+\n                     'As of today, {} {} record highs/lows have been set. '.format(thisYearRecords, var.lower())+\n                     'Last year, {} records were set.'.format(lastYearRecords),\n               background_fill_color='#404040', border_fill_color='#404040',\n               width=1000, height=600, x_axis_type='datetime',\n               y_range=(round_down(df['Record Low'].min(), 10), round_up(df['Record High'].max(), 10)),\n               tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n               outline_line_color=None, sizing_mode='scale_height')\n\n    # This year record highs\n    hr = p.scatter(x='xdates', y='High Records', source=source,\n                   name=f'{thisYear} High Record', size=6, color='white')\n    # This year record lows\n    lr = p.scatter(x='xdates', y='Low Records', source=source,\n                   name=f'{thisYear} Low Record', size=6, color='white')\n    # Record highs\n    rh = p.scatter(x='xdates', y='Record High', source=source,\n                   name='Record High', size=2,\n                   color=colors[scheme]['Record High'])\n    # Average high\n    ah = p.line(x='xdates', y='Average High Curve', source=source,\n                name='Average High', width=3,\n                color=colors[scheme]['Average High'])\n    # Daily average\n    da = p.line(x='xdates', y='Daily Average Curve', source=source,\n                name='Daily Average', width=2,\n                color=colors[scheme]['Daily Average'])\n    # Average lows\n    al = p.line(x='xdates', y='Average Low Curve', source=source,\n                name='Average Low', width=3,\n                color=colors[scheme]['Average Low'])\n    # Record lows\n    rl = p.scatter(x='xdates', y='Record Low', source=source,\n                   name='Record Low', size=2,\n                   color=colors[scheme]['Record Low'],\n                   hover_fill_color='white', hover_alpha=0.5)\n\n    # Flood thresholds (water level plot only)\n    if var=='Water Level' and threshold is not None:\n        for level, threshold in flood_thresholds.items():\n            hline = Span(location=threshold, dimension='width',\n                         line_dash=[20,8], line_alpha=0.75,\n                         line_color='cadetblue', line_width=2)\n            p.renderers.extend([hline])\n            mytext = bm.Label(x=pd.to_datetime('2019-12-15'), y=threshold+0.1,\n                              text=level.upper(), text_color='cadetblue',\n                              text_font_size='8px',\n                              text_font='arial narrow')\n            p.add_layout(mytext)\n    \n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                              line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[da],\n                      formatters={'@xdates': 'datetime'})\n    hover.tooltips = \"\"\"\n        &lt;b&gt; @xdates{{%b %d}} &lt;/b&gt; &lt;br&gt;\n        Record High: @{{Record High}}{{0.0}} &lt;br&gt;\n        Average High: @{{Average High Curve}}{{0.0}} &lt;br&gt;\n        Daily Average: @{{Daily Average Curve}}{{0.0}} &lt;br&gt;\n        Average Low: @{{Average Low Curve}}{{0.0}} &lt;br&gt;\n        Record Low: @{{Record Low}}{{0.0}} &lt;br&gt;\n        {} High Record: @{{High Records}}{{0.0}} &lt;br&gt;\n        {} Low Record: @{{Low Records}}{{0.0}}\n        \"\"\".format(thisYear, thisYear)\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n\n    # x-axis\n    p.xaxis[0].formatter = bm.DatetimeTickFormatter(months=\"%b %d\")\n    p.xaxis[0].ticker.desired_num_ticks = 12\n    p.xgrid.grid_line_color = None\n    p.xaxis.axis_line_color = 'grey'\n    p.xaxis.major_tick_line_color = 'grey'\n    \n    # y-axis\n    p.yaxis.axis_label=f'{var} ({data.attrs[f\"{var} units\"]})'\n    p.yaxis.axis_label_text_color = colors[scheme]['Plot Light Color']\n    p.ygrid.grid_line_color = 'grey'\n    p.yaxis.axis_line_color = None\n    p.yaxis.major_tick_line_color = None\n    p.yaxis.minor_tick_line_color = None\n    \n    # Fonts\n    p.title.text_font = 'arial narrow'\n    p.title.text_font_size = '16px'\n    p.title.text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font = 'arial narrow'\n    p.xaxis.major_label_text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.major_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font_style = 'normal'\n    p.yaxis.major_label_text_color = colors[scheme]['Plot Light Color']    \n    p.yaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.axis_label_text_font_size = \"14px\"\n\n    # Legend\n    legend = bm.Legend(items=[\n        ('{} Record'.format(thisYear), [hr, lr]),\n        ('Record High', [rh]),\n        ('Average High', [ah]),\n        ('Daily Average', [da]),\n        ('Average Low', [al]),\n        ('Record Low', [rl])],\n                    background_fill_color='#404040', border_line_color=None,\n                    label_text_color=colors[scheme]['Plot Light Color'],\n                    location='center_right', click_policy='mute')\n    p.add_layout(legend, 'right')\n    \n    # Show the results\n    show(p)\n\ndef monthly_climo(data, var, scheme='mg'):\n    \"\"\"Create a monthly climatology plot for environmental variable 'var'\n    from 'data' using color scheme 'scheme'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        scheme: str specifying which color scheme to use. Options: 'mg'\n            for M. Grossi's, 'bm' for B. McNoldy's, or 'cb' to use a\n            colorblind scheme\n    \"\"\"\n\n    # Dates for x axis\n    df = data.sel(variable=var).to_dataframe().drop('variable', axis=1).reset_index()\n    df['Average High Curve'] = cos_fit(df['Average High']).round(1)\n    df['Monthly Average Curve'] = cos_fit(df['Monthly Average']).round(1)\n    df['Average Low Curve'] = cos_fit(df['Average Low']).round(1)\n    \n    # Record this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1)[['Record High Year', 'Record Low Year']].sum().sum()\n    df['High Records'] = df['Record High'].where(df['Record High Year'] == thisYear)\n    df['Low Records'] = df['Record Low'].where(df['Record Low Year'] == thisYear)\n    source = bm.ColumnDataSource(df)\n    \n    # Create a new plot\n    ts_start = dt.strptime(data.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    ts_end = dt.strptime(data.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    p = figure(title='Monthly {} records  |  {} - {}\\n'.format(var.lower(), ts_start, ts_end).upper()+\n                     'As of today, {} {} record highs/lows have been set. '.format(thisYearRecords, var.lower())+\n                     'Last year, {} records were set.'.format(lastYearRecords),\n               background_fill_color='#404040', border_fill_color='#404040',\n               width=1000, height=600,\n               x_range=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n               y_range=(round_down(df['Record Low'].min(), 10), round_up(df['Record High'].max(), 10)),\n               tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n               outline_line_color=None, sizing_mode='scale_height')\n\n    # This year record highs\n    hr = p.scatter(x='Month', y='High Records', source=source,\n                   name=f'{thisYear} High Record', size=6, color='white')\n    # This year record lows\n    lr = p.scatter(x='Month', y='Low Records', source=source,\n                   name=f'{thisYear} Low Record', size=6, color='white')\n    # Record highs\n    rh = p.scatter(x='Month', y='Record High', source=source,\n                   name='Record High', size=7,\n                   color=colors[scheme]['Record High'])\n    # Average high\n    ah = p.line(x='Month', y='Average High Curve', source=source,\n                name='Average High', width=4,\n                color=colors[scheme]['Average High'])\n    # Monthly average\n    ma = p.line(x='Month', y='Monthly Average Curve', source=source,\n                name='Monthly Average', width=3,\n                color=colors[scheme]['Monthly Average'])\n    # Average lows\n    al = p.line(x='Month', y='Average Low Curve', source=source,\n                name='Average Low', width=4,\n                color=colors[scheme]['Average Low'])\n    # Record lows\n    rl = p.scatter(x='Month', y='Record Low', source=source,\n                   name='Record Low', size=7,\n                   color=colors[scheme]['Record Low'],\n                   hover_fill_color='white', hover_alpha=0.5)\n    \n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                              line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[ma],\n                      formatters={'@xdates': 'datetime'})\n    hover.tooltips = \"\"\"\n        &lt;b&gt; @Month &lt;/b&gt; &lt;br&gt;\n        Record High: @{{Record High}}{{0.0}} &lt;br&gt;\n        Average High: @{{Average High Curve}}{{0.0}} &lt;br&gt;\n        Daily Average: @{{Daily Average Curve}}{{0.0}} &lt;br&gt;\n        Average Low: @{{Average Low Curve}}{{0.0}} &lt;br&gt;\n        Record Low: @{{Record Low}}{{0.0}} &lt;br&gt;\n        {} High Record: @{{High Records}}{{0.0}} &lt;br&gt;\n        {} Low Record: @{{Low Records}}{{0.0}}\n        \"\"\".format(thisYear, thisYear)\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n\n    # x-axis\n    p.xgrid.grid_line_color = None\n    p.xaxis.axis_line_color = 'grey'\n    p.xaxis.major_tick_line_color = 'grey'\n    \n    # y-axis\n    p.yaxis.axis_label=f'{var} ({data.attrs[f\"{var} units\"]})'\n    p.yaxis.axis_label_text_color = colors[scheme]['Plot Light Color']\n    p.ygrid.grid_line_color = 'grey'\n    p.yaxis.axis_line_color = None\n    p.yaxis.major_tick_line_color = None\n    p.yaxis.minor_tick_line_color = None\n    \n    # Fonts\n    p.title.text_font = 'arial narrow'\n    p.title.text_font_size = '16px'\n    p.title.text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font = 'arial narrow'\n    p.xaxis.major_label_text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.major_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font_style = 'normal'\n    p.yaxis.major_label_text_color = colors[scheme]['Plot Light Color']    \n    p.yaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.axis_label_text_font_size = \"14px\"\n\n    # Legend\n    legend = bm.Legend(items=[\n        ('{} Record'.format(thisYear), [hr, lr]),\n        ('Record High', [rh]),\n        ('Average High', [ah]),\n        ('Monthly Average', [ma]),\n        ('Average Low', [al]),\n        ('Record Low', [rl])],\n                    background_fill_color='#404040', border_line_color=None,\n                    label_text_color=colors[scheme]['Plot Light Color'],\n                    location='center_right', click_policy='mute')\n    p.add_layout(legend, 'right')\n    \n    # Show the results\n    show(p)\n\n\n\nLoading data\nNow we need to load in the records for the desired station, which will be used to determine the directory from which to load the data. As before, stationname is the custom human-readable “City, ST” string for the station.\n\nstationname = 'Virginia Key, FL'\n\nDerive the local directory name containing the data from the station name. This is the same way the directory was created when the data were downloaded.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: /workspaces/climatology-quarto/virginiaKeyFl\n\n\nNext, load the data and metadata.\n\n# Records\ndays = xr.load_dataset(os.path.join(outdir, 'statistics-daily.nc'))\nmons = xr.load_dataset(os.path.join(outdir, 'statistics-monthly.nc'))\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 96 from PyObject\n\n\nAnd finally, we can make some plots. Let’s look at daily and monthly climatologies for Air Temperature.\n\nvar = 'Air Temperature'\ndaily_climo(data=days, var=var, flood_thresholds=floods, scheme='mg')\n\n\n  \n\n\n\n\n\n\nmonthly_climo(data=mons, var=var, scheme='mg')\n\n\n  \n\n\n\n\n\n\n\nData Table\nOne may wish to see the data behind these plots, or see the other records not plotted. We will use the great_table library to display colored tables. We’ll demonstrate this below for Air Temperature.\n“great_tables” displays dataframes, so we first need to extract the data from the xarray object, convert to a Pandas datarame, and reset the index.\n\nstats = mons.sel(variable=var.title()).to_dataframe().drop('variable', axis=1).reset_index()\n\n# Create the `great_tables`` object and add the columns\n# We also specify any formatting of each column here including the color using the color dictionary defined above.\ngtbl = GT(stats)\nfor column in stats.columns:\n    gtbl = gtbl.tab_style(style=[style.fill(color=colors['mg'][column]), style.text(align='center', v_align='middle')], locations=loc.body(columns=column))\n\n# Now we format the rest of the table\ngtbl = (gtbl\n.cols_align(align='center')\n.tab_style(style=[style.text(color='gainsboro', weight='bold'), style.fill(color='dimgray')], locations=loc.column_header())\n.tab_options(table_font_size='13px', table_body_hlines_color='white'))\n\ngtbl.show()\n\n\n\n\n\n\n\nMonth\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\nJan\n68.7\n72.6\n2013\n63.0\n2001\n76.0\n73.0\n2011\n78.0\n2015\n55.6\n63.5\n2013\n48.3\n1997\n23\n\n\nFeb\n70.8\n74.9\n2018\n65.5\n1996\n76.5\n74.2\n2000\n78.6\n2021\n59.4\n70.0\n2018\n47.9\n1996\n23\n\n\nMar\n72.3\n77.6\n2003\n66.1\n2010\n78.5\n74.2\n2010\n82.8\n2003\n63.3\n72.0\n1997\n55.1\n1996\n24\n\n\nApr\n75.6\n79.4\n2020\n72.8\n2004\n80.8\n77.3\n2004\n85.8\n2020\n68.3\n72.6\n2015\n61.2\n2009\n24\n\n\nMay\n78.7\n80.7\n1995\n77.0\n2013\n82.5\n80.8\n2014\n85.2\n1995\n73.8\n77.1\n2003\n67.9\n1999\n21\n\n\nJun\n81.5\n83.6\n2010\n79.8\n2014\n84.8\n82.8\n2014\n87.6\n2009\n77.6\n80.8\n2004\n75.1\n1995\n20\n\n\nJul\n82.9\n85.0\n2023\n81.0\n2013\n85.8\n84.2\n2012\n88.7\n2018\n79.0\n82.3\n2022\n76.1\n2013\n25\n\n\nAug\n83.2\n85.9\n2022\n81.8\n1994\n85.7\n84.0\n2003\n88.5\n2022\n79.3\n83.6\n2022\n76.1\n1996\n24\n\n\nSep\n82.0\n82.7\n2017\n80.6\n2001\n85.1\n83.9\n2000\n86.7\n2021\n78.2\n79.8\n2009\n74.3\n2001\n24\n\n\nOct\n79.6\n81.2\n2020\n77.5\n2000\n83.8\n81.0\n2010\n86.8\n2023\n72.7\n77.8\n1995\n64.6\n2005\n23\n\n\nNov\n75.0\n78.6\n2015\n71.4\n2012\n79.7\n76.9\n2012\n82.0\n2020\n66.0\n74.4\n2020\n57.4\n2006\n23\n\n\nDec\n71.4\n76.9\n2015\n62.1\n2010\n77.5\n72.5\n2010\n79.6\n1994\n59.2\n70.5\n2015\n48.8\n2010\n24\n\n\n\n\n\n\n        \n\n\nAnd there we have it! All of the records for each month, color coded for easier reading.\nSome concluding remarks on the choice of packages here. Another common Python library for making interactive plots is Plotly. We tried this first (see below), but encountered a known issue with rendering Plotly plots in Quarto web dashboards. In short, the first time Plotly is called in a web application, the plot renders to the proper size of the web container, but subsequent calls to Plotly (like navigating to a new tab or page) do not size figures properly. The workaround demonstrated here fixed the width rendering, but the all of the resulting plots were only half the height of the container/page. Plotly also supports displaying colored tables, but these experienced the same rendering issue with Quarto. Cue Bokeh. This library did not have the rendering problem, although the plots had slighly less interactivity than the Plotly version. Creating colored tables with Bokeh, however, turned out to be frustratingly difficult and very poorly documented. For example, Bokeh tables are colored using HTML, but there was no documentation on how to color an entire column of data. In contrast, the new library great_tables made this easy, although it too currently lacks the full interactivity that Plotly offered (e.g., sorting by column).\n\nThe following is a Plotly of the daily climatology plot above. It is basically the same but supports some behaviors that, so far, are not possible (or much harder to accomplish) with Bokeh, such as only showing records in the hoverbox on days when a record is set.\n\nimport plotly.graph_objects as go\n\n\ndef daily_climo(data, var, scheme='mg'):\n    \"\"\"Create a daily climatology plot for environmental variable 'var'\n    from 'data'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        scheme: str, either 'mg' or 'bm' specifying whether to use M. Grossi's\n            color scheme or B. McNoldy's\n        show: Bool, display the plot to screen instead of saving to file\n    \"\"\"\n\n    # Dates for x axis\n    xdates = pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D')\n    df = data.sel(variable=var)\n    \n    # Color dictionary\n    colors = dict(\n        mg=dict({\n            'Record High Year': 'white',\n            'Record High': '#d26c6c',\n            'Average High': '#dc8d8d',\n            'Daily Average': '#F5F5F5',\n            'Average Low': '#a2bff4',\n            'Record Low': '#74a0ef',\n            'Record Low Year': 'white'}),\n        bm=dict({\n            'Record High Year': 'white',\n            'Record High': 'orange',\n            'Average High': 'red',\n            'Daily Average': 'grey',\n            'Average Low': 'purple',\n            'Record Low': 'white'}        \n        ))\n    \n    # Create figure\n    fig = go.Figure()\n\n    # Record highs\n    # High records this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear).to_dataframe().drop('variable', axis=1)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1).to_dataframe().drop('variable', axis=1)[['Record High Year', 'Record Low Year']].sum().sum()\n    highRecords = df['Record High'].where(df['Record High Year'] == thisYear).to_dataframe()['Record High']\n    highRecords.index = pd.to_datetime(highRecords.index+'-2020')\n    lowRecords = df['Record Low'].where(df['Record Low Year'] == thisYear).to_dataframe()['Record Low']\n    lowRecords.index = pd.to_datetime(lowRecords.index+'-2020')\n    \n    first_time = dt.strptime(df.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    last_time = dt.strptime(df.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    fig.add_trace(\n    go.Scatter(\n        x=highRecords.index, y=highRecords.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=6, color='white'),\n        hovertext=[f'{thisYear} Record: {i}' if not pd.isnull(i) else '' for i in highRecords.values],\n        hoverinfo='text'\n    ))\n    fig.add_trace(\n    go.Scatter(\n        x=lowRecords.index, y=lowRecords.values,\n        name='Low Record',\n        mode='markers',\n        marker=dict(size=6, color='white'),\n        hoverinfo='none'\n    ))\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=df['Record High'],\n        name='Record High'.upper(),\n        mode='markers',\n        marker=dict(size=3, color=colors[scheme]['Record High'])\n    ))\n    # Average highs\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=cos_fit(df['Average High']).round(1),\n        name='Average High'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Average High'])\n    ))\n    # Daily average\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=cos_fit(df['Daily Average']).round(1),\n        name='Daily Average'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Daily Average'])\n    ))\n    # Average lows\n    fig.add_trace(\n    go.Scatter(\n        x=xdates,\n        y=cos_fit(df['Average Low']).round(1),\n        name='Average Low'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Average Low'])\n    ))\n    # Record lows\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=df['Record Low'],\n        name='Record Low'.upper(),\n        mode='markers',\n        marker=dict(size=3, color=colors[scheme]['Record Low'])\n    ))\n    # Hover box\n    fig.update_traces(\n        hoverlabel = dict(bordercolor='white')\n    )\n    # Plot settings\n    fig.update_layout(\n        template='plotly_dark',\n        paper_bgcolor='#404040',\n        plot_bgcolor='#404040',\n        height=600, width=1000,\n        title=dict(text='Daily {} records'.format(var.lower())+\n                        '&lt;br&gt;&lt;sup&gt;{}-{}&lt;/sup&gt;'.format(first_time, last_time)+\n                        '&lt;br&gt;&lt;sup&gt;As of today, &lt;b&gt;{}&lt;/b&gt; {} record highs/lows have been set. Last year, {} records were set.&lt;/sup&gt;'.format(\n                            thisYearRecords, var.lower(), lastYearRecords\n                        ),\n                  font=dict(size=20)),\n        yaxis = dict(title=f'{var} ({data.attrs[f\"{var} units\"]})',\n                     showgrid=True, gridcolor='grey'),\n        xaxis = dict(showgrid=False, showspikes=True,\n                     dtick='M1', tickformat='%b %d'),\n        hovermode='x unified',\n        legend=dict(itemsizing='constant'),\n        hoverlabel=dict(font_size=12)\n    )\n    for trace in fig['data']: \n        if trace['name'] == 'Low Record':\n            trace['showlegend'] = False\n    fig.show()\n\n\ndaily_climo(days, 'Air Temperature', scheme='mg')\n\n                                                \n\n\nThat concludes this climatology demonstration series.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Overview",
      "Demonstrations",
      "Plotting Records"
    ]
  },
  {
    "objectID": "content/demos/NOAA-CO-OPS-records.html",
    "href": "content/demos/NOAA-CO-OPS-records.html",
    "title": "Data Cleansing and Records Calculations",
    "section": "",
    "text": "This notebook follows sequentially from NOAA-CO-OPS-data in which we downloaded the latest data for a particular NOAA CO-OPS weather and tide station. The data record and corresponding metadata were written to file. Here we use those data and calculates several daily and monthly statistics and records. This is done in two steps:\n\nFilter the data: We do not perform any quality assurance or quality control checks, but we do remove from the records any days missing a specified amount of data and any months missing a specified number of days of data.\nCalculate records:\n\nDaily and monthly averages\nRecord high daily and monthly averages*\nRecord low daily and monthly averages*\nAverage daily and monthly high\nLowest daily and monthly high*\nRecord daily and monthly high*\nAverage daily and monthly low\nHighest daily and monthly low*\nRecord daily and monthly low*\n\n\nYears are also noted for those records marked by an asterisk (*).\n\nPackages and configurations\nFirst we import the packages we need.\n\nimport pandas as pd\nimport xarray as xr\nimport calendar\nimport yaml\nimport os\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes soem trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nNext, we define a number of functions that will come in handy later.\n\nHelper functions\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef DOY(df):\n    \"\"\"Determine year day out of 366\"\"\"\n    # Day of year as integer\n    df['YearDay'] = df.index.day_of_year.astype(int)\n    # Years that are NOT leap years\n    leapInd = [not calendar.isleap(i) for i in df.index.year]\n    mask = (leapInd) & (df.index.month &gt; 2)\n    # Advance by one day everything after February 28 \n    df.loc[mask, 'YearDay'] += 1\n    return df\n\n\n\nFiltering data\n\ndef count_missing_hours(group, threshold=3):\n    \"\"\"Return True if the number of hours in a day with missing data is less\n    than or equal to 'threshold' and False otherwise.\n    \"\"\"\n    missing_hours = group.resample('1h').mean().isna().sum()\n    return missing_hours &lt;= threshold\n\ndef count_missing_days(group, threshold=2):\n    \"\"\"Return True if the number of days in a month with missing data is less\n    than or equal to 'theshold' and False otherwise. Two tests are performed:\n    missing data (NaN) and compare to the number of days in the given month.\n    \"\"\"\n    try:\n        days_in_month = pd.Period(group.index[0].strftime(format='%Y-%m-%d')).days_in_month\n        missing_days = group.resample('1D').mean().isna().sum()\n        missing_days_flag = missing_days &lt;= threshold\n        days_in_month_flag = days_in_month - group.resample('1D').mean().size &lt;= threshold\n        return min(missing_days_flag, days_in_month_flag)\n    except IndexError:\n        pass\n\ndef filter_data(data, hr_threshold=3, day_threshold=2):\n    \"\"\"Filter data to remove days with more than 'hr_threshold' missing hours\n    of data and months with more than 'day_threshold' days of missing data.\n    \"\"\"\n    # Filter out days missing more than &lt;hr_threshold&gt; hours\n    filtered = data.groupby(pd.Grouper(freq='1D')).filter(lambda x: count_missing_hours(group=x, threshold=hr_threshold))\n    # Filter out months missing more than &lt;day_threshold&gt; days\n    filtered = filtered.groupby(pd.Grouper(freq='1M')).filter(lambda x: count_missing_days(group=x, threshold=day_threshold))\n    return filtered\n\n\n\nCalculate records\n\ndef daily_highs(df):\n    \"\"\"Daily highs\"\"\"\n    return df.groupby(pd.Grouper(freq='1D')).max(numeric_only=True)\n\ndef daily_lows(df):\n    \"\"\"Daily lows\"\"\"\n    return df.groupby(pd.Grouper(freq='1D')).min(numeric_only=True)\n\ndef daily_avgs(df, decimals=1, true_average=False):\n    \"\"\"Daily averages by calendar day rounded to 'decimals'. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    if true_average:\n        results = df.groupby(pd.Grouper(freq='1D')).mean(numeric_only=True)\n    else:\n        dailyHighs = daily_highs(df)\n        dailyLows = daily_lows(df)\n        results = (dailyHighs + dailyLows) / 2\n    return results.round(decimals)\n\ndef daily_avg(df, decimals=1, true_average=False):\n    \"\"\"Daily averages rounded to 'decimals'. If 'true_average' is True, all\n    measurements from each 24-hour day will be used to calculate the daily\n    average. Otherwise, only the maximum and minimum observations are used.\n    Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    dailyAvg = dailyAvgs.groupby('YearDay').mean(numeric_only=True).round(decimals)\n    dailyAvg.index = dailyAvg.index.astype(int)\n    results = xr.DataArray(dailyAvg, dims=['yearday', 'variable'])\n    results.name = 'Daily Average'\n    return results\n\ndef monthly_highs(df, decimals=1, true_average=False):\n    \"\"\"Monthly highs rounded to 'decimals'. If 'true_average' is True, all\n    measurements from each 24-hour day will be used to calculate the daily\n    average. Otherwise, only the maximum and minimum observations are used.\n    Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=False)\n    monthHighs = dailyAvgs.groupby(pd.Grouper(freq='M')).max(numeric_only=True)\n    return monthHighs\n  \ndef monthly_lows(df, decimals=1, true_average=False):\n    \"\"\"Monthly lows rounded to 'decimals'. If 'true_average' is True, all\n    measurements from each 24-hour day will be used to calculate the daily\n    average. Otherwise, only the maximum and minimum observations are used.\n    Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthLows = dailyAvgs.groupby(pd.Grouper(freq='M')).min(numeric_only=True)\n    return monthLows\n    \ndef monthly_avg(df, decimals=1, true_average=False):\n    \"\"\"Monthly averages for variable 'var' rounded to 'decimals'. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the daily average. Otherwise, only the maximum and\n    minimum observations are used. Defaults to False (meteorological\n    standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthlyMeans = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True).round(decimals)\n    monthlyMeans.drop('YearDay', axis=1, inplace=True)\n    monthlyAvg = monthlyMeans.groupby(monthlyMeans.index.month).mean(numeric_only=True).round(decimals)\n    monthlyAvg.index = monthlyAvg.index.astype(int)\n    results = xr.DataArray(monthlyAvg, dims=['month', 'variable'])\n    results.name = 'Monthly Average'\n    return results\n\ndef record_high_daily_avg(df, decimals=1, true_average=False):\n    \"\"\"Record high daily averages rounded to 'decimals'. If 'true_average'\n    is True, all measurements from each 24-hour day will be used to\n    calculate the daily average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df=df, decimals=decimals, true_average=true_average)\n    recordHighDailyAvg = dailyAvgs.groupby('YearDay').max(numeric_only=True).round(decimals)\n    recordHighDailyAvg.index = recordHighDailyAvg.index.astype(int)\n    # Record years\n    recordHighDailyAvgYear = dailyAvgs.groupby('YearDay').apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordHighDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n    recordHighDailyAvgYear.index = recordHighDailyAvgYear.index.astype(int)\n    recordHighDailyAvgYear.columns = [i+' Year' for i in recordHighDailyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordHighDailyAvg, recordHighDailyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record High Daily Average'\n    return results\n    \ndef record_high_monthly_avg(df, decimals=1, true_average=False):\n    \"\"\"Record high monthly averages rounded to 'decimals'. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the daily average. Otherwise, only the maximum and\n    minimum observations are used. Defaults to False (meteorological\n    standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True).round(decimals)\n    monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n    recordHighMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month).max(numeric_only=True)\n    recordHighMonthlyAvg.index = recordHighMonthlyAvg.index.astype(int)\n    # Record years\n    recordHighMonthlyAvgYear = monthlyAvgs.groupby(monthlyAvgs.index.month).apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordHighMonthlyAvgYear.index = recordHighMonthlyAvgYear.index.astype(int)\n    recordHighMonthlyAvgYear.columns = [i+' Year' for i in recordHighMonthlyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordHighMonthlyAvg, recordHighMonthlyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record High Monthly Average'\n    return results\n\ndef record_low_daily_avg(df, decimals=1, true_average=False):\n    \"\"\"Record low daily averages rounded to 'decimals'.  If 'true_average'\n    True, all measurements from each 24-hour day will be used to calculate\n    the average. Otherwise, only the maximum and minimum observations are\n    used. Defaults to False (meteorological standard).\"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df=df, decimals=decimals, true_average=true_average)\n    recordLowDailyAvg = dailyAvgs.groupby('YearDay').min(numeric_only=True).round(decimals)\n    recordLowDailyAvg.index = recordLowDailyAvg.index.astype(int)\n    # Record years\n    recordLowDailyAvgYear = dailyAvgs.groupby('YearDay').apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordLowDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n    recordLowDailyAvgYear.index = recordLowDailyAvgYear.index.astype(int)\n    recordLowDailyAvgYear.columns = [i+' Year' for i in recordLowDailyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordLowDailyAvg, recordLowDailyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Low Daily Average'\n    return results\n\ndef record_low_monthly_avg(df, decimals=1, true_average=False):\n    \"\"\"Record low monthly averages rounded to 'decimals'. If 'true_average'\n    is True, all measurements from each 24-hour day will be used to\n    calculate the daily average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True).round(decimals)\n    monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n    recordLowMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month).min(numeric_only=True)\n    recordLowMonthlyAvg.index = recordLowMonthlyAvg.index.astype(int)\n    # Record years\n    recordLowMonthlyAvgYear = monthlyAvgs.groupby(monthlyAvgs.index.month).apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordLowMonthlyAvgYear.index = recordLowMonthlyAvgYear.index.astype(int)\n    recordLowMonthlyAvgYear.columns = [i+' Year' for i in recordLowMonthlyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordLowMonthlyAvg, recordLowMonthlyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Low Monthly Average'\n    return results\n\ndef avg_daily_high(df, decimals=1):\n    \"\"\"Average daily highs rounded to 'decimals'.\"\"\"        \n    dailyHighs = daily_highs(df)\n    results = dailyHighs.groupby('YearDay').mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Average Daily High'\n    return results\n\ndef avg_monthly_high(df, decimals=1, true_average=False):\n    \"\"\"Average monthly highs rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    monthlyHighs = monthly_highs(df, decimals=decimals, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    avgMonthlyHighs = monthlyHighs.groupby(monthlyHighs.index.month).mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(avgMonthlyHighs, dims=['month', 'variable'])\n    results.name = 'Average Monthly High'\n    return results\n\ndef lowest_daily_high(df, decimals=1):\n    \"\"\"Lowest daily highs rounded to 'decimals'.\"\"\"\n    # Calculate the record\n    dailyHighs = daily_highs(df)\n    lowestHigh = dailyHighs.groupby('YearDay').min(numeric_only=True).round(decimals)\n    lowestHigh.index = lowestHigh.index.astype(int)\n    # Record years\n    lowestHighYear = dailyHighs.groupby('YearDay').apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    lowestHighYear.drop('YearDay', axis=1, inplace=True)\n    lowestHighYear.index = lowestHighYear.index.astype(int)\n    lowestHighYear.columns = [i+' Year' for i in lowestHighYear.columns]\n    # Create xarray\n    results = pd.concat((lowestHigh, lowestHighYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Lowest Daily High'\n    return results\n    \ndef lowest_monthly_high(df, decimals=1, true_average=False):\n    \"\"\"Lowest monthly highs rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyHighs = monthly_highs(df, decimals=decimals, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    lowMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month).min(numeric_only=True).round(decimals)\n    lowMonthlyHigh.index = lowMonthlyHigh.index.astype(int)\n    # Record years\n    lowMonthlyHighYear = monthlyHighs.groupby(monthlyHighs.index.month).apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    lowMonthlyHighYear.index = lowMonthlyHighYear.index.astype(int)\n    lowMonthlyHighYear.columns = [i+' Year' for i in lowMonthlyHighYear.columns]\n    # Create xarray\n    results = pd.concat((lowMonthlyHigh, lowMonthlyHighYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Lowest Monthly High'\n    return results\n\ndef record_daily_high(df, decimals=1):\n    \"\"\"Record daily highs rounded to 'decimal'.\"\"\"\n    # Calculate the record\n    dailyHighs = daily_highs(df)\n    recordHigh = dailyHighs.groupby('YearDay').max(numeric_only=True).round(decimals)\n    recordHigh.index = recordHigh.index.astype(int)\n    # Record years\n    recordHighYear = dailyHighs.groupby('YearDay').apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordHighYear.drop('YearDay', axis=1, inplace=True)\n    recordHighYear.index = recordHighYear.index.astype(int)\n    recordHighYear.columns = [i+' Year' for i in recordHighYear.columns]\n    # Create xarray\n    results = pd.concat((recordHigh, recordHighYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Daily High'\n    return results\n\ndef record_monthly_high(df, decimals=1, true_average=False):\n    \"\"\"Record monthly highs rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyHighs = monthly_highs(df, decimals=decimals, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    recordMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month).max(numeric_only=True).round(decimals)\n    recordMonthlyHigh.index = recordMonthlyHigh.index.astype(int)\n    # Record years\n    recordMonthlyHighYear = monthlyHighs.groupby(monthlyHighs.index.month).apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordMonthlyHighYear.index = recordMonthlyHighYear.index.astype(int)\n    recordMonthlyHighYear.columns = [i+' Year' for i in recordMonthlyHighYear.columns]\n    # Create xarray\n    results = pd.concat((recordMonthlyHigh, recordMonthlyHighYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Monthly High'\n    return results\n\ndef avg_daily_low(df, decimals=1):\n    \"\"\"Average daily lows rounded to 'decimals'.\"\"\"        \n    dailyLows = daily_lows(df)\n    results = dailyLows.groupby('YearDay').mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Average Daily Low'\n    return results\n\ndef avg_monthly_low(df, decimals=1, true_average=False):\n    \"\"\"Average monthly lows rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    monthlyLows = monthly_lows(df, decimals=decimals, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    avgMonthlyLows = monthlyLows.groupby(monthlyLows.index.month).mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(avgMonthlyLows, dims=['month', 'variable'])\n    results.name = 'Average Monthly Low'\n    return results\n\ndef highest_daily_low(df, decimals=1):\n    \"\"\"Highest daily lows rounded to 'decimals'.\"\"\"\n    # Calculate the record\n    dailyLows = daily_lows(df)\n    highestLow = dailyLows.groupby('YearDay').max(numeric_only=True).round(decimals)\n    highestLow.index = highestLow.index.astype(int)\n    # Record years\n    highestLowYear = dailyLows.groupby('YearDay').apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    highestLowYear.drop('YearDay', axis=1, inplace=True)\n    highestLowYear.index = highestLowYear.index.astype(int)\n    highestLowYear.columns = [i+' Year' for i in highestLowYear.columns]\n    # Create xarray\n    results = pd.concat((highestLow, highestLowYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Highest Daily Low'\n    return results\n    \ndef highest_monthly_low(df, decimals=1, true_average=False):\n    \"\"\"Highest monthly lows rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyLows = monthly_lows(df, decimals=decimals, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    highestMonthlyLow = monthlyLows.groupby(monthlyLows.index.month).max(numeric_only=True).round(decimals)\n    highestMonthlyLow.index = highestMonthlyLow.index.astype(int)\n    # Record years\n    highestMonthlyLowYear = monthlyLows.groupby(monthlyLows.index.month).apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    highestMonthlyLowYear.index = highestMonthlyLowYear.index.astype(int)\n    highestMonthlyLowYear.columns = [i+' Year' for i in highestMonthlyLowYear.columns]\n    # Create xarray\n    results = pd.concat((highestMonthlyLow, highestMonthlyLowYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Highest Monthly Low'\n    return results\n\ndef record_daily_low(df, decimals=1):\n    \"\"\"Record daily lows rounded to 'decimals'.\"\"\"\n    # Calculate the record\n    dailyLows = daily_lows(df)\n    recordLow = dailyLows.groupby('YearDay').min(numeric_only=True).round(decimals)\n    recordLow.index = recordLow.index.astype(int)\n    # Record years\n    recordLowYear = dailyLows.groupby('YearDay').apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordLowYear.drop('YearDay', axis=1, inplace=True)\n    recordLowYear.index = recordLowYear.index.astype(int)\n    recordLowYear.columns = [i+' Year' for i in recordLowYear.columns]\n    # Create xarray\n    results = pd.concat((recordLow, recordLowYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Daily Low'\n    return results\n\ndef record_monthly_low(df, decimals=1, true_average=False):\n    \"\"\"Record monthly lows rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyLows = monthly_lows(df, decimals=decimals, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    recordMonthlyLow = monthlyLows.groupby(monthlyLows.index.month).min(numeric_only=True).round(decimals)\n    recordMonthlyLow.index = recordMonthlyLow.index.astype(int)\n    # Record years\n    recordMonthlyLowYear = monthlyLows.groupby(monthlyLows.index.month).apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordMonthlyLowYear.index = recordMonthlyLowYear.index.astype(int)\n    recordMonthlyLowYear.columns = [i+' Year' for i in recordMonthlyLowYear.columns]\n    # Create xarray\n    results = pd.concat((recordMonthlyLow, recordMonthlyLowYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Monthly Low'\n    return results\n\ndef number_of_years_byday(df):\n    \"\"\"Number of years in the historical data records by day of year.\"\"\"\n    numYears = pd.concat([df[[v, 'YearDay']].dropna().groupby('YearDay')\\\n                                        .apply(lambda x: len(x.index.year.unique())) \\\n                         for v in filtered_data.columns if v != 'YearDay'], axis=1)\n    numYears.columns = [v for v in df.columns if v != 'YearDay']\n    results = xr.DataArray(numYears, dims=['yearday', 'variable'])\n    results.name = 'Number of Years'\n    return results\n\ndef number_of_years_bymonth(df):\n    \"\"\"Number of years in the historical data records by month.\"\"\"\n    numYears = pd.concat([df[v].dropna().groupby(df[v].dropna().index.month)\\\n                                        .apply(lambda x: len(x.index.year.unique())) \\\n                         for v in filtered_data.columns if v != 'YearDay'], axis=1)\n    numYears.columns = [v for v in df.columns if v != 'YearDay']\n    results = xr.DataArray(numYears, dims=['month', 'variable'])\n    results.name = 'Number of Years'\n    return results\n\ndef generate_yeardays():\n    return pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D').strftime('%d-%b')\n\n\n\n\nData cleaning\nFirst we need to load in the data and metadata for the desired station. This will be used to determine the directory from which to load the data.\nAs before, stationname is the custom human-readable “City, ST” string for the station. Since we are not downloading data, we do not need the NOAA-COOPS station ID number.\n\nstationname = 'Virginia Key, FL'\n\nDerive the local directory name containing for data from the station name. This is the same way the directory was created when the data were downloaded.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: /home/climatology/virginiaKeyFl\n\n\nNext, load the data and metadata.\n\n# Metadata\nwith open(os.path.join(outdir, 'metadata.yml')) as m:\n    meta = yaml.safe_load(m)\n\n# Observational data\ndata = pd.read_csv(os.path.join(outdir, 'observational_data_record.csv.gz'),\n                   index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n                   compression='infer')\n\nNow we filter the data to remove days with more than 3 hours of missing data and months with more than 2 days of missing data. These thresholds are stored in meta and can easily be changed. We have to do this one variable at a time because this is sensor-dependent, so it takes a short while to run.\n\nfiltered_data = pd.concat([filter_data(data[var],\n                                       hr_threshold=meta['hr_threshold'],\n                                       day_threshold=meta['day_threshold'])\n                                       for var in meta['variables']], axis=1)\n\nConfirm that the data were filtered:\n\ndata.shape\n\n(2466580, 2)\n\n\n\nfiltered_data.shape\n\n(2174766, 2)\n\n\n\n\nCalculate records\nNow we’re ready to determine the records using all of the functions above. We’ll store these in an xarray dataset and add the appropriate metadata for convenience. But first, we need to add a day of year (DOY) column so that we can calculate daily records. We’ve used a function to do this because accounting for leap years is not trivial.\n\nfiltered_data = DOY(filtered_data)\n\n\ndaily_records = \\\n    xr.Dataset({'Daily Average': daily_avg(filtered_data),\n                'Record High Daily Average': record_high_daily_avg(filtered_data),\n                'Record Low Daily Average': record_low_daily_avg(filtered_data),\n                'Average High': avg_daily_high(filtered_data),\n                'Lowest High': lowest_daily_high(filtered_data),\n                'Record High': record_daily_high(filtered_data),\n                'Average Low': avg_daily_low(filtered_data),\n                'Highest Low': highest_daily_low(filtered_data),\n                'Record Low': record_daily_low(filtered_data),\n                'Years': number_of_years_byday(filtered_data)},\n               attrs={k:v for k, v in meta.items() if k not in ['outdir', 'variables', 'units']})\n\n\nmonthly_records = \\\n    xr.Dataset({'Monthly Average': monthly_avg(filtered_data),\n                'Record High Monthly Average': record_high_monthly_avg(filtered_data),\n                'Record Low Monthly Average': record_low_monthly_avg(filtered_data),\n                'Average High': avg_monthly_high(filtered_data),\n                'Lowest High': lowest_monthly_high(filtered_data),\n                'Record High': record_monthly_high(filtered_data),\n                'Average Low': avg_monthly_low(filtered_data),\n                'Highest Low': highest_monthly_low(filtered_data),\n                'Record Low': record_monthly_low(filtered_data),\n                'Years': number_of_years_bymonth(filtered_data)},\n               attrs={k:v for k, v in meta.items() if k not in ['outdir', 'variables', 'units']})\n\nAdd data units and time series ranges for each variable to the arrays as metadata attributes.\n\nfor k, v in meta['units'].items():\n    daily_records.attrs[k+' units'] = v\n\nfor var in daily_records.coords['variable'].values:\n    if 'Year' not in var:\n        daily_records.attrs[var+' data range'] = \\\n            (filtered_data[var].dropna().index.min().strftime('%Y-%m-%d'),\n             filtered_data[var].dropna().index.max().strftime('%Y-%m-%d'))\n\n\nfor k, v in meta['units'].items():\n    monthly_records.attrs[k+' units'] = v\n\nfor var in monthly_records.coords['variable'].values:\n    if 'Year' not in var:\n        monthly_records.attrs[var+' data range'] = \\\n            (filtered_data[var].dropna().index.min().strftime('%Y-%m-%d'),\n             filtered_data[var].dropna().index.max().strftime('%Y-%m-%d'))\n\nWhat do we have now? Let’s take a look:\n\ndaily_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 120kB\nDimensions:                    (yearday: 366, variable: 4)\nCoordinates:\n  * yearday                    (yearday) int64 3kB 1 2 3 4 5 ... 363 364 365 366\n  * variable                   (variable) object 32B 'Air Temperature' ... 'W...\nData variables:\n    Daily Average              (yearday, variable) float64 12kB 71.5 nan ... nan\n    Record High Daily Average  (yearday, variable) float64 12kB 78.0 ... 2.02...\n    Record Low Daily Average   (yearday, variable) float64 12kB 54.4 ... 2.01...\n    Average High               (yearday, variable) float64 12kB 75.0 nan ... nan\n    Lowest High                (yearday, variable) float64 12kB 63.3 ... 2.01...\n    Record High                (yearday, variable) float64 12kB 79.3 ... 2.02...\n    Average Low                (yearday, variable) float64 12kB 67.9 nan ... nan\n    Highest Low                (yearday, variable) float64 12kB 76.8 ... 2.02...\n    Record Low                 (yearday, variable) float64 12kB 45.5 ... 2.01...\n    Years                      (yearday, variable) float64 12kB 23.0 nan ... nan\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:yearday: 366variable: 4Coordinates: (2)yearday(yearday)int641 2 3 4 5 6 ... 362 363 364 365 366array([  1,   2,   3, ..., 364, 365, 366])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Data variables: (10)Daily Average(yearday, variable)float6471.5 nan 72.4 nan ... nan 72.6 nanarray([[71.5,  nan, 72.4,  nan],\n       [71.8,  nan, 72.9,  nan],\n       [70. ,  nan, 73. ,  nan],\n       ...,\n       [70.6,  nan, 72.6,  nan],\n       [69.6,  nan, 72.7,  nan],\n       [70.8,  nan, 72.6,  nan]])Record High Daily Average(yearday, variable)float6478.0 2.022e+03 ... 80.5 2.021e+03array([[  78. , 2022. ,   80.4, 2022. ],\n       [  77.8, 2022. ,   80.2, 2022. ],\n       [  78. , 2015. ,   80.7, 2017. ],\n       ...,\n       [  79.4, 2015. ,   82.6, 2016. ],\n       [  79.5, 2015. ,   81.9, 2016. ],\n       [  79.2, 2015. ,   80.5, 2021. ]])Record Low Daily Average(yearday, variable)float6454.4 2.001e+03 ... 66.1 2.01e+03array([[  54.4, 2001. ,   66.4, 2011. ],\n       [  56.6, 2010. ,   66.8, 2011. ],\n       [  51.7, 2012. ,   67.3, 2011. ],\n       ...,\n       [  58.7, 2009. ,   66.6, 1995. ],\n       [  54.8, 2000. ,   66.4, 2010. ],\n       [  49.9, 2000. ,   66.1, 2010. ]])Average High(yearday, variable)float6475.0 nan 73.7 nan ... nan 73.9 nanarray([[75. ,  nan, 73.7,  nan],\n       [75.1,  nan, 74.2,  nan],\n       [73.9,  nan, 74.3,  nan],\n       ...,\n       [74.4,  nan, 74.1,  nan],\n       [73.2,  nan, 74.1,  nan],\n       [74.3,  nan, 73.9,  nan]])Lowest High(yearday, variable)float6463.3 2.001e+03 ... 67.8 2.01e+03array([[  63.3, 2001. ,   67.8, 2011. ],\n       [  64.2, 2010. ,   68. , 2011. ],\n       [  57. , 2012. ,   68.9, 2011. ],\n       ...,\n       [  67.1, 2010. ,   69.4, 2003. ],\n       [  59.5, 2000. ,   68.4, 2010. ],\n       [  55.6, 2000. ,   67.8, 2010. ]])Record High(yearday, variable)float6479.3 2.022e+03 ... 81.7 2.021e+03array([[  79.3, 2022. ,   81.1, 2022. ],\n       [  79.3, 2022. ,   81. , 2022. ],\n       [  79.2, 2019. ,   81.5, 2017. ],\n       ...,\n       [  80.6, 2015. ,   83.3, 2016. ],\n       [  80.6, 2013. ,   83.1, 2016. ],\n       [  80.1, 2015. ,   81.7, 2021. ]])Average Low(yearday, variable)float6467.9 nan 71.1 nan ... nan 71.4 nanarray([[67.9,  nan, 71.1,  nan],\n       [68.5,  nan, 71.6,  nan],\n       [66.1,  nan, 71.7,  nan],\n       ...,\n       [66.7,  nan, 71.2,  nan],\n       [66.1,  nan, 71.4,  nan],\n       [67.3,  nan, 71.4,  nan]])Highest Low(yearday, variable)float6476.8 2.022e+03 ... 79.3 2.021e+03array([[  76.8, 2022. ,   79.7, 2022. ],\n       [  76.3, 2017. ,   79.5, 2022. ],\n       [  77. , 2015. ,   79.9, 2017. ],\n       ...,\n       [  78.3, 2015. ,   81.9, 2016. ],\n       [  78.4, 2015. ,   80.8, 2016. ],\n       [  78.3, 2015. ,   79.3, 2021. ]])Record Low(yearday, variable)float6445.5 2.001e+03 ... 64.4 2.01e+03array([[  45.5, 2001. ,   63.9, 2001. ],\n       [  49.1, 2010. ,   64.4, 2001. ],\n       [  46.4, 2012. ,   65.5, 2001. ],\n       ...,\n       [  50.1, 2009. ,   62.2, 2010. ],\n       [  50. , 2000. ,   64.4, 2010. ],\n       [  44.2, 2000. ,   64.4, 2010. ]])Years(yearday, variable)float6423.0 nan 24.0 nan ... nan 24.0 nanarray([[23., nan, 24., nan],\n       [23., nan, 24., nan],\n       [23., nan, 24., nan],\n       ...,\n       [24., nan, 24., nan],\n       [24., nan, 24., nan],\n       [23., nan, 24., nan]])Indexes: (2)yeardayPandasIndexPandasIndex(Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n            ...\n            357, 358, 359, 360, 361, 362, 363, 364, 365, 366],\n           dtype='int64', name='yearday', length=366))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4kB\nDimensions:                      (month: 12, variable: 4)\nCoordinates:\n  * month                        (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * variable                     (variable) object 32B 'Air Temperature' ... ...\nData variables:\n    Monthly Average              (month, variable) float64 384B 68.7 nan ... nan\n    Record High Monthly Average  (month, variable) float64 384B 72.6 ... 2.01...\n    Record Low Monthly Average   (month, variable) float64 384B 63.0 ... 2.01...\n    Average High                 (month, variable) float64 384B 76.0 nan ... nan\n    Lowest High                  (month, variable) float64 384B 73.0 ... 2.00...\n    Record High                  (month, variable) float64 384B 78.0 ... 2.01...\n    Average Low                  (month, variable) float64 384B 55.6 nan ... nan\n    Highest Low                  (month, variable) float64 384B 63.5 ... 2.01...\n    Record Low                   (month, variable) float64 384B 48.3 ... 2.01...\n    Years                        (month, variable) float64 384B 23.0 nan ... nan\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:month: 12variable: 4Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Data variables: (10)Monthly Average(month, variable)float6468.7 nan 71.6 nan ... nan 74.0 nanarray([[68.7,  nan, 71.6,  nan],\n       [70.8,  nan, 72.8,  nan],\n       [72.3,  nan, 75. ,  nan],\n       [75.6,  nan, 78.5,  nan],\n       [78.7,  nan, 82. ,  nan],\n       [81.5,  nan, 85.2,  nan],\n       [82.9,  nan, 87.1,  nan],\n       [83.2,  nan, 87.3,  nan],\n       [82. ,  nan, 85.7,  nan],\n       [79.6,  nan, 82.1,  nan],\n       [75. ,  nan, 77.4,  nan],\n       [71.4,  nan, 74. ,  nan]])Record High Monthly Average(month, variable)float6472.6 2.013e+03 ... 82.5 2.016e+03array([[  72.6, 2013. ,   78.9, 2017. ],\n       [  74.9, 2018. ,   76.3, 2021. ],\n       [  77.6, 2003. ,   80. , 2003. ],\n       [  79.4, 2020. ,   83.4, 2020. ],\n       [  80.7, 1995. ,   84.1, 2021. ],\n       [  83.6, 2010. ,   87.6, 2010. ],\n       [  85. , 2023. ,   89.5, 2023. ],\n       [  85.9, 2022. ,   90.1, 2021. ],\n       [  82.7, 2017. ,   89.5, 2021. ],\n       [  81.2, 2020. ,   85.9, 2021. ],\n       [  78.6, 2015. ,   81.5, 2016. ],\n       [  76.9, 2015. ,   82.5, 2016. ]])Record Low Monthly Average(month, variable)float6463.0 2.001e+03 ... 68.2 2.01e+03array([[  63. , 2001. ,   67.5, 2001. ],\n       [  65.5, 1996. ,   67.7, 2005. ],\n       [  66.1, 2010. ,   69.2, 2010. ],\n       [  72.8, 2004. ,   75.1, 2004. ],\n       [  77. , 2013. ,   78.6, 2001. ],\n       [  79.8, 2014. ,   83.3, 2002. ],\n       [  81. , 2013. ,   84.5, 2013. ],\n       [  81.8, 1994. ,   85.4, 1995. ],\n       [  80.6, 2001. ,   82.7, 2004. ],\n       [  77.5, 2000. ,   79.6, 2000. ],\n       [  71.4, 2012. ,   74.6, 2012. ],\n       [  62.1, 2010. ,   68.2, 2010. ]])Average High(month, variable)float6476.0 nan 75.4 nan ... nan 77.6 nanarray([[76. ,  nan, 75.4,  nan],\n       [76.5,  nan, 76.7,  nan],\n       [78.5,  nan, 79.2,  nan],\n       [80.8,  nan, 81.9,  nan],\n       [82.5,  nan, 85.1,  nan],\n       [84.8,  nan, 87.9,  nan],\n       [85.8,  nan, 89.1,  nan],\n       [85.7,  nan, 89.4,  nan],\n       [85.1,  nan, 88. ,  nan],\n       [83.8,  nan, 85.6,  nan],\n       [79.7,  nan, 80.6,  nan],\n       [77.5,  nan, 77.6,  nan]])Lowest High(month, variable)float6473.0 2.011e+03 ... 73.0 2.003e+03array([[  73. , 2011. ,   70.5, 2011. ],\n       [  74.2, 2000. ,   73.7, 2016. ],\n       [  74.2, 2010. ,   73.3, 2010. ],\n       [  77.3, 2004. ,   78.4, 2010. ],\n       [  80.8, 2014. ,   82.8, 2013. ],\n       [  82.8, 2014. ,   85.3, 1996. ],\n       [  84.2, 2012. ,   86.4, 2013. ],\n       [  84. , 2003. ,   87.2, 2000. ],\n       [  83.9, 2000. ,   85.2, 1997. ],\n       [  81. , 2010. ,   82.7, 2004. ],\n       [  76.9, 2012. ,   76.8, 2001. ],\n       [  72.5, 2010. ,   73. , 2003. ]])Record High(month, variable)float6478.0 2.015e+03 ... 84.6 2.016e+03array([[  78. , 2015. ,   81.7, 2017. ],\n       [  78.6, 2021. ,   81.5, 2021. ],\n       [  82.8, 2003. ,   83.2, 2021. ],\n       [  85.8, 2020. ,   85.8, 2020. ],\n       [  85.2, 1995. ,   87.7, 2021. ],\n       [  87.6, 2009. ,   90.4, 2010. ],\n       [  88.7, 2018. ,   92. , 2021. ],\n       [  88.5, 2022. ,   92.2, 2021. ],\n       [  86.7, 2021. ,   91.2, 2021. ],\n       [  86.8, 2023. ,   89. , 2016. ],\n       [  82. , 2020. ,   85. , 2020. ],\n       [  79.6, 1994. ,   84.6, 2016. ]])Average Low(month, variable)float6455.6 nan 67.6 nan ... nan 70.2 nanarray([[55.6,  nan, 67.6,  nan],\n       [59.4,  nan, 68.9,  nan],\n       [63.3,  nan, 70.9,  nan],\n       [68.3,  nan, 74.6,  nan],\n       [73.8,  nan, 78.1,  nan],\n       [77.6,  nan, 82.2,  nan],\n       [79. ,  nan, 84.5,  nan],\n       [79.3,  nan, 84.4,  nan],\n       [78.2,  nan, 83. ,  nan],\n       [72.7,  nan, 77.9,  nan],\n       [66. ,  nan, 74.2,  nan],\n       [59.2,  nan, 70.2,  nan]])Highest Low(month, variable)float6463.5 2.013e+03 ... 79.6 2.016e+03array([[  63.5, 2013. ,   75.9, 2017. ],\n       [  70. , 2018. ,   73.4, 2023. ],\n       [  72. , 1997. ,   75.4, 1997. ],\n       [  72.6, 2015. ,   81.1, 2020. ],\n       [  77.1, 2003. ,   80.4, 1994. ],\n       [  80.8, 2004. ,   85.2, 2004. ],\n       [  82.3, 2022. ,   87.2, 2023. ],\n       [  83.6, 2022. ,   87.2, 2021. ],\n       [  79.8, 2009. ,   87.1, 2021. ],\n       [  77.8, 1995. ,   83.4, 2021. ],\n       [  74.4, 2020. ,   80. , 2016. ],\n       [  70.5, 2015. ,   79.6, 2016. ]])Record Low(month, variable)float6448.3 1.997e+03 ... 63.7 2.01e+03array([[  48.3, 1997. ,   64. , 2003. ],\n       [  47.9, 1996. ,   63.2, 2005. ],\n       [  55.1, 1996. ,   64.8, 2010. ],\n       [  61.2, 2009. ,   69.4, 2003. ],\n       [  67.9, 1999. ,   74.1, 2001. ],\n       [  75.1, 1995. ,   80. , 1996. ],\n       [  76.1, 2013. ,   80.9, 2013. ],\n       [  76.1, 1996. ,   81. , 2012. ],\n       [  74.3, 2001. ,   79.5, 2004. ],\n       [  64.6, 2005. ,   73.2, 2005. ],\n       [  57.4, 2006. ,   70.8, 2000. ],\n       [  48.8, 2010. ,   63.7, 2010. ]])Years(month, variable)float6423.0 nan 24.0 nan ... nan 24.0 nanarray([[23., nan, 24., nan],\n       [23., nan, 21., nan],\n       [24., nan, 25., nan],\n       [24., nan, 25., nan],\n       [21., nan, 23., nan],\n       [20., nan, 23., nan],\n       [25., nan, 25., nan],\n       [24., nan, 25., nan],\n       [24., nan, 24., nan],\n       [23., nan, 23., nan],\n       [23., nan, 24., nan],\n       [24., nan, 24., nan]])Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\nHow are these stored? Let’s consider the monthly stats. Each statistic is its own variable within the dataset. Take Record High for example:\n\nmonthly_records['Record High']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'Record High' (month: 12, variable: 4)&gt; Size: 384B\narray([[  78. , 2015. ,   81.7, 2017. ],\n       [  78.6, 2021. ,   81.5, 2021. ],\n       [  82.8, 2003. ,   83.2, 2021. ],\n       [  85.8, 2020. ,   85.8, 2020. ],\n       [  85.2, 1995. ,   87.7, 2021. ],\n       [  87.6, 2009. ,   90.4, 2010. ],\n       [  88.7, 2018. ,   92. , 2021. ],\n       [  88.5, 2022. ,   92.2, 2021. ],\n       [  86.7, 2021. ,   91.2, 2021. ],\n       [  86.8, 2023. ,   89. , 2016. ],\n       [  82. , 2020. ,   85. , 2020. ],\n       [  79.6, 1994. ,   84.6, 2016. ]])\nCoordinates:\n  * month     (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * variable  (variable) object 32B 'Air Temperature' ... 'Water Temperature ...xarray.DataArray'Record High'month: 12variable: 478.0 2.015e+03 81.7 2.017e+03 78.6 ... 79.6 1.994e+03 84.6 2.016e+03array([[  78. , 2015. ,   81.7, 2017. ],\n       [  78.6, 2021. ,   81.5, 2021. ],\n       [  82.8, 2003. ,   83.2, 2021. ],\n       [  85.8, 2020. ,   85.8, 2020. ],\n       [  85.2, 1995. ,   87.7, 2021. ],\n       [  87.6, 2009. ,   90.4, 2010. ],\n       [  88.7, 2018. ,   92. , 2021. ],\n       [  88.5, 2022. ,   92.2, 2021. ],\n       [  86.7, 2021. ,   91.2, 2021. ],\n       [  86.8, 2023. ,   89. , 2016. ],\n       [  82. , 2020. ,   85. , 2020. ],\n       [  79.6, 1994. ,   84.6, 2016. ]])Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (0)\n\n\nHere, the rows are months and the columns are the records or corresponding year. Let’s see what the variables are:\n\nmonthly_records['Record High'].coords['variable']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'variable' (variable: 4)&gt; Size: 32B\narray(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)\nCoordinates:\n  * variable  (variable) object 32B 'Air Temperature' ... 'Water Temperature ...xarray.DataArray'variable'variable: 4'Air Temperature' 'Air Temperature Year' ... 'Water Temperature Year'array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Coordinates: (1)variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Indexes: (1)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (0)\n\n\nAlternatively, we can select a specific variable and see all of its stats (converting to a dataframe makes it easier to see):\n\nmonthly_records.sel(variable='Air Temperature').to_dataframe().drop('variable', axis=1)\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord Low Monthly Average\nAverage High\nLowest High\nRecord High\nAverage Low\nHighest Low\nRecord Low\nYears\n\n\nmonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n68.7\n72.6\n63.0\n76.0\n73.0\n78.0\n55.6\n63.5\n48.3\n23.0\n\n\n2\n70.8\n74.9\n65.5\n76.5\n74.2\n78.6\n59.4\n70.0\n47.9\n23.0\n\n\n3\n72.3\n77.6\n66.1\n78.5\n74.2\n82.8\n63.3\n72.0\n55.1\n24.0\n\n\n4\n75.6\n79.4\n72.8\n80.8\n77.3\n85.8\n68.3\n72.6\n61.2\n24.0\n\n\n5\n78.7\n80.7\n77.0\n82.5\n80.8\n85.2\n73.8\n77.1\n67.9\n21.0\n\n\n6\n81.5\n83.6\n79.8\n84.8\n82.8\n87.6\n77.6\n80.8\n75.1\n20.0\n\n\n7\n82.9\n85.0\n81.0\n85.8\n84.2\n88.7\n79.0\n82.3\n76.1\n25.0\n\n\n8\n83.2\n85.9\n81.8\n85.7\n84.0\n88.5\n79.3\n83.6\n76.1\n24.0\n\n\n9\n82.0\n82.7\n80.6\n85.1\n83.9\n86.7\n78.2\n79.8\n74.3\n24.0\n\n\n10\n79.6\n81.2\n77.5\n83.8\n81.0\n86.8\n72.7\n77.8\n64.6\n23.0\n\n\n11\n75.0\n78.6\n71.4\n79.7\n76.9\n82.0\n66.0\n74.4\n57.4\n23.0\n\n\n12\n71.4\n76.9\n62.1\n77.5\n72.5\n79.6\n59.2\n70.5\n48.8\n24.0\n\n\n\n\n\n\n\n\n\nReorganize\nFor the sake of convenience later, let’s rearrange these data arrays before saving them. It will be more useful to have record years as data variables instead of a dimension, but we’ll have to do some renaming in order to pull that off.\nFirst, separate the records and years into smaller xarrays:\n\nday_records = daily_records.sel(variable=[i for i in daily_records.coords['variable'].values if 'Year' not in i])\nday_years = daily_records.sel(variable=[i for i in daily_records.coords['variable'].values if 'Year' in i])\n\nmon_records = monthly_records.sel(variable=[i for i in monthly_records.coords['variable'].values if 'Year' not in i])\nmon_years = monthly_records.sel(variable=[i for i in monthly_records.coords['variable'].values if 'Year' in i])\n\nNext, add “Year” to all of the variable names and remove it from the coordinate name:\n\nday_years = day_years.rename_vars({i:i+' Year' for i in day_years.data_vars})\nday_years.coords['variable'] = [i.removesuffix(' Year') for i in day_years.coords['variable'].values]\n\nmon_years = mon_years.rename_vars({i:i+' Year' for i in mon_years.data_vars})\nmon_years.coords['variable'] = [i.removesuffix(' Year') for i in mon_years.coords['variable'].values]\n\nNow we can merge these two xarrays together, rearrange the order of the variables, and drop those that do not contain a year, such as daily average.\n\ndaily_records = xr.merge([day_records, day_years])\ndaily_records = daily_records[[item for items in zip(day_records.data_vars, day_years.data_vars) for item in items]]\ndaily_records = daily_records.drop_vars([x for x in daily_records.data_vars if daily_records[x].isnull().all()])\n\nmonthly_records = xr.merge([mon_records, mon_years])\nmonthly_records = monthly_records[[item for items in zip(mon_records.data_vars, mon_years.data_vars) for item in items]]\nmonthly_records = monthly_records.drop_vars([x for x in monthly_records.data_vars if monthly_records[x].isnull().all()])\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:                           (month: 12, variable: 2)\nCoordinates:\n  * month                             (month) int64 96B 1 2 3 4 5 ... 9 10 11 12\n  * variable                          (variable) object 16B 'Air Temperature'...\nData variables: (12/16)\n    Monthly Average                   (month, variable) float64 192B 68.7 ......\n    Record High Monthly Average       (month, variable) float64 192B 72.6 ......\n    Record High Monthly Average Year  (month, variable) float64 192B 2.013e+0...\n    Record Low Monthly Average        (month, variable) float64 192B 63.0 ......\n    Record Low Monthly Average Year   (month, variable) float64 192B 2.001e+0...\n    Average High                      (month, variable) float64 192B 76.0 ......\n    ...                                ...\n    Average Low                       (month, variable) float64 192B 55.6 ......\n    Highest Low                       (month, variable) float64 192B 63.5 ......\n    Highest Low Year                  (month, variable) float64 192B 2.013e+0...\n    Record Low                        (month, variable) float64 192B 48.3 ......\n    Record Low Year                   (month, variable) float64 192B 1.997e+0...\n    Years                             (month, variable) float64 192B 23.0 ......\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:month: 12variable: 2Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Data variables: (16)Monthly Average(month, variable)float6468.7 71.6 70.8 ... 77.4 71.4 74.0array([[68.7, 71.6],\n       [70.8, 72.8],\n       [72.3, 75. ],\n       [75.6, 78.5],\n       [78.7, 82. ],\n       [81.5, 85.2],\n       [82.9, 87.1],\n       [83.2, 87.3],\n       [82. , 85.7],\n       [79.6, 82.1],\n       [75. , 77.4],\n       [71.4, 74. ]])Record High Monthly Average(month, variable)float6472.6 78.9 74.9 ... 81.5 76.9 82.5array([[72.6, 78.9],\n       [74.9, 76.3],\n       [77.6, 80. ],\n       [79.4, 83.4],\n       [80.7, 84.1],\n       [83.6, 87.6],\n       [85. , 89.5],\n       [85.9, 90.1],\n       [82.7, 89.5],\n       [81.2, 85.9],\n       [78.6, 81.5],\n       [76.9, 82.5]])Record High Monthly Average Year(month, variable)float642.013e+03 2.017e+03 ... 2.016e+03array([[2013., 2017.],\n       [2018., 2021.],\n       [2003., 2003.],\n       [2020., 2020.],\n       [1995., 2021.],\n       [2010., 2010.],\n       [2023., 2023.],\n       [2022., 2021.],\n       [2017., 2021.],\n       [2020., 2021.],\n       [2015., 2016.],\n       [2015., 2016.]])Record Low Monthly Average(month, variable)float6463.0 67.5 65.5 ... 74.6 62.1 68.2array([[63. , 67.5],\n       [65.5, 67.7],\n       [66.1, 69.2],\n       [72.8, 75.1],\n       [77. , 78.6],\n       [79.8, 83.3],\n       [81. , 84.5],\n       [81.8, 85.4],\n       [80.6, 82.7],\n       [77.5, 79.6],\n       [71.4, 74.6],\n       [62.1, 68.2]])Record Low Monthly Average Year(month, variable)float642.001e+03 2.001e+03 ... 2.01e+03array([[2001., 2001.],\n       [1996., 2005.],\n       [2010., 2010.],\n       [2004., 2004.],\n       [2013., 2001.],\n       [2014., 2002.],\n       [2013., 2013.],\n       [1994., 1995.],\n       [2001., 2004.],\n       [2000., 2000.],\n       [2012., 2012.],\n       [2010., 2010.]])Average High(month, variable)float6476.0 75.4 76.5 ... 80.6 77.5 77.6array([[76. , 75.4],\n       [76.5, 76.7],\n       [78.5, 79.2],\n       [80.8, 81.9],\n       [82.5, 85.1],\n       [84.8, 87.9],\n       [85.8, 89.1],\n       [85.7, 89.4],\n       [85.1, 88. ],\n       [83.8, 85.6],\n       [79.7, 80.6],\n       [77.5, 77.6]])Lowest High(month, variable)float6473.0 70.5 74.2 ... 76.8 72.5 73.0array([[73. , 70.5],\n       [74.2, 73.7],\n       [74.2, 73.3],\n       [77.3, 78.4],\n       [80.8, 82.8],\n       [82.8, 85.3],\n       [84.2, 86.4],\n       [84. , 87.2],\n       [83.9, 85.2],\n       [81. , 82.7],\n       [76.9, 76.8],\n       [72.5, 73. ]])Lowest High Year(month, variable)float642.011e+03 2.011e+03 ... 2.003e+03array([[2011., 2011.],\n       [2000., 2016.],\n       [2010., 2010.],\n       [2004., 2010.],\n       [2014., 2013.],\n       [2014., 1996.],\n       [2012., 2013.],\n       [2003., 2000.],\n       [2000., 1997.],\n       [2010., 2004.],\n       [2012., 2001.],\n       [2010., 2003.]])Record High(month, variable)float6478.0 81.7 78.6 ... 85.0 79.6 84.6array([[78. , 81.7],\n       [78.6, 81.5],\n       [82.8, 83.2],\n       [85.8, 85.8],\n       [85.2, 87.7],\n       [87.6, 90.4],\n       [88.7, 92. ],\n       [88.5, 92.2],\n       [86.7, 91.2],\n       [86.8, 89. ],\n       [82. , 85. ],\n       [79.6, 84.6]])Record High Year(month, variable)float642.015e+03 2.017e+03 ... 2.016e+03array([[2015., 2017.],\n       [2021., 2021.],\n       [2003., 2021.],\n       [2020., 2020.],\n       [1995., 2021.],\n       [2009., 2010.],\n       [2018., 2021.],\n       [2022., 2021.],\n       [2021., 2021.],\n       [2023., 2016.],\n       [2020., 2020.],\n       [1994., 2016.]])Average Low(month, variable)float6455.6 67.6 59.4 ... 74.2 59.2 70.2array([[55.6, 67.6],\n       [59.4, 68.9],\n       [63.3, 70.9],\n       [68.3, 74.6],\n       [73.8, 78.1],\n       [77.6, 82.2],\n       [79. , 84.5],\n       [79.3, 84.4],\n       [78.2, 83. ],\n       [72.7, 77.9],\n       [66. , 74.2],\n       [59.2, 70.2]])Highest Low(month, variable)float6463.5 75.9 70.0 ... 80.0 70.5 79.6array([[63.5, 75.9],\n       [70. , 73.4],\n       [72. , 75.4],\n       [72.6, 81.1],\n       [77.1, 80.4],\n       [80.8, 85.2],\n       [82.3, 87.2],\n       [83.6, 87.2],\n       [79.8, 87.1],\n       [77.8, 83.4],\n       [74.4, 80. ],\n       [70.5, 79.6]])Highest Low Year(month, variable)float642.013e+03 2.017e+03 ... 2.016e+03array([[2013., 2017.],\n       [2018., 2023.],\n       [1997., 1997.],\n       [2015., 2020.],\n       [2003., 1994.],\n       [2004., 2004.],\n       [2022., 2023.],\n       [2022., 2021.],\n       [2009., 2021.],\n       [1995., 2021.],\n       [2020., 2016.],\n       [2015., 2016.]])Record Low(month, variable)float6448.3 64.0 47.9 ... 70.8 48.8 63.7array([[48.3, 64. ],\n       [47.9, 63.2],\n       [55.1, 64.8],\n       [61.2, 69.4],\n       [67.9, 74.1],\n       [75.1, 80. ],\n       [76.1, 80.9],\n       [76.1, 81. ],\n       [74.3, 79.5],\n       [64.6, 73.2],\n       [57.4, 70.8],\n       [48.8, 63.7]])Record Low Year(month, variable)float641.997e+03 2.003e+03 ... 2.01e+03array([[1997., 2003.],\n       [1996., 2005.],\n       [1996., 2010.],\n       [2009., 2003.],\n       [1999., 2001.],\n       [1995., 1996.],\n       [2013., 2013.],\n       [1996., 2012.],\n       [2001., 2004.],\n       [2005., 2005.],\n       [2006., 2000.],\n       [2010., 2010.]])Years(month, variable)float6423.0 24.0 23.0 ... 24.0 24.0 24.0array([[23., 24.],\n       [23., 21.],\n       [24., 25.],\n       [24., 25.],\n       [21., 23.],\n       [20., 23.],\n       [25., 25.],\n       [24., 25.],\n       [24., 24.],\n       [23., 23.],\n       [23., 24.],\n       [24., 24.]])Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\nFinally, let’s convert years to integers since we do not need decimal years.\n\ndaily_records[[i for i in daily_records.data_vars if \"Year\" in i]] = \\\n    daily_records[[i for i in daily_records.data_vars if \"Year\" in i]].astype(int)\n\nmonthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]] = \\\n    monthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]].astype(int)\n\n‘yearday’ is not intuitive, so we can change it to calendar day instead and rename the coordinate. Similarly, we can use month names instead of numbers for the sake of clarity.\n\ndaily_records.coords['yearday'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D').strftime('%d-%b')\ndaily_records = daily_records.rename({'yearday':'Date'})\n\nmonthly_records.coords['month'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1m').strftime('%b')\nmonthly_records = monthly_records.rename({'month': 'Month'})\n\nNow take a look at the final products\n\ndaily_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 97kB\nDimensions:                         (Date: 366, variable: 2)\nCoordinates:\n  * variable                        (variable) object 16B 'Air Temperature' '...\n  * Date                            (Date) object 3kB '01-Jan' ... '31-Dec'\nData variables: (12/16)\n    Daily Average                   (Date, variable) float64 6kB 71.5 ... 72.6\n    Record High Daily Average       (Date, variable) float64 6kB 78.0 ... 80.5\n    Record High Daily Average Year  (Date, variable) int64 6kB 2022 ... 2021\n    Record Low Daily Average        (Date, variable) float64 6kB 54.4 ... 66.1\n    Record Low Daily Average Year   (Date, variable) int64 6kB 2001 ... 2010\n    Average High                    (Date, variable) float64 6kB 75.0 ... 73.9\n    ...                              ...\n    Average Low                     (Date, variable) float64 6kB 67.9 ... 71.4\n    Highest Low                     (Date, variable) float64 6kB 76.8 ... 79.3\n    Highest Low Year                (Date, variable) int64 6kB 2022 ... 2021\n    Record Low                      (Date, variable) float64 6kB 45.5 ... 64.4\n    Record Low Year                 (Date, variable) int64 6kB 2001 ... 2010\n    Years                           (Date, variable) int64 6kB 23 24 ... 23 24\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:Date: 366variable: 2Coordinates: (2)variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Date(Date)object'01-Jan' '02-Jan' ... '31-Dec'array(['01-Jan', '02-Jan', '03-Jan', ..., '29-Dec', '30-Dec', '31-Dec'],\n      dtype=object)Data variables: (16)Daily Average(Date, variable)float6471.5 72.4 71.8 ... 72.7 70.8 72.6array([[71.5, 72.4],\n       [71.8, 72.9],\n       [70. , 73. ],\n       [69.3, 72.7],\n       [68.2, 72.5],\n       [69.1, 72.3],\n       [68.4, 72.3],\n       [67.4, 72. ],\n       [68. , 71.7],\n       [68.3, 71.6],\n       [70.3, 71.6],\n       [70.7, 71.8],\n       [69.6, 71.9],\n       [68.6, 71.7],\n       [69.6, 71.4],\n       [69.3, 71.4],\n       [67.5, 71.1],\n       [67.6, 70.7],\n       [68. , 70.9],\n       [68.1, 71. ],\n...\n       [72.1, 74.8],\n       [73. , 74.8],\n       [72.9, 74.7],\n       [71. , 74.2],\n       [71.7, 74.3],\n       [71.8, 74.2],\n       [70.9, 74.2],\n       [70.3, 73.9],\n       [69.1, 73.4],\n       [69. , 72.9],\n       [70.3, 72.8],\n       [71.7, 72.9],\n       [71.6, 72.9],\n       [70.6, 72.7],\n       [69.6, 72.6],\n       [68.1, 72.3],\n       [69.4, 72.5],\n       [70.6, 72.6],\n       [69.6, 72.7],\n       [70.8, 72.6]])Record High Daily Average(Date, variable)float6478.0 80.4 77.8 ... 81.9 79.2 80.5array([[78. , 80.4],\n       [77.8, 80.2],\n       [78. , 80.7],\n       [77.9, 81.2],\n       [77.3, 81.4],\n       [76.8, 81.7],\n       [77.4, 81.5],\n       [76.8, 78.8],\n       [77.1, 78.2],\n       [76.9, 78.2],\n       [76.6, 78.2],\n       [77.4, 77.2],\n       [76.3, 77.4],\n       [76.7, 77.8],\n       [76. , 78. ],\n       [76. , 78. ],\n       [74.8, 77.4],\n       [75.8, 78.6],\n       [74.5, 79.8],\n       [74.1, 80.4],\n...\n       [78.8, 81.7],\n       [78.8, 82.6],\n       [78. , 83.3],\n       [78.4, 83.3],\n       [78.4, 82.8],\n       [79.1, 82.2],\n       [78.8, 82.4],\n       [78.9, 83.1],\n       [78.3, 83.2],\n       [77.6, 83.4],\n       [78.4, 83. ],\n       [79. , 83.2],\n       [79.2, 83. ],\n       [79. , 82.8],\n       [78.6, 82.3],\n       [78.4, 81.8],\n       [79. , 82.2],\n       [79.4, 82.6],\n       [79.5, 81.9],\n       [79.2, 80.5]])Record High Daily Average Year(Date, variable)int642022 2022 2022 ... 2016 2015 2021array([[2022, 2022],\n       [2022, 2022],\n       [2015, 2017],\n       [2015, 2017],\n       [2015, 2017],\n       [2015, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2013, 2022],\n       [2014, 2022],\n       [2020, 2022],\n       [2020, 2022],\n       [2020, 2017],\n       [2020, 2017],\n       [2020, 2017],\n       [2020, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2020, 2017],\n       [2017, 2017],\n...\n       [2021, 2021],\n       [2021, 2016],\n       [2015, 2016],\n       [2009, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2013, 2016],\n       [2013, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2021]])Record Low Daily Average(Date, variable)float6454.4 66.4 56.6 ... 66.4 49.9 66.1array([[54.4, 66.4],\n       [56.6, 66.8],\n       [51.7, 67.3],\n       [51.6, 67.6],\n       [51. , 66.2],\n       [48.4, 64.8],\n       [53. , 65.9],\n       [49. , 66.2],\n       [50. , 64.5],\n       [54.6, 65. ],\n       [59.6, 64. ],\n       [52.5, 65.9],\n       [53.6, 65.6],\n       [58.6, 66.2],\n       [61.2, 66.9],\n       [58.4, 66.8],\n       [55.4, 66.4],\n       [50. , 66.7],\n       [48.3, 64.9],\n       [57.8, 65. ],\n...\n       [60.5, 69.1],\n       [53.7, 67.6],\n       [62.2, 66.3],\n       [52.6, 65.8],\n       [60.6, 63.7],\n       [63.2, 65. ],\n       [54.7, 65.3],\n       [59.9, 67.1],\n       [50.6, 67.1],\n       [57.6, 65.8],\n       [57.2, 66.8],\n       [58.8, 67.8],\n       [51.8, 67.3],\n       [49.4, 66.4],\n       [54.7, 66.6],\n       [48.8, 65.8],\n       [52.2, 65.2],\n       [58.7, 66.6],\n       [54.8, 66.4],\n       [49.9, 66.1]])Record Low Daily Average Year(Date, variable)int642001 2011 2010 ... 2010 2000 2010array([[2001, 2011],\n       [2010, 2011],\n       [2012, 2011],\n       [2018, 2001],\n       [2010, 2001],\n       [2010, 2001],\n       [2010, 2010],\n       [1996, 2002],\n       [1996, 1996],\n       [2001, 1996],\n       [2004, 2010],\n       [2010, 2010],\n       [1996, 1996],\n       [1996, 1996],\n       [2012, 2011],\n       [2014, 2011],\n       [1997, 2012],\n       [1997, 1997],\n       [1997, 2003],\n       [1997, 2003],\n...\n       [2004, 1996],\n       [2010, 2010],\n       [2017, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [1997, 2010],\n       [2003, 2010],\n       [2003, 2010],\n       [1996, 2003],\n       [2009, 2003],\n       [2012, 2003],\n       [1995, 2010],\n       [1995, 2003],\n       [1995, 2003],\n       [1995, 2010],\n       [2010, 1995],\n       [2010, 2010],\n       [2009, 1995],\n       [2000, 2010],\n       [2000, 2010]])Average High(Date, variable)float6475.0 73.7 75.1 ... 74.1 74.3 73.9array([[75. , 73.7],\n       [75.1, 74.2],\n       [73.9, 74.3],\n       [73.2, 74.1],\n       [72.9, 74. ],\n       [73.9, 73.6],\n       [73.4, 73.7],\n       [72.2, 73.5],\n       [72.3, 73.1],\n       [73.4, 73.1],\n       [74.1, 73. ],\n       [74. , 73.2],\n       [73.6, 73.2],\n       [73.4, 73.1],\n       [73.7, 72.9],\n       [73.3, 73. ],\n       [72.3, 72.5],\n       [72.2, 72.2],\n       [72.8, 72.3],\n       [73.3, 72.4],\n...\n       [75.9, 75.9],\n       [76.3, 75.9],\n       [76.6, 75.9],\n       [75.1, 75.7],\n       [75.4, 75.4],\n       [76.1, 75.3],\n       [75.6, 75.4],\n       [74.7, 75.3],\n       [72.5, 74.6],\n       [73.7, 74.2],\n       [73.9, 74. ],\n       [74.8, 74.3],\n       [74.8, 74.2],\n       [74.4, 74. ],\n       [74. , 73.9],\n       [72.7, 73.6],\n       [73.1, 73.8],\n       [74.4, 74.1],\n       [73.2, 74.1],\n       [74.3, 73.9]])Lowest High(Date, variable)float6463.3 67.8 64.2 ... 68.4 55.6 67.8array([[63.3, 67.8],\n       [64.2, 68. ],\n       [57. , 68.9],\n       [58.7, 69.1],\n       [57.8, 68.5],\n       [55.7, 66.2],\n       [59.7, 67.1],\n       [54.5, 67.8],\n       [59.7, 66.6],\n       [65.3, 67.3],\n       [68.7, 68. ],\n       [60.1, 68.9],\n       [59.5, 68. ],\n       [67.3, 67.6],\n       [67.3, 68.9],\n       [63.5, 68. ],\n       [61.9, 67.5],\n       [55.8, 68.2],\n       [55.2, 67.1],\n       [65.7, 66.9],\n...\n       [66.9, 69.8],\n       [62.6, 70.9],\n       [68.9, 69.8],\n       [61.7, 69.3],\n       [64.6, 65.3],\n       [70.2, 68. ],\n       [62.1, 68. ],\n       [64.6, 68.9],\n       [57. , 68.5],\n       [63. , 68.7],\n       [64. , 69.1],\n       [62.2, 69.4],\n       [57.9, 69.1],\n       [57.7, 67.3],\n       [61.7, 68.7],\n       [55.4, 67.8],\n       [57.7, 67.1],\n       [67.1, 69.4],\n       [59.5, 68.4],\n       [55.6, 67.8]])Lowest High Year(Date, variable)int642001 2011 2010 ... 2010 2000 2010array([[2001, 2011],\n       [2010, 2011],\n       [2012, 2011],\n       [2010, 2011],\n       [2010, 2001],\n       [2010, 2001],\n       [2014, 2002],\n       [1996, 2011],\n       [1996, 1996],\n       [2001, 1996],\n       [2001, 2010],\n       [2010, 2001],\n       [1996, 1996],\n       [1996, 2011],\n       [2000, 1996],\n       [2014, 2011],\n       [1997, 2012],\n       [1997, 2012],\n       [1997, 2003],\n       [1997, 2003],\n...\n       [2004, 1996],\n       [2010, 2010],\n       [2017, 2010],\n       [2010, 2010],\n       [1998, 2010],\n       [1998, 2010],\n       [2003, 2010],\n       [2003, 1997],\n       [1996, 1997],\n       [2009, 2003],\n       [1995, 2004],\n       [1995, 2004],\n       [1995, 2003],\n       [1995, 2003],\n       [1995, 2010],\n       [2010, 1995],\n       [1995, 1995],\n       [2010, 2003],\n       [2000, 2010],\n       [2000, 2010]])Record High(Date, variable)float6479.3 81.1 79.3 ... 83.1 80.1 81.7array([[79.3, 81.1],\n       [79.3, 81. ],\n       [79.2, 81.5],\n       [81.7, 81.9],\n       [80.2, 82.2],\n       [78.3, 82.6],\n       [81. , 82.2],\n       [79.2, 80.6],\n       [77.9, 79. ],\n       [79. , 79.2],\n       [79. , 79. ],\n       [79. , 78.4],\n       [78.4, 79.2],\n       [78.4, 79.7],\n       [78.6, 79.9],\n       [80.4, 79.5],\n       [77.7, 78.4],\n       [77.7, 79.9],\n       [78.4, 81.1],\n       [80.2, 81.5],\n...\n       [81.5, 82.6],\n       [82.9, 83.5],\n       [80.1, 84. ],\n       [80.4, 84. ],\n       [79.7, 83.7],\n       [82.2, 82.9],\n       [82.8, 83.1],\n       [79.9, 83.8],\n       [80.4, 83.8],\n       [79.3, 84. ],\n       [80.4, 83.7],\n       [79.9, 83.8],\n       [80.1, 83.7],\n       [79.7, 83.5],\n       [80.8, 82.9],\n       [80.2, 82.6],\n       [80.1, 82.9],\n       [80.6, 83.3],\n       [80.6, 83.1],\n       [80.1, 81.7]])Record High Year(Date, variable)int642022 2022 2022 ... 2016 2015 2021array([[2022, 2022],\n       [2022, 2022],\n       [2019, 2017],\n       [2020, 2017],\n       [2019, 2017],\n       [2015, 2017],\n       [2017, 2017],\n       [2007, 2017],\n       [2013, 2017],\n       [2022, 2022],\n       [2020, 2022],\n       [2024, 2017],\n       [2024, 2017],\n       [2014, 2017],\n       [2024, 2017],\n       [1997, 2017],\n       [2007, 2017],\n       [2015, 2017],\n       [2011, 2017],\n       [2017, 2017],\n...\n       [2021, 2021],\n       [2020, 2016],\n       [2009, 2016],\n       [2016, 2016],\n       [2009, 2016],\n       [2020, 2016],\n       [2012, 2016],\n       [2016, 2016],\n       [2021, 2016],\n       [2020, 2016],\n       [2017, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2023, 2016],\n       [2021, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2013, 2016],\n       [2015, 2021]])Average Low(Date, variable)float6467.9 71.1 68.5 ... 71.4 67.3 71.4array([[67.9, 71.1],\n       [68.5, 71.6],\n       [66.1, 71.7],\n       [65.4, 71.3],\n       [63.6, 71.1],\n       [64.4, 71. ],\n       [63.4, 70.9],\n       [62.7, 70.6],\n       [63.6, 70.4],\n       [63.2, 70.1],\n       [66.6, 70.2],\n       [67.4, 70.5],\n       [65.6, 70.6],\n       [63.8, 70.3],\n       [65.4, 70. ],\n       [65.2, 70. ],\n       [62.7, 69.8],\n       [63. , 69.2],\n       [63.2, 69.5],\n       [62.8, 69.6],\n...\n       [68.3, 73.7],\n       [69.7, 73.7],\n       [69.2, 73.6],\n       [66.9, 72.7],\n       [68.1, 73.2],\n       [67.5, 73.1],\n       [66.3, 72.9],\n       [65.8, 72.6],\n       [65.8, 72.2],\n       [64.3, 71.6],\n       [66.6, 71.5],\n       [68.5, 71.6],\n       [68.3, 71.5],\n       [66.7, 71.4],\n       [65.3, 71.3],\n       [63.4, 71. ],\n       [65.8, 71.2],\n       [66.7, 71.2],\n       [66.1, 71.4],\n       [67.3, 71.4]])Highest Low(Date, variable)float6476.8 79.7 76.3 ... 80.8 78.3 79.3array([[76.8, 79.7],\n       [76.3, 79.5],\n       [77. , 79.9],\n       [76.8, 80.6],\n       [75.9, 80.6],\n       [75.4, 80.8],\n       [76.6, 80.8],\n       [75.4, 77.9],\n       [76.3, 77.5],\n       [75.4, 77.2],\n       [74.8, 77.5],\n       [76.1, 76.6],\n       [75.2, 75.9],\n       [75. , 75.9],\n       [74.3, 76.1],\n       [74.5, 76.5],\n       [73. , 76.5],\n       [74.8, 77.2],\n       [73. , 78.6],\n       [70.5, 79.2],\n...\n       [76.1, 80.8],\n       [77.5, 81.7],\n       [76.5, 82.6],\n       [77. , 82.6],\n       [77. , 81.9],\n       [78.1, 81.5],\n       [77.4, 81.7],\n       [77.9, 82.4],\n       [77.4, 82.6],\n       [76.3, 82.8],\n       [77.4, 82.2],\n       [78.1, 82.6],\n       [78.3, 82.2],\n       [78.3, 82. ],\n       [77.2, 81.7],\n       [77.5, 81.1],\n       [77.9, 81.5],\n       [78.3, 81.9],\n       [78.4, 80.8],\n       [78.3, 79.3]])Highest Low Year(Date, variable)int642022 2022 2017 ... 2016 2015 2021array([[2022, 2022],\n       [2017, 2022],\n       [2015, 2017],\n       [2015, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2013, 2022],\n       [2013, 2022],\n       [2013, 2022],\n       [2013, 2022],\n       [2020, 2022],\n       [2020, 2022],\n       [2020, 2017],\n       [2013, 2017],\n       [2020, 2017],\n       [2017, 2017],\n       [2007, 2017],\n       [2001, 2017],\n       [2015, 2017],\n...\n       [1997, 2021],\n       [2021, 2016],\n       [2001, 2016],\n       [2009, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2013, 2016],\n       [2013, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2021]])Record Low(Date, variable)float6445.5 63.9 49.1 ... 64.4 44.2 64.4array([[45.5, 63.9],\n       [49.1, 64.4],\n       [46.4, 65.5],\n       [43.7, 64.5],\n       [44.2, 63.6],\n       [41. , 61.7],\n       [45.5, 61.7],\n       [43.5, 62.5],\n       [40.3, 60.9],\n       [43.9, 61.2],\n       [49.3, 60.1],\n       [44.9, 62.2],\n       [46.4, 62.3],\n       [50. , 62.2],\n       [53.6, 63.9],\n       [53.2, 65. ],\n       [48.9, 65.3],\n       [44.1, 64. ],\n       [41.4, 62.8],\n       [49.8, 63. ],\n...\n       [54.1, 67.3],\n       [44.8, 64.4],\n       [55.6, 62.8],\n       [43.5, 62.2],\n       [51.6, 62.1],\n       [55.8, 62.1],\n       [47.3, 62.6],\n       [48.9, 63.7],\n       [44.2, 65.1],\n       [49.3, 63. ],\n       [49.5, 64.4],\n       [55.4, 64.9],\n       [45.7, 65.5],\n       [41. , 63.3],\n       [47.5, 64. ],\n       [42.1, 63. ],\n       [42.4, 62.2],\n       [50.1, 62.2],\n       [50. , 64.4],\n       [44.2, 64.4]])Record Low Year(Date, variable)int642001 2001 2010 ... 2010 2000 2010array([[2001, 2001],\n       [2010, 2001],\n       [2012, 2001],\n       [2018, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [1996, 2010],\n       [1996, 2010],\n       [2001, 2010],\n       [2004, 2010],\n       [2010, 2010],\n       [2011, 2010],\n       [1996, 2010],\n       [2012, 2010],\n       [2014, 2010],\n       [1997, 2012],\n       [1997, 1997],\n       [1997, 2003],\n       [1997, 1997],\n...\n       [2004, 2010],\n       [2010, 2010],\n       [2017, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [1997, 2010],\n       [2003, 2010],\n       [1996, 2010],\n       [1996, 2003],\n       [2003, 2003],\n       [2012, 2003],\n       [1995, 2003],\n       [1995, 2003],\n       [1995, 1995],\n       [2010, 1995],\n       [2010, 2010],\n       [2010, 2010],\n       [2009, 2010],\n       [2000, 2010],\n       [2000, 2010]])Years(Date, variable)int6423 24 23 24 23 ... 24 24 24 23 24array([[23, 24],\n       [23, 24],\n       [23, 24],\n       [22, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [22, 24],\n       [23, 24],\n       [22, 24],\n       [22, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n...\n       [24, 24],\n       [24, 24],\n       [23, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [23, 23],\n       [24, 24],\n       [23, 23],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [23, 24]])Indexes: (2)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))DatePandasIndexPandasIndex(Index(['01-Jan', '02-Jan', '03-Jan', '04-Jan', '05-Jan', '06-Jan', '07-Jan',\n       '08-Jan', '09-Jan', '10-Jan',\n       ...\n       '22-Dec', '23-Dec', '24-Dec', '25-Dec', '26-Dec', '27-Dec', '28-Dec',\n       '29-Dec', '30-Dec', '31-Dec'],\n      dtype='object', name='Date', length=366))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:                           (Month: 12, variable: 2)\nCoordinates:\n  * variable                          (variable) object 16B 'Air Temperature'...\n  * Month                             (Month) object 96B 'Jan' 'Feb' ... 'Dec'\nData variables: (12/16)\n    Monthly Average                   (Month, variable) float64 192B 68.7 ......\n    Record High Monthly Average       (Month, variable) float64 192B 72.6 ......\n    Record High Monthly Average Year  (Month, variable) int64 192B 2013 ... 2016\n    Record Low Monthly Average        (Month, variable) float64 192B 63.0 ......\n    Record Low Monthly Average Year   (Month, variable) int64 192B 2001 ... 2010\n    Average High                      (Month, variable) float64 192B 76.0 ......\n    ...                                ...\n    Average Low                       (Month, variable) float64 192B 55.6 ......\n    Highest Low                       (Month, variable) float64 192B 63.5 ......\n    Highest Low Year                  (Month, variable) int64 192B 2013 ... 2016\n    Record Low                        (Month, variable) float64 192B 48.3 ......\n    Record Low Year                   (Month, variable) int64 192B 1997 ... 2010\n    Years                             (Month, variable) int64 192B 23 24 ... 24\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:Month: 12variable: 2Coordinates: (2)variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Month(Month)object'Jan' 'Feb' 'Mar' ... 'Nov' 'Dec'array(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct',\n       'Nov', 'Dec'], dtype=object)Data variables: (16)Monthly Average(Month, variable)float6468.7 71.6 70.8 ... 77.4 71.4 74.0array([[68.7, 71.6],\n       [70.8, 72.8],\n       [72.3, 75. ],\n       [75.6, 78.5],\n       [78.7, 82. ],\n       [81.5, 85.2],\n       [82.9, 87.1],\n       [83.2, 87.3],\n       [82. , 85.7],\n       [79.6, 82.1],\n       [75. , 77.4],\n       [71.4, 74. ]])Record High Monthly Average(Month, variable)float6472.6 78.9 74.9 ... 81.5 76.9 82.5array([[72.6, 78.9],\n       [74.9, 76.3],\n       [77.6, 80. ],\n       [79.4, 83.4],\n       [80.7, 84.1],\n       [83.6, 87.6],\n       [85. , 89.5],\n       [85.9, 90.1],\n       [82.7, 89.5],\n       [81.2, 85.9],\n       [78.6, 81.5],\n       [76.9, 82.5]])Record High Monthly Average Year(Month, variable)int642013 2017 2018 ... 2016 2015 2016array([[2013, 2017],\n       [2018, 2021],\n       [2003, 2003],\n       [2020, 2020],\n       [1995, 2021],\n       [2010, 2010],\n       [2023, 2023],\n       [2022, 2021],\n       [2017, 2021],\n       [2020, 2021],\n       [2015, 2016],\n       [2015, 2016]])Record Low Monthly Average(Month, variable)float6463.0 67.5 65.5 ... 74.6 62.1 68.2array([[63. , 67.5],\n       [65.5, 67.7],\n       [66.1, 69.2],\n       [72.8, 75.1],\n       [77. , 78.6],\n       [79.8, 83.3],\n       [81. , 84.5],\n       [81.8, 85.4],\n       [80.6, 82.7],\n       [77.5, 79.6],\n       [71.4, 74.6],\n       [62.1, 68.2]])Record Low Monthly Average Year(Month, variable)int642001 2001 1996 ... 2012 2010 2010array([[2001, 2001],\n       [1996, 2005],\n       [2010, 2010],\n       [2004, 2004],\n       [2013, 2001],\n       [2014, 2002],\n       [2013, 2013],\n       [1994, 1995],\n       [2001, 2004],\n       [2000, 2000],\n       [2012, 2012],\n       [2010, 2010]])Average High(Month, variable)float6476.0 75.4 76.5 ... 80.6 77.5 77.6array([[76. , 75.4],\n       [76.5, 76.7],\n       [78.5, 79.2],\n       [80.8, 81.9],\n       [82.5, 85.1],\n       [84.8, 87.9],\n       [85.8, 89.1],\n       [85.7, 89.4],\n       [85.1, 88. ],\n       [83.8, 85.6],\n       [79.7, 80.6],\n       [77.5, 77.6]])Lowest High(Month, variable)float6473.0 70.5 74.2 ... 76.8 72.5 73.0array([[73. , 70.5],\n       [74.2, 73.7],\n       [74.2, 73.3],\n       [77.3, 78.4],\n       [80.8, 82.8],\n       [82.8, 85.3],\n       [84.2, 86.4],\n       [84. , 87.2],\n       [83.9, 85.2],\n       [81. , 82.7],\n       [76.9, 76.8],\n       [72.5, 73. ]])Lowest High Year(Month, variable)int642011 2011 2000 ... 2001 2010 2003array([[2011, 2011],\n       [2000, 2016],\n       [2010, 2010],\n       [2004, 2010],\n       [2014, 2013],\n       [2014, 1996],\n       [2012, 2013],\n       [2003, 2000],\n       [2000, 1997],\n       [2010, 2004],\n       [2012, 2001],\n       [2010, 2003]])Record High(Month, variable)float6478.0 81.7 78.6 ... 85.0 79.6 84.6array([[78. , 81.7],\n       [78.6, 81.5],\n       [82.8, 83.2],\n       [85.8, 85.8],\n       [85.2, 87.7],\n       [87.6, 90.4],\n       [88.7, 92. ],\n       [88.5, 92.2],\n       [86.7, 91.2],\n       [86.8, 89. ],\n       [82. , 85. ],\n       [79.6, 84.6]])Record High Year(Month, variable)int642015 2017 2021 ... 2020 1994 2016array([[2015, 2017],\n       [2021, 2021],\n       [2003, 2021],\n       [2020, 2020],\n       [1995, 2021],\n       [2009, 2010],\n       [2018, 2021],\n       [2022, 2021],\n       [2021, 2021],\n       [2023, 2016],\n       [2020, 2020],\n       [1994, 2016]])Average Low(Month, variable)float6455.6 67.6 59.4 ... 74.2 59.2 70.2array([[55.6, 67.6],\n       [59.4, 68.9],\n       [63.3, 70.9],\n       [68.3, 74.6],\n       [73.8, 78.1],\n       [77.6, 82.2],\n       [79. , 84.5],\n       [79.3, 84.4],\n       [78.2, 83. ],\n       [72.7, 77.9],\n       [66. , 74.2],\n       [59.2, 70.2]])Highest Low(Month, variable)float6463.5 75.9 70.0 ... 80.0 70.5 79.6array([[63.5, 75.9],\n       [70. , 73.4],\n       [72. , 75.4],\n       [72.6, 81.1],\n       [77.1, 80.4],\n       [80.8, 85.2],\n       [82.3, 87.2],\n       [83.6, 87.2],\n       [79.8, 87.1],\n       [77.8, 83.4],\n       [74.4, 80. ],\n       [70.5, 79.6]])Highest Low Year(Month, variable)int642013 2017 2018 ... 2016 2015 2016array([[2013, 2017],\n       [2018, 2023],\n       [1997, 1997],\n       [2015, 2020],\n       [2003, 1994],\n       [2004, 2004],\n       [2022, 2023],\n       [2022, 2021],\n       [2009, 2021],\n       [1995, 2021],\n       [2020, 2016],\n       [2015, 2016]])Record Low(Month, variable)float6448.3 64.0 47.9 ... 70.8 48.8 63.7array([[48.3, 64. ],\n       [47.9, 63.2],\n       [55.1, 64.8],\n       [61.2, 69.4],\n       [67.9, 74.1],\n       [75.1, 80. ],\n       [76.1, 80.9],\n       [76.1, 81. ],\n       [74.3, 79.5],\n       [64.6, 73.2],\n       [57.4, 70.8],\n       [48.8, 63.7]])Record Low Year(Month, variable)int641997 2003 1996 ... 2000 2010 2010array([[1997, 2003],\n       [1996, 2005],\n       [1996, 2010],\n       [2009, 2003],\n       [1999, 2001],\n       [1995, 1996],\n       [2013, 2013],\n       [1996, 2012],\n       [2001, 2004],\n       [2005, 2005],\n       [2006, 2000],\n       [2010, 2010]])Years(Month, variable)int6423 24 23 21 24 ... 23 23 24 24 24array([[23, 24],\n       [23, 21],\n       [24, 25],\n       [24, 25],\n       [21, 23],\n       [20, 23],\n       [25, 25],\n       [24, 25],\n       [24, 24],\n       [23, 23],\n       [23, 24],\n       [24, 24]])Indexes: (2)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))MonthPandasIndexPandasIndex(Index(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct',\n       'Nov', 'Dec'],\n      dtype='object', name='Month'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\n\nmonthly_records.coords['variable']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'variable' (variable: 2)&gt; Size: 16B\narray(['Air Temperature', 'Water Temperature'], dtype=object)\nCoordinates:\n  * variable  (variable) object 16B 'Air Temperature' 'Water Temperature'xarray.DataArray'variable'variable: 2'Air Temperature' 'Water Temperature'array(['Air Temperature', 'Water Temperature'], dtype=object)Coordinates: (1)variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Indexes: (1)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))Attributes: (0)\n\n\nWe can still choose one environmental variable at a time, but now we get all of the records and corresponding years:\n\nmonthly_records.sel(variable='Air Temperature').to_dataframe().drop('variable', axis=1)\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan\n68.7\n72.6\n2013\n63.0\n2001\n76.0\n73.0\n2011\n78.0\n2015\n55.6\n63.5\n2013\n48.3\n1997\n23\n\n\nFeb\n70.8\n74.9\n2018\n65.5\n1996\n76.5\n74.2\n2000\n78.6\n2021\n59.4\n70.0\n2018\n47.9\n1996\n23\n\n\nMar\n72.3\n77.6\n2003\n66.1\n2010\n78.5\n74.2\n2010\n82.8\n2003\n63.3\n72.0\n1997\n55.1\n1996\n24\n\n\nApr\n75.6\n79.4\n2020\n72.8\n2004\n80.8\n77.3\n2004\n85.8\n2020\n68.3\n72.6\n2015\n61.2\n2009\n24\n\n\nMay\n78.7\n80.7\n1995\n77.0\n2013\n82.5\n80.8\n2014\n85.2\n1995\n73.8\n77.1\n2003\n67.9\n1999\n21\n\n\nJun\n81.5\n83.6\n2010\n79.8\n2014\n84.8\n82.8\n2014\n87.6\n2009\n77.6\n80.8\n2004\n75.1\n1995\n20\n\n\nJul\n82.9\n85.0\n2023\n81.0\n2013\n85.8\n84.2\n2012\n88.7\n2018\n79.0\n82.3\n2022\n76.1\n2013\n25\n\n\nAug\n83.2\n85.9\n2022\n81.8\n1994\n85.7\n84.0\n2003\n88.5\n2022\n79.3\n83.6\n2022\n76.1\n1996\n24\n\n\nSep\n82.0\n82.7\n2017\n80.6\n2001\n85.1\n83.9\n2000\n86.7\n2021\n78.2\n79.8\n2009\n74.3\n2001\n24\n\n\nOct\n79.6\n81.2\n2020\n77.5\n2000\n83.8\n81.0\n2010\n86.8\n2023\n72.7\n77.8\n1995\n64.6\n2005\n23\n\n\nNov\n75.0\n78.6\n2015\n71.4\n2012\n79.7\n76.9\n2012\n82.0\n2020\n66.0\n74.4\n2020\n57.4\n2006\n23\n\n\nDec\n71.4\n76.9\n2015\n62.1\n2010\n77.5\n72.5\n2010\n79.6\n1994\n59.2\n70.5\n2015\n48.8\n2010\n24\n\n\n\n\n\n\n\nFinally, write these to file for safe keeping.\n\ndaily_records.to_netcdf(os.path.join(outdir, 'statistics-daily.nc'), mode='w')\nmonthly_records.to_netcdf(os.path.join(outdir, 'statistics-monthly.nc'), mode='w')\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 96 from PyObject\n\n\nWe will plot these results in Part 3, NOAA-CO-OPS-plots.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Overview",
      "Demonstrations",
      "Data Cleansing and Records Calculations"
    ]
  },
  {
    "objectID": "content/demos/index.html",
    "href": "content/demos/index.html",
    "title": "Demonstrations",
    "section": "",
    "text": "The following notebooks demonstrate the code behind the dashboards. There are three steps:\n\nDownload the data\nCalculate the statistics and determine the records\nPlot and display the results\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "About",
      "Demonstrations"
    ]
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Overview",
    "section": "",
    "text": "This site contains daily and monthly atmopsheric and oceanographic climatologies – highs, lows, and averages – derived from NOAA CO-OPS weather and tide observational data. This project is inspired by Brian McNoldy at the University of Miami, whose long-standing “Climatology of Virginia Key, FL” site never ceased to provide insightful weather perpectives during my time at the Rosenstiel School of Marine, Atmospheric, and Earth Science.\nClimatology dashboards are provided here for a number of locations along the east coast to which I have some degree of connection. Some are updated more regularly than others. A list of the available sites can be found on the landing page. The pages that follow describe the data and the methodology used to derive these statistics. Use the buttons at the bottom of the page to learn more.\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Overview"
    ]
  },
  {
    "objectID": "content/stations/index.html",
    "href": "content/stations/index.html",
    "title": "Active Stations",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Home",
      "Overview",
      "Active Stations"
    ]
  },
  {
    "objectID": "content/archived/index.html",
    "href": "content/archived/index.html",
    "title": "Archived Stations",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Home",
      "About",
      "Archived Stations"
    ]
  },
  {
    "objectID": "content/about.html#daily-climatologies",
    "href": "content/about.html#daily-climatologies",
    "title": "How are these statistics calculated?",
    "section": "Daily Climatologies",
    "text": "Daily Climatologies\nDaily climatologies are calculated for each day-of-year (DOY), where January 1 is Day 1, January 2 is Day 2,…, December 31 is Day 366. Instead of eliminating February 29 (Day 60) on leap years, we simply skip Day 60 in years that are not leap years by adding 1 to the DOY of every day after February 28. Days start at midnight (00:00) and go until 23:59 (11:59 PM) local time.\n\nDaily High\nThis is the maximum temperature recorded on any given day. It is determined for every day in the time series.\nLet \\(X\\) be a 24-hr time series of some environmental variable (e.g., air temperature) sampled \\(n\\) times during the day:\n\\[X = \\{x_1, x_2,...,x_n\\}\\]\nThe daily high is the maximum value in this observation set:\n\\[\\text{daily high} = \\max(X) \\tag{1}\\]\n\n\nDaily Low\nThis is the minimum temperature recorded on any given day. It is determined for every day in the time series.\nThe daily low is the minimum value in this observation set:\n\\[\\text{daily low} = \\min(X) \\tag{2}\\]\n\n\nDaily Average\nThe daily average is the average of all recorded observations of a given variable on any given day. It is determined for every day in the time series. The daily average can be calculated in one of two ways:\n\nMethod 1: True average\nThis is the conventional method of calculating an average where one sums up all observations during the 24-hour period and divides by the number of observations:\n\\[\\text{true daily average} = \\frac{1}{n} \\sum_{i=1}^n X_i \\tag{3}\\]\n\n\nMethod 2: Meteorological average\nThe meteorological average is customarily calculated using only the maximum and minimum values recorded during a 24-hour period:\n\\[\\text{meteorological daily average} = \\frac{\\max(X) + \\min(X)}{2} \\tag{4}\\]\nThis project uses the true average (Equation 3) for all calculations.\n\n\n\nDOY Daily Average\nThe Day of Year (DOY) daily average is the average of all daily averages for any given DOY. It is calculated by taking the daily averages calculated using Equation 3, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{A}\\) be a matrix of daily averages from Equation 3 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{A} = (a_{yd}) = \\left( \\begin{array}{cccc}\na_{1,1} & a_{1,2} & ... & a_{1,d} \\\\\na_{2,1} & a_{2,2} & ... & a_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\na_{y,1} & a_{y,2} & ... & a_{y,d} \\end{array} \\right) \\tag{5}\\]\nThe DOY daily average is the average over each column:\n\\[\\text{DOY daily average} = \\frac{1}{Y}\\sum_{y=1}^Y a_{yd} \\tag{6}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nNote: The Daily Average reported in the statistics dashboard are DOY daily averages.\n\n\nRecord High Daily Average\nThe record high daily average is the maximum daily average for any given DOY. It is determined by taking the daily averages calculated using Equation 3, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record high daily average} = {\\max}_d |a_{yd}| = \\max\\{|a_{yd}|: d=1,2,...,366\\} \\tag{7}\\]\n\n\nRecord Low Daily Average\nThe record low daily average is the minimum daily average for any given DOY. It is determined by taking the daily averages calculated using Equation 3, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record low daily average} = {\\min}_d |a_{yd}| = \\min\\{|a_{yd}|: d=1,2,...,366\\} \\tag{8}\\]\n\n\nAverage High\nThe average high is the average of all daily highs for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{H}\\) be a matrix of daily highs from Equation 1 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{H} = (h_{yd}) = \\left( \\begin{array}{cccc}\nh_{1,1} & h_{1,2} & ... & h_{1,d} \\\\\nh_{2,1} & h_{2,2} & ... & h_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nh_{y,1} & h_{y,2} & ... & h_{y,d} \\end{array} \\right) \\tag{9}\\]\nThe average high is the average over each column:\n\\[\\text{average high} = \\frac{1}{Y}\\sum_{y=1}^Y h_{yd} \\tag{10}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nRecord High\nThe record high is the maximum daily high for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{record high} = {\\max}_d |h_{yd}| = \\max\\{|h_{yd}|: d=1,2,...,366\\} \\tag{11}\\]\n\n\nLowest High\nThe lowest high is the minimum daily high for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{lowest high} = {\\min}_d |h_{yd}| = \\min\\{|h_{yd}|: d=1,2,...,366\\} \\tag{12}\\]\n\n\nAverage Low\nThe average low is the average of all daily lows for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{L}\\) be a matrix of daily lows from Equation 2 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{L} = (l_{yd}) = \\left( \\begin{array}{cccc}\nl_{1,1} & l_{1,2} & ... & l_{1,d} \\\\\nl_{2,1} & l_{2,2} & ... & l_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nl_{y,1} & l_{y,2} & ... & l_{y,d} \\end{array} \\right) \\tag{13}\\]\nThe average low is the average over each column:\n\\[\\text{average low} = \\frac{1}{Y}\\sum_{y=1}^Y l_{yd} \\tag{14}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nHighest Low\nThe highest low is the maximum daily low for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{highest low} = {\\max}_d |l_{yd}| = \\max\\{|l_{yd}|: d=1,2,...,366\\} \\tag{15}\\]\n\n\nRecord Low\nThe record low is the minimum daily low for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{record low} = {\\min}_d |l_{yd}| = \\min\\{|l_{yd}|: d=1,2,...,366\\} \\tag{16}\\]",
    "crumbs": [
      "Home",
      "Overview",
      "How are these statistics calculated?"
    ]
  },
  {
    "objectID": "content/about.html#monthly-climatologies",
    "href": "content/about.html#monthly-climatologies",
    "title": "How are these statistics calculated?",
    "section": "Monthly Climatologies",
    "text": "Monthly Climatologies\n\nMonthly Average\n\n\nRecord High Monthly Average\n\n\nRecord Low Monthly Average\n\n\nAverage High\n\n\nRecord High\n\n\nLowest High\n\n\nAverage Low\n\n\nHighest Low\n\n\nRecord Low",
    "crumbs": [
      "Home",
      "Overview",
      "How are these statistics calculated?"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "How are these statistics calculated?",
    "section": "",
    "text": "All data from the beginning of each time series to the present are retrieved from the NOAA CO-OPS Tides and Currents data portal using a noaa-coops utility and saved to file to avoid having to repeatedly re-download the historical data. Subsequent data updates retrieve from the most recently saved timestamp onward and append these new data to the saved historical record.\nSix-minute data are used whenever possible and hourly data otherwise.\nAny observations flagged by NOAA as being suspect for any reason (flag &gt; 0) are discarded. Examples of flagged data are a minimum or maximum value or a rate of change exceeding an acceptable tolerance. A day is allowed to have up to three hours of missing data to be counted in the daily climatologies, and a month is allowed up to two days of missing data to be counted in the monthly climatologies. Climatological statistics are calculated as follows.",
    "crumbs": [
      "Home",
      "How are these statistics calculated?"
    ]
  },
  {
    "objectID": "about.html#daily-climatologies",
    "href": "about.html#daily-climatologies",
    "title": "How are these statistics calculated?",
    "section": "Daily Climatologies",
    "text": "Daily Climatologies\nDaily climatologies are calculated for each day-of-year (DOY), where January 1 is Day 1, January 2 is Day 2,…, December 31 is Day 366. Instead of eliminating February 29 (Day 60) on leap years, we simply skip Day 60 in years that are not leap years by adding 1 to the DOY of every day after February 28. Days start at midnight (00:00) and go until 23:59 (11:59 PM) local time.\n\nDaily High\nThis is the maximum temperature recorded on any given day. It is determined for every day in the time series.\nLet \\(X\\) be a 24-hr time series of some environmental variable (e.g., air temperature) sampled \\(n\\) times during the day:\n\\[X = \\{x_1, x_2,...,x_n\\}\\]\nThe daily high is the maximum value in this observation set:\n\\[\\text{daily high} = \\max(X) \\tag{1}\\]\n\n\nDaily Low\nThis is the minimum temperature recorded on any given day. It is determined for every day in the time series.\nThe daily low is the minimum value in this observation set:\n\\[\\text{daily low} = \\min(X) \\tag{2}\\]\n\n\nDaily Average\nThe daily average is the average of all recorded observations of a given variable on any given day. It is determined for every day in the time series. The daily average can be calculated in one of two ways:\n\nMethod 1: True average\nThis is the conventional method of calculating an average where one sums up all observations during the 24-hour period and divides by the number of observations:\n\\[\\text{true daily average} = \\frac{1}{n} \\sum_{i=1}^n X_i \\tag{3}\\]\n\n\nMethod 2: Meteorological average\nThe meteorological average is customarily calculated using only the maximum and minimum values recorded during a 24-hour period:\n\\[\\text{meteorological daily average} = \\frac{\\max(X) + \\min(X)}{2} \\tag{4}\\]\nThis project uses the true average (Equation 3) for all calculations.\n\n\n\nDOY Daily Average\nThe Day of Year (DOY) daily average is the average of all daily averages for any given DOY. It is calculated by taking the daily averages calculated using Equation 3, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{A}\\) be a matrix of daily averages from Equation 3 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{A} = (a_{yd}) = \\left( \\begin{array}{cccc}\na_{1,1} & a_{1,2} & ... & a_{1,d} \\\\\na_{2,1} & a_{2,2} & ... & a_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\na_{y,1} & a_{y,2} & ... & a_{y,d} \\end{array} \\right) \\tag{5}\\]\nThe DOY daily average is the average over each column:\n\\[\\text{DOY daily average} = \\frac{1}{Y}\\sum_{y=1}^Y a_{yd} \\tag{6}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nNote: The Daily Average reported in the statistics dashboard are DOY daily averages.\n\n\nRecord High Daily Average\nThe record high daily average is the maximum daily average for any given DOY. It is determined by taking the daily averages calculated using Equation 3, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record high daily average} = {\\max}_d |a_{yd}| = \\max\\{|a_{yd}|: d=1,2,...,366\\} \\tag{7}\\]\n\n\nRecord Low Daily Average\nThe record low daily average is the minimum daily average for any given DOY. It is determined by taking the daily averages calculated using Equation 3, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record low daily average} = {\\min}_d |a_{yd}| = \\min\\{|a_{yd}|: d=1,2,...,366\\} \\tag{8}\\]\n\n\nAverage High\nThe average high is the average of all daily highs for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{H}\\) be a matrix of daily highs from Equation 1 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{H} = (h_{yd}) = \\left( \\begin{array}{cccc}\nh_{1,1} & h_{1,2} & ... & h_{1,d} \\\\\nh_{2,1} & h_{2,2} & ... & h_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nh_{y,1} & h_{y,2} & ... & h_{y,d} \\end{array} \\right) \\tag{9}\\]\nThe average high is the average over each column:\n\\[\\text{average high} = \\frac{1}{Y}\\sum_{y=1}^Y h_{yd} \\tag{10}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nRecord High\nThe record high is the maximum daily high for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{record high} = {\\max}_d |h_{yd}| = \\max\\{|h_{yd}|: d=1,2,...,366\\} \\tag{11}\\]\n\n\nLowest High\nThe lowest high is the minimum daily high for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{lowest high} = {\\min}_d |h_{yd}| = \\min\\{|h_{yd}|: d=1,2,...,366\\} \\tag{12}\\]\n\n\nAverage Low\nThe average low is the average of all daily lows for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{L}\\) be a matrix of daily lows from Equation 2 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{L} = (l_{yd}) = \\left( \\begin{array}{cccc}\nl_{1,1} & l_{1,2} & ... & l_{1,d} \\\\\nl_{2,1} & l_{2,2} & ... & l_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nl_{y,1} & l_{y,2} & ... & l_{y,d} \\end{array} \\right) \\tag{13}\\]\nThe average low is the average over each column:\n\\[\\text{average low} = \\frac{1}{Y}\\sum_{y=1}^Y l_{yd} \\tag{14}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nHighest Low\nThe highest low is the maximum daily low for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{highest low} = {\\max}_d |l_{yd}| = \\max\\{|l_{yd}|: d=1,2,...,366\\} \\tag{15}\\]\n\n\nRecord Low\nThe record low is the minimum daily low for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{record low} = {\\min}_d |l_{yd}| = \\min\\{|l_{yd}|: d=1,2,...,366\\} \\tag{16}\\]",
    "crumbs": [
      "Home",
      "How are these statistics calculated?"
    ]
  },
  {
    "objectID": "about.html#monthly-climatologies",
    "href": "about.html#monthly-climatologies",
    "title": "How are these statistics calculated?",
    "section": "Monthly Climatologies",
    "text": "Monthly Climatologies\n\nMonthly Average\n\n\nRecord High Monthly Average\n\n\nRecord Low Monthly Average\n\n\nAverage High\n\n\nRecord High\n\n\nLowest High\n\n\nAverage Low\n\n\nHighest Low\n\n\nRecord Low",
    "crumbs": [
      "Home",
      "How are these statistics calculated?"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "What are these data?",
    "section": "",
    "text": "The National Oceanographic and Atmospheric Administration (NOAA) National Ocean Service Center for Operational Oceanographic Products and Services (CO-OPS) operates hundreds of water level observation stations along the United States coasts and Great Lakes. This National Water Level Observation Network (NWLON), part of the Integrating Ocean Observing System (IOOS), provides the data from which official tidal predictions are generated. Most of these observation stations also observe water temperature as well as air temperature, barometric pressure, and wind. All of these data are publically available via the NOAA CO-OPS Tides and Currents data portal.\nThe historical time series vary in length among sites and environmental parameters. Water level sensors often came first, with eather stations added later. Data collected since circa 1995 are generally available in 6-minute observations; prior to that, observations are hourly. Data inventories are available for every site:\n\nBeaufort, North Carolina\nWoods Hole, Massachusetts\nNaples, Florida\nBay St. Louis, Mississippi\nVirginia Key, Florida\nLewes, Delaware\n\nWater level sensors are calibrated and the observations are verified. None of the other variables are verified and should be used with caution.\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "About the Data"
    ]
  },
  {
    "objectID": "demos/NOAA-CO-OPS-plots.html",
    "href": "demos/NOAA-CO-OPS-plots.html",
    "title": "Plotting Records",
    "section": "",
    "text": "This notebook is the last in a series of three notebooks demonstrating how daily and monthly record highs, lows, and averages are calculated from NOAA CO-OPS weather and tide station data. The notebook follows sequentially from NOAA-CO-OPS-records in which we calculated record highs, lows, and averages from observational data for a particular NOAA CO-OPS weather and tide station. Daily and monthly records were written to netCDF files. Here we visualize these records as plots and as a colored dataframe.\nIn the previous notebook we calculated several records of interest:\n\nDaily and monthly averages\nRecord high daily and monthly averages*\nRecord low daily and monthly averages*\nAverage daily and monthly high\nLowest daily and monthly high*\nRecord daily and monthly high*\nAverage daily and monthly low\nHighest daily and monthly low*\nRecord daily and monthly low*\n\nFor those records marked with an asterisk (*), we also noted the year in which that particular record was set. Now let’s return to these statistics to visualize them.\n\nPackages and configurations\nAs always, we frst import the packages we need. We will use Bokeh to make interactive plots and great_tables to display the data behind the plots in a visually appealing manner.\nTo better visualize the seasonality of daily and monthly averages, average highs, and average lows, we will fit a curve to the calculated averages and plot these curves instead of the actual values. This will be done with curve_fit from SciPy.\n\nfrom datetime import datetime as dt\nfrom scipy.optimize import curve_fit\nfrom great_tables import GT, loc, style\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nimport bokeh.models as bm\nimport pandas as pd\nimport xarray as xr\nimport numpy as np\nimport os\noutput_notebook(hide_banner=True)\n\n\n\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes some trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nLet’s define functions to plot the daily and monthly data. These two plots will be similar in appearance but have some differences (for example, the x axis), so two separate functions will be needed.\nFirst, we’ll need some helper functions. Some of these were used previously, while others are new:\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef round_down(num, divisor):\n    \"\"\"Round num down to the nearest divisor.\n    For example, round_down(45.5, 10) will return 40.\n    \"\"\"\n    return num - (num%divisor)\n\ndef round_up(num, divisor):\n    \"\"\"Round num up to the nearest divisor.\n    For example, round_up(45.5, 10) will return 50.\n    \"\"\"\n    return num + (divisor - (num%divisor))\n\ndef cos_fit(data, plot=False):\n    \"\"\"Fit cosine curve to data\"\"\"\n    X = np.arange(0, len(data))/len(data)\n\n    # Initial parameter values\n    guess_freq = 1\n    guess_amplitude = 3*np.std(data)/(2**0.5)\n    guess_phase = 0\n    guess_offset = np.mean(data)\n    p0 = [guess_freq, guess_amplitude,\n          guess_phase, guess_offset]\n\n    # Function to fit\n    def my_cos(x, freq, amplitude, phase, offset):\n        return np.cos(x * freq + phase) * amplitude + offset\n\n    # Fit curve to data\n    fit = curve_fit(my_cos, X, data, p0=p0)\n\n    if plot:\n        fig, ax = plt.subplots(1, 1, figsize=(12,5))\n\n        ax.plot(data, label=data.name)\n        ax.plot(fit, color='red', label=f'Cosine fit')\n\n        ax.legend(loc='best')\n        plt.show()\n    else:\n        return my_cos(np.array(X), *fit[0])\n    \n\nDefining all of the colors in a dictionary will make it easier to customize everything later and will clean up the plotting codes. Below is a dictionary of three color schemes: “mg” are my chosen colors, “bm” colors are the same color scheme as Brian McNoldy’s figures on his website, and “cb” are colorblind-friendly colors.\n\n# Color dictionary\n# https://www.tutorialrepublic.com/css-reference/css-color-names.php\ncolors = dict(\n    mg=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': '#F5F5F5',\n        'Monthly Average': '#F5F5F5',\n        'Record High Daily Average': '#ff8080',\n        'Record High Daily Average Year': '#ff8080',\n        'Record High Monthly Average': '#ff8080',\n        'Record High Monthly Average Year': '#ff8080',\n        'Record Low Daily Average': '#c1d5f8',\n        'Record Low Daily Average Year': '#c1d5f8',\n        'Record Low Monthly Average': '#c1d5f8',\n        'Record Low Monthly Average Year': '#c1d5f8',\n        'Average High': '#dc8d8d',\n        'Lowest High': '#e6aeae',\n        'Lowest High Year': '#e6aeae',        \n        'Record High': '#d26c6c',\n        'Record High Year': '#d26c6c',\n        'Average Low': '#a2bff4',\n        'Highest Low': '#d1dffa',\n        'Highest Low Year': '#d1dffa',\n        'Record Low': '#74a0ef',\n        'Record Low Year': '#74a0ef',\n        'Years': 'white',\n        'Plot Light Color': '#D3D3D3'}),\n    bm=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': 'gainsboro',\n        'Monthly Average': 'gainsboro',\n        'Record High Daily Average': 'mistyrose',\n        'Record High Daily Average Year': 'mistyrose',\n        'Record High Monthly Average': 'mistyrose',\n        'Record High Monthly Average Year': 'mistyrose',\n        'Record Low Daily Average': 'lavender',\n        'Record Low Daily Average Year': 'lavender',\n        'Record Low Monthly Average': 'lavender',\n        'Record Low Monthly Average Year': 'lavender',\n        'Average High': 'orangered',\n        'Lowest High': 'darkorange',\n        'Lowest High Year': 'darkorange',        \n        'Record High': 'orange',\n        'Record High Year': 'orange',\n        'Average Low': 'mediumpurple',\n        'Highest Low': 'navyblue',\n        'Highest Low Year': 'navyblue',\n        'Record Low': 'lightblue',\n        'Record Low Year': 'lightblue',\n        'Years': 'white',\n        'Plot Light Color': 'white'}),\n    cb=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': '#F5F5F5',\n        'Monthly Average': '#F5F5F5',\n        'Record High Daily Average': '#',\n        'Record High Daily Average Year': '#',\n        'Record High Monthly Average': '#',\n        'Record High Monthly Average Year': '#',\n        'Record Low Daily Average': '#',\n        'Record Low Daily Average Year': '#',\n        'Record Low Monthly Average': '#',\n        'Record Low Monthly Average Year': '#',\n        'Average High': '#dc8d8d',\n        'Lowest High': '#',\n        'Lowest High Year': '#',        \n        'Record High': '#d26c6c',\n        'Record High Year': '#d26c6c',\n        'Average Low': '#a2bff4',\n        'Highest Low': '#',\n        'Highest Low Year': '#',\n        'Record Low': '#74a0ef',\n        'Record Low Year': '#74a0ef',\n        'Years': 'white',\n        'Plot Light Color': 'white'})\n    )\n\nThe plots will be made using Bokeh for interactivity. Consequently, there are many steps involved in building and formatting the plot with the desired functionality. We will plot daily/monthly averages, average highs, and average lows as curves; record highs and record lows as points, and will highlight records set this year for emphasis. The plot will also contain a legend and a hoverbox that displays the values of each series for a given date when one hovers one’s mouse over the plot. The functions below will be used to generate daily and monthly climatology plots, and comments within the functions explain what each step does.\nNote that daily_climo also supports showing flood thresholds when used to plot water level data. THese thresholds need to be retrieved for each site and passed as a dictionary, for example:\n\nfloods = {'Major Flood Threshold': 2.5,\n          'Moderate Flood Threshold': 1.7,\n          'Minor Flood Threshold': 1.3}\n\n\ndef daily_climo(data, var, flood_thresholds=None, scheme='mg'):\n    \"\"\"Create a daily climatology plot for environmental variable 'var'\n    from 'data' using color scheme 'scheme'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        flood_threshold: dict containing flood thresholds to add to water\n            level plot\n        scheme: str specifying which color scheme to use. Options: 'mg'\n            for M. Grossi's, 'bm' for B. McNoldy's, or 'cb' to use a\n            colorblind scheme\n    \"\"\"\n\n    # Dates for x axis\n    df = data.sel(variable=var).to_dataframe().drop('variable', axis=1)\n    df['xdates'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D')\n    df['Average High Curve'] = cos_fit(df['Average High']).round(1)\n    df['Daily Average Curve'] = cos_fit(df['Daily Average']).round(1)\n    df['Average Low Curve'] = cos_fit(df['Average Low']).round(1)\n    \n    # Record this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1)[['Record High Year', 'Record Low Year']].sum().sum()\n    df['High Records'] = df['Record High'].where(df['Record High Year'] == thisYear)\n    df['Low Records'] = df['Record Low'].where(df['Record Low Year'] == thisYear)\n    source = bm.ColumnDataSource(df)\n    \n    # Create a new plot\n    ts_start = dt.strptime(data.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    ts_end = dt.strptime(data.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    p = figure(title='Daily {} records  |  {} - {}\\n'.format(var.lower(), ts_start, ts_end).upper()+\n                     'As of today, {} {} record highs/lows have been set. '.format(thisYearRecords, var.lower())+\n                     'Last year, {} records were set.'.format(lastYearRecords),\n               background_fill_color='#404040', border_fill_color='#404040',\n               width=1000, height=600, x_axis_type='datetime',\n               y_range=(round_down(df['Record Low'].min(), 10), round_up(df['Record High'].max(), 10)),\n               tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n               outline_line_color=None, sizing_mode='scale_height')\n\n    # This year record highs\n    hr = p.scatter(x='xdates', y='High Records', source=source,\n                   name=f'{thisYear} High Record', size=6, color='white')\n    # This year record lows\n    lr = p.scatter(x='xdates', y='Low Records', source=source,\n                   name=f'{thisYear} Low Record', size=6, color='white')\n    # Record highs\n    rh = p.scatter(x='xdates', y='Record High', source=source,\n                   name='Record High', size=2,\n                   color=colors[scheme]['Record High'])\n    # Average high\n    ah = p.line(x='xdates', y='Average High Curve', source=source,\n                name='Average High', width=3,\n                color=colors[scheme]['Average High'])\n    # Daily average\n    da = p.line(x='xdates', y='Daily Average Curve', source=source,\n                name='Daily Average', width=2,\n                color=colors[scheme]['Daily Average'])\n    # Average lows\n    al = p.line(x='xdates', y='Average Low Curve', source=source,\n                name='Average Low', width=3,\n                color=colors[scheme]['Average Low'])\n    # Record lows\n    rl = p.scatter(x='xdates', y='Record Low', source=source,\n                   name='Record Low', size=2,\n                   color=colors[scheme]['Record Low'],\n                   hover_fill_color='white', hover_alpha=0.5)\n\n    # Flood thresholds (water level plot only)\n    if var=='Water Level' and threshold is not None:\n        for level, threshold in flood_thresholds.items():\n            hline = Span(location=threshold, dimension='width',\n                         line_dash=[20,8], line_alpha=0.75,\n                         line_color='cadetblue', line_width=2)\n            p.renderers.extend([hline])\n            mytext = bm.Label(x=pd.to_datetime('2019-12-15'), y=threshold+0.1,\n                              text=level.upper(), text_color='cadetblue',\n                              text_font_size='8px',\n                              text_font='arial narrow')\n            p.add_layout(mytext)\n    \n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                              line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[da],\n                      formatters={'@xdates': 'datetime'})\n    hover.tooltips = \"\"\"\n        &lt;b&gt; @xdates{{%b %d}} &lt;/b&gt; &lt;br&gt;\n        Record High: @{{Record High}}{{0.0}} &lt;br&gt;\n        Average High: @{{Average High Curve}}{{0.0}} &lt;br&gt;\n        Daily Average: @{{Daily Average Curve}}{{0.0}} &lt;br&gt;\n        Average Low: @{{Average Low Curve}}{{0.0}} &lt;br&gt;\n        Record Low: @{{Record Low}}{{0.0}} &lt;br&gt;\n        {} High Record: @{{High Records}}{{0.0}} &lt;br&gt;\n        {} Low Record: @{{Low Records}}{{0.0}}\n        \"\"\".format(thisYear, thisYear)\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n\n    # x-axis\n    p.xaxis[0].formatter = bm.DatetimeTickFormatter(months=\"%b %d\")\n    p.xaxis[0].ticker.desired_num_ticks = 12\n    p.xgrid.grid_line_color = None\n    p.xaxis.axis_line_color = 'grey'\n    p.xaxis.major_tick_line_color = 'grey'\n    \n    # y-axis\n    p.yaxis.axis_label=f'{var} ({data.attrs[f\"{var} units\"]})'\n    p.yaxis.axis_label_text_color = colors[scheme]['Plot Light Color']\n    p.ygrid.grid_line_color = 'grey'\n    p.yaxis.axis_line_color = None\n    p.yaxis.major_tick_line_color = None\n    p.yaxis.minor_tick_line_color = None\n    \n    # Fonts\n    p.title.text_font = 'arial narrow'\n    p.title.text_font_size = '16px'\n    p.title.text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font = 'arial narrow'\n    p.xaxis.major_label_text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.major_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font_style = 'normal'\n    p.yaxis.major_label_text_color = colors[scheme]['Plot Light Color']    \n    p.yaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.axis_label_text_font_size = \"14px\"\n\n    # Legend\n    legend = bm.Legend(items=[\n        ('{} Record'.format(thisYear), [hr, lr]),\n        ('Record High', [rh]),\n        ('Average High', [ah]),\n        ('Daily Average', [da]),\n        ('Average Low', [al]),\n        ('Record Low', [rl])],\n                    background_fill_color='#404040', border_line_color=None,\n                    label_text_color=colors[scheme]['Plot Light Color'],\n                    location='center_right', click_policy='mute')\n    p.add_layout(legend, 'right')\n    \n    # Show the results\n    show(p)\n\ndef monthly_climo(data, var, scheme='mg'):\n    \"\"\"Create a monthly climatology plot for environmental variable 'var'\n    from 'data' using color scheme 'scheme'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        scheme: str specifying which color scheme to use. Options: 'mg'\n            for M. Grossi's, 'bm' for B. McNoldy's, or 'cb' to use a\n            colorblind scheme\n    \"\"\"\n\n    # Dates for x axis\n    df = data.sel(variable=var).to_dataframe().drop('variable', axis=1).reset_index()\n    df['Average High Curve'] = cos_fit(df['Average High']).round(1)\n    df['Monthly Average Curve'] = cos_fit(df['Monthly Average']).round(1)\n    df['Average Low Curve'] = cos_fit(df['Average Low']).round(1)\n    \n    # Record this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1)[['Record High Year', 'Record Low Year']].sum().sum()\n    df['High Records'] = df['Record High'].where(df['Record High Year'] == thisYear)\n    df['Low Records'] = df['Record Low'].where(df['Record Low Year'] == thisYear)\n    source = bm.ColumnDataSource(df)\n    \n    # Create a new plot\n    ts_start = dt.strptime(data.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    ts_end = dt.strptime(data.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    p = figure(title='Monthly {} records  |  {} - {}\\n'.format(var.lower(), ts_start, ts_end).upper()+\n                     'As of today, {} {} record highs/lows have been set. '.format(thisYearRecords, var.lower())+\n                     'Last year, {} records were set.'.format(lastYearRecords),\n               background_fill_color='#404040', border_fill_color='#404040',\n               width=1000, height=600,\n               x_range=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n               y_range=(round_down(df['Record Low'].min(), 10), round_up(df['Record High'].max(), 10)),\n               tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n               outline_line_color=None, sizing_mode='scale_height')\n\n    # This year record highs\n    hr = p.scatter(x='Month', y='High Records', source=source,\n                   name=f'{thisYear} High Record', size=6, color='white')\n    # This year record lows\n    lr = p.scatter(x='Month', y='Low Records', source=source,\n                   name=f'{thisYear} Low Record', size=6, color='white')\n    # Record highs\n    rh = p.scatter(x='Month', y='Record High', source=source,\n                   name='Record High', size=7,\n                   color=colors[scheme]['Record High'])\n    # Average high\n    ah = p.line(x='Month', y='Average High Curve', source=source,\n                name='Average High', width=4,\n                color=colors[scheme]['Average High'])\n    # Monthly average\n    ma = p.line(x='Month', y='Monthly Average Curve', source=source,\n                name='Monthly Average', width=3,\n                color=colors[scheme]['Monthly Average'])\n    # Average lows\n    al = p.line(x='Month', y='Average Low Curve', source=source,\n                name='Average Low', width=4,\n                color=colors[scheme]['Average Low'])\n    # Record lows\n    rl = p.scatter(x='Month', y='Record Low', source=source,\n                   name='Record Low', size=7,\n                   color=colors[scheme]['Record Low'],\n                   hover_fill_color='white', hover_alpha=0.5)\n    \n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                              line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[ma],\n                      formatters={'@xdates': 'datetime'})\n    hover.tooltips = \"\"\"\n        &lt;b&gt; @Month &lt;/b&gt; &lt;br&gt;\n        Record High: @{{Record High}}{{0.0}} &lt;br&gt;\n        Average High: @{{Average High Curve}}{{0.0}} &lt;br&gt;\n        Daily Average: @{{Daily Average Curve}}{{0.0}} &lt;br&gt;\n        Average Low: @{{Average Low Curve}}{{0.0}} &lt;br&gt;\n        Record Low: @{{Record Low}}{{0.0}} &lt;br&gt;\n        {} High Record: @{{High Records}}{{0.0}} &lt;br&gt;\n        {} Low Record: @{{Low Records}}{{0.0}}\n        \"\"\".format(thisYear, thisYear)\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n\n    # x-axis\n    p.xgrid.grid_line_color = None\n    p.xaxis.axis_line_color = 'grey'\n    p.xaxis.major_tick_line_color = 'grey'\n    \n    # y-axis\n    p.yaxis.axis_label=f'{var} ({data.attrs[f\"{var} units\"]})'\n    p.yaxis.axis_label_text_color = colors[scheme]['Plot Light Color']\n    p.ygrid.grid_line_color = 'grey'\n    p.yaxis.axis_line_color = None\n    p.yaxis.major_tick_line_color = None\n    p.yaxis.minor_tick_line_color = None\n    \n    # Fonts\n    p.title.text_font = 'arial narrow'\n    p.title.text_font_size = '16px'\n    p.title.text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font = 'arial narrow'\n    p.xaxis.major_label_text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.major_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font_style = 'normal'\n    p.yaxis.major_label_text_color = colors[scheme]['Plot Light Color']    \n    p.yaxis.major_label_text_font_size = \"14px\"\n    p.yaxis.axis_label_text_font_size = \"14px\"\n\n    # Legend\n    legend = bm.Legend(items=[\n        ('{} Record'.format(thisYear), [hr, lr]),\n        ('Record High', [rh]),\n        ('Average High', [ah]),\n        ('Monthly Average', [ma]),\n        ('Average Low', [al]),\n        ('Record Low', [rl])],\n                    background_fill_color='#404040', border_line_color=None,\n                    label_text_color=colors[scheme]['Plot Light Color'],\n                    location='center_right', click_policy='mute')\n    p.add_layout(legend, 'right')\n    \n    # Show the results\n    show(p)\n\n\n\nLoading data\nNow we need to load in the records for the desired station, which will be used to determine the directory from which to load the data. As before, stationname is the custom human-readable “City, ST” string for the station.\n\nstationname = 'Virginia Key, FL'\n\nDerive the local directory name containing the data from the station name. This is the same way the directory was created when the data were downloaded.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: /workspaces/climatology-quarto/virginiaKeyFl\n\n\nNext, load the data and metadata.\n\n# Records\ndays = xr.load_dataset(os.path.join(outdir, 'statistics-daily.nc'))\nmons = xr.load_dataset(os.path.join(outdir, 'statistics-monthly.nc'))\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 96 from PyObject\n\n\nAnd finally, we can make some plots. Let’s look at daily and monthly climatologies for Air Temperature.\n\nvar = 'Air Temperature'\ndaily_climo(data=days, var=var, flood_thresholds=floods, scheme='mg')\n\n\n  \n\n\n\n\n\n\nmonthly_climo(data=mons, var=var, scheme='mg')\n\n\n  \n\n\n\n\n\n\n\nData Table\nOne may wish to see the data behind these plots, or see the other records not plotted. We will use the great_table library to display colored tables. We’ll demonstrate this below for Air Temperature.\n“great_tables” displays dataframes, so we first need to extract the data from the xarray object, convert to a Pandas datarame, and reset the index.\n\nstats = mons.sel(variable=var.title()).to_dataframe().drop('variable', axis=1).reset_index()\n\n# Create the `great_tables`` object and add the columns\n# We also specify any formatting of each column here including the color using the color dictionary defined above.\ngtbl = GT(stats)\nfor column in stats.columns:\n    gtbl = gtbl.tab_style(style=[style.fill(color=colors['mg'][column]), style.text(align='center', v_align='middle')], locations=loc.body(columns=column))\n\n# Now we format the rest of the table\ngtbl = (gtbl\n.cols_align(align='center')\n.tab_style(style=[style.text(color='gainsboro', weight='bold'), style.fill(color='dimgray')], locations=loc.column_header())\n.tab_options(table_font_size='13px', table_body_hlines_color='white'))\n\ngtbl.show()\n\n\n\n\n\n\n\nMonth\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\nJan\n68.7\n72.6\n2013\n63.0\n2001\n76.0\n73.0\n2011\n78.0\n2015\n55.6\n63.5\n2013\n48.3\n1997\n23\n\n\nFeb\n70.8\n74.9\n2018\n65.5\n1996\n76.5\n74.2\n2000\n78.6\n2021\n59.4\n70.0\n2018\n47.9\n1996\n23\n\n\nMar\n72.3\n77.6\n2003\n66.1\n2010\n78.5\n74.2\n2010\n82.8\n2003\n63.3\n72.0\n1997\n55.1\n1996\n24\n\n\nApr\n75.6\n79.4\n2020\n72.8\n2004\n80.8\n77.3\n2004\n85.8\n2020\n68.3\n72.6\n2015\n61.2\n2009\n24\n\n\nMay\n78.7\n80.7\n1995\n77.0\n2013\n82.5\n80.8\n2014\n85.2\n1995\n73.8\n77.1\n2003\n67.9\n1999\n21\n\n\nJun\n81.5\n83.6\n2010\n79.8\n2014\n84.8\n82.8\n2014\n87.6\n2009\n77.6\n80.8\n2004\n75.1\n1995\n20\n\n\nJul\n82.9\n85.0\n2023\n81.0\n2013\n85.8\n84.2\n2012\n88.7\n2018\n79.0\n82.3\n2022\n76.1\n2013\n25\n\n\nAug\n83.2\n85.9\n2022\n81.8\n1994\n85.7\n84.0\n2003\n88.5\n2022\n79.3\n83.6\n2022\n76.1\n1996\n24\n\n\nSep\n82.0\n82.7\n2017\n80.6\n2001\n85.1\n83.9\n2000\n86.7\n2021\n78.2\n79.8\n2009\n74.3\n2001\n24\n\n\nOct\n79.6\n81.2\n2020\n77.5\n2000\n83.8\n81.0\n2010\n86.8\n2023\n72.7\n77.8\n1995\n64.6\n2005\n23\n\n\nNov\n75.0\n78.6\n2015\n71.4\n2012\n79.7\n76.9\n2012\n82.0\n2020\n66.0\n74.4\n2020\n57.4\n2006\n23\n\n\nDec\n71.4\n76.9\n2015\n62.1\n2010\n77.5\n72.5\n2010\n79.6\n1994\n59.2\n70.5\n2015\n48.8\n2010\n24\n\n\n\n\n\n\n        \n\n\nAnd there we have it! All of the records for each month, color coded for easier reading.\nSome concluding remarks on the choice of packages here. Another common Python library for making interactive plots is Plotly. We tried this first (see below), but encountered a known issue with rendering Plotly plots in Quarto web dashboards. In short, the first time Plotly is called in a web application, the plot renders to the proper size of the web container, but subsequent calls to Plotly (like navigating to a new tab or page) do not size figures properly. The workaround demonstrated here fixed the width rendering, but the all of the resulting plots were only half the height of the container/page. Plotly also supports displaying colored tables, but these experienced the same rendering issue with Quarto. Cue Bokeh. This library did not have the rendering problem, although the plots had slighly less interactivity than the Plotly version. Creating colored tables with Bokeh, however, turned out to be frustratingly difficult and very poorly documented. For example, Bokeh tables are colored using HTML, but there was no documentation on how to color an entire column of data. In contrast, the new library great_tables made this easy, although it too currently lacks the full interactivity that Plotly offered (e.g., sorting by column).\n\nThe following is a Plotly of the daily climatology plot above. It is basically the same but supports some behaviors that, so far, are not possible (or much harder to accomplish) with Bokeh, such as only showing records in the hoverbox on days when a record is set.\n\nimport plotly.graph_objects as go\n\n\ndef daily_climo(data, var, scheme='mg'):\n    \"\"\"Create a daily climatology plot for environmental variable 'var'\n    from 'data'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        scheme: str, either 'mg' or 'bm' specifying whether to use M. Grossi's\n            color scheme or B. McNoldy's\n        show: Bool, display the plot to screen instead of saving to file\n    \"\"\"\n\n    # Dates for x axis\n    xdates = pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D')\n    df = data.sel(variable=var)\n    \n    # Color dictionary\n    colors = dict(\n        mg=dict({\n            'Record High Year': 'white',\n            'Record High': '#d26c6c',\n            'Average High': '#dc8d8d',\n            'Daily Average': '#F5F5F5',\n            'Average Low': '#a2bff4',\n            'Record Low': '#74a0ef',\n            'Record Low Year': 'white'}),\n        bm=dict({\n            'Record High Year': 'white',\n            'Record High': 'orange',\n            'Average High': 'red',\n            'Daily Average': 'grey',\n            'Average Low': 'purple',\n            'Record Low': 'white'}        \n        ))\n    \n    # Create figure\n    fig = go.Figure()\n\n    # Record highs\n    # High records this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear).to_dataframe().drop('variable', axis=1)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1).to_dataframe().drop('variable', axis=1)[['Record High Year', 'Record Low Year']].sum().sum()\n    highRecords = df['Record High'].where(df['Record High Year'] == thisYear).to_dataframe()['Record High']\n    highRecords.index = pd.to_datetime(highRecords.index+'-2020')\n    lowRecords = df['Record Low'].where(df['Record Low Year'] == thisYear).to_dataframe()['Record Low']\n    lowRecords.index = pd.to_datetime(lowRecords.index+'-2020')\n    \n    first_time = dt.strptime(df.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    last_time = dt.strptime(df.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    fig.add_trace(\n    go.Scatter(\n        x=highRecords.index, y=highRecords.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=6, color='white'),\n        hovertext=[f'{thisYear} Record: {i}' if not pd.isnull(i) else '' for i in highRecords.values],\n        hoverinfo='text'\n    ))\n    fig.add_trace(\n    go.Scatter(\n        x=lowRecords.index, y=lowRecords.values,\n        name='Low Record',\n        mode='markers',\n        marker=dict(size=6, color='white'),\n        hoverinfo='none'\n    ))\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=df['Record High'],\n        name='Record High'.upper(),\n        mode='markers',\n        marker=dict(size=3, color=colors[scheme]['Record High'])\n    ))\n    # Average highs\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=cos_fit(df['Average High']).round(1),\n        name='Average High'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Average High'])\n    ))\n    # Daily average\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=cos_fit(df['Daily Average']).round(1),\n        name='Daily Average'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Daily Average'])\n    ))\n    # Average lows\n    fig.add_trace(\n    go.Scatter(\n        x=xdates,\n        y=cos_fit(df['Average Low']).round(1),\n        name='Average Low'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Average Low'])\n    ))\n    # Record lows\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=df['Record Low'],\n        name='Record Low'.upper(),\n        mode='markers',\n        marker=dict(size=3, color=colors[scheme]['Record Low'])\n    ))\n    # Hover box\n    fig.update_traces(\n        hoverlabel = dict(bordercolor='white')\n    )\n    # Plot settings\n    fig.update_layout(\n        template='plotly_dark',\n        paper_bgcolor='#404040',\n        plot_bgcolor='#404040',\n        height=600, width=1000,\n        title=dict(text='Daily {} records'.format(var.lower())+\n                        '&lt;br&gt;&lt;sup&gt;{}-{}&lt;/sup&gt;'.format(first_time, last_time)+\n                        '&lt;br&gt;&lt;sup&gt;As of today, &lt;b&gt;{}&lt;/b&gt; {} record highs/lows have been set. Last year, {} records were set.&lt;/sup&gt;'.format(\n                            thisYearRecords, var.lower(), lastYearRecords\n                        ),\n                  font=dict(size=20)),\n        yaxis = dict(title=f'{var} ({data.attrs[f\"{var} units\"]})',\n                     showgrid=True, gridcolor='grey'),\n        xaxis = dict(showgrid=False, showspikes=True,\n                     dtick='M1', tickformat='%b %d'),\n        hovermode='x unified',\n        legend=dict(itemsizing='constant'),\n        hoverlabel=dict(font_size=12)\n    )\n    for trace in fig['data']: \n        if trace['name'] == 'Low Record':\n            trace['showlegend'] = False\n    fig.show()\n\n\ndaily_climo(days, 'Air Temperature', scheme='mg')\n\n                                                \n\n\nThat concludes this climatology demonstration series.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Demonstration",
      "Plotting Records"
    ]
  },
  {
    "objectID": "demos/NOAA-CO-OPS-data.html",
    "href": "demos/NOAA-CO-OPS-data.html",
    "title": "Downloading NOAA CO-OPS Data",
    "section": "",
    "text": "In this notebook, we will download atmospheric and water observations from the National Oceanic and Atmospheric Administration (NOAA) Center for Operational Oceanographic Products and Services (CO-OPS) data portal. The objective is to replicate the Climatology for Virginia Key, FL page created and maintained by Brian McNoldy at the University of Miami Rosenstiel School of Marine, Atmospheric, and Earth Science.\nFor sake of demonstration, we will focus on air and water temperature from Virginia Key, FL. Ultimately, however, there are several variables of interest:\n\nAir temperature\nBarometric pressure\nWater temperature\nWater level (i.e., tides)\nWind speed\n\nThis notebook will simply download the data, store the metadata, and write these to file. The second notebook, NOAA-CO-OPS-records, will filter these data and calculate a set of statistics and records. Part 3, NOAA-CO-OPS-plots, will plot and display the data.\n\nPackages and configurations\nFirst we import the packages we need.\n\nfrom noaa_coops import Station\nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nimport yaml\nimport os\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes soem trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.n\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nNext, we define a number of functions that will come in handy later.\n\nHelper functions\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef get_units(variable, unit_system):\n    \"\"\"Return the desired units for 'variable'\"\"\"\n    unit_options = dict({\n        'Air Temperature': {'metric': 'C', 'english': 'F'},\n        'Barometric Pressure': {'metric': 'mb', 'english': 'mb'},\n        'Wind Speed': {'metric': 'm/s', 'english': 'kn'},\n        'Wind Gust': {'metric': 'm/s', 'english': 'kn'},\n        'Wind Direction': {'metric': 'deg', 'english': 'deg'},\n        'Water Temperature': {'metric': 'C', 'english': 'F'},\n        'Water Level': {'metric': 'm', 'english': 'ft'}\n    })\n    return unit_options[variable][unit_system]\n\ndef format_date(datestr):\n    \"\"\"Format date strings into YYYYMMDD format\"\"\"\n    dtdt = pd.to_datetime(datestr)\n    return dt.datetime.strftime(dtdt, '%Y%m%d')\n\n\n\nDownloading data\n\ndef load_atemp(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download air temperature data from NOAA CO-OPS between 'start_date'\n    and 'end_date' for 'stationid', 'unit_system', and timezone 'tz'\n    provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving air temperature data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Air Temperature']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    air_temp = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='air_temperature',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    air_temp.columns = ['atemp', 'atemp_flag']\n    return air_temp\n\ndef load_wind(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download wind data from NOAA CO-OPS between 'start_date' and\n    'end_date' for 'stationid', 'unit_system', and timezone 'tz' provided\n    in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving wind data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Wind']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    wind = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='wind',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    wind.columns = ['windspeed', 'winddir_deg', 'winddir',\n                    'windgust', 'wind_flag']\n    return wind\n\ndef load_atm_pres(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download barometric pressure data from NOAA CO-OPS between\n    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n    timezone 'tz' provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving barometric pressure data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Barometric Pressure']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    pressure = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='air_pressure',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    pressure.columns = ['apres', 'apres_flag']\n    return pressure\n\ndef load_water_temp(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download water temperature data from NOAA CO-OPS between\n    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n    timezone 'tz' provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving water temperature data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Water Temperature']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    water_temp = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='water_temperature',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    water_temp.columns = ['wtemp', 'wtemp_flag']\n    return water_temp\n\ndef load_water_level(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download water level data from NOAA CO-OPS between 'start_date' and\n    'end_date' for 'stationid', 'unit_system', 'datum', and timezone 'tz'\n    provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving water level tide data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Verified 6-Minute Water Level']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    water_levels = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='water_level',\n        datum=metadata['datum'],\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    water_levels.columns = ['wlevel', 's', 'wlevel_flag', 'wlevel_qc']\n    return water_levels\n\ndef download_data(metadata, start_date=None, end_date=None, verbose=True):\n    \"\"\"Download data from NOAA CO-OPS\"\"\"\n    # List of data variables to combine at the end\n    datasets = []\n            \n    # If no 'end_date' is passed, download through end of current date\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    \n    # Air temperature\n    if 'Air Temperature' in metadata['variables']:\n        air_temp = load_atemp(metadata=metadata, start_date=start_date,\n                              end_date=end_date, verbose=verbose)\n        air_temp['atemp_flag'] = air_temp['atemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        air_temp.loc[air_temp['atemp_flag'] &gt; 0, 'atemp'] = np.nan\n        datasets.append(air_temp['atemp'])\n\n    # Barometric pressure\n    if 'Barometric Pressure' in metadata['variables']:\n        pressure = load_atm_pres(metadata=metadata, start_date=start_date,\n                                 end_date=end_date, verbose=verbose)\n        pressure['apres_flag'] = pressure['apres_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        pressure.loc[pressure['apres_flag'] &gt; 0, 'apres'] = np.nan\n        datasets.append(pressure['apres'])\n\n    # Wind\n    if 'Wind Speed' in metadata['variables']:\n        metadata['variables'].extend(['Wind Gust'])\n        wind = load_wind(metadata=metadata, start_date=start_date,\n                         end_date=end_date, verbose=verbose)\n        wind['windflag'] = wind['wind_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        wind.loc[wind['wind_flag'] &gt; 0, ['windspeed', 'windgust']] = np.nan\n        datasets.append(wind[['windspeed', 'windgust']])\n\n    # Water temperature\n    if 'Water Temperature' in metadata['variables']:\n        water_temp = load_water_temp(metadata=metadata, start_date=start_date,\n                                     end_date=end_date, verbose=verbose)\n        water_temp['wtemp_flag'] = water_temp['wtemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        water_temp.loc[water_temp['wtemp_flag'] &gt; 0, 'wtemp'] = np.nan\n        datasets.append(water_temp['wtemp'])\n\n    # Water level (tides)\n    if 'Verified 6-Minute Water Level' in metadata['variables']:\n        water_levels = load_water_level(metadata=metadata, start_date=start_date,\n                                        end_date=end_date, verbose=verbose)\n        water_levels['wlevel_flag'] = water_levels['wlevel_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        water_levels.loc[water_levels['wlevel_flag'] &gt; 0, 'wlevel'] = np.nan\n        datasets.append(water_levels['wlevel'])\n\n    # Merge into single dataframe and rename columns\n    newdata = pd.concat(datasets, axis=1)\n    newdata.index.name = f'time_{metadata[\"tz\"]}'\n    newdata.columns = [i for i in metadata['variables']]\n    return newdata\n\n\n\n\nLoad / download data\nNow it’s time to load the data. First, specify the station we want to load. This will be used to load saved data or download all data from a new station, if we have not yet retrieved data from this particular stationname.\nstationname is a custom human-readable “City, ST” string for the station, while id is the NOAA-COOPS station ID number.\n\nstationname = 'Virginia Key, FL'\nid = '8723214'\n\nDerive the directory name containing for data from the station name. This is where the data are or will be saved locally.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: /home/climatology/virginiaKeyFl\n\n\nFlag for printing statuses\n\nverbose = True\n\nLet’s see if we already have data from this station saved locally. This will be true if a directory already exists for the station.\nIf the directory outdir does not exist, then no data have been downloaded for this station, so we need to download everything through the present. This requires a few steps:\n\nCreate outdir\nLoad the configuration settings from station-init.yml. This file contains settings such as unit system, time zone, and what variables to retrieve. Using a init file like this makes it easier to keep the same settings across multiple stations. It will be read in as a Python dictionary, which we will call meta and will use to store all relevant metadata for the station.\nDownload the data and record the timestamp of the last observation in the metadata. This will be used later when updating the data.\nWrite the data and metadata to file.\n\nOn the other hand, if data already exist locally, we will load it from file and download new data we do not yet have:\n\nLoad the data and metadata from file\nRetrieve new data\nCombine new data to existing data, update the ‘last_updated’ metadata entry, and write data and metadata to file\n\nThe noaa-coops tool only accepts dates without times, so it is possible to download data we already have. We therefore have to check what we download against what we already have to avoid duplicating data.\nThe most likely (and perhaps only) scenerio is if the data we have for the most recent day is incomplete. For example, assume today is May 5, 2024 and we download data at noon. Also assume the start date is some earlier day, the last time we retrieved data, and this will be automatically determined from the metadata. Specifying an end date 2024-05-01 will retrieve all data available through noon on May 5. In this case, we do not yet have these data, so we concatenate what we do not have to what we do have. However, if we then run the download function again (say, for diagnostic purposes) with the new start date of 2024-05-01 and the end date 2024-05-01, it will again download the data through noon on May 5. But since we already have those data, we do not want to re-concatenate them.\nThis cell may take several seconds or minutes to run, depending on how much data is being downloaded.\n\nif not os.path.exists(outdir):\n    if verbose:\n        print('Creating new directory for this station.')\n    os.makedirs(outdir)\n\n    # Metadata configuration\n    with open('station-init.yml') as d:\n        meta = yaml.safe_load(d)\n    meta['units'] = {k:get_units(k, meta['unit_system']) for k in meta['variables']}\n    meta['outdir'] = outdir\n    meta['stationname'] = stationname\n    meta['stationid'] = id\n\n    # Download all data (set start and end date to None to get all data)\n    if verbose:\n        print('Downloading all data for this station.')\n    data = download_data(metadata=meta, start_date=None, end_date=None)\n    data.to_csv(os.path.join(meta['outdir'], 'observational_data_record.csv.gz'),\n                             compression='infer')\n    print(\"Updated observational data written to file \"\\\n          f\"{os.path.join(meta['outdir'], 'observational_data_record.csv')}.\")\n\n    # Save metadata\n    meta['last_updated'] = str(data.index.max())\n    if verbose:\n        print(f\"Metadata written to file {os.path.join(meta['outdir'], 'metadata.yml')}\")\n    with open(os.path.join(meta['outdir'], 'metadata.yml'), 'w') as fp:\n        yaml.dump(meta, fp)\n    \nelse:\n    # Load the metadata\n    if verbose:\n        print('Loading metadata from file')\n    with open(os.path.join(outdir, 'metadata.yml')) as m:\n        meta = yaml.safe_load(m)\n    \n    # Load the historical data\n    if verbose:\n        print('Loading data from file')\n    data = pd.read_csv(os.path.join(outdir, 'observational_data_record.csv.gz'),\n                       index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n                       compression='infer')\n\n    # Retrieve new data\n    newdata = download_data(metadata=meta, start_date=format_date(meta['last_updated']))\n    if sum(~newdata.index.isin(data.index)) == 0:\n        print('No new data available.')\n    else:\n        data = pd.concat([data,\n                          newdata[newdata.index.isin(data.index) == False]], axis=0)\n        data.to_csv(os.path.join(meta['outdir'], 'observational_data_record.csv.gz'),\n                                 compression='infer')\n        meta['last_updated'] = str(data.index.max())\n        with open(os.path.join(meta['outdir'], 'metadata.yml'), 'w') as fp:\n            yaml.dump(meta, fp)\n        print(\"Updated observational data written to file \"\\\n              f\"{os.path.join(meta['outdir'], 'observational_data_record.csv')}.\")\n\nLoading metadata from file\nLoading data from file\nRetrieving air temperature data\nRetrieving water temperature data\nNo new data available.\n\n\nCheck the data and metadata for sanity:\n\ndata\n\n\n\n\n\n\n\n\nAir Temperature\nWater Temperature\n\n\ntime_lst\n\n\n\n\n\n\n1994-01-28 00:00:00\nNaN\nNaN\n\n\n1994-01-28 00:06:00\nNaN\nNaN\n\n\n1994-01-28 00:12:00\nNaN\nNaN\n\n\n1994-01-28 00:18:00\nNaN\nNaN\n\n\n1994-01-28 00:24:00\nNaN\nNaN\n\n\n...\n...\n...\n\n\n2024-05-25 09:36:00\n83.5\n86.0\n\n\n2024-05-25 09:42:00\n83.5\n86.2\n\n\n2024-05-25 09:48:00\n83.7\n86.2\n\n\n2024-05-25 09:54:00\n83.8\n86.2\n\n\n2024-05-25 10:00:00\n83.7\n86.2\n\n\n\n\n2466580 rows × 2 columns\n\n\n\n\nmeta\n\n{'datum': 'MHHW',\n 'day_threshold': 2,\n 'hr_threshold': 3,\n 'last_updated': '2024-05-25 10:00:00',\n 'outdir': '/home/climatology/virginiaKeyFl',\n 'stationid': '8723214',\n 'stationname': 'Virginia Key, FL',\n 'tz': 'lst',\n 'unit_system': 'english',\n 'units': {'Air Temperature': 'F', 'Water Temperature': 'F'},\n 'variables': ['Air Temperature', 'Water Temperature']}\n\n\n\nlen(data.index.unique()) == data.shape[0]\n\nTrue\n\n\nThe ‘last_updated’ metadata flag matches the last observation in the data record and corresponds to the most recently available observation. Also, every observation time is unique, so there are no duplicated entries. So, everything checks out.\nIn the next part, NOAA-CO-OPS-records, we will clean filter these data and calculate statistics and records.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Behind the Scenes",
      "Downloading NOAA CO-OPS Data"
    ]
  },
  {
    "objectID": "howto.html",
    "href": "howto.html",
    "title": "Climatology",
    "section": "",
    "text": "Create local directory\nIn VS Code, install\n\nGit\nQuarto\nRemote - SSH (should also install “Remote - SSH: Editing Configuration Files” and “Remote Explorer”)\n\nCreate Containerfile (or Dockerfile)\nCreate requirements.txt\nIn VS Code:\n\nOpen the project directory: File &gt; Open Folder…\nView &gt; Command Palette… &gt; Dev Containers: Open Folder in Container &gt; select project folder &gt; select Dockerfile\n\nTHe Docker image will now be built. This may take awhile the first time.",
    "crumbs": [
      "Home",
      "Set up environment"
    ]
  },
  {
    "objectID": "howto.html#set-up-environment",
    "href": "howto.html#set-up-environment",
    "title": "Climatology",
    "section": "",
    "text": "Create local directory\nIn VS Code, install\n\nGit\nQuarto\nRemote - SSH (should also install “Remote - SSH: Editing Configuration Files” and “Remote Explorer”)\n\nCreate Containerfile (or Dockerfile)\nCreate requirements.txt\nIn VS Code:\n\nOpen the project directory: File &gt; Open Folder…\nView &gt; Command Palette… &gt; Dev Containers: Open Folder in Container &gt; select project folder &gt; select Dockerfile\n\nTHe Docker image will now be built. This may take awhile the first time.",
    "crumbs": [
      "Home",
      "Set up environment"
    ]
  },
  {
    "objectID": "demos/index.html",
    "href": "demos/index.html",
    "title": "Demonstrations",
    "section": "",
    "text": "The following notebooks demonstrate the code behind the dashboards. There are three steps:\n\nDownload the data\nCalculate the statistics and determine the records\nPlot and display the results\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Behind the Scenes"
    ]
  },
  {
    "objectID": "demos/NOAA-CO-OPS-records.html",
    "href": "demos/NOAA-CO-OPS-records.html",
    "title": "Data Cleansing and Records Calculations",
    "section": "",
    "text": "This notebook follows sequentially from NOAA-CO-OPS-data in which we downloaded the latest data for a particular NOAA CO-OPS weather and tide station. The data record and corresponding metadata were written to file. Here we use those data and calculates several daily and monthly statistics and records. This is done in two steps:\n\nFilter the data: We do not perform any quality assurance or quality control checks, but we do remove from the records any days missing a specified amount of data and any months missing a specified number of days of data.\nCalculate records:\n\nDaily and monthly averages\nRecord high daily and monthly averages*\nRecord low daily and monthly averages*\nAverage daily and monthly high\nLowest daily and monthly high*\nRecord daily and monthly high*\nAverage daily and monthly low\nHighest daily and monthly low*\nRecord daily and monthly low*\n\n\nYears are also noted for those records marked by an asterisk (*).\n\nPackages and configurations\nFirst we import the packages we need.\n\nimport pandas as pd\nimport xarray as xr\nimport calendar\nimport yaml\nimport os\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes soem trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nNext, we define a number of functions that will come in handy later.\n\nHelper functions\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef DOY(df):\n    \"\"\"Determine year day out of 366\"\"\"\n    # Day of year as integer\n    df['YearDay'] = df.index.day_of_year.astype(int)\n    # Years that are NOT leap years\n    leapInd = [not calendar.isleap(i) for i in df.index.year]\n    mask = (leapInd) & (df.index.month &gt; 2)\n    # Advance by one day everything after February 28 \n    df.loc[mask, 'YearDay'] += 1\n    return df\n\n\n\nFiltering data\n\ndef count_missing_hours(group, threshold=3):\n    \"\"\"Return True if the number of hours in a day with missing data is less\n    than or equal to 'threshold' and False otherwise.\n    \"\"\"\n    missing_hours = group.resample('1h').mean().isna().sum()\n    return missing_hours &lt;= threshold\n\ndef count_missing_days(group, threshold=2):\n    \"\"\"Return True if the number of days in a month with missing data is less\n    than or equal to 'theshold' and False otherwise. Two tests are performed:\n    missing data (NaN) and compare to the number of days in the given month.\n    \"\"\"\n    try:\n        days_in_month = pd.Period(group.index[0].strftime(format='%Y-%m-%d')).days_in_month\n        missing_days = group.resample('1D').mean().isna().sum()\n        missing_days_flag = missing_days &lt;= threshold\n        days_in_month_flag = days_in_month - group.resample('1D').mean().size &lt;= threshold\n        return min(missing_days_flag, days_in_month_flag)\n    except IndexError:\n        pass\n\ndef filter_data(data, hr_threshold=3, day_threshold=2):\n    \"\"\"Filter data to remove days with more than 'hr_threshold' missing hours\n    of data and months with more than 'day_threshold' days of missing data.\n    \"\"\"\n    # Filter out days missing more than &lt;hr_threshold&gt; hours\n    filtered = data.groupby(pd.Grouper(freq='1D')).filter(lambda x: count_missing_hours(group=x, threshold=hr_threshold))\n    # Filter out months missing more than &lt;day_threshold&gt; days\n    filtered = filtered.groupby(pd.Grouper(freq='1M')).filter(lambda x: count_missing_days(group=x, threshold=day_threshold))\n    return filtered\n\n\n\nCalculate records\n\ndef daily_highs(df):\n    \"\"\"Daily highs\"\"\"\n    return df.groupby(pd.Grouper(freq='1D')).max(numeric_only=True)\n\ndef daily_lows(df):\n    \"\"\"Daily lows\"\"\"\n    return df.groupby(pd.Grouper(freq='1D')).min(numeric_only=True)\n\ndef daily_avgs(df, decimals=1, true_average=False):\n    \"\"\"Daily averages by calendar day rounded to 'decimals'. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    if true_average:\n        results = df.groupby(pd.Grouper(freq='1D')).mean(numeric_only=True)\n    else:\n        dailyHighs = daily_highs(df)\n        dailyLows = daily_lows(df)\n        results = (dailyHighs + dailyLows) / 2\n    return results.round(decimals)\n\ndef daily_avg(df, decimals=1, true_average=False):\n    \"\"\"Daily averages rounded to 'decimals'. If 'true_average' is True, all\n    measurements from each 24-hour day will be used to calculate the daily\n    average. Otherwise, only the maximum and minimum observations are used.\n    Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    dailyAvg = dailyAvgs.groupby('YearDay').mean(numeric_only=True).round(decimals)\n    dailyAvg.index = dailyAvg.index.astype(int)\n    results = xr.DataArray(dailyAvg, dims=['yearday', 'variable'])\n    results.name = 'Daily Average'\n    return results\n\ndef monthly_highs(df, decimals=1, true_average=False):\n    \"\"\"Monthly highs rounded to 'decimals'. If 'true_average' is True, all\n    measurements from each 24-hour day will be used to calculate the daily\n    average. Otherwise, only the maximum and minimum observations are used.\n    Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=False)\n    monthHighs = dailyAvgs.groupby(pd.Grouper(freq='M')).max(numeric_only=True)\n    return monthHighs\n  \ndef monthly_lows(df, decimals=1, true_average=False):\n    \"\"\"Monthly lows rounded to 'decimals'. If 'true_average' is True, all\n    measurements from each 24-hour day will be used to calculate the daily\n    average. Otherwise, only the maximum and minimum observations are used.\n    Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthLows = dailyAvgs.groupby(pd.Grouper(freq='M')).min(numeric_only=True)\n    return monthLows\n    \ndef monthly_avg(df, decimals=1, true_average=False):\n    \"\"\"Monthly averages for variable 'var' rounded to 'decimals'. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the daily average. Otherwise, only the maximum and\n    minimum observations are used. Defaults to False (meteorological\n    standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthlyMeans = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True).round(decimals)\n    monthlyMeans.drop('YearDay', axis=1, inplace=True)\n    monthlyAvg = monthlyMeans.groupby(monthlyMeans.index.month).mean(numeric_only=True).round(decimals)\n    monthlyAvg.index = monthlyAvg.index.astype(int)\n    results = xr.DataArray(monthlyAvg, dims=['month', 'variable'])\n    results.name = 'Monthly Average'\n    return results\n\ndef record_high_daily_avg(df, decimals=1, true_average=False):\n    \"\"\"Record high daily averages rounded to 'decimals'. If 'true_average'\n    is True, all measurements from each 24-hour day will be used to\n    calculate the daily average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df=df, decimals=decimals, true_average=true_average)\n    recordHighDailyAvg = dailyAvgs.groupby('YearDay').max(numeric_only=True).round(decimals)\n    recordHighDailyAvg.index = recordHighDailyAvg.index.astype(int)\n    # Record years\n    recordHighDailyAvgYear = dailyAvgs.groupby('YearDay').apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordHighDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n    recordHighDailyAvgYear.index = recordHighDailyAvgYear.index.astype(int)\n    recordHighDailyAvgYear.columns = [i+' Year' for i in recordHighDailyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordHighDailyAvg, recordHighDailyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record High Daily Average'\n    return results\n    \ndef record_high_monthly_avg(df, decimals=1, true_average=False):\n    \"\"\"Record high monthly averages rounded to 'decimals'. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the daily average. Otherwise, only the maximum and\n    minimum observations are used. Defaults to False (meteorological\n    standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True).round(decimals)\n    monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n    recordHighMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month).max(numeric_only=True)\n    recordHighMonthlyAvg.index = recordHighMonthlyAvg.index.astype(int)\n    # Record years\n    recordHighMonthlyAvgYear = monthlyAvgs.groupby(monthlyAvgs.index.month).apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordHighMonthlyAvgYear.index = recordHighMonthlyAvgYear.index.astype(int)\n    recordHighMonthlyAvgYear.columns = [i+' Year' for i in recordHighMonthlyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordHighMonthlyAvg, recordHighMonthlyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record High Monthly Average'\n    return results\n\ndef record_low_daily_avg(df, decimals=1, true_average=False):\n    \"\"\"Record low daily averages rounded to 'decimals'.  If 'true_average'\n    True, all measurements from each 24-hour day will be used to calculate\n    the average. Otherwise, only the maximum and minimum observations are\n    used. Defaults to False (meteorological standard).\"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df=df, decimals=decimals, true_average=true_average)\n    recordLowDailyAvg = dailyAvgs.groupby('YearDay').min(numeric_only=True).round(decimals)\n    recordLowDailyAvg.index = recordLowDailyAvg.index.astype(int)\n    # Record years\n    recordLowDailyAvgYear = dailyAvgs.groupby('YearDay').apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordLowDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n    recordLowDailyAvgYear.index = recordLowDailyAvgYear.index.astype(int)\n    recordLowDailyAvgYear.columns = [i+' Year' for i in recordLowDailyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordLowDailyAvg, recordLowDailyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Low Daily Average'\n    return results\n\ndef record_low_monthly_avg(df, decimals=1, true_average=False):\n    \"\"\"Record low monthly averages rounded to 'decimals'. If 'true_average'\n    is True, all measurements from each 24-hour day will be used to\n    calculate the daily average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df, decimals=decimals, true_average=true_average)\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True).round(decimals)\n    monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n    recordLowMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month).min(numeric_only=True)\n    recordLowMonthlyAvg.index = recordLowMonthlyAvg.index.astype(int)\n    # Record years\n    recordLowMonthlyAvgYear = monthlyAvgs.groupby(monthlyAvgs.index.month).apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordLowMonthlyAvgYear.index = recordLowMonthlyAvgYear.index.astype(int)\n    recordLowMonthlyAvgYear.columns = [i+' Year' for i in recordLowMonthlyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordLowMonthlyAvg, recordLowMonthlyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Low Monthly Average'\n    return results\n\ndef avg_daily_high(df, decimals=1):\n    \"\"\"Average daily highs rounded to 'decimals'.\"\"\"        \n    dailyHighs = daily_highs(df)\n    results = dailyHighs.groupby('YearDay').mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Average Daily High'\n    return results\n\ndef avg_monthly_high(df, decimals=1, true_average=False):\n    \"\"\"Average monthly highs rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    monthlyHighs = monthly_highs(df, decimals=decimals, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    avgMonthlyHighs = monthlyHighs.groupby(monthlyHighs.index.month).mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(avgMonthlyHighs, dims=['month', 'variable'])\n    results.name = 'Average Monthly High'\n    return results\n\ndef lowest_daily_high(df, decimals=1):\n    \"\"\"Lowest daily highs rounded to 'decimals'.\"\"\"\n    # Calculate the record\n    dailyHighs = daily_highs(df)\n    lowestHigh = dailyHighs.groupby('YearDay').min(numeric_only=True).round(decimals)\n    lowestHigh.index = lowestHigh.index.astype(int)\n    # Record years\n    lowestHighYear = dailyHighs.groupby('YearDay').apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    lowestHighYear.drop('YearDay', axis=1, inplace=True)\n    lowestHighYear.index = lowestHighYear.index.astype(int)\n    lowestHighYear.columns = [i+' Year' for i in lowestHighYear.columns]\n    # Create xarray\n    results = pd.concat((lowestHigh, lowestHighYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Lowest Daily High'\n    return results\n    \ndef lowest_monthly_high(df, decimals=1, true_average=False):\n    \"\"\"Lowest monthly highs rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyHighs = monthly_highs(df, decimals=decimals, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    lowMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month).min(numeric_only=True).round(decimals)\n    lowMonthlyHigh.index = lowMonthlyHigh.index.astype(int)\n    # Record years\n    lowMonthlyHighYear = monthlyHighs.groupby(monthlyHighs.index.month).apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    lowMonthlyHighYear.index = lowMonthlyHighYear.index.astype(int)\n    lowMonthlyHighYear.columns = [i+' Year' for i in lowMonthlyHighYear.columns]\n    # Create xarray\n    results = pd.concat((lowMonthlyHigh, lowMonthlyHighYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Lowest Monthly High'\n    return results\n\ndef record_daily_high(df, decimals=1):\n    \"\"\"Record daily highs rounded to 'decimal'.\"\"\"\n    # Calculate the record\n    dailyHighs = daily_highs(df)\n    recordHigh = dailyHighs.groupby('YearDay').max(numeric_only=True).round(decimals)\n    recordHigh.index = recordHigh.index.astype(int)\n    # Record years\n    recordHighYear = dailyHighs.groupby('YearDay').apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordHighYear.drop('YearDay', axis=1, inplace=True)\n    recordHighYear.index = recordHighYear.index.astype(int)\n    recordHighYear.columns = [i+' Year' for i in recordHighYear.columns]\n    # Create xarray\n    results = pd.concat((recordHigh, recordHighYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Daily High'\n    return results\n\ndef record_monthly_high(df, decimals=1, true_average=False):\n    \"\"\"Record monthly highs rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyHighs = monthly_highs(df, decimals=decimals, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    recordMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month).max(numeric_only=True).round(decimals)\n    recordMonthlyHigh.index = recordMonthlyHigh.index.astype(int)\n    # Record years\n    recordMonthlyHighYear = monthlyHighs.groupby(monthlyHighs.index.month).apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    recordMonthlyHighYear.index = recordMonthlyHighYear.index.astype(int)\n    recordMonthlyHighYear.columns = [i+' Year' for i in recordMonthlyHighYear.columns]\n    # Create xarray\n    results = pd.concat((recordMonthlyHigh, recordMonthlyHighYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Monthly High'\n    return results\n\ndef avg_daily_low(df, decimals=1):\n    \"\"\"Average daily lows rounded to 'decimals'.\"\"\"        \n    dailyLows = daily_lows(df)\n    results = dailyLows.groupby('YearDay').mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Average Daily Low'\n    return results\n\ndef avg_monthly_low(df, decimals=1, true_average=False):\n    \"\"\"Average monthly lows rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    monthlyLows = monthly_lows(df, decimals=decimals, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    avgMonthlyLows = monthlyLows.groupby(monthlyLows.index.month).mean(numeric_only=True).round(decimals)\n    results = xr.DataArray(avgMonthlyLows, dims=['month', 'variable'])\n    results.name = 'Average Monthly Low'\n    return results\n\ndef highest_daily_low(df, decimals=1):\n    \"\"\"Highest daily lows rounded to 'decimals'.\"\"\"\n    # Calculate the record\n    dailyLows = daily_lows(df)\n    highestLow = dailyLows.groupby('YearDay').max(numeric_only=True).round(decimals)\n    highestLow.index = highestLow.index.astype(int)\n    # Record years\n    highestLowYear = dailyLows.groupby('YearDay').apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    highestLowYear.drop('YearDay', axis=1, inplace=True)\n    highestLowYear.index = highestLowYear.index.astype(int)\n    highestLowYear.columns = [i+' Year' for i in highestLowYear.columns]\n    # Create xarray\n    results = pd.concat((highestLow, highestLowYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Highest Daily Low'\n    return results\n    \ndef highest_monthly_low(df, decimals=1, true_average=False):\n    \"\"\"Highest monthly lows rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyLows = monthly_lows(df, decimals=decimals, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    highestMonthlyLow = monthlyLows.groupby(monthlyLows.index.month).max(numeric_only=True).round(decimals)\n    highestMonthlyLow.index = highestMonthlyLow.index.astype(int)\n    # Record years\n    highestMonthlyLowYear = monthlyLows.groupby(monthlyLows.index.month).apply(lambda x: x.idxmax(numeric_only=True).dt.year)\n    highestMonthlyLowYear.index = highestMonthlyLowYear.index.astype(int)\n    highestMonthlyLowYear.columns = [i+' Year' for i in highestMonthlyLowYear.columns]\n    # Create xarray\n    results = pd.concat((highestMonthlyLow, highestMonthlyLowYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Highest Monthly Low'\n    return results\n\ndef record_daily_low(df, decimals=1):\n    \"\"\"Record daily lows rounded to 'decimals'.\"\"\"\n    # Calculate the record\n    dailyLows = daily_lows(df)\n    recordLow = dailyLows.groupby('YearDay').min(numeric_only=True).round(decimals)\n    recordLow.index = recordLow.index.astype(int)\n    # Record years\n    recordLowYear = dailyLows.groupby('YearDay').apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordLowYear.drop('YearDay', axis=1, inplace=True)\n    recordLowYear.index = recordLowYear.index.astype(int)\n    recordLowYear.columns = [i+' Year' for i in recordLowYear.columns]\n    # Create xarray\n    results = pd.concat((recordLow, recordLowYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Daily Low'\n    return results\n\ndef record_monthly_low(df, decimals=1, true_average=False):\n    \"\"\"Record monthly lows rounded to 'decimals'. If 'true_average' is\n    True, all measurements from each 24-hour day will be used to calculate\n    the daily average. Otherwise, only the maximum and minimum observations\n    are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyLows = monthly_lows(df, decimals=decimals, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    recordMonthlyLow = monthlyLows.groupby(monthlyLows.index.month).min(numeric_only=True).round(decimals)\n    recordMonthlyLow.index = recordMonthlyLow.index.astype(int)\n    # Record years\n    recordMonthlyLowYear = monthlyLows.groupby(monthlyLows.index.month).apply(lambda x: x.idxmin(numeric_only=True).dt.year)\n    recordMonthlyLowYear.index = recordMonthlyLowYear.index.astype(int)\n    recordMonthlyLowYear.columns = [i+' Year' for i in recordMonthlyLowYear.columns]\n    # Create xarray\n    results = pd.concat((recordMonthlyLow, recordMonthlyLowYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Monthly Low'\n    return results\n\ndef number_of_years_byday(df):\n    \"\"\"Number of years in the historical data records by day of year.\"\"\"\n    numYears = pd.concat([df[[v, 'YearDay']].dropna().groupby('YearDay')\\\n                                        .apply(lambda x: len(x.index.year.unique())) \\\n                         for v in filtered_data.columns if v != 'YearDay'], axis=1)\n    numYears.columns = [v for v in df.columns if v != 'YearDay']\n    results = xr.DataArray(numYears, dims=['yearday', 'variable'])\n    results.name = 'Number of Years'\n    return results\n\ndef number_of_years_bymonth(df):\n    \"\"\"Number of years in the historical data records by month.\"\"\"\n    numYears = pd.concat([df[v].dropna().groupby(df[v].dropna().index.month)\\\n                                        .apply(lambda x: len(x.index.year.unique())) \\\n                         for v in filtered_data.columns if v != 'YearDay'], axis=1)\n    numYears.columns = [v for v in df.columns if v != 'YearDay']\n    results = xr.DataArray(numYears, dims=['month', 'variable'])\n    results.name = 'Number of Years'\n    return results\n\ndef generate_yeardays():\n    return pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D').strftime('%d-%b')\n\n\n\n\nData cleaning\nFirst we need to load in the data and metadata for the desired station. This will be used to determine the directory from which to load the data.\nAs before, stationname is the custom human-readable “City, ST” string for the station. Since we are not downloading data, we do not need the NOAA-COOPS station ID number.\n\nstationname = 'Virginia Key, FL'\n\nDerive the local directory name containing for data from the station name. This is the same way the directory was created when the data were downloaded.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: /home/climatology/virginiaKeyFl\n\n\nNext, load the data and metadata.\n\n# Metadata\nwith open(os.path.join(outdir, 'metadata.yml')) as m:\n    meta = yaml.safe_load(m)\n\n# Observational data\ndata = pd.read_csv(os.path.join(outdir, 'observational_data_record.csv.gz'),\n                   index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n                   compression='infer')\n\nNow we filter the data to remove days with more than 3 hours of missing data and months with more than 2 days of missing data. These thresholds are stored in meta and can easily be changed. We have to do this one variable at a time because this is sensor-dependent, so it takes a short while to run.\n\nfiltered_data = pd.concat([filter_data(data[var],\n                                       hr_threshold=meta['hr_threshold'],\n                                       day_threshold=meta['day_threshold'])\n                                       for var in meta['variables']], axis=1)\n\nConfirm that the data were filtered:\n\ndata.shape\n\n(2466580, 2)\n\n\n\nfiltered_data.shape\n\n(2174766, 2)\n\n\n\n\nCalculate records\nNow we’re ready to determine the records using all of the functions above. We’ll store these in an xarray dataset and add the appropriate metadata for convenience. But first, we need to add a day of year (DOY) column so that we can calculate daily records. We’ve used a function to do this because accounting for leap years is not trivial.\n\nfiltered_data = DOY(filtered_data)\n\n\ndaily_records = \\\n    xr.Dataset({'Daily Average': daily_avg(filtered_data),\n                'Record High Daily Average': record_high_daily_avg(filtered_data),\n                'Record Low Daily Average': record_low_daily_avg(filtered_data),\n                'Average High': avg_daily_high(filtered_data),\n                'Lowest High': lowest_daily_high(filtered_data),\n                'Record High': record_daily_high(filtered_data),\n                'Average Low': avg_daily_low(filtered_data),\n                'Highest Low': highest_daily_low(filtered_data),\n                'Record Low': record_daily_low(filtered_data),\n                'Years': number_of_years_byday(filtered_data)},\n               attrs={k:v for k, v in meta.items() if k not in ['outdir', 'variables', 'units']})\n\n\nmonthly_records = \\\n    xr.Dataset({'Monthly Average': monthly_avg(filtered_data),\n                'Record High Monthly Average': record_high_monthly_avg(filtered_data),\n                'Record Low Monthly Average': record_low_monthly_avg(filtered_data),\n                'Average High': avg_monthly_high(filtered_data),\n                'Lowest High': lowest_monthly_high(filtered_data),\n                'Record High': record_monthly_high(filtered_data),\n                'Average Low': avg_monthly_low(filtered_data),\n                'Highest Low': highest_monthly_low(filtered_data),\n                'Record Low': record_monthly_low(filtered_data),\n                'Years': number_of_years_bymonth(filtered_data)},\n               attrs={k:v for k, v in meta.items() if k not in ['outdir', 'variables', 'units']})\n\nAdd data units and time series ranges for each variable to the arrays as metadata attributes.\n\nfor k, v in meta['units'].items():\n    daily_records.attrs[k+' units'] = v\n\nfor var in daily_records.coords['variable'].values:\n    if 'Year' not in var:\n        daily_records.attrs[var+' data range'] = \\\n            (filtered_data[var].dropna().index.min().strftime('%Y-%m-%d'),\n             filtered_data[var].dropna().index.max().strftime('%Y-%m-%d'))\n\n\nfor k, v in meta['units'].items():\n    monthly_records.attrs[k+' units'] = v\n\nfor var in monthly_records.coords['variable'].values:\n    if 'Year' not in var:\n        monthly_records.attrs[var+' data range'] = \\\n            (filtered_data[var].dropna().index.min().strftime('%Y-%m-%d'),\n             filtered_data[var].dropna().index.max().strftime('%Y-%m-%d'))\n\nWhat do we have now? Let’s take a look:\n\ndaily_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 120kB\nDimensions:                    (yearday: 366, variable: 4)\nCoordinates:\n  * yearday                    (yearday) int64 3kB 1 2 3 4 5 ... 363 364 365 366\n  * variable                   (variable) object 32B 'Air Temperature' ... 'W...\nData variables:\n    Daily Average              (yearday, variable) float64 12kB 71.5 nan ... nan\n    Record High Daily Average  (yearday, variable) float64 12kB 78.0 ... 2.02...\n    Record Low Daily Average   (yearday, variable) float64 12kB 54.4 ... 2.01...\n    Average High               (yearday, variable) float64 12kB 75.0 nan ... nan\n    Lowest High                (yearday, variable) float64 12kB 63.3 ... 2.01...\n    Record High                (yearday, variable) float64 12kB 79.3 ... 2.02...\n    Average Low                (yearday, variable) float64 12kB 67.9 nan ... nan\n    Highest Low                (yearday, variable) float64 12kB 76.8 ... 2.02...\n    Record Low                 (yearday, variable) float64 12kB 45.5 ... 2.01...\n    Years                      (yearday, variable) float64 12kB 23.0 nan ... nan\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:yearday: 366variable: 4Coordinates: (2)yearday(yearday)int641 2 3 4 5 6 ... 362 363 364 365 366array([  1,   2,   3, ..., 364, 365, 366])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Data variables: (10)Daily Average(yearday, variable)float6471.5 nan 72.4 nan ... nan 72.6 nanarray([[71.5,  nan, 72.4,  nan],\n       [71.8,  nan, 72.9,  nan],\n       [70. ,  nan, 73. ,  nan],\n       ...,\n       [70.6,  nan, 72.6,  nan],\n       [69.6,  nan, 72.7,  nan],\n       [70.8,  nan, 72.6,  nan]])Record High Daily Average(yearday, variable)float6478.0 2.022e+03 ... 80.5 2.021e+03array([[  78. , 2022. ,   80.4, 2022. ],\n       [  77.8, 2022. ,   80.2, 2022. ],\n       [  78. , 2015. ,   80.7, 2017. ],\n       ...,\n       [  79.4, 2015. ,   82.6, 2016. ],\n       [  79.5, 2015. ,   81.9, 2016. ],\n       [  79.2, 2015. ,   80.5, 2021. ]])Record Low Daily Average(yearday, variable)float6454.4 2.001e+03 ... 66.1 2.01e+03array([[  54.4, 2001. ,   66.4, 2011. ],\n       [  56.6, 2010. ,   66.8, 2011. ],\n       [  51.7, 2012. ,   67.3, 2011. ],\n       ...,\n       [  58.7, 2009. ,   66.6, 1995. ],\n       [  54.8, 2000. ,   66.4, 2010. ],\n       [  49.9, 2000. ,   66.1, 2010. ]])Average High(yearday, variable)float6475.0 nan 73.7 nan ... nan 73.9 nanarray([[75. ,  nan, 73.7,  nan],\n       [75.1,  nan, 74.2,  nan],\n       [73.9,  nan, 74.3,  nan],\n       ...,\n       [74.4,  nan, 74.1,  nan],\n       [73.2,  nan, 74.1,  nan],\n       [74.3,  nan, 73.9,  nan]])Lowest High(yearday, variable)float6463.3 2.001e+03 ... 67.8 2.01e+03array([[  63.3, 2001. ,   67.8, 2011. ],\n       [  64.2, 2010. ,   68. , 2011. ],\n       [  57. , 2012. ,   68.9, 2011. ],\n       ...,\n       [  67.1, 2010. ,   69.4, 2003. ],\n       [  59.5, 2000. ,   68.4, 2010. ],\n       [  55.6, 2000. ,   67.8, 2010. ]])Record High(yearday, variable)float6479.3 2.022e+03 ... 81.7 2.021e+03array([[  79.3, 2022. ,   81.1, 2022. ],\n       [  79.3, 2022. ,   81. , 2022. ],\n       [  79.2, 2019. ,   81.5, 2017. ],\n       ...,\n       [  80.6, 2015. ,   83.3, 2016. ],\n       [  80.6, 2013. ,   83.1, 2016. ],\n       [  80.1, 2015. ,   81.7, 2021. ]])Average Low(yearday, variable)float6467.9 nan 71.1 nan ... nan 71.4 nanarray([[67.9,  nan, 71.1,  nan],\n       [68.5,  nan, 71.6,  nan],\n       [66.1,  nan, 71.7,  nan],\n       ...,\n       [66.7,  nan, 71.2,  nan],\n       [66.1,  nan, 71.4,  nan],\n       [67.3,  nan, 71.4,  nan]])Highest Low(yearday, variable)float6476.8 2.022e+03 ... 79.3 2.021e+03array([[  76.8, 2022. ,   79.7, 2022. ],\n       [  76.3, 2017. ,   79.5, 2022. ],\n       [  77. , 2015. ,   79.9, 2017. ],\n       ...,\n       [  78.3, 2015. ,   81.9, 2016. ],\n       [  78.4, 2015. ,   80.8, 2016. ],\n       [  78.3, 2015. ,   79.3, 2021. ]])Record Low(yearday, variable)float6445.5 2.001e+03 ... 64.4 2.01e+03array([[  45.5, 2001. ,   63.9, 2001. ],\n       [  49.1, 2010. ,   64.4, 2001. ],\n       [  46.4, 2012. ,   65.5, 2001. ],\n       ...,\n       [  50.1, 2009. ,   62.2, 2010. ],\n       [  50. , 2000. ,   64.4, 2010. ],\n       [  44.2, 2000. ,   64.4, 2010. ]])Years(yearday, variable)float6423.0 nan 24.0 nan ... nan 24.0 nanarray([[23., nan, 24., nan],\n       [23., nan, 24., nan],\n       [23., nan, 24., nan],\n       ...,\n       [24., nan, 24., nan],\n       [24., nan, 24., nan],\n       [23., nan, 24., nan]])Indexes: (2)yeardayPandasIndexPandasIndex(Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n            ...\n            357, 358, 359, 360, 361, 362, 363, 364, 365, 366],\n           dtype='int64', name='yearday', length=366))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4kB\nDimensions:                      (month: 12, variable: 4)\nCoordinates:\n  * month                        (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * variable                     (variable) object 32B 'Air Temperature' ... ...\nData variables:\n    Monthly Average              (month, variable) float64 384B 68.7 nan ... nan\n    Record High Monthly Average  (month, variable) float64 384B 72.6 ... 2.01...\n    Record Low Monthly Average   (month, variable) float64 384B 63.0 ... 2.01...\n    Average High                 (month, variable) float64 384B 76.0 nan ... nan\n    Lowest High                  (month, variable) float64 384B 73.0 ... 2.00...\n    Record High                  (month, variable) float64 384B 78.0 ... 2.01...\n    Average Low                  (month, variable) float64 384B 55.6 nan ... nan\n    Highest Low                  (month, variable) float64 384B 63.5 ... 2.01...\n    Record Low                   (month, variable) float64 384B 48.3 ... 2.01...\n    Years                        (month, variable) float64 384B 23.0 nan ... nan\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:month: 12variable: 4Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Data variables: (10)Monthly Average(month, variable)float6468.7 nan 71.6 nan ... nan 74.0 nanarray([[68.7,  nan, 71.6,  nan],\n       [70.8,  nan, 72.8,  nan],\n       [72.3,  nan, 75. ,  nan],\n       [75.6,  nan, 78.5,  nan],\n       [78.7,  nan, 82. ,  nan],\n       [81.5,  nan, 85.2,  nan],\n       [82.9,  nan, 87.1,  nan],\n       [83.2,  nan, 87.3,  nan],\n       [82. ,  nan, 85.7,  nan],\n       [79.6,  nan, 82.1,  nan],\n       [75. ,  nan, 77.4,  nan],\n       [71.4,  nan, 74. ,  nan]])Record High Monthly Average(month, variable)float6472.6 2.013e+03 ... 82.5 2.016e+03array([[  72.6, 2013. ,   78.9, 2017. ],\n       [  74.9, 2018. ,   76.3, 2021. ],\n       [  77.6, 2003. ,   80. , 2003. ],\n       [  79.4, 2020. ,   83.4, 2020. ],\n       [  80.7, 1995. ,   84.1, 2021. ],\n       [  83.6, 2010. ,   87.6, 2010. ],\n       [  85. , 2023. ,   89.5, 2023. ],\n       [  85.9, 2022. ,   90.1, 2021. ],\n       [  82.7, 2017. ,   89.5, 2021. ],\n       [  81.2, 2020. ,   85.9, 2021. ],\n       [  78.6, 2015. ,   81.5, 2016. ],\n       [  76.9, 2015. ,   82.5, 2016. ]])Record Low Monthly Average(month, variable)float6463.0 2.001e+03 ... 68.2 2.01e+03array([[  63. , 2001. ,   67.5, 2001. ],\n       [  65.5, 1996. ,   67.7, 2005. ],\n       [  66.1, 2010. ,   69.2, 2010. ],\n       [  72.8, 2004. ,   75.1, 2004. ],\n       [  77. , 2013. ,   78.6, 2001. ],\n       [  79.8, 2014. ,   83.3, 2002. ],\n       [  81. , 2013. ,   84.5, 2013. ],\n       [  81.8, 1994. ,   85.4, 1995. ],\n       [  80.6, 2001. ,   82.7, 2004. ],\n       [  77.5, 2000. ,   79.6, 2000. ],\n       [  71.4, 2012. ,   74.6, 2012. ],\n       [  62.1, 2010. ,   68.2, 2010. ]])Average High(month, variable)float6476.0 nan 75.4 nan ... nan 77.6 nanarray([[76. ,  nan, 75.4,  nan],\n       [76.5,  nan, 76.7,  nan],\n       [78.5,  nan, 79.2,  nan],\n       [80.8,  nan, 81.9,  nan],\n       [82.5,  nan, 85.1,  nan],\n       [84.8,  nan, 87.9,  nan],\n       [85.8,  nan, 89.1,  nan],\n       [85.7,  nan, 89.4,  nan],\n       [85.1,  nan, 88. ,  nan],\n       [83.8,  nan, 85.6,  nan],\n       [79.7,  nan, 80.6,  nan],\n       [77.5,  nan, 77.6,  nan]])Lowest High(month, variable)float6473.0 2.011e+03 ... 73.0 2.003e+03array([[  73. , 2011. ,   70.5, 2011. ],\n       [  74.2, 2000. ,   73.7, 2016. ],\n       [  74.2, 2010. ,   73.3, 2010. ],\n       [  77.3, 2004. ,   78.4, 2010. ],\n       [  80.8, 2014. ,   82.8, 2013. ],\n       [  82.8, 2014. ,   85.3, 1996. ],\n       [  84.2, 2012. ,   86.4, 2013. ],\n       [  84. , 2003. ,   87.2, 2000. ],\n       [  83.9, 2000. ,   85.2, 1997. ],\n       [  81. , 2010. ,   82.7, 2004. ],\n       [  76.9, 2012. ,   76.8, 2001. ],\n       [  72.5, 2010. ,   73. , 2003. ]])Record High(month, variable)float6478.0 2.015e+03 ... 84.6 2.016e+03array([[  78. , 2015. ,   81.7, 2017. ],\n       [  78.6, 2021. ,   81.5, 2021. ],\n       [  82.8, 2003. ,   83.2, 2021. ],\n       [  85.8, 2020. ,   85.8, 2020. ],\n       [  85.2, 1995. ,   87.7, 2021. ],\n       [  87.6, 2009. ,   90.4, 2010. ],\n       [  88.7, 2018. ,   92. , 2021. ],\n       [  88.5, 2022. ,   92.2, 2021. ],\n       [  86.7, 2021. ,   91.2, 2021. ],\n       [  86.8, 2023. ,   89. , 2016. ],\n       [  82. , 2020. ,   85. , 2020. ],\n       [  79.6, 1994. ,   84.6, 2016. ]])Average Low(month, variable)float6455.6 nan 67.6 nan ... nan 70.2 nanarray([[55.6,  nan, 67.6,  nan],\n       [59.4,  nan, 68.9,  nan],\n       [63.3,  nan, 70.9,  nan],\n       [68.3,  nan, 74.6,  nan],\n       [73.8,  nan, 78.1,  nan],\n       [77.6,  nan, 82.2,  nan],\n       [79. ,  nan, 84.5,  nan],\n       [79.3,  nan, 84.4,  nan],\n       [78.2,  nan, 83. ,  nan],\n       [72.7,  nan, 77.9,  nan],\n       [66. ,  nan, 74.2,  nan],\n       [59.2,  nan, 70.2,  nan]])Highest Low(month, variable)float6463.5 2.013e+03 ... 79.6 2.016e+03array([[  63.5, 2013. ,   75.9, 2017. ],\n       [  70. , 2018. ,   73.4, 2023. ],\n       [  72. , 1997. ,   75.4, 1997. ],\n       [  72.6, 2015. ,   81.1, 2020. ],\n       [  77.1, 2003. ,   80.4, 1994. ],\n       [  80.8, 2004. ,   85.2, 2004. ],\n       [  82.3, 2022. ,   87.2, 2023. ],\n       [  83.6, 2022. ,   87.2, 2021. ],\n       [  79.8, 2009. ,   87.1, 2021. ],\n       [  77.8, 1995. ,   83.4, 2021. ],\n       [  74.4, 2020. ,   80. , 2016. ],\n       [  70.5, 2015. ,   79.6, 2016. ]])Record Low(month, variable)float6448.3 1.997e+03 ... 63.7 2.01e+03array([[  48.3, 1997. ,   64. , 2003. ],\n       [  47.9, 1996. ,   63.2, 2005. ],\n       [  55.1, 1996. ,   64.8, 2010. ],\n       [  61.2, 2009. ,   69.4, 2003. ],\n       [  67.9, 1999. ,   74.1, 2001. ],\n       [  75.1, 1995. ,   80. , 1996. ],\n       [  76.1, 2013. ,   80.9, 2013. ],\n       [  76.1, 1996. ,   81. , 2012. ],\n       [  74.3, 2001. ,   79.5, 2004. ],\n       [  64.6, 2005. ,   73.2, 2005. ],\n       [  57.4, 2006. ,   70.8, 2000. ],\n       [  48.8, 2010. ,   63.7, 2010. ]])Years(month, variable)float6423.0 nan 24.0 nan ... nan 24.0 nanarray([[23., nan, 24., nan],\n       [23., nan, 21., nan],\n       [24., nan, 25., nan],\n       [24., nan, 25., nan],\n       [21., nan, 23., nan],\n       [20., nan, 23., nan],\n       [25., nan, 25., nan],\n       [24., nan, 25., nan],\n       [24., nan, 24., nan],\n       [23., nan, 23., nan],\n       [23., nan, 24., nan],\n       [24., nan, 24., nan]])Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\nHow are these stored? Let’s consider the monthly stats. Each statistic is its own variable within the dataset. Take Record High for example:\n\nmonthly_records['Record High']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'Record High' (month: 12, variable: 4)&gt; Size: 384B\narray([[  78. , 2015. ,   81.7, 2017. ],\n       [  78.6, 2021. ,   81.5, 2021. ],\n       [  82.8, 2003. ,   83.2, 2021. ],\n       [  85.8, 2020. ,   85.8, 2020. ],\n       [  85.2, 1995. ,   87.7, 2021. ],\n       [  87.6, 2009. ,   90.4, 2010. ],\n       [  88.7, 2018. ,   92. , 2021. ],\n       [  88.5, 2022. ,   92.2, 2021. ],\n       [  86.7, 2021. ,   91.2, 2021. ],\n       [  86.8, 2023. ,   89. , 2016. ],\n       [  82. , 2020. ,   85. , 2020. ],\n       [  79.6, 1994. ,   84.6, 2016. ]])\nCoordinates:\n  * month     (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * variable  (variable) object 32B 'Air Temperature' ... 'Water Temperature ...xarray.DataArray'Record High'month: 12variable: 478.0 2.015e+03 81.7 2.017e+03 78.6 ... 79.6 1.994e+03 84.6 2.016e+03array([[  78. , 2015. ,   81.7, 2017. ],\n       [  78.6, 2021. ,   81.5, 2021. ],\n       [  82.8, 2003. ,   83.2, 2021. ],\n       [  85.8, 2020. ,   85.8, 2020. ],\n       [  85.2, 1995. ,   87.7, 2021. ],\n       [  87.6, 2009. ,   90.4, 2010. ],\n       [  88.7, 2018. ,   92. , 2021. ],\n       [  88.5, 2022. ,   92.2, 2021. ],\n       [  86.7, 2021. ,   91.2, 2021. ],\n       [  86.8, 2023. ,   89. , 2016. ],\n       [  82. , 2020. ,   85. , 2020. ],\n       [  79.6, 1994. ,   84.6, 2016. ]])Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (0)\n\n\nHere, the rows are months and the columns are the records or corresponding year. Let’s see what the variables are:\n\nmonthly_records['Record High'].coords['variable']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'variable' (variable: 4)&gt; Size: 32B\narray(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)\nCoordinates:\n  * variable  (variable) object 32B 'Air Temperature' ... 'Water Temperature ...xarray.DataArray'variable'variable: 4'Air Temperature' 'Air Temperature Year' ... 'Water Temperature Year'array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Coordinates: (1)variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'], dtype=object)Indexes: (1)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Temperature',\n       'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (0)\n\n\nAlternatively, we can select a specific variable and see all of its stats (converting to a dataframe makes it easier to see):\n\nmonthly_records.sel(variable='Air Temperature').to_dataframe().drop('variable', axis=1)\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord Low Monthly Average\nAverage High\nLowest High\nRecord High\nAverage Low\nHighest Low\nRecord Low\nYears\n\n\nmonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n68.7\n72.6\n63.0\n76.0\n73.0\n78.0\n55.6\n63.5\n48.3\n23.0\n\n\n2\n70.8\n74.9\n65.5\n76.5\n74.2\n78.6\n59.4\n70.0\n47.9\n23.0\n\n\n3\n72.3\n77.6\n66.1\n78.5\n74.2\n82.8\n63.3\n72.0\n55.1\n24.0\n\n\n4\n75.6\n79.4\n72.8\n80.8\n77.3\n85.8\n68.3\n72.6\n61.2\n24.0\n\n\n5\n78.7\n80.7\n77.0\n82.5\n80.8\n85.2\n73.8\n77.1\n67.9\n21.0\n\n\n6\n81.5\n83.6\n79.8\n84.8\n82.8\n87.6\n77.6\n80.8\n75.1\n20.0\n\n\n7\n82.9\n85.0\n81.0\n85.8\n84.2\n88.7\n79.0\n82.3\n76.1\n25.0\n\n\n8\n83.2\n85.9\n81.8\n85.7\n84.0\n88.5\n79.3\n83.6\n76.1\n24.0\n\n\n9\n82.0\n82.7\n80.6\n85.1\n83.9\n86.7\n78.2\n79.8\n74.3\n24.0\n\n\n10\n79.6\n81.2\n77.5\n83.8\n81.0\n86.8\n72.7\n77.8\n64.6\n23.0\n\n\n11\n75.0\n78.6\n71.4\n79.7\n76.9\n82.0\n66.0\n74.4\n57.4\n23.0\n\n\n12\n71.4\n76.9\n62.1\n77.5\n72.5\n79.6\n59.2\n70.5\n48.8\n24.0\n\n\n\n\n\n\n\n\n\nReorganize\nFor the sake of convenience later, let’s rearrange these data arrays before saving them. It will be more useful to have record years as data variables instead of a dimension, but we’ll have to do some renaming in order to pull that off.\nFirst, separate the records and years into smaller xarrays:\n\nday_records = daily_records.sel(variable=[i for i in daily_records.coords['variable'].values if 'Year' not in i])\nday_years = daily_records.sel(variable=[i for i in daily_records.coords['variable'].values if 'Year' in i])\n\nmon_records = monthly_records.sel(variable=[i for i in monthly_records.coords['variable'].values if 'Year' not in i])\nmon_years = monthly_records.sel(variable=[i for i in monthly_records.coords['variable'].values if 'Year' in i])\n\nNext, add “Year” to all of the variable names and remove it from the coordinate name:\n\nday_years = day_years.rename_vars({i:i+' Year' for i in day_years.data_vars})\nday_years.coords['variable'] = [i.removesuffix(' Year') for i in day_years.coords['variable'].values]\n\nmon_years = mon_years.rename_vars({i:i+' Year' for i in mon_years.data_vars})\nmon_years.coords['variable'] = [i.removesuffix(' Year') for i in mon_years.coords['variable'].values]\n\nNow we can merge these two xarrays together, rearrange the order of the variables, and drop those that do not contain a year, such as daily average.\n\ndaily_records = xr.merge([day_records, day_years])\ndaily_records = daily_records[[item for items in zip(day_records.data_vars, day_years.data_vars) for item in items]]\ndaily_records = daily_records.drop_vars([x for x in daily_records.data_vars if daily_records[x].isnull().all()])\n\nmonthly_records = xr.merge([mon_records, mon_years])\nmonthly_records = monthly_records[[item for items in zip(mon_records.data_vars, mon_years.data_vars) for item in items]]\nmonthly_records = monthly_records.drop_vars([x for x in monthly_records.data_vars if monthly_records[x].isnull().all()])\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:                           (month: 12, variable: 2)\nCoordinates:\n  * month                             (month) int64 96B 1 2 3 4 5 ... 9 10 11 12\n  * variable                          (variable) object 16B 'Air Temperature'...\nData variables: (12/16)\n    Monthly Average                   (month, variable) float64 192B 68.7 ......\n    Record High Monthly Average       (month, variable) float64 192B 72.6 ......\n    Record High Monthly Average Year  (month, variable) float64 192B 2.013e+0...\n    Record Low Monthly Average        (month, variable) float64 192B 63.0 ......\n    Record Low Monthly Average Year   (month, variable) float64 192B 2.001e+0...\n    Average High                      (month, variable) float64 192B 76.0 ......\n    ...                                ...\n    Average Low                       (month, variable) float64 192B 55.6 ......\n    Highest Low                       (month, variable) float64 192B 63.5 ......\n    Highest Low Year                  (month, variable) float64 192B 2.013e+0...\n    Record Low                        (month, variable) float64 192B 48.3 ......\n    Record Low Year                   (month, variable) float64 192B 1.997e+0...\n    Years                             (month, variable) float64 192B 23.0 ......\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:month: 12variable: 2Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Data variables: (16)Monthly Average(month, variable)float6468.7 71.6 70.8 ... 77.4 71.4 74.0array([[68.7, 71.6],\n       [70.8, 72.8],\n       [72.3, 75. ],\n       [75.6, 78.5],\n       [78.7, 82. ],\n       [81.5, 85.2],\n       [82.9, 87.1],\n       [83.2, 87.3],\n       [82. , 85.7],\n       [79.6, 82.1],\n       [75. , 77.4],\n       [71.4, 74. ]])Record High Monthly Average(month, variable)float6472.6 78.9 74.9 ... 81.5 76.9 82.5array([[72.6, 78.9],\n       [74.9, 76.3],\n       [77.6, 80. ],\n       [79.4, 83.4],\n       [80.7, 84.1],\n       [83.6, 87.6],\n       [85. , 89.5],\n       [85.9, 90.1],\n       [82.7, 89.5],\n       [81.2, 85.9],\n       [78.6, 81.5],\n       [76.9, 82.5]])Record High Monthly Average Year(month, variable)float642.013e+03 2.017e+03 ... 2.016e+03array([[2013., 2017.],\n       [2018., 2021.],\n       [2003., 2003.],\n       [2020., 2020.],\n       [1995., 2021.],\n       [2010., 2010.],\n       [2023., 2023.],\n       [2022., 2021.],\n       [2017., 2021.],\n       [2020., 2021.],\n       [2015., 2016.],\n       [2015., 2016.]])Record Low Monthly Average(month, variable)float6463.0 67.5 65.5 ... 74.6 62.1 68.2array([[63. , 67.5],\n       [65.5, 67.7],\n       [66.1, 69.2],\n       [72.8, 75.1],\n       [77. , 78.6],\n       [79.8, 83.3],\n       [81. , 84.5],\n       [81.8, 85.4],\n       [80.6, 82.7],\n       [77.5, 79.6],\n       [71.4, 74.6],\n       [62.1, 68.2]])Record Low Monthly Average Year(month, variable)float642.001e+03 2.001e+03 ... 2.01e+03array([[2001., 2001.],\n       [1996., 2005.],\n       [2010., 2010.],\n       [2004., 2004.],\n       [2013., 2001.],\n       [2014., 2002.],\n       [2013., 2013.],\n       [1994., 1995.],\n       [2001., 2004.],\n       [2000., 2000.],\n       [2012., 2012.],\n       [2010., 2010.]])Average High(month, variable)float6476.0 75.4 76.5 ... 80.6 77.5 77.6array([[76. , 75.4],\n       [76.5, 76.7],\n       [78.5, 79.2],\n       [80.8, 81.9],\n       [82.5, 85.1],\n       [84.8, 87.9],\n       [85.8, 89.1],\n       [85.7, 89.4],\n       [85.1, 88. ],\n       [83.8, 85.6],\n       [79.7, 80.6],\n       [77.5, 77.6]])Lowest High(month, variable)float6473.0 70.5 74.2 ... 76.8 72.5 73.0array([[73. , 70.5],\n       [74.2, 73.7],\n       [74.2, 73.3],\n       [77.3, 78.4],\n       [80.8, 82.8],\n       [82.8, 85.3],\n       [84.2, 86.4],\n       [84. , 87.2],\n       [83.9, 85.2],\n       [81. , 82.7],\n       [76.9, 76.8],\n       [72.5, 73. ]])Lowest High Year(month, variable)float642.011e+03 2.011e+03 ... 2.003e+03array([[2011., 2011.],\n       [2000., 2016.],\n       [2010., 2010.],\n       [2004., 2010.],\n       [2014., 2013.],\n       [2014., 1996.],\n       [2012., 2013.],\n       [2003., 2000.],\n       [2000., 1997.],\n       [2010., 2004.],\n       [2012., 2001.],\n       [2010., 2003.]])Record High(month, variable)float6478.0 81.7 78.6 ... 85.0 79.6 84.6array([[78. , 81.7],\n       [78.6, 81.5],\n       [82.8, 83.2],\n       [85.8, 85.8],\n       [85.2, 87.7],\n       [87.6, 90.4],\n       [88.7, 92. ],\n       [88.5, 92.2],\n       [86.7, 91.2],\n       [86.8, 89. ],\n       [82. , 85. ],\n       [79.6, 84.6]])Record High Year(month, variable)float642.015e+03 2.017e+03 ... 2.016e+03array([[2015., 2017.],\n       [2021., 2021.],\n       [2003., 2021.],\n       [2020., 2020.],\n       [1995., 2021.],\n       [2009., 2010.],\n       [2018., 2021.],\n       [2022., 2021.],\n       [2021., 2021.],\n       [2023., 2016.],\n       [2020., 2020.],\n       [1994., 2016.]])Average Low(month, variable)float6455.6 67.6 59.4 ... 74.2 59.2 70.2array([[55.6, 67.6],\n       [59.4, 68.9],\n       [63.3, 70.9],\n       [68.3, 74.6],\n       [73.8, 78.1],\n       [77.6, 82.2],\n       [79. , 84.5],\n       [79.3, 84.4],\n       [78.2, 83. ],\n       [72.7, 77.9],\n       [66. , 74.2],\n       [59.2, 70.2]])Highest Low(month, variable)float6463.5 75.9 70.0 ... 80.0 70.5 79.6array([[63.5, 75.9],\n       [70. , 73.4],\n       [72. , 75.4],\n       [72.6, 81.1],\n       [77.1, 80.4],\n       [80.8, 85.2],\n       [82.3, 87.2],\n       [83.6, 87.2],\n       [79.8, 87.1],\n       [77.8, 83.4],\n       [74.4, 80. ],\n       [70.5, 79.6]])Highest Low Year(month, variable)float642.013e+03 2.017e+03 ... 2.016e+03array([[2013., 2017.],\n       [2018., 2023.],\n       [1997., 1997.],\n       [2015., 2020.],\n       [2003., 1994.],\n       [2004., 2004.],\n       [2022., 2023.],\n       [2022., 2021.],\n       [2009., 2021.],\n       [1995., 2021.],\n       [2020., 2016.],\n       [2015., 2016.]])Record Low(month, variable)float6448.3 64.0 47.9 ... 70.8 48.8 63.7array([[48.3, 64. ],\n       [47.9, 63.2],\n       [55.1, 64.8],\n       [61.2, 69.4],\n       [67.9, 74.1],\n       [75.1, 80. ],\n       [76.1, 80.9],\n       [76.1, 81. ],\n       [74.3, 79.5],\n       [64.6, 73.2],\n       [57.4, 70.8],\n       [48.8, 63.7]])Record Low Year(month, variable)float641.997e+03 2.003e+03 ... 2.01e+03array([[1997., 2003.],\n       [1996., 2005.],\n       [1996., 2010.],\n       [2009., 2003.],\n       [1999., 2001.],\n       [1995., 1996.],\n       [2013., 2013.],\n       [1996., 2012.],\n       [2001., 2004.],\n       [2005., 2005.],\n       [2006., 2000.],\n       [2010., 2010.]])Years(month, variable)float6423.0 24.0 23.0 ... 24.0 24.0 24.0array([[23., 24.],\n       [23., 21.],\n       [24., 25.],\n       [24., 25.],\n       [21., 23.],\n       [20., 23.],\n       [25., 25.],\n       [24., 25.],\n       [24., 24.],\n       [23., 23.],\n       [23., 24.],\n       [24., 24.]])Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\nFinally, let’s convert years to integers since we do not need decimal years.\n\ndaily_records[[i for i in daily_records.data_vars if \"Year\" in i]] = \\\n    daily_records[[i for i in daily_records.data_vars if \"Year\" in i]].astype(int)\n\nmonthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]] = \\\n    monthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]].astype(int)\n\n‘yearday’ is not intuitive, so we can change it to calendar day instead and rename the coordinate. Similarly, we can use month names instead of numbers for the sake of clarity.\n\ndaily_records.coords['yearday'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D').strftime('%d-%b')\ndaily_records = daily_records.rename({'yearday':'Date'})\n\nmonthly_records.coords['month'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1m').strftime('%b')\nmonthly_records = monthly_records.rename({'month': 'Month'})\n\nNow take a look at the final products\n\ndaily_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 97kB\nDimensions:                         (Date: 366, variable: 2)\nCoordinates:\n  * variable                        (variable) object 16B 'Air Temperature' '...\n  * Date                            (Date) object 3kB '01-Jan' ... '31-Dec'\nData variables: (12/16)\n    Daily Average                   (Date, variable) float64 6kB 71.5 ... 72.6\n    Record High Daily Average       (Date, variable) float64 6kB 78.0 ... 80.5\n    Record High Daily Average Year  (Date, variable) int64 6kB 2022 ... 2021\n    Record Low Daily Average        (Date, variable) float64 6kB 54.4 ... 66.1\n    Record Low Daily Average Year   (Date, variable) int64 6kB 2001 ... 2010\n    Average High                    (Date, variable) float64 6kB 75.0 ... 73.9\n    ...                              ...\n    Average Low                     (Date, variable) float64 6kB 67.9 ... 71.4\n    Highest Low                     (Date, variable) float64 6kB 76.8 ... 79.3\n    Highest Low Year                (Date, variable) int64 6kB 2022 ... 2021\n    Record Low                      (Date, variable) float64 6kB 45.5 ... 64.4\n    Record Low Year                 (Date, variable) int64 6kB 2001 ... 2010\n    Years                           (Date, variable) int64 6kB 23 24 ... 23 24\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:Date: 366variable: 2Coordinates: (2)variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Date(Date)object'01-Jan' '02-Jan' ... '31-Dec'array(['01-Jan', '02-Jan', '03-Jan', ..., '29-Dec', '30-Dec', '31-Dec'],\n      dtype=object)Data variables: (16)Daily Average(Date, variable)float6471.5 72.4 71.8 ... 72.7 70.8 72.6array([[71.5, 72.4],\n       [71.8, 72.9],\n       [70. , 73. ],\n       [69.3, 72.7],\n       [68.2, 72.5],\n       [69.1, 72.3],\n       [68.4, 72.3],\n       [67.4, 72. ],\n       [68. , 71.7],\n       [68.3, 71.6],\n       [70.3, 71.6],\n       [70.7, 71.8],\n       [69.6, 71.9],\n       [68.6, 71.7],\n       [69.6, 71.4],\n       [69.3, 71.4],\n       [67.5, 71.1],\n       [67.6, 70.7],\n       [68. , 70.9],\n       [68.1, 71. ],\n...\n       [72.1, 74.8],\n       [73. , 74.8],\n       [72.9, 74.7],\n       [71. , 74.2],\n       [71.7, 74.3],\n       [71.8, 74.2],\n       [70.9, 74.2],\n       [70.3, 73.9],\n       [69.1, 73.4],\n       [69. , 72.9],\n       [70.3, 72.8],\n       [71.7, 72.9],\n       [71.6, 72.9],\n       [70.6, 72.7],\n       [69.6, 72.6],\n       [68.1, 72.3],\n       [69.4, 72.5],\n       [70.6, 72.6],\n       [69.6, 72.7],\n       [70.8, 72.6]])Record High Daily Average(Date, variable)float6478.0 80.4 77.8 ... 81.9 79.2 80.5array([[78. , 80.4],\n       [77.8, 80.2],\n       [78. , 80.7],\n       [77.9, 81.2],\n       [77.3, 81.4],\n       [76.8, 81.7],\n       [77.4, 81.5],\n       [76.8, 78.8],\n       [77.1, 78.2],\n       [76.9, 78.2],\n       [76.6, 78.2],\n       [77.4, 77.2],\n       [76.3, 77.4],\n       [76.7, 77.8],\n       [76. , 78. ],\n       [76. , 78. ],\n       [74.8, 77.4],\n       [75.8, 78.6],\n       [74.5, 79.8],\n       [74.1, 80.4],\n...\n       [78.8, 81.7],\n       [78.8, 82.6],\n       [78. , 83.3],\n       [78.4, 83.3],\n       [78.4, 82.8],\n       [79.1, 82.2],\n       [78.8, 82.4],\n       [78.9, 83.1],\n       [78.3, 83.2],\n       [77.6, 83.4],\n       [78.4, 83. ],\n       [79. , 83.2],\n       [79.2, 83. ],\n       [79. , 82.8],\n       [78.6, 82.3],\n       [78.4, 81.8],\n       [79. , 82.2],\n       [79.4, 82.6],\n       [79.5, 81.9],\n       [79.2, 80.5]])Record High Daily Average Year(Date, variable)int642022 2022 2022 ... 2016 2015 2021array([[2022, 2022],\n       [2022, 2022],\n       [2015, 2017],\n       [2015, 2017],\n       [2015, 2017],\n       [2015, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2013, 2022],\n       [2014, 2022],\n       [2020, 2022],\n       [2020, 2022],\n       [2020, 2017],\n       [2020, 2017],\n       [2020, 2017],\n       [2020, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2020, 2017],\n       [2017, 2017],\n...\n       [2021, 2021],\n       [2021, 2016],\n       [2015, 2016],\n       [2009, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2013, 2016],\n       [2013, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2021]])Record Low Daily Average(Date, variable)float6454.4 66.4 56.6 ... 66.4 49.9 66.1array([[54.4, 66.4],\n       [56.6, 66.8],\n       [51.7, 67.3],\n       [51.6, 67.6],\n       [51. , 66.2],\n       [48.4, 64.8],\n       [53. , 65.9],\n       [49. , 66.2],\n       [50. , 64.5],\n       [54.6, 65. ],\n       [59.6, 64. ],\n       [52.5, 65.9],\n       [53.6, 65.6],\n       [58.6, 66.2],\n       [61.2, 66.9],\n       [58.4, 66.8],\n       [55.4, 66.4],\n       [50. , 66.7],\n       [48.3, 64.9],\n       [57.8, 65. ],\n...\n       [60.5, 69.1],\n       [53.7, 67.6],\n       [62.2, 66.3],\n       [52.6, 65.8],\n       [60.6, 63.7],\n       [63.2, 65. ],\n       [54.7, 65.3],\n       [59.9, 67.1],\n       [50.6, 67.1],\n       [57.6, 65.8],\n       [57.2, 66.8],\n       [58.8, 67.8],\n       [51.8, 67.3],\n       [49.4, 66.4],\n       [54.7, 66.6],\n       [48.8, 65.8],\n       [52.2, 65.2],\n       [58.7, 66.6],\n       [54.8, 66.4],\n       [49.9, 66.1]])Record Low Daily Average Year(Date, variable)int642001 2011 2010 ... 2010 2000 2010array([[2001, 2011],\n       [2010, 2011],\n       [2012, 2011],\n       [2018, 2001],\n       [2010, 2001],\n       [2010, 2001],\n       [2010, 2010],\n       [1996, 2002],\n       [1996, 1996],\n       [2001, 1996],\n       [2004, 2010],\n       [2010, 2010],\n       [1996, 1996],\n       [1996, 1996],\n       [2012, 2011],\n       [2014, 2011],\n       [1997, 2012],\n       [1997, 1997],\n       [1997, 2003],\n       [1997, 2003],\n...\n       [2004, 1996],\n       [2010, 2010],\n       [2017, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [1997, 2010],\n       [2003, 2010],\n       [2003, 2010],\n       [1996, 2003],\n       [2009, 2003],\n       [2012, 2003],\n       [1995, 2010],\n       [1995, 2003],\n       [1995, 2003],\n       [1995, 2010],\n       [2010, 1995],\n       [2010, 2010],\n       [2009, 1995],\n       [2000, 2010],\n       [2000, 2010]])Average High(Date, variable)float6475.0 73.7 75.1 ... 74.1 74.3 73.9array([[75. , 73.7],\n       [75.1, 74.2],\n       [73.9, 74.3],\n       [73.2, 74.1],\n       [72.9, 74. ],\n       [73.9, 73.6],\n       [73.4, 73.7],\n       [72.2, 73.5],\n       [72.3, 73.1],\n       [73.4, 73.1],\n       [74.1, 73. ],\n       [74. , 73.2],\n       [73.6, 73.2],\n       [73.4, 73.1],\n       [73.7, 72.9],\n       [73.3, 73. ],\n       [72.3, 72.5],\n       [72.2, 72.2],\n       [72.8, 72.3],\n       [73.3, 72.4],\n...\n       [75.9, 75.9],\n       [76.3, 75.9],\n       [76.6, 75.9],\n       [75.1, 75.7],\n       [75.4, 75.4],\n       [76.1, 75.3],\n       [75.6, 75.4],\n       [74.7, 75.3],\n       [72.5, 74.6],\n       [73.7, 74.2],\n       [73.9, 74. ],\n       [74.8, 74.3],\n       [74.8, 74.2],\n       [74.4, 74. ],\n       [74. , 73.9],\n       [72.7, 73.6],\n       [73.1, 73.8],\n       [74.4, 74.1],\n       [73.2, 74.1],\n       [74.3, 73.9]])Lowest High(Date, variable)float6463.3 67.8 64.2 ... 68.4 55.6 67.8array([[63.3, 67.8],\n       [64.2, 68. ],\n       [57. , 68.9],\n       [58.7, 69.1],\n       [57.8, 68.5],\n       [55.7, 66.2],\n       [59.7, 67.1],\n       [54.5, 67.8],\n       [59.7, 66.6],\n       [65.3, 67.3],\n       [68.7, 68. ],\n       [60.1, 68.9],\n       [59.5, 68. ],\n       [67.3, 67.6],\n       [67.3, 68.9],\n       [63.5, 68. ],\n       [61.9, 67.5],\n       [55.8, 68.2],\n       [55.2, 67.1],\n       [65.7, 66.9],\n...\n       [66.9, 69.8],\n       [62.6, 70.9],\n       [68.9, 69.8],\n       [61.7, 69.3],\n       [64.6, 65.3],\n       [70.2, 68. ],\n       [62.1, 68. ],\n       [64.6, 68.9],\n       [57. , 68.5],\n       [63. , 68.7],\n       [64. , 69.1],\n       [62.2, 69.4],\n       [57.9, 69.1],\n       [57.7, 67.3],\n       [61.7, 68.7],\n       [55.4, 67.8],\n       [57.7, 67.1],\n       [67.1, 69.4],\n       [59.5, 68.4],\n       [55.6, 67.8]])Lowest High Year(Date, variable)int642001 2011 2010 ... 2010 2000 2010array([[2001, 2011],\n       [2010, 2011],\n       [2012, 2011],\n       [2010, 2011],\n       [2010, 2001],\n       [2010, 2001],\n       [2014, 2002],\n       [1996, 2011],\n       [1996, 1996],\n       [2001, 1996],\n       [2001, 2010],\n       [2010, 2001],\n       [1996, 1996],\n       [1996, 2011],\n       [2000, 1996],\n       [2014, 2011],\n       [1997, 2012],\n       [1997, 2012],\n       [1997, 2003],\n       [1997, 2003],\n...\n       [2004, 1996],\n       [2010, 2010],\n       [2017, 2010],\n       [2010, 2010],\n       [1998, 2010],\n       [1998, 2010],\n       [2003, 2010],\n       [2003, 1997],\n       [1996, 1997],\n       [2009, 2003],\n       [1995, 2004],\n       [1995, 2004],\n       [1995, 2003],\n       [1995, 2003],\n       [1995, 2010],\n       [2010, 1995],\n       [1995, 1995],\n       [2010, 2003],\n       [2000, 2010],\n       [2000, 2010]])Record High(Date, variable)float6479.3 81.1 79.3 ... 83.1 80.1 81.7array([[79.3, 81.1],\n       [79.3, 81. ],\n       [79.2, 81.5],\n       [81.7, 81.9],\n       [80.2, 82.2],\n       [78.3, 82.6],\n       [81. , 82.2],\n       [79.2, 80.6],\n       [77.9, 79. ],\n       [79. , 79.2],\n       [79. , 79. ],\n       [79. , 78.4],\n       [78.4, 79.2],\n       [78.4, 79.7],\n       [78.6, 79.9],\n       [80.4, 79.5],\n       [77.7, 78.4],\n       [77.7, 79.9],\n       [78.4, 81.1],\n       [80.2, 81.5],\n...\n       [81.5, 82.6],\n       [82.9, 83.5],\n       [80.1, 84. ],\n       [80.4, 84. ],\n       [79.7, 83.7],\n       [82.2, 82.9],\n       [82.8, 83.1],\n       [79.9, 83.8],\n       [80.4, 83.8],\n       [79.3, 84. ],\n       [80.4, 83.7],\n       [79.9, 83.8],\n       [80.1, 83.7],\n       [79.7, 83.5],\n       [80.8, 82.9],\n       [80.2, 82.6],\n       [80.1, 82.9],\n       [80.6, 83.3],\n       [80.6, 83.1],\n       [80.1, 81.7]])Record High Year(Date, variable)int642022 2022 2022 ... 2016 2015 2021array([[2022, 2022],\n       [2022, 2022],\n       [2019, 2017],\n       [2020, 2017],\n       [2019, 2017],\n       [2015, 2017],\n       [2017, 2017],\n       [2007, 2017],\n       [2013, 2017],\n       [2022, 2022],\n       [2020, 2022],\n       [2024, 2017],\n       [2024, 2017],\n       [2014, 2017],\n       [2024, 2017],\n       [1997, 2017],\n       [2007, 2017],\n       [2015, 2017],\n       [2011, 2017],\n       [2017, 2017],\n...\n       [2021, 2021],\n       [2020, 2016],\n       [2009, 2016],\n       [2016, 2016],\n       [2009, 2016],\n       [2020, 2016],\n       [2012, 2016],\n       [2016, 2016],\n       [2021, 2016],\n       [2020, 2016],\n       [2017, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2023, 2016],\n       [2021, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2013, 2016],\n       [2015, 2021]])Average Low(Date, variable)float6467.9 71.1 68.5 ... 71.4 67.3 71.4array([[67.9, 71.1],\n       [68.5, 71.6],\n       [66.1, 71.7],\n       [65.4, 71.3],\n       [63.6, 71.1],\n       [64.4, 71. ],\n       [63.4, 70.9],\n       [62.7, 70.6],\n       [63.6, 70.4],\n       [63.2, 70.1],\n       [66.6, 70.2],\n       [67.4, 70.5],\n       [65.6, 70.6],\n       [63.8, 70.3],\n       [65.4, 70. ],\n       [65.2, 70. ],\n       [62.7, 69.8],\n       [63. , 69.2],\n       [63.2, 69.5],\n       [62.8, 69.6],\n...\n       [68.3, 73.7],\n       [69.7, 73.7],\n       [69.2, 73.6],\n       [66.9, 72.7],\n       [68.1, 73.2],\n       [67.5, 73.1],\n       [66.3, 72.9],\n       [65.8, 72.6],\n       [65.8, 72.2],\n       [64.3, 71.6],\n       [66.6, 71.5],\n       [68.5, 71.6],\n       [68.3, 71.5],\n       [66.7, 71.4],\n       [65.3, 71.3],\n       [63.4, 71. ],\n       [65.8, 71.2],\n       [66.7, 71.2],\n       [66.1, 71.4],\n       [67.3, 71.4]])Highest Low(Date, variable)float6476.8 79.7 76.3 ... 80.8 78.3 79.3array([[76.8, 79.7],\n       [76.3, 79.5],\n       [77. , 79.9],\n       [76.8, 80.6],\n       [75.9, 80.6],\n       [75.4, 80.8],\n       [76.6, 80.8],\n       [75.4, 77.9],\n       [76.3, 77.5],\n       [75.4, 77.2],\n       [74.8, 77.5],\n       [76.1, 76.6],\n       [75.2, 75.9],\n       [75. , 75.9],\n       [74.3, 76.1],\n       [74.5, 76.5],\n       [73. , 76.5],\n       [74.8, 77.2],\n       [73. , 78.6],\n       [70.5, 79.2],\n...\n       [76.1, 80.8],\n       [77.5, 81.7],\n       [76.5, 82.6],\n       [77. , 82.6],\n       [77. , 81.9],\n       [78.1, 81.5],\n       [77.4, 81.7],\n       [77.9, 82.4],\n       [77.4, 82.6],\n       [76.3, 82.8],\n       [77.4, 82.2],\n       [78.1, 82.6],\n       [78.3, 82.2],\n       [78.3, 82. ],\n       [77.2, 81.7],\n       [77.5, 81.1],\n       [77.9, 81.5],\n       [78.3, 81.9],\n       [78.4, 80.8],\n       [78.3, 79.3]])Highest Low Year(Date, variable)int642022 2022 2017 ... 2016 2015 2021array([[2022, 2022],\n       [2017, 2022],\n       [2015, 2017],\n       [2015, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2007, 2017],\n       [2013, 2022],\n       [2013, 2022],\n       [2013, 2022],\n       [2013, 2022],\n       [2020, 2022],\n       [2020, 2022],\n       [2020, 2017],\n       [2013, 2017],\n       [2020, 2017],\n       [2017, 2017],\n       [2007, 2017],\n       [2001, 2017],\n       [2015, 2017],\n...\n       [1997, 2021],\n       [2021, 2016],\n       [2001, 2016],\n       [2009, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2016, 2016],\n       [2013, 2016],\n       [2013, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2016],\n       [2015, 2021]])Record Low(Date, variable)float6445.5 63.9 49.1 ... 64.4 44.2 64.4array([[45.5, 63.9],\n       [49.1, 64.4],\n       [46.4, 65.5],\n       [43.7, 64.5],\n       [44.2, 63.6],\n       [41. , 61.7],\n       [45.5, 61.7],\n       [43.5, 62.5],\n       [40.3, 60.9],\n       [43.9, 61.2],\n       [49.3, 60.1],\n       [44.9, 62.2],\n       [46.4, 62.3],\n       [50. , 62.2],\n       [53.6, 63.9],\n       [53.2, 65. ],\n       [48.9, 65.3],\n       [44.1, 64. ],\n       [41.4, 62.8],\n       [49.8, 63. ],\n...\n       [54.1, 67.3],\n       [44.8, 64.4],\n       [55.6, 62.8],\n       [43.5, 62.2],\n       [51.6, 62.1],\n       [55.8, 62.1],\n       [47.3, 62.6],\n       [48.9, 63.7],\n       [44.2, 65.1],\n       [49.3, 63. ],\n       [49.5, 64.4],\n       [55.4, 64.9],\n       [45.7, 65.5],\n       [41. , 63.3],\n       [47.5, 64. ],\n       [42.1, 63. ],\n       [42.4, 62.2],\n       [50.1, 62.2],\n       [50. , 64.4],\n       [44.2, 64.4]])Record Low Year(Date, variable)int642001 2001 2010 ... 2010 2000 2010array([[2001, 2001],\n       [2010, 2001],\n       [2012, 2001],\n       [2018, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [1996, 2010],\n       [1996, 2010],\n       [2001, 2010],\n       [2004, 2010],\n       [2010, 2010],\n       [2011, 2010],\n       [1996, 2010],\n       [2012, 2010],\n       [2014, 2010],\n       [1997, 2012],\n       [1997, 1997],\n       [1997, 2003],\n       [1997, 1997],\n...\n       [2004, 2010],\n       [2010, 2010],\n       [2017, 2010],\n       [2010, 2010],\n       [2010, 2010],\n       [1997, 2010],\n       [2003, 2010],\n       [1996, 2010],\n       [1996, 2003],\n       [2003, 2003],\n       [2012, 2003],\n       [1995, 2003],\n       [1995, 2003],\n       [1995, 1995],\n       [2010, 1995],\n       [2010, 2010],\n       [2010, 2010],\n       [2009, 2010],\n       [2000, 2010],\n       [2000, 2010]])Years(Date, variable)int6423 24 23 24 23 ... 24 24 24 23 24array([[23, 24],\n       [23, 24],\n       [23, 24],\n       [22, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [22, 24],\n       [23, 24],\n       [22, 24],\n       [22, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n       [23, 24],\n...\n       [24, 24],\n       [24, 24],\n       [23, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [23, 23],\n       [24, 24],\n       [23, 23],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [24, 24],\n       [23, 24]])Indexes: (2)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))DatePandasIndexPandasIndex(Index(['01-Jan', '02-Jan', '03-Jan', '04-Jan', '05-Jan', '06-Jan', '07-Jan',\n       '08-Jan', '09-Jan', '10-Jan',\n       ...\n       '22-Dec', '23-Dec', '24-Dec', '25-Dec', '26-Dec', '27-Dec', '28-Dec',\n       '29-Dec', '30-Dec', '31-Dec'],\n      dtype='object', name='Date', length=366))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:                           (Month: 12, variable: 2)\nCoordinates:\n  * variable                          (variable) object 16B 'Air Temperature'...\n  * Month                             (Month) object 96B 'Jan' 'Feb' ... 'Dec'\nData variables: (12/16)\n    Monthly Average                   (Month, variable) float64 192B 68.7 ......\n    Record High Monthly Average       (Month, variable) float64 192B 72.6 ......\n    Record High Monthly Average Year  (Month, variable) int64 192B 2013 ... 2016\n    Record Low Monthly Average        (Month, variable) float64 192B 63.0 ......\n    Record Low Monthly Average Year   (Month, variable) int64 192B 2001 ... 2010\n    Average High                      (Month, variable) float64 192B 76.0 ......\n    ...                                ...\n    Average Low                       (Month, variable) float64 192B 55.6 ......\n    Highest Low                       (Month, variable) float64 192B 63.5 ......\n    Highest Low Year                  (Month, variable) int64 192B 2013 ... 2016\n    Record Low                        (Month, variable) float64 192B 48.3 ......\n    Record Low Year                   (Month, variable) int64 192B 1997 ... 2010\n    Years                             (Month, variable) int64 192B 23 24 ... 24\nAttributes:\n    datum:                         MHHW\n    day_threshold:                 2\n    hr_threshold:                  3\n    last_updated:                  2024-05-25 10:00:00\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    tz:                            lst\n    unit_system:                   english\n    Air Temperature units:         F\n    Water Temperature units:       F\n    Air Temperature data range:    ('1994-04-01', '2024-04-30')\n    Water Temperature data range:  ('1994-04-01', '2024-04-30')xarray.DatasetDimensions:Month: 12variable: 2Coordinates: (2)variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Month(Month)object'Jan' 'Feb' 'Mar' ... 'Nov' 'Dec'array(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct',\n       'Nov', 'Dec'], dtype=object)Data variables: (16)Monthly Average(Month, variable)float6468.7 71.6 70.8 ... 77.4 71.4 74.0array([[68.7, 71.6],\n       [70.8, 72.8],\n       [72.3, 75. ],\n       [75.6, 78.5],\n       [78.7, 82. ],\n       [81.5, 85.2],\n       [82.9, 87.1],\n       [83.2, 87.3],\n       [82. , 85.7],\n       [79.6, 82.1],\n       [75. , 77.4],\n       [71.4, 74. ]])Record High Monthly Average(Month, variable)float6472.6 78.9 74.9 ... 81.5 76.9 82.5array([[72.6, 78.9],\n       [74.9, 76.3],\n       [77.6, 80. ],\n       [79.4, 83.4],\n       [80.7, 84.1],\n       [83.6, 87.6],\n       [85. , 89.5],\n       [85.9, 90.1],\n       [82.7, 89.5],\n       [81.2, 85.9],\n       [78.6, 81.5],\n       [76.9, 82.5]])Record High Monthly Average Year(Month, variable)int642013 2017 2018 ... 2016 2015 2016array([[2013, 2017],\n       [2018, 2021],\n       [2003, 2003],\n       [2020, 2020],\n       [1995, 2021],\n       [2010, 2010],\n       [2023, 2023],\n       [2022, 2021],\n       [2017, 2021],\n       [2020, 2021],\n       [2015, 2016],\n       [2015, 2016]])Record Low Monthly Average(Month, variable)float6463.0 67.5 65.5 ... 74.6 62.1 68.2array([[63. , 67.5],\n       [65.5, 67.7],\n       [66.1, 69.2],\n       [72.8, 75.1],\n       [77. , 78.6],\n       [79.8, 83.3],\n       [81. , 84.5],\n       [81.8, 85.4],\n       [80.6, 82.7],\n       [77.5, 79.6],\n       [71.4, 74.6],\n       [62.1, 68.2]])Record Low Monthly Average Year(Month, variable)int642001 2001 1996 ... 2012 2010 2010array([[2001, 2001],\n       [1996, 2005],\n       [2010, 2010],\n       [2004, 2004],\n       [2013, 2001],\n       [2014, 2002],\n       [2013, 2013],\n       [1994, 1995],\n       [2001, 2004],\n       [2000, 2000],\n       [2012, 2012],\n       [2010, 2010]])Average High(Month, variable)float6476.0 75.4 76.5 ... 80.6 77.5 77.6array([[76. , 75.4],\n       [76.5, 76.7],\n       [78.5, 79.2],\n       [80.8, 81.9],\n       [82.5, 85.1],\n       [84.8, 87.9],\n       [85.8, 89.1],\n       [85.7, 89.4],\n       [85.1, 88. ],\n       [83.8, 85.6],\n       [79.7, 80.6],\n       [77.5, 77.6]])Lowest High(Month, variable)float6473.0 70.5 74.2 ... 76.8 72.5 73.0array([[73. , 70.5],\n       [74.2, 73.7],\n       [74.2, 73.3],\n       [77.3, 78.4],\n       [80.8, 82.8],\n       [82.8, 85.3],\n       [84.2, 86.4],\n       [84. , 87.2],\n       [83.9, 85.2],\n       [81. , 82.7],\n       [76.9, 76.8],\n       [72.5, 73. ]])Lowest High Year(Month, variable)int642011 2011 2000 ... 2001 2010 2003array([[2011, 2011],\n       [2000, 2016],\n       [2010, 2010],\n       [2004, 2010],\n       [2014, 2013],\n       [2014, 1996],\n       [2012, 2013],\n       [2003, 2000],\n       [2000, 1997],\n       [2010, 2004],\n       [2012, 2001],\n       [2010, 2003]])Record High(Month, variable)float6478.0 81.7 78.6 ... 85.0 79.6 84.6array([[78. , 81.7],\n       [78.6, 81.5],\n       [82.8, 83.2],\n       [85.8, 85.8],\n       [85.2, 87.7],\n       [87.6, 90.4],\n       [88.7, 92. ],\n       [88.5, 92.2],\n       [86.7, 91.2],\n       [86.8, 89. ],\n       [82. , 85. ],\n       [79.6, 84.6]])Record High Year(Month, variable)int642015 2017 2021 ... 2020 1994 2016array([[2015, 2017],\n       [2021, 2021],\n       [2003, 2021],\n       [2020, 2020],\n       [1995, 2021],\n       [2009, 2010],\n       [2018, 2021],\n       [2022, 2021],\n       [2021, 2021],\n       [2023, 2016],\n       [2020, 2020],\n       [1994, 2016]])Average Low(Month, variable)float6455.6 67.6 59.4 ... 74.2 59.2 70.2array([[55.6, 67.6],\n       [59.4, 68.9],\n       [63.3, 70.9],\n       [68.3, 74.6],\n       [73.8, 78.1],\n       [77.6, 82.2],\n       [79. , 84.5],\n       [79.3, 84.4],\n       [78.2, 83. ],\n       [72.7, 77.9],\n       [66. , 74.2],\n       [59.2, 70.2]])Highest Low(Month, variable)float6463.5 75.9 70.0 ... 80.0 70.5 79.6array([[63.5, 75.9],\n       [70. , 73.4],\n       [72. , 75.4],\n       [72.6, 81.1],\n       [77.1, 80.4],\n       [80.8, 85.2],\n       [82.3, 87.2],\n       [83.6, 87.2],\n       [79.8, 87.1],\n       [77.8, 83.4],\n       [74.4, 80. ],\n       [70.5, 79.6]])Highest Low Year(Month, variable)int642013 2017 2018 ... 2016 2015 2016array([[2013, 2017],\n       [2018, 2023],\n       [1997, 1997],\n       [2015, 2020],\n       [2003, 1994],\n       [2004, 2004],\n       [2022, 2023],\n       [2022, 2021],\n       [2009, 2021],\n       [1995, 2021],\n       [2020, 2016],\n       [2015, 2016]])Record Low(Month, variable)float6448.3 64.0 47.9 ... 70.8 48.8 63.7array([[48.3, 64. ],\n       [47.9, 63.2],\n       [55.1, 64.8],\n       [61.2, 69.4],\n       [67.9, 74.1],\n       [75.1, 80. ],\n       [76.1, 80.9],\n       [76.1, 81. ],\n       [74.3, 79.5],\n       [64.6, 73.2],\n       [57.4, 70.8],\n       [48.8, 63.7]])Record Low Year(Month, variable)int641997 2003 1996 ... 2000 2010 2010array([[1997, 2003],\n       [1996, 2005],\n       [1996, 2010],\n       [2009, 2003],\n       [1999, 2001],\n       [1995, 1996],\n       [2013, 2013],\n       [1996, 2012],\n       [2001, 2004],\n       [2005, 2005],\n       [2006, 2000],\n       [2010, 2010]])Years(Month, variable)int6423 24 23 21 24 ... 23 23 24 24 24array([[23, 24],\n       [23, 21],\n       [24, 25],\n       [24, 25],\n       [21, 23],\n       [20, 23],\n       [25, 25],\n       [24, 25],\n       [24, 24],\n       [23, 23],\n       [23, 24],\n       [24, 24]])Indexes: (2)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))MonthPandasIndexPandasIndex(Index(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct',\n       'Nov', 'Dec'],\n      dtype='object', name='Month'))Attributes: (12)datum :MHHWday_threshold :2hr_threshold :3last_updated :2024-05-25 10:00:00stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :FWater Temperature units :FAir Temperature data range :('1994-04-01', '2024-04-30')Water Temperature data range :('1994-04-01', '2024-04-30')\n\n\n\nmonthly_records.coords['variable']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'variable' (variable: 2)&gt; Size: 16B\narray(['Air Temperature', 'Water Temperature'], dtype=object)\nCoordinates:\n  * variable  (variable) object 16B 'Air Temperature' 'Water Temperature'xarray.DataArray'variable'variable: 2'Air Temperature' 'Water Temperature'array(['Air Temperature', 'Water Temperature'], dtype=object)Coordinates: (1)variable(variable)object'Air Temperature' 'Water Tempera...array(['Air Temperature', 'Water Temperature'], dtype=object)Indexes: (1)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Temperature'], dtype='object', name='variable'))Attributes: (0)\n\n\nWe can still choose one environmental variable at a time, but now we get all of the records and corresponding years:\n\nmonthly_records.sel(variable='Air Temperature').to_dataframe().drop('variable', axis=1)\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan\n68.7\n72.6\n2013\n63.0\n2001\n76.0\n73.0\n2011\n78.0\n2015\n55.6\n63.5\n2013\n48.3\n1997\n23\n\n\nFeb\n70.8\n74.9\n2018\n65.5\n1996\n76.5\n74.2\n2000\n78.6\n2021\n59.4\n70.0\n2018\n47.9\n1996\n23\n\n\nMar\n72.3\n77.6\n2003\n66.1\n2010\n78.5\n74.2\n2010\n82.8\n2003\n63.3\n72.0\n1997\n55.1\n1996\n24\n\n\nApr\n75.6\n79.4\n2020\n72.8\n2004\n80.8\n77.3\n2004\n85.8\n2020\n68.3\n72.6\n2015\n61.2\n2009\n24\n\n\nMay\n78.7\n80.7\n1995\n77.0\n2013\n82.5\n80.8\n2014\n85.2\n1995\n73.8\n77.1\n2003\n67.9\n1999\n21\n\n\nJun\n81.5\n83.6\n2010\n79.8\n2014\n84.8\n82.8\n2014\n87.6\n2009\n77.6\n80.8\n2004\n75.1\n1995\n20\n\n\nJul\n82.9\n85.0\n2023\n81.0\n2013\n85.8\n84.2\n2012\n88.7\n2018\n79.0\n82.3\n2022\n76.1\n2013\n25\n\n\nAug\n83.2\n85.9\n2022\n81.8\n1994\n85.7\n84.0\n2003\n88.5\n2022\n79.3\n83.6\n2022\n76.1\n1996\n24\n\n\nSep\n82.0\n82.7\n2017\n80.6\n2001\n85.1\n83.9\n2000\n86.7\n2021\n78.2\n79.8\n2009\n74.3\n2001\n24\n\n\nOct\n79.6\n81.2\n2020\n77.5\n2000\n83.8\n81.0\n2010\n86.8\n2023\n72.7\n77.8\n1995\n64.6\n2005\n23\n\n\nNov\n75.0\n78.6\n2015\n71.4\n2012\n79.7\n76.9\n2012\n82.0\n2020\n66.0\n74.4\n2020\n57.4\n2006\n23\n\n\nDec\n71.4\n76.9\n2015\n62.1\n2010\n77.5\n72.5\n2010\n79.6\n1994\n59.2\n70.5\n2015\n48.8\n2010\n24\n\n\n\n\n\n\n\nFinally, write these to file for safe keeping.\n\ndaily_records.to_netcdf(os.path.join(outdir, 'statistics-daily.nc'), mode='w')\nmonthly_records.to_netcdf(os.path.join(outdir, 'statistics-monthly.nc'), mode='w')\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 96 from PyObject\n\n\nWe will plot these results in Part 3, NOAA-CO-OPS-plots.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Demonstration",
      "Data Cleansing and Records Calculations"
    ]
  },
  {
    "objectID": "methods/index.html",
    "href": "methods/index.html",
    "title": "Calculating the statistics",
    "section": "",
    "text": "All data from the beginning of each time series to the present are retrieved from the NOAA CO-OPS Tides and Currents data portal using a noaa-coops utility and saved to file to avoid having to repeatedly re-download the historical data. Subsequent data updates retrieve from the most recently saved timestamp onward and append these new data to the saved historical record.\nSix-minute data are used whenever possible and hourly data otherwise.\nAny observations flagged by NOAA as being suspect for any reason (flag &gt; 0) are discarded. Examples of flagged data are a minimum or maximum value or a rate of change exceeding an acceptable tolerance. A day is allowed to have up to three hours of missing data to be counted in the daily climatologies, and a month is allowed up to two days of missing data to be counted in the monthly climatologies.\nAll of the statistics and records herein start with one of three quantities: daily highs, daily lows, or daily averages. Each of these is first determined for every day in the data time series as follows.\n\nDaily High\nThis is the maximum temperature recorded on any given day. Let \\(X\\) be a 24-hr time series of some environmental variable (e.g., air temperature) sampled \\(n\\) times during the day:\n\\[X = \\{x_1, x_2,...,x_n\\}\\]\nThe daily high is the maximum value in this observation set:\n\\[\\text{daily high} = \\max(X) \\tag{1}\\]\n\n\nDaily Low\nSimilarly, the daily low is the minimum temperature recorded on any given day:\n\\[\\text{daily low} = \\min(X) \\tag{2}\\]\n\n\nDaily Average\nThe daily average is the average of all recorded observations of a given variable on any given day. It can be calculated in one of two ways:\n\nMethod 1: True average\nThis is the conventional method of calculating an average where one sums up all observations during the 24-hour period and divides by the number of observations, \\(n\\):\n\\[\\text{true daily average} = \\frac{1}{n} \\sum_{i=1}^n X_i \\tag{3}\\]\n\n\nMethod 2: Meteorological average\nThe meteorological average is customarily calculated using only the maximum and minimum values recorded during a 24-hour period:\n\\[\\text{meteorological daily average} = \\frac{\\max(X) + \\min(X)}{2} \\tag{4}\\]\nThis project uses the true average (Equation 3) for all calculations.\nDaily statistics are calculated next, followed by monthly statistics.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Calculating the statistics"
    ]
  },
  {
    "objectID": "methods/monthlyeqs.html",
    "href": "methods/monthlyeqs.html",
    "title": "Monthly climatologies",
    "section": "",
    "text": "Daily climatologies are calculated for each day-of-year (DOY), where January 1 is Day 1, January 2 is Day 2,…, December 31 is Day 366. Instead of eliminating February 29 (Day 60) on leap years, we simply skip Day 60 in years that are not leap years by adding 1 to the DOY of every day after February 28. Days start at midnight (00:00) and go until 23:59 (11:59 PM) local time.",
    "crumbs": [
      "Home",
      "Calculating the statistics",
      "Monthly climatologies"
    ]
  },
  {
    "objectID": "methods/monthlyeqs.html#monthly-climatologies",
    "href": "methods/monthlyeqs.html#monthly-climatologies",
    "title": "Monthly climatologies",
    "section": "Monthly Climatologies",
    "text": "Monthly Climatologies\n\nMonthly Average\n\n\nRecord High Monthly Average\n\n\nRecord Low Monthly Average\n\n\nAverage High\n\n\nRecord High\n\n\nLowest High\n\n\nAverage Low\n\n\nHighest Low\n\n\nRecord Low",
    "crumbs": [
      "Home",
      "Calculating the statistics",
      "Monthly climatologies"
    ]
  },
  {
    "objectID": "methods/dailyeqs.html",
    "href": "methods/dailyeqs.html",
    "title": "Daily climatologies",
    "section": "",
    "text": "Daily climatologies are calculated for each day-of-year (DOY), where January 1 is Day 1, January 2 is Day 2,…, December 31 is Day 366. Instead of eliminating February 29 (Day 60) on leap years, we simply skip Day 60 in years that are not leap years by adding 1 to the DOY of every day after February 28. Days start at midnight (00:00) and go until 23:59 (11:59 PM) local time.",
    "crumbs": [
      "Home",
      "Calculating the statistics",
      "Daily climatologies"
    ]
  },
  {
    "objectID": "methods/dailyeqs.html#monthly-climatologies",
    "href": "methods/dailyeqs.html#monthly-climatologies",
    "title": "Daily climatologies",
    "section": "Monthly Climatologies",
    "text": "Monthly Climatologies\n\nMonthly Average\n\n\nRecord High Monthly Average\n\n\nRecord Low Monthly Average\n\n\nAverage High\n\n\nRecord High\n\n\nLowest High\n\n\nAverage Low\n\n\nHighest Low\n\n\nRecord Low",
    "crumbs": [
      "Home",
      "Calculating the statistics",
      "Daily climatologies"
    ]
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "How are these records calculated?",
    "section": "",
    "text": "All data from the beginning of each time series to the present are retrieved from the NOAA CO-OPS Tides and Currents data portal and saved to file to avoid having to repeatedly re-download the historical data. Subsequent data updates retrieve from the most recently saved timestamp onward and append these new data to the saved historical record.\nSix-minute data are used whenever possible and hourly data otherwise.\nAny observations flagged by NOAA as being suspect for any reason (flag &gt; 0) are discarded. Examples of flagged data are a minimum or maximum value or a rate of change exceeding an acceptable tolerance. A day is allowed to have up to three hours of missing data to be counted in the daily climatologies, and a month is allowed up to two days of missing data to be counted in the monthly climatologies.\nAll of the statistics and records herein start with one of three quantities: daily highs, daily lows, or daily averages. Each of these is first calculated for each environmental variable (i.e., air temperature, water temperature, water level) and for every day in the data time series as follows.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#daily-climatologies",
    "href": "methods.html#daily-climatologies",
    "title": "How are these records calculated?",
    "section": "Daily Climatologies",
    "text": "Daily Climatologies\nDaily climatologies are calculated for each day-of-year (DOY), where\n\nJan 1 \\(\\longrightarrow\\) Day 1\nJan 2 \\(\\longrightarrow\\) Day 2\n…\nFeb 28 \\(\\longrightarrow\\) Day 59\nFeb 29 \\(\\longrightarrow\\) Day 60\n…\nDec 30 \\(\\longrightarrow\\) Day 365\nDec 31 \\(\\longrightarrow\\) Day 366\n\nInstead of eliminating February 29 on leap years, Day 60 simply skipped in years that are not leap years. Thus, December 31 is always Day 366. Days start at midnight (00:00) and go until 23:59 (11:59 PM) local time.\n\nDOY Daily Average\nThe DOY daily average is the average of all daily averages for any given DOY. It is calculated by taking the daily averages calculated using Equation 3, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{A}\\) be a matrix of daily averages from Equation 3 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{A} = (a_{yd}) = \\left( \\begin{array}{cccc}\na_{1,1} & a_{1,2} & ... & a_{1,d} \\\\\na_{2,1} & a_{2,2} & ... & a_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\na_{y,1} & a_{y,2} & ... & a_{y,d} \\end{array} \\right) \\tag{5}\\]\nThe DOY daily average is the average over each column:\n\\[\\text{DOY daily average} = \\frac{1}{Y}\\sum_{y=1}^Y a_{yd} \\tag{6}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nNote: The Daily Average reported in the statistics dashboard are DOY daily averages from Equation 6.\n\n\nRecord High Daily Average\nThe record high daily average is the maximum daily average for any given DOY. It is determined by taking the daily averages calculated using Equation 3, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record high daily average} = {\\max}_d |a_{yd}| = \\max\\{|a_{yd}|: d=1,2,...,366\\} \\tag{7}\\]\n\n\nRecord Low Daily Average\nThe record low daily average is the minimum daily average for any given DOY. It is determined by taking the daily averages calculated using Equation 3, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record low daily average} = {\\min}_d |a_{yd}| = \\min\\{|a_{yd}|: d=1,2,...,366\\} \\tag{8}\\]\n\n\nAverage High\nThe average high is the average of all daily highs for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{H}\\) be a matrix of daily highs from Equation 1 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{H} = (h_{yd}) = \\left( \\begin{array}{cccc}\nh_{1,1} & h_{1,2} & ... & h_{1,d} \\\\\nh_{2,1} & h_{2,2} & ... & h_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nh_{y,1} & h_{y,2} & ... & h_{y,d} \\end{array} \\right) \\tag{9}\\]\nThe average high is the average over each column:\n\\[\\text{average high} = \\frac{1}{Y}\\sum_{y=1}^Y h_{yd} \\tag{10}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nRecord High\nThe record high is the maximum daily high for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{record high} = {\\max}_d |h_{yd}| = \\max\\{|h_{yd}|: d=1,2,...,366\\} \\tag{11}\\]\n\n\nLowest High\nThe lowest high is the minimum daily high for any given DOY. It is determined by taking the daily highs calculated using Equation 1, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{lowest high} = {\\min}_d |h_{yd}| = \\min\\{|h_{yd}|: d=1,2,...,366\\} \\tag{12}\\]\n\n\nAverage Low\nThe average low is the average of all daily lows for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{L}\\) be a matrix of daily lows from Equation 2 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{L} = (l_{yd}) = \\left( \\begin{array}{cccc}\nl_{1,1} & l_{1,2} & ... & l_{1,d} \\\\\nl_{2,1} & l_{2,2} & ... & l_{2,d} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nl_{y,1} & l_{y,2} & ... & l_{y,d} \\end{array} \\right) \\tag{13}\\]\nThe average low is the average over each column:\n\\[\\text{average low} = \\frac{1}{Y}\\sum_{y=1}^Y l_{yd} \\tag{14}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nHighest Low\nThe highest low is the maximum daily low for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{highest low} = {\\max}_d |l_{yd}| = \\max\\{|l_{yd}|: d=1,2,...,366\\} \\tag{15}\\]\n\n\nRecord Low\nThe record low is the minimum daily low for any given DOY. It is determined by taking the daily lows calculated using Equation 2, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{record low} = {\\min}_d |l_{yd}| = \\min\\{|l_{yd}|: d=1,2,...,366\\} \\tag{16}\\]\n\n\nNumber of Years in Record\nThe number of years of data available varies from day to day and between variables due to sensor availability, gaps in the observational record, or bad data being filtered out. Years are tallied by grouping the entire time series by DOY and counting the number of years for each day. For example, given \\(\\textbf{A}\\) from Equation 5 above, the number of years is the total number of unique years in each column.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#monthly-climatologies",
    "href": "methods.html#monthly-climatologies",
    "title": "How are these records calculated?",
    "section": "Monthly Climatologies",
    "text": "Monthly Climatologies\nMonthly climatologies are calculated in the same way as daily climatologies except daily highs, lows, and averages are grouped by calendar month instead of DOY.\n\nMonthly Average\nThe monthly average is the average of all daily averages for any given month. It is calculated by taking the daily averages calculated using Equation 3, grouping them by calendar month, and calculating the average for each month.\nLet \\(\\textbf{A}\\) now be a matrix of daily averages from Equation 3 arranged with years in rows and months in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(m\\) indicate month:\n\\[\\textbf{A} = (a_{ym}) = \\left( \\begin{array}{cccc}\na_{1,1} & a_{1,2} & ... & a_{1,12} \\\\\na_{2,1} & a_{2,2} & ... & a_{2,12} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\na_{y,1} & a_{y,2} & ... & a_{y,12} \\end{array} \\right) \\tag{17}\\]\nThe monthly average is the average over each column:\n\\[\\text{monthly average} = \\frac{1}{Y}\\sum_{y=1}^Y a_{ym} \\tag{18}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nRecord High Monthly Average\nThe record high monthly average is the maximum daily average for any given calendar month. It is determined by taking the daily averages calculated using Equation 3, grouping them by calendar month, and finding the maximum value for each month. Given \\(\\textbf{A}\\) from Equation 17 above:\n\\[\\text{record high monthly average} = {\\max}_m |a_{ym}| = \\max\\{|a_{ym}|: m=1,2,...,12\\} \\tag{19}\\]\n\n\nRecord Low Monthly Average\nThe record low monthly average is the minimum daily average for any given calendar month. It is determined by taking the daily averages calculated using Equation 3, grouping them by calendar month, and finding the minimum value for each month. Given \\(\\textbf{A}\\) from Equation 17 above:\n\\[\\text{record low monthly average} = {\\min}_m |a_{ym}| = \\min\\{|a_{ym}|: m=1,2,...,12\\} \\tag{20}\\]\n\n\nAverage High\nThe average high is the average of all daily highs for any given calendar month. It is determined by taking the daily highs calculated using Equation 1, grouping them by calendar month, and calculating the average for each month.\nLet \\(\\textbf{H}\\) now be a matrix of daily highs from Equation 1 arranged with years in rows and months in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(m\\) indicate month:\n\\[\\textbf{H} = (h_{ym}) = \\left( \\begin{array}{cccc}\nh_{1,1} & h_{1,2} & ... & h_{1,12} \\\\\nh_{2,1} & h_{2,2} & ... & h_{2,12} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nh_{y,1} & h_{y,2} & ... & h_{y,12} \\end{array} \\right) \\tag{21}\\]\nThe average high is the average over each column:\n\\[\\text{average high} = \\frac{1}{Y}\\sum_{y=1}^Y h_{ym} \\tag{22}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nRecord High\nThe record high is the maximum daily high for any given calendar month. It is determined by taking the daily highs calculated using Equation 1, grouping them by calendar month, and finding the maximum value for each month. Given \\(\\textbf{H}\\) from Equation 21 above:\n\\[\\text{record high} = {\\max}_m |h_{ym}| = \\max\\{|h_{ym}|: m=1,2,...,12\\} \\tag{23}\\]\n\n\nLowest High\nThe lowest high is the minimum daily high for any given calendar month. It is determined by taking the daily highs calculated using Equation 1, grouping them by calendar month, and finding the minimum value for each month. Given \\(\\textbf{H}\\) from Equation 21 above:\n\\[\\text{lowest high} = {\\min}_m |h_{ym}| = \\min\\{|h_{ym}|: m=1,2,...,12\\} \\tag{24}\\]\n\n\nAverage Low\nThe average low is the average of all daily lows for any given calendar month. It is determined by taking the daily lows calculated using Equation 2, grouping them by calendar month, and calculating the average for each month.\nLet \\(\\textbf{L}\\) now be a matrix of daily lows from Equation 2 arranged with years in rows and months in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(m\\) indicate month:\n\\[\\textbf{L} = (l_{ym}) = \\left( \\begin{array}{cccc}\nl_{1,1} & l_{1,2} & ... & l_{1,12} \\\\\nl_{2,1} & l_{2,2} & ... & l_{2,12} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nl_{y,1} & l_{y,2} & ... & l_{y,12} \\end{array} \\right) \\tag{25}\\]\nThe average low is the average over each column:\n\\[\\text{average low} = \\frac{1}{Y}\\sum_{y=1}^Y l_{ym} \\tag{26}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\nHighest Low\nThe highest low is the maximum daily low for any given calendar month. It is determined by taking the daily lows calculated using Equation 2, grouping them by calendar month, and finding the maximum value for each month. Given \\(\\textbf{L}\\) from Equation 25 above:\n\\[\\text{highest low} = {\\max}_m |l_{ym}| = \\max\\{|l_{ym}|: m=1,2,...,12\\} \\tag{27}\\]\n\n\nRecord Low\nThe record low is the minimum daily low for any given calendar month. It is determined by taking the daily lows calculated using Equation 2, grouping them by calendar month, and finding the minimum value for each month. Given \\(\\textbf{L}\\) from Equation 25 above:\n\\[\\text{record low} = {\\min}_m |l_{ym}| = \\min\\{|l_{ym}|: m=1,2,...,12\\} \\tag{28}\\]\n\n\nNumber of Years in Record\nThe number of years of data available varies from month to month and between variables due to sensor availability, gaps in the observational record, or bad data being filtered out. Years are tallied by grouping the entire time series by calendar month and counting the number of years for each month. For example, given \\(\\textbf{A}\\) from Equation 17 above, the number of years is the total number of unique years in each column.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#length-of-time-series",
    "href": "methods.html#length-of-time-series",
    "title": "Methodology",
    "section": "Length of Time Series",
    "text": "Length of Time Series\nFinally, the length of each time series is determined",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Giving credit where credit is due",
    "section": "",
    "text": "This project is inspired by Brian McNoldy at the University of Miami, whose long-standing “Climatology of Virginia Key, FL” site never ceased to provide insightful weather perpectives during my time at the Rosenstiel School of Marine, Atmospheric, and Earth Science.\nClimatology dashboards are provided here for a number of locations along the east coast to which I have some degree of connection. Some are updated more regularly than others.\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Shout Out"
    ]
  }
]