[
  {
    "objectID": "demos/index.html",
    "href": "demos/index.html",
    "title": "Demonstrations",
    "section": "",
    "text": "SAVE NOAA!\n\n\n\n\n\n \n\n The products on this page rely on data from the National Oceanic and Atmospheric Administration (NOAA). NOAA is a critical tax-funded federal agency whose data collection, modeling and science capabilities, and personnel expertise keep the country safer and more prosperous—all at a cost of 6¢ per day per taxpayer. If you are visiting this page and reading this, you have an interest in NOAA’s science, service, and stewardship to the nation. Contact your representatives in Congress today to demand that NOAA employees are restored, facilities are maintained, and budget is preserved.\n\n\n\n\n\nDemonstrations\nThe following notebooks demonstrate the code behind the dashboards. There are three steps:\n\nDownload the data\nCalculate the statistics and determine the records\nPlot and display the results\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Behind the Scenes"
    ]
  },
  {
    "objectID": "demos/NOAA-CO-OPS-plots.html",
    "href": "demos/NOAA-CO-OPS-plots.html",
    "title": "Plotting Records",
    "section": "",
    "text": "This notebook is the last in a series of three notebooks demonstrating how daily and monthly record highs, lows, and averages are calculated from NOAA CO-OPS weather and tide station data. The notebook follows sequentially from NOAA-CO-OPS-records in which we calculated record highs, lows, and averages from observational data for a particular NOAA CO-OPS weather and tide station. Daily and monthly records were written to netCDF files. Here we visualize these records as plots and as a colored dataframe.\nIn the previous notebook we calculated several records of interest:\n\nDaily and monthly averages\nRecord high daily and monthly averages*\nRecord low daily and monthly averages*\nAverage daily and monthly high\nLowest daily and monthly high*\nRecord daily and monthly high*\nAverage daily and monthly low\nHighest daily and monthly low*\nRecord daily and monthly low*\n\nFor those records marked with an asterisk (*), we also noted the year in which that particular record was set. Now let’s return to these statistics to visualize them.\n\nPackages and configurations\nAs always, we first import the packages we need. We will use Bokeh to make interactive plots and great_tables to display the data behind the plots in a visually appealing manner.\nTo better visualize the seasonality of daily and monthly averages, average highs, and average lows, we will fit a curve to the calculated averages and plot these curves instead of the actual values. This will be done with curve_fit from SciPy.\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom datetime import datetime as dt\nfrom scipy.optimize import curve_fit\nfrom scipy.interpolate import interp1d\nfrom great_tables import GT, loc, style\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nimport bokeh.models as bm\nimport xarray as xr\nimport pandas as pd\nimport numpy as np\nimport json\nimport sys\nimport os\noutput_notebook(hide_banner=True)\n\nsys.path.append('/workspaces/climatology/')\nfrom clipy import climo\n\n\n\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes some trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nLet’s define functions to plot the daily and monthly data. These two plots will be similar in appearance but have some differences (for example, the x axis), so two separate functions will be needed.\nFirst, we’ll need some helper functions. Some of these were used previously, while others are new:\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef round_down(num, divisor):\n    \"\"\"Round down to the nearest divisor. For example, round_down(45.5, 10)\n    will return 40. To round up to the nearest divisor, see `round_up`.\n\n    Parameters\n    ----------\n    num : float\n        Number to be rounded down\n    divisor : int\n        Divisor of num\n    \n    Returns\n    -------\n    Float resulting from `num - (num % divisor)`\n    \"\"\"\n    return num - (num%divisor)\n\ndef round_up(num, divisor):\n    \"\"\"Round up to the nearest divisor. For example, round_up(45.5, 10) will\n    return 50. To round down to the nearest divisor, see `round_down`.\n\n    Parameters\n    ----------\n    num : float\n        Number to be rounded up\n    divisor : int\n        Divisor of num\n    \n    Returns\n    -------\n    Float resulting from `num + (num % divisor)`\n    \"\"\"\n    return num + (divisor - (num%divisor))\n\ndef cos_fit(data):\n    \"\"\"Fit cosine curve to data\n    \n    Parameters\n    ----------\n    data : list or 1d array of data to be fit\n\n    Returns\n    -------\n    Array of fitted values\n    \"\"\"\n    X = np.arange(0, len(data))/len(data)\n\n    # Initial parameter values\n    guess_freq = 1\n    guess_amplitude = 3*np.std(data)/(2**0.5)\n    guess_phase = 0\n    guess_offset = np.mean(data)\n    p0 = [guess_freq, guess_amplitude,\n          guess_phase, guess_offset]\n\n    # Function to fit\n    def my_cos(x, freq, amplitude, phase, offset):\n        return np.cos(x * freq + phase) * amplitude + offset\n\n    # Fit curve to data\n    fit = curve_fit(my_cos, X, data, p0=p0)\n    \n    return my_cos(np.array(X), *fit[0])\n    \n\nDefining all of the colors in a dictionary will make it easier to customize everything later and will clean up the plotting codes. Below is a dictionary of three color schemes: “mg” are my chosen colors, “bm” colors are the same color scheme as Brian McNoldy’s figures on his website, and “cb” are colorblind-friendly colors.\n\n# Color dictionary\n# https://www.tutorialrepublic.com/css-reference/css-color-names.php\ncolors = dict(\n    mg=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': '#F5F5F5',\n        'Monthly Average': '#F5F5F5',\n        'Record High Daily Average': '#ff8080',\n        'Record High Daily Average Year': '#ff8080',\n        'Record High Monthly Average': '#ff8080',\n        'Record High Monthly Average Year': '#ff8080',\n        'Record Low Daily Average': '#c1d5f8',\n        'Record Low Daily Average Year': '#c1d5f8',\n        'Record Low Monthly Average': '#c1d5f8',\n        'Record Low Monthly Average Year': '#c1d5f8',\n        'Average High': '#dc8d8d',\n        'Lowest High': '#e6aeae',\n        'Lowest High Year': '#e6aeae',        \n        'Record High': '#d26c6c',\n        'Record High Year': '#d26c6c',\n        'Average Low': '#a2bff4',\n        'Highest Low': '#d1dffa',\n        'Highest Low Year': '#d1dffa',\n        'Record Low': '#74a0ef',\n        'Record Low Year': '#74a0ef',\n        'Years': 'white',\n        'Plot Light Color': '#D3D3D3'}),\n    bm=dict({\n        'Date': 'white',\n        'Month': 'white',\n        'Daily Average': 'gainsboro',\n        'Monthly Average': 'gainsboro',\n        'Record High Daily Average': 'mistyrose',\n        'Record High Daily Average Year': 'mistyrose',\n        'Record High Monthly Average': 'mistyrose',\n        'Record High Monthly Average Year': 'mistyrose',\n        'Record Low Daily Average': 'lavender',\n        'Record Low Daily Average Year': 'lavender',\n        'Record Low Monthly Average': 'lavender',\n        'Record Low Monthly Average Year': 'lavender',\n        'Average High': 'orangered',\n        'Lowest High': 'darkorange',\n        'Lowest High Year': 'darkorange',        \n        'Record High': 'orange',\n        'Record High Year': 'orange',\n        'Average Low': 'mediumpurple',\n        'Highest Low': 'navyblue',\n        'Highest Low Year': 'navyblue',\n        'Record Low': 'lightblue',\n        'Record Low Year': 'lightblue',\n        'Years': 'white',\n        'Plot Light Color': 'white'}),\n    cb=dict({\n        'Date': '#f9f9f9',\n        'Month': '#f9f9f9',\n        'Daily Average': '#F5F5F5',\n        'Monthly Average': '#F5F5F5',\n        'Record High Daily Average': '#d75f4c',\n        'Record High Daily Average Year': '#d75f4c',\n        'Record High Monthly Average': '#d75f4c',\n        'Record High Monthly Average Year': '#d75f4c',\n        'Record Low Daily Average': '#3a93c3',\n        'Record Low Daily Average Year': '#3a93c3',\n        'Record Low Monthly Average': '#3a93c3',\n        'Record Low Monthly Average Year': '#3a93c3',\n        'Average High': '#f6a482',\n        'Lowest High': '#fedbc7',\n        'Lowest High Year': '#fedbc7',        \n        'Record High': '#b31529',\n        'Record High Year': '#b31529',\n        'Average Low': '#8ec4de',\n        'Highest Low': '#d1e5f0',\n        'Highest Low Year': '#d1e5f0',\n        'Record Low': '#1065ab',\n        'Record Low Year': '#1065ab',\n        'Years': '#f9f9f9',\n        'Plot Light Color': '#f9f9f9'})\n    )\n\nThe plots will be made using Bokeh for interactivity. Consequently, there are many steps involved in building and formatting the plot with the desired functionality. We will plot daily/monthly averages, average highs, and average lows as curves; record highs and record lows as points; and will highlight records set this year for emphasis. The plot will also contain a legend and a hoverbox that displays the values of each series for a given date when one hovers the mouse pointer over the plot. The functions below will be used to generate daily and monthly climatology plots, and comments within the functions explain what each step does.\nNote that daily_climo also supports showing flood thresholds when used to plot water level data. These thresholds need to be retrieved for each site and passed as a dictionary, for example:\n\nflood_thresholds = {\n    'major': 2.5,\n    'moderate': 1.7,\n    'minor': 1.3\n    }\n\n\ndef config_plot(p, scheme='cb'):\n    \"\"\"Configure Bokeh plot for website\n\n    Parameters\n    ----------\n    p : Bokeh Figure class\n    scheme : {'mg', 'bm', 'cb}\n        Specifies which color scheme to use: 'mg' for M. Grossi's, 'bm' for\n        B. McNoldy's, or 'cb' to use a colorblind scheme. Defaults to 'mg'.\n    \"\"\"\n\n    # Plot properties\n    p.background_fill_color = '#404040'\n    p.border_fill_color = '#404040'\n    p.width = 1000\n    p.outline_line_color = None\n    p.sizing_mode = 'scale_height'\n\n    # x-axis\n    p.xgrid.grid_line_color = None\n    p.xaxis.axis_line_color = 'grey'\n    p.xaxis.major_tick_line_color = 'grey'\n        \n    # y-axis\n    p.yaxis.axis_label_text_color = colors[scheme]['Plot Light Color']\n    p.ygrid.grid_line_color = 'grey'\n    p.yaxis.axis_line_color = None\n    p.yaxis.major_tick_line_color = None\n    p.yaxis.minor_tick_line_color = None\n    p.outline_line_color = None\n\n    # Fonts\n    p.title.text_font = 'arial narrow'\n    p.title.text_font_size = '16px'\n    p.title.text_color = 'darkgray'\n    p.xaxis.major_label_text_font = 'arial narrow'\n    p.xaxis.major_label_text_color = colors[scheme]['Plot Light Color']\n    p.xaxis.major_label_text_font_size = '14px'\n    p.yaxis.major_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font = 'arial narrow'\n    p.yaxis.axis_label_text_font_style = 'normal'\n    p.yaxis.major_label_text_color = colors[scheme]['Plot Light Color']    \n    p.yaxis.major_label_text_font_size = '14px'\n    p.yaxis.axis_label_text_font_size = '14px'\n\n\ndef daily_climo(data, var, flood_thresholds, scheme='cb'):\n    \"\"\"Create a daily climatology plot for environmental variable `var`\n    from `data`.\n    \n    Parameters\n    ----------\n        data : xarray\n            Data array containing climatological stats\n        var : str\n            One of the available environmental variables in `data`\n        flood_threshold : dict\n            Flood thresholds to add to water level plot\n        scheme : {'mg', 'bm', 'cb}\n            Specifies which color scheme to use: 'mg' for M. Grossi's, 'bm' for\n            B. McNoldy's, or 'cb' to use a colorblind scheme. Defaults to 'mg'.\n    \"\"\"\n\n    # Dates for x axis\n    df = data.sel(variable=var).to_dataframe().drop('variable', axis=1)\n    df['xdates'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D')\n    df['Average High Curve'] = cos_fit(df['Average High'])\n    df['Daily Average Curve'] = cos_fit(df['Daily Average'])\n    df['Average Low Curve'] = cos_fit(df['Average Low'])\n    \n    # Records this year\n    thisYear = pd.to_datetime('today').year\n    df['High Records'] = df['Record High'].where(df['Record High Year'] == thisYear)\n    df['Low Records'] = df['Record Low'].where(df['Record Low Year'] == thisYear)\n    source = bm.ColumnDataSource(df)\n    \n    # Create a new plot\n    ts_start = dt.strptime(data.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    ts_end = dt.strptime(data.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    p = figure(title=f'DATA RECORD: {ts_start} - {ts_end}',\n               x_axis_type='datetime', height=600,\n               y_range=(round_down(df['Record Low'].min(), 10),\n                        round_up(df['Record High'].max(), 10)),\n               tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen')\n\n    # This year record highs\n    hr = p.scatter(x='xdates', y='High Records', source=source,\n                   name=f'{thisYear} High Record', size=4, color='white',\n                   hover_fill_color='white', hover_alpha=0.5)\n    hr.level = 'overlay'\n    # This year record lows\n    lr = p.scatter(x='xdates', y='Low Records', source=source,\n                   name=f'{thisYear} Low Record', size=4, color='white',\n                   hover_fill_color='white', hover_alpha=0.5)\n    lr.level = 'overlay'\n    # Record highs\n    rh = p.scatter(x='xdates', y='Record High', source=source,\n                   name='Record High', size=2,\n                   color=colors[scheme]['Record High'])\n    # Average high\n    ah = p.line(x='xdates', y='Average High Curve', source=source,\n                name='Average High', width=3,\n                color=colors[scheme]['Average High'])\n    # Daily average\n    da = p.line(x='xdates', y='Daily Average Curve', source=source,\n                name='Daily Average', width=2,\n                color=colors[scheme]['Daily Average'])\n    # Average lows\n    al = p.line(x='xdates', y='Average Low Curve', source=source,\n                name='Average Low', width=3,\n                color=colors[scheme]['Average Low'])\n    # Record lows\n    rl = p.scatter(x='xdates', y='Record Low', source=source,\n                   name='Record Low', size=2,\n                   color=colors[scheme]['Record Low'])\n    config_plot(p)\n\n    # Flood thresholds (water level plot only)\n    if var=='Water Level':\n        for level, threshold in flood_thresholds.items():\n            hline = bm.Span(location=threshold, dimension='width',\n                         line_dash=[20,8], line_alpha=0.75,\n                         line_color='cadetblue', line_width=2)\n            p.renderers.extend([hline])\n            mytext = bm.Label(x=pd.to_datetime('2019-12-15'), y=threshold+0.1,\n                              text=f'{level} flood threshold'.upper(), text_color='cadetblue',\n                              text_font_size='8px',\n                              text_font='arial narrow')\n            p.add_layout(mytext)\n    \n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                              line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[da],\n                      formatters={'@xdates': 'datetime'})\n    units = data.attrs[f\"{var} units\"]\n    if var == 'Water Level':\n        hover.tooltips = \"\"\"\n            &lt;b&gt; @xdates{{%b %d}} &lt;/b&gt; &lt;br&gt;\n            Record High: @{{Record High}}{{0.00}} {u}&lt;br&gt;\n            Average High: @{{Average High Curve}}{{0.00}} {u}&lt;br&gt;\n            Daily Average: @{{Daily Average Curve}}{{0.00}} {u}&lt;br&gt;\n            Average Low: @{{Average Low Curve}}{{0.00}} {u}&lt;br&gt;\n            Record Low: @{{Record Low}}{{0.00}} {u}&lt;br&gt;\n            {y} High Record: @{{High Records}}{{0.00}} {u}&lt;br&gt;\n            {y} Low Record: @{{Low Records}}{{0.00}} {u}\n            \"\"\".format(u=units, y=thisYear)\n    else:\n        hover.tooltips = \"\"\"\n            &lt;b&gt; @xdates{{%b %d}} &lt;/b&gt; &lt;br&gt;\n            Record High: @{{Record High}}{{0.0}} {u}&lt;br&gt;\n            Average High: @{{Average High Curve}}{{0.0}} {u}&lt;br&gt;\n            Daily Average: @{{Daily Average Curve}}{{0.0}} {u}&lt;br&gt;\n            Average Low: @{{Average Low Curve}}{{0.0}} {u}&lt;br&gt;\n            Record Low: @{{Record Low}}{{0.0}} {u}&lt;br&gt;\n            {y} High Record: @{{High Records}}{{0.0}} {u}&lt;br&gt;\n            {y} Low Record: @{{Low Records}}{{0.0}} {u}\n            \"\"\".format(u=units, y=thisYear)\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n\n    # x-axis\n    p.xaxis[0].formatter = bm.DatetimeTickFormatter(months=\"%b %d\")\n    p.xaxis[0].ticker.desired_num_ticks = 12\n    \n    # y-axis\n    if var == 'Water Level':\n        p.yaxis.axis_label=f'{var} relative to {data.attrs[\"datum\"].upper()} ({data.attrs[f\"{var} units\"]})'\n    else:\n        p.yaxis.axis_label=f'{var} ({data.attrs[f\"{var} units\"]})'\n    ymin = round_down(df['Record Low'].min(), 10)\n    ymax = round_up(df['Record High'].max(), 10)\n    p.y_range = bm.Range1d(ymin, ymax, bounds=(ymin, ymax))\n    \n    # Legend\n    legend = bm.Legend(items=[\n        ('{} Record'.format(thisYear), [hr, lr]),\n        ('Record High', [rh]),\n        ('Average High', [ah]),\n        ('Daily Average', [da]),\n        ('Average Low', [al]),\n        ('Record Low', [rl])],\n                    background_fill_color='#404040', border_line_color=None,\n                    label_text_color=colors[scheme]['Plot Light Color'],\n                    location='center_right', click_policy='mute')\n    p.add_layout(legend, 'right')\n    show(p)\n\ndef monthly_climo(data, var, scheme='cb'):\n    \"\"\"Create a monthly climatology plot for environmental variable `var`\n    from `data`.\n    \n    Parameters\n    ----------\n        data : xarray\n            Data array containing climatological stats\n        var : str\n            One of the available environmental variables in `data`\n        flood_threshold : dict\n            Flood thresholds to add to water level plot\n        scheme : {'mg', 'bm', 'cb}\n            Specifies which color scheme to use: 'mg' for M. Grossi's, 'bm' for\n            B. McNoldy's, or 'cb' to use a colorblind scheme. Defaults to 'mg'.\n    \"\"\"\n\n    # Dates for x axis\n    df = data.sel(variable=var).to_dataframe().drop('variable', axis=1).reset_index()\n    df['Average High Curve'] = cos_fit(df['Average High'])\n    df['Monthly Average Curve'] = cos_fit(df['Monthly Average'])\n    df['Average Low Curve'] = cos_fit(df['Average Low'])\n    \n    # Record this year\n    thisYear = pd.to_datetime('today').year\n    df['High Records'] = df['Record High'].where(df['Record High Year'] == thisYear)\n    df['Low Records'] = df['Record Low'].where(df['Record Low Year'] == thisYear)\n    source = bm.ColumnDataSource(df)\n    \n    # Create a new plot\n    ts_start = dt.strptime(data.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    ts_end = dt.strptime(data.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    p = figure(title=f'DATA RECORD: {ts_start} - {ts_end}', height=600,\n               x_range=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n               y_range=(round_down(df['Record Low'].min(), 1), round_up(df['Record High'].max(), 1)),\n               tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen')\n\n    # This year record highs\n    hr = p.scatter(x='Month', y='High Records', source=source,\n                   name=f'{thisYear} High Record', size=7, color='white',\n                   hover_fill_color='white', hover_alpha=0.5)\n    hr.level = 'overlay'\n    # This year record lows\n    lr = p.scatter(x='Month', y='Low Records', source=source,\n                   name=f'{thisYear} Low Record', size=7, color='white',\n                   hover_fill_color='white', hover_alpha=0.5)\n    lr.level = 'overlay'\n    # Record highs\n    rh = p.scatter(x='Month', y='Record High', source=source,\n                   name='Record High', size=7,\n                   color=colors[scheme]['Record High'])\n    # Average high\n    ah = p.line(x='Month', y='Average High Curve', source=source,\n                name='Average High', width=4,\n                color=colors[scheme]['Average High'])\n    # Monthly average\n    ma = p.line(x='Month', y='Monthly Average Curve', source=source,\n                name='Monthly Average', width=3,\n                color=colors[scheme]['Monthly Average'])\n    # Average lows\n    al = p.line(x='Month', y='Average Low Curve', source=source,\n                name='Average Low', width=4,\n                color=colors[scheme]['Average Low'])\n    # Record lows\n    rl = p.scatter(x='Month', y='Record Low', source=source,\n                   name='Record Low', size=7,\n                   color=colors[scheme]['Record Low'])\n    config_plot(p)\n    \n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                              line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[ma],\n                      formatters={'@xdates': 'datetime'})\n    units = data.attrs[f\"{var} units\"]\n    if var == 'Water Level':\n        hover.tooltips = \"\"\"\n            &lt;b&gt; @Month &lt;/b&gt; &lt;br&gt;\n            Record High: @{{Record High}}{{0.00}} {u}&lt;br&gt;\n            Average High: @{{Average High Curve}}{{0.00}} {u}&lt;br&gt;\n            Monthly Average: @{{Monthly Average Curve}}{{0.00}} {u}&lt;br&gt;\n            Average Low: @{{Average Low Curve}}{{0.00}} {u}&lt;br&gt;\n            Record Low: @{{Record Low}}{{0.00}} {u}&lt;br&gt;\n            {y} High Record: @{{High Records}}{{0.00}} {u}&lt;br&gt;\n            {y} Low Record: @{{Low Records}}{{0.00}} {u}\n            \"\"\".format(u=units, y=thisYear)\n    else:\n        hover.tooltips = \"\"\"\n            &lt;b&gt; @Month &lt;/b&gt; &lt;br&gt;\n            Record High: @{{Record High}}{{0.0}} {u}&lt;br&gt;\n            Average High: @{{Average High Curve}}{{0.0}} {u}&lt;br&gt;\n            Monthly Average: @{{Monthly Average Curve}}{{0.0}} {u}&lt;br&gt;\n            Average Low: @{{Average Low Curve}}{{0.0}} {u}&lt;br&gt;\n            Record Low: @{{Record Low}}{{0.0}} {u}&lt;br&gt;\n            {y} High Record: @{{High Records}}{{0.0}} {u}&lt;br&gt;\n            {y} Low Record: @{{Low Records}}{{0.0}} {u}\n            \"\"\".format(u=units, y=thisYear)\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n    \n    # y-axis\n    if var == 'Water Level':\n        p.yaxis.axis_label=f'{var} relative to {data.attrs[\"datum\"].upper()} ({data.attrs[f\"{var} units\"]})'\n    else:\n        p.yaxis.axis_label=f'{var} ({data.attrs[f\"{var} units\"]})'\n    \n    # Legend\n    legend = bm.Legend(items=[\n        ('{} Record'.format(thisYear), [hr, lr]),\n        ('Record High', [rh]),\n        ('Average High', [ah]),\n        ('Monthly Average', [ma]),\n        ('Average Low', [al]),\n        ('Record Low', [rl])],\n                    background_fill_color='#404040', border_line_color=None,\n                    label_text_color=colors[scheme]['Plot Light Color'],\n                    location='center_right', click_policy='mute')\n    p.add_layout(legend, 'right')\n    show(p)\n\ndef histograms(stats, var, y_range=None, scheme='cb'):\n    \"\"\"Plot histograms of record counts per year\n\n    Paramaters\n    ----------\n    stats : xarray\n        xarray containing daily or monthly records for a CO-OPS station,\n        arranged with years as rows and record as columns\n    var : str\n        Name of variable to be plotted. Must be in `stats`.\n    y_range : list or tuple of length 2\n        List of tuple containing the lower and upper bounds of the y-axis to be displayed. These are create scroll limits for interactivity.\n    scheme : {'mg', 'bm', 'cb}\n        Specifies which color scheme to use: 'mg' for M. Grossi's, 'bm' for\n        B. McNoldy's, or 'cb' to use a colorblind scheme. Defaults to 'mg'.\n    \"\"\"\n    data = record_counts(data=stats, var=var)\n    # Create histogram for each record\n    for col in data.columns:\n        if col != 'Year':\n\n            # Create plot\n            p = figure(x_range=data['Year'], tooltips=\"@Year: @$name\", height=400,\n                       tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n                       title=f'Distribution of {col.lower()}s'.upper())\n            bars = p.vbar(x='Year', top=col, source=data,\n                          name=col, color=colors[scheme][col], alpha=0.85)\n            config_plot(p, scheme=scheme)\n            p.title.text_font_size = '20px'\n\n            # x-axis\n            p.xaxis.major_label_orientation = 45\n            p.x_range.range_padding = 0.05\n\n            # y-axis\n            p.yaxis.axis_label='Number of Records Set'\n            p.y_range.start = 0\n            p.yaxis.axis_label='Number of Records'\n            if y_range is not None:\n                p.y_range = bm.Range1d(min(y_range), max(y_range),\n                                       bounds=(min(y_range), max(y_range)))\n            show(p)\n\ndef trend(data, var, scheme='cb', true_average=False, fname=None):\n    \"\"\"Plot time series trend\n\n    Parameters\n    ----------\n    data : pyclimo Data object\n        Data object containing observational data for a CO-OPS station\n    var : str\n        Name of the variable to regress. Must be in climatology dataset.\n    scheme : {'mg', 'bm', 'cb}\n        Specifies which color scheme to use: 'mg' for M. Grossi's, 'bm' for\n        B. McNoldy's, or 'cb' to use a colorblind scheme. Defaults to 'mg'.\n    true_average : Bool\n        If True, all measurements from each 24-hour day will be used to calculate the\n        average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    fname : str or None\n        File name with directory to be written out, if provided. If None, plot will be displayed instead. Defaults to None.\n    \"\"\"\n \n    # Monthly averages\n    dailyAvgs = data.mon_daily_avgs(true_average=true_average)[var]\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\n    df = pd.DataFrame(monthlyAvgs)\n    df = df.loc[df.first_valid_index():]\n    \n    # Linearly interpret missing data\n    df['rownum'] = np.arange(df.shape[0])\n    col = df.columns.values[0]\n    df_nona = df.dropna(subset = [col])\n    f = interp1d(df_nona['rownum'], df_nona[col])\n    df['linear_fill'] = f(df['rownum'])\n\n    # Normalize time series to deseasonalize\n    tsMin = df['linear_fill'].min()\n    tsMax = df['linear_fill'].max()\n    tseries_norm = (df['linear_fill'] - tsMin) / (tsMax - tsMin)\n\n    # Deseasonalize time series and un-normalize\n    components = seasonal_decompose(tseries_norm, model='additive', period=4)\n    deseasoned = tseries_norm - components.seasonal\n    df['deseasoned'] = (deseasoned * (tsMax - tsMin)) + tsMin\n\n    # Apply linear regression\n    coef = np.polyfit(df['rownum'], df['deseasoned'], 1)\n    slope = coef[0] # height/mon\n    poly1d_fn = np.poly1d(coef)\n    df['linear_reg'] = poly1d_fn(df['rownum'])\n    mask = ~df[var].isna()\n    masked = np.ma.masked_where(df[var].isna(), df['deseasoned'])\n    \n    # Create plot\n    df.index.name = 'xdates'\n    ts_start = df.index.min().strftime('%-m/%-d/%Y')\n    ts_end = df.index.max().strftime('%-m/%-d/%Y')\n    source = bm.ColumnDataSource(df.reset_index())\n    p = figure(title=f'RELATIVE {var.upper()} TREND: {ts_start} - {ts_end}\\n'+\n                     f'{np.round(slope*12, 4)} {data.units[var]}/yr or {np.round(slope*12*100, 2)} {data.units[var]} in 100 years',\n                background_fill_color='#404040', border_fill_color='#404040',\n                width=1000, height=400, x_axis_type='datetime',\n                tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n                outline_line_color=None, sizing_mode='scale_height')\n\n    # Data with regression line\n    sct = p.line(x='xdates', y=var, source=source, name='Monthly Average',\n                color=colors['mg']['Plot Light Color'], alpha=0.5)\n    sct.level = 'overlay'\n    reg = p.line(x='xdates', y='linear_reg', source=source, name='Trend',\n                color=colors['mg']['Record Low'], line_width=5)\n    reg.level = 'overlay'\n    config_plot(p)\n\n    # Tools\n    crosshair = bm.CrosshairTool(dimensions='height',\n                                line_color='grey', line_alpha=0.5)\n    hover = bm.HoverTool(mode='vline', renderers=[sct],\n                        formatters={'@xdates': 'datetime'})\n    hover.tooltips = f\"\"\"\n    &lt;b&gt; @xdates{{%b %Y}} &lt;/b&gt; &lt;br&gt;\n    Monthly Average: @{{Water Level}}{{0.00}} {data.units[var]}\n    \"\"\"\n    p.add_tools(hover, crosshair)\n    p.toolbar.autohide = True\n\n    # y-axis\n    p.yaxis.axis_label = f'Monthly average {var.lower()} relative to {data.datum}'\n    if max(df[var]) &lt; 0:\n        p.y_range = bm.Range1d(-max(abs(df[var]))-0.5, 0.45,\n                                bounds=(-max(abs(df[var]))-0.5, 0.45))\n    \n    # Save or display\n    if fname is not None:\n        from bokeh.io import output_file\n        from bokeh.plotting import save\n        output_file(fname)\n        save(p)\n    else:\n        show(p)\n\n\n\nLoading data\nNow we need to load in the records for the desired station, which will be used to determine the directory from which to load the data. As before, stationname is the custom human-readable “City, ST” string for the station.\n\nstationname = 'Virginia Key, FL'\n\nDerive the local directory name containing the data from the station name. This is the same way the directory was created when the data were downloaded.\n\ndirname = camel(stationname)\noutdir = '../'+dirname\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: ../virginiaKeyFl\n\n\nNext, load the data and metadata.\n\n# Records\ndays = xr.load_dataset(os.path.join(outdir, 'statistics-daily.nc'))\nmons = xr.load_dataset(os.path.join(outdir, 'statistics-monthly.nc'))\n\nAnd finally, we can make some plots. Let’s look at daily and monthly climatology for Air Temperature.\n\n\nRecords\n\nvar = 'Air Temperature'\ndaily_climo(data=days, var=var, flood_thresholds=flood_thresholds, scheme='cb')\n\n\n  \n\n\n\n\n\n\nmonthly_climo(data=mons, var=var, scheme='cb')\n\n\n  \n\n\n\n\n\nNotice that for the average high, average low, and daily/monthly average, we fit a cosine curve to the data and plot this instead. This is but one of many possible ways to illustrate these data.\n\n\nRecord Counts\nWe can also consider the number of records held by each year in the time series. Let’s demonstrate daily air temperature record counts here. Start by creating a data frame and count the number of times each year appears.\n\n# Dataframe\nstats = days.sel(variable=var).to_dataframe()\nstats = stats[stats.columns[stats.columns.str.endswith('Year')]]\n\n# Value counts for each year\ncounts = stats.stack().groupby(level=[1]).value_counts().unstack().T.fillna(0)\ncounts\n\n\n\n\n\n\n\n\nHighest Low Year\nLowest High Year\nRecord High Daily Average Year\nRecord High Year\nRecord Low Daily Average Year\nRecord Low Year\n\n\n\n\n1994\n13.0\n13.0\n10.0\n8.0\n14.0\n11.0\n\n\n1995\n2.0\n25.0\n3.0\n9.0\n21.0\n19.0\n\n\n1996\n2.0\n29.0\n0.0\n4.0\n26.0\n26.0\n\n\n1997\n1.0\n8.0\n1.0\n4.0\n16.0\n20.0\n\n\n1998\n23.0\n12.0\n26.0\n11.0\n9.0\n8.0\n\n\n1999\n3.0\n21.0\n3.0\n7.0\n24.0\n20.0\n\n\n2000\n0.0\n24.0\n0.0\n2.0\n20.0\n17.0\n\n\n2001\n5.0\n33.0\n4.0\n5.0\n23.0\n13.0\n\n\n2002\n7.0\n8.0\n12.0\n11.0\n8.0\n8.0\n\n\n2003\n22.0\n11.0\n15.0\n16.0\n9.0\n6.0\n\n\n2004\n3.0\n14.0\n2.0\n2.0\n9.0\n7.0\n\n\n2005\n3.0\n8.0\n3.0\n3.0\n7.0\n12.0\n\n\n2006\n3.0\n17.0\n0.0\n2.0\n18.0\n17.0\n\n\n2007\n10.0\n21.0\n5.0\n6.0\n14.0\n10.0\n\n\n2009\n9.0\n10.0\n10.0\n16.0\n15.0\n13.0\n\n\n2010\n7.0\n32.0\n6.0\n7.0\n40.0\n37.0\n\n\n2011\n4.0\n6.0\n1.0\n5.0\n4.0\n9.0\n\n\n2012\n1.0\n21.0\n3.0\n4.0\n18.0\n14.0\n\n\n2013\n9.0\n20.0\n6.0\n11.0\n16.0\n19.0\n\n\n2014\n10.0\n5.0\n13.0\n8.0\n10.0\n17.0\n\n\n2015\n36.0\n4.0\n36.0\n27.0\n6.0\n6.0\n\n\n2016\n13.0\n1.0\n9.0\n10.0\n5.0\n7.0\n\n\n2017\n13.0\n6.0\n14.0\n13.0\n6.0\n14.0\n\n\n2018\n12.0\n4.0\n8.0\n18.0\n8.0\n8.0\n\n\n2019\n0.0\n1.0\n0.0\n2.0\n1.0\n0.0\n\n\n2020\n39.0\n2.0\n45.0\n29.0\n3.0\n4.0\n\n\n2021\n16.0\n3.0\n19.0\n23.0\n4.0\n6.0\n\n\n2022\n42.0\n1.0\n45.0\n31.0\n4.0\n6.0\n\n\n2023\n27.0\n2.0\n32.0\n49.0\n5.0\n8.0\n\n\n2024\n20.0\n3.0\n29.0\n20.0\n2.0\n3.0\n\n\n2025\n11.0\n1.0\n6.0\n3.0\n1.0\n1.0\n\n\n\n\n\n\n\nResort the rows and columns after the unstack and restructure for plotting.\n\n# Resort rows and columns\ncounts = counts.reindex(range(min(counts.index), max(counts.index)+1), fill_value=0)\ncounts = counts[stats.columns[stats.columns.str.endswith('Year')]]\n\n# Restructure\ncounts.columns = [i.replace(' Year', '') for i in counts.columns]\ncounts.index.name = 'Year'\ncounts.index = counts.index.astype(str)\ncounts.reset_index(inplace=True)\ncounts\n\n\n\n\n\n\n\n\nYear\nRecord High Daily Average\nRecord Low Daily Average\nLowest High\nRecord High\nHighest Low\nRecord Low\n\n\n\n\n0\n1994\n10.0\n14.0\n13.0\n8.0\n13.0\n11.0\n\n\n1\n1995\n3.0\n21.0\n25.0\n9.0\n2.0\n19.0\n\n\n2\n1996\n0.0\n26.0\n29.0\n4.0\n2.0\n26.0\n\n\n3\n1997\n1.0\n16.0\n8.0\n4.0\n1.0\n20.0\n\n\n4\n1998\n26.0\n9.0\n12.0\n11.0\n23.0\n8.0\n\n\n5\n1999\n3.0\n24.0\n21.0\n7.0\n3.0\n20.0\n\n\n6\n2000\n0.0\n20.0\n24.0\n2.0\n0.0\n17.0\n\n\n7\n2001\n4.0\n23.0\n33.0\n5.0\n5.0\n13.0\n\n\n8\n2002\n12.0\n8.0\n8.0\n11.0\n7.0\n8.0\n\n\n9\n2003\n15.0\n9.0\n11.0\n16.0\n22.0\n6.0\n\n\n10\n2004\n2.0\n9.0\n14.0\n2.0\n3.0\n7.0\n\n\n11\n2005\n3.0\n7.0\n8.0\n3.0\n3.0\n12.0\n\n\n12\n2006\n0.0\n18.0\n17.0\n2.0\n3.0\n17.0\n\n\n13\n2007\n5.0\n14.0\n21.0\n6.0\n10.0\n10.0\n\n\n14\n2008\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n15\n2009\n10.0\n15.0\n10.0\n16.0\n9.0\n13.0\n\n\n16\n2010\n6.0\n40.0\n32.0\n7.0\n7.0\n37.0\n\n\n17\n2011\n1.0\n4.0\n6.0\n5.0\n4.0\n9.0\n\n\n18\n2012\n3.0\n18.0\n21.0\n4.0\n1.0\n14.0\n\n\n19\n2013\n6.0\n16.0\n20.0\n11.0\n9.0\n19.0\n\n\n20\n2014\n13.0\n10.0\n5.0\n8.0\n10.0\n17.0\n\n\n21\n2015\n36.0\n6.0\n4.0\n27.0\n36.0\n6.0\n\n\n22\n2016\n9.0\n5.0\n1.0\n10.0\n13.0\n7.0\n\n\n23\n2017\n14.0\n6.0\n6.0\n13.0\n13.0\n14.0\n\n\n24\n2018\n8.0\n8.0\n4.0\n18.0\n12.0\n8.0\n\n\n25\n2019\n0.0\n1.0\n1.0\n2.0\n0.0\n0.0\n\n\n26\n2020\n45.0\n3.0\n2.0\n29.0\n39.0\n4.0\n\n\n27\n2021\n19.0\n4.0\n3.0\n23.0\n16.0\n6.0\n\n\n28\n2022\n45.0\n4.0\n1.0\n31.0\n42.0\n6.0\n\n\n29\n2023\n32.0\n5.0\n2.0\n49.0\n27.0\n8.0\n\n\n30\n2024\n29.0\n2.0\n3.0\n20.0\n20.0\n3.0\n\n\n31\n2025\n6.0\n1.0\n1.0\n3.0\n11.0\n1.0\n\n\n\n\n\n\n\nNow the rows are sorted monotonically by year, the column names indicate the record, and the table values are the number of times each year appears in the record. Thus, we are finally ready to create a histogram for each record:\n\nfor col in counts.columns:\n    if col != 'Year':\n\n        # Create plot\n        p = figure(x_range=counts['Year'], tooltips=\"@Year: @$name\", height=400,\n                    tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n                    title=f'Distribution of {col.lower()}s'.upper())\n        bars = p.vbar(x='Year', top=col, source=counts,\n                        name=col, color=colors['cb'][col], alpha=0.85)\n        config_plot(p, scheme='cb')\n        p.title.text_font_size = '20px'\n\n        # x-axis\n        p.xaxis.major_label_orientation = 45\n        p.x_range.range_padding = 0.05\n\n        # y-axis\n        p.yaxis.axis_label='Number of Records Set'\n        p.y_range.start = 0\n        p.yaxis.axis_label='Number of Records'\n        show(p)\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\nThe website shows similar histograms of monthly record counts, made in exactly the same way.\n\n\nWater Level Trend\nWater level data are the only data that are quality controlled and, in many locations, the time series span several decades, making it possible to discern trends. To do this, we need to read in the full data record.\n\nos.chdir('..')\nwith open('stations.json', 'r') as f:\n    stationlist = json.load(f)\n    \ndata = climo.Data(stationname=stationname, stationid=stationlist[stationname])\n\nLoading metadata from file\nLoading historical data from file\nLoading daily statistics from file\nLoading monthly statistics from file\nFiltering observational data\nDone!\n\n\nNow we calculate monthly averages for each month in the time series.\n\nvar = 'Water Level'\ndailyAvgs = data.mon_daily_avgs(true_average=False)[var]\nmonthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\ndf = pd.DataFrame(monthlyAvgs)\ndf = df.loc[df.first_valid_index():df.last_valid_index()]\n\nNext, we fill in missing data gaps by applying a simple linear interpretation.\n\ndf['rownum'] = np.arange(df.shape[0])\ncol = df.columns.values[0]\ndf_nona = df.dropna(subset = [col])\nf = interp1d(df_nona['rownum'], df_nona[col])\ndf['linear_fill'] = f(df['rownum'])\n\nIn order to apply a linear regression, we need to remove the seasonal signal from the time series to extract the long term trend. But first, we normalize the time series.\n\n# Normalize time series to deseasonalize\ntsMin = df['linear_fill'].min()\ntsMax = df['linear_fill'].max()\ntseries_norm = (df['linear_fill'] - tsMin) / (tsMax - tsMin)\n\n\n# Deseasonalize time series and un-normalize\ncomponents = seasonal_decompose(tseries_norm, model='additive', period=4)\ndeseasoned = tseries_norm - components.seasonal\ndf['deseasoned'] = (deseasoned * (tsMax - tsMin)) + tsMin\n\n\n# Apply linear regression\ncoef = np.polyfit(df['rownum'], df['deseasoned'], 1)\nslope = coef[0] # height/mon\npoly1d_fn = np.poly1d(coef)\ndf['linear_reg'] = poly1d_fn(df['rownum'])\nmask = ~df[var].isna()\nmasked = np.ma.masked_where(df[var].isna(), df['deseasoned'])\n\nFinally, let’s make the plot:\n\n# Create plot\ndf.index.name = 'xdates'\nts_start = df.index.min().strftime('%-m/%-d/%Y')\nts_end = df.index.max().strftime('%-m/%-d/%Y')\nsource = bm.ColumnDataSource(df.reset_index())\np = figure(title=f'RELATIVE {var.upper()} TREND: {ts_start} - {ts_end}\\n'+\n                    f'{np.round(slope*12, 4)} {data.units[var]}/yr or {np.round(slope*12*100, 2)} {data.units[var]} in 100 years',\n            background_fill_color='#404040', border_fill_color='#404040',\n            width=1000, height=600, x_axis_type='datetime',\n            tools='pan, wheel_zoom, box_zoom, undo, reset, fullscreen',\n            outline_line_color=None, sizing_mode='scale_height')\n\n# Data with regression line\nsct = p.line(x='xdates', y=var, source=source, name='Monthly Average',\n            color=colors['mg']['Plot Light Color'], alpha=0.5)\nsct.level = 'overlay'\nreg = p.line(x='xdates', y='linear_reg', source=source, name='Trend',\n            color=colors['mg']['Record Low'], line_width=5)\nreg.level = 'overlay'\nconfig_plot(p)\n\n# Tools\ncrosshair = bm.CrosshairTool(dimensions='height',\n                            line_color='grey', line_alpha=0.5)\nhover = bm.HoverTool(mode='vline', renderers=[sct],\n                    formatters={'@xdates': 'datetime'})\nhover.tooltips = f\"\"\"\n&lt;b&gt; @xdates{{%b %Y}} &lt;/b&gt; &lt;br&gt;\nMonthly Average: @{{Water Level}}{{0.00}} {data.units[var]}\n\"\"\"\np.add_tools(hover, crosshair)\np.toolbar.autohide = True\n\n# y-axis\np.yaxis.axis_label = f'Monthly average {var.lower()} relative to {data.datum}'\nif max(df[var]) &lt; 0:\n    p.y_range = bm.Range1d(-max(abs(df[var]))-0.5, 0.45,\n                            bounds=(-max(abs(df[var]))-0.5, 0.45))\n\nshow(p)\n\n\n  \n\n\n\n\n\n\n\nData Table\nOne may wish to see the data behind these plots, or see the other records not plotted. We will use the great_tables library to display colored tables. We’ll demonstrate this below for Air Temperature.\ngreat_tables displays dataframes, so we first need to extract the data from the xarray object, convert to a Pandas datarame, and reset the index.\n\ndef getrows(record):\n    thisyear = dt.today().year\n    return df[(df[record] == thisyear)].index.to_list()\n\ndef getcols(record):\n    return [record.replace(' Year', ''), record]\n\ndf = mons.sel(variable=var.title()).to_dataframe().drop('variable', axis=1).round(2).reset_index()\n\nIt is helpful to highly records set this year, so let’s find those in the dataframe.\n\n# Data record\nts_start = dt.strptime(mons.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\nts_end = dt.strptime(mons.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n\n# Records this year\nthisYear = pd.to_datetime('today').year\ncols = df.columns[df.columns.str.endswith('Year')]\nthisYearRecords = (df==thisYear)[cols].sum().sum()\nlastYearRecords = (df==thisYear-1)[cols].sum().sum()\n\nNow create the table and add the columns. We also specify any formatting of each column here including the colors, which is taken from the color dictionary above.\n\ngtbl = GT(stats)\nfor column in stats.columns:\n    gtbl = gtbl.tab_style(style=[style.fill(color=colors['cb'][column]), style.text(v_align='middle')], locations=loc.body(columns=column))\n\nFinally, format the rest of the table, including text alignment, font, header formatting, and title. We also show the records set this year in bold to make them stand out.\n\ngtbl = (gtbl\n.cols_align(align='center')\n.tab_style(style=[style.text(color='gainsboro', weight='bold'), style.fill(color='dimgray')], locations=loc.column_header())\n.tab_options(table_font_size='13px', \n             table_body_hlines_color='white',\n             heading_align='left',\n             heading_title_font_weight='bold',\n             heading_background_color='gainsboro')\n.tab_header(title=\"\"\"As of today, {} {} record observations have been reported this year. Last year, {} records were reported.\"\"\".format(thisYearRecords, var.lower(), lastYearRecords),\n            subtitle='DATA RECORD: {} - {}'.format(ts_start, ts_end))\n)\n\n# Bolden records this year\nfor record in df.columns[df.columns.str.endswith('Year')]:\n    gtbl = gtbl.tab_style(\n        style = style.text(weight='bold'),\n        locations = loc.body(columns=getcols(record), rows=getrows(record)))\n\ngtbl.show()\n\n\n\n\n\n\n\nAs of today, 0 air temperature record observations have been reported this year. Last year, 4 records were reported.\n\n\nDATA RECORD: 2/1/1994 - 5/30/2025\n\n\nMonth\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\n\n\nJan\n68.66\n72.57\n2013\n63.04\n2001\n76.05\n72.95\n2011\n78.05\n2022\n55.55\n63.5\n2013\n48.3\n1997\n23\n\n\nFeb\n70.89\n74.9\n2018\n65.47\n1996\n76.49\n74.2\n2000\n78.55\n2021\n59.36\n70.0\n2018\n47.9\n1996\n24\n\n\nMar\n72.27\n77.62\n2003\n66.08\n2010\n78.49\n74.15\n2010\n82.85\n2003\n63.33\n72.0\n1997\n55.1\n1996\n25\n\n\nApr\n75.63\n79.38\n2020\n72.81\n2004\n80.74\n77.3\n2004\n85.8\n2020\n68.4\n72.6\n2015\n61.2\n2009\n25\n\n\nMay\n78.73\n81.93\n2024\n76.97\n2007\n82.48\n79.35\n2007\n87.25\n2024\n73.95\n77.1\n2003\n67.95\n1999\n26\n\n\nJun\n81.54\n83.61\n2010\n79.84\n2014\n84.75\n82.75\n2014\n87.65\n2009\n77.64\n80.75\n2004\n75.1\n1995\n21\n\n\nJul\n82.91\n85.0\n2023\n80.98\n2013\n85.79\n84.2\n2012\n88.7\n2018\n79.02\n82.3\n2022\n76.1\n2013\n26\n\n\nAug\n83.3\n85.91\n2022\n81.82\n1994\n85.85\n84.05\n2003\n88.5\n2022\n79.51\n83.55\n2022\n77.0\n1994\n24\n\n\nSep\n82.09\n83.74\n2024\n80.57\n2001\n85.17\n83.9\n2000\n86.7\n2021\n78.34\n81.6\n2024\n74.3\n2001\n25\n\n\nOct\n79.63\n81.24\n2020\n77.55\n2000\n83.81\n80.95\n2010\n86.75\n2023\n72.88\n77.8\n2020\n64.6\n2005\n24\n\n\nNov\n75.04\n78.62\n2015\n71.37\n2012\n79.84\n76.9\n2012\n82.05\n2020\n65.97\n74.45\n2020\n57.35\n2006\n24\n\n\nDec\n71.43\n76.87\n2015\n62.1\n2010\n77.47\n72.5\n2010\n79.65\n1994\n59.41\n70.5\n2015\n48.75\n2010\n25\n\n\n\n\n\n\n\n\nAnd there we have it! All of the records for each month, color coded for easier reading.\nSome concluding remarks on the choice of packages here. Another common Python library for making interactive plots is Plotly. I tried this first (see below) but encountered a known issue with rendering Plotly plots in Quarto web dashboards. In short, the first time Plotly is called in a web application, the plot renders to the proper size of the web container, but subsequent calls to Plotly (like navigating to a new tab or page) do not size figures properly. The workaround demonstrated here fixed the width rendering, but all of the resulting plots were only half the height of the container/page. Plotly also supports displaying colored tables, but these experienced the same rendering issue with Quarto. Cue Bokeh. This library did not have the rendering problem, although the plots had slighly less interactivity than the Plotly versions. Creating colored tables with Bokeh, however, turned out to be frustratingly difficult and very poorly documented. For example, Bokeh tables are colored using HTML, but there was no documentation on how to color an entire column of data. In contrast, the library great_tables made this easy, although it too currently lacks the full interactivity that Plotly offered (e.g., sorting by column).\n\nThe following is a Plotly version of the daily climatology plot above. It is basically the same but supports some behaviors that, so far, are not possible (or much harder to accomplish) with Bokeh, such as only showing records in the hoverbox on days when a record is set.\n\nimport plotly.graph_objects as go\n\n\ndef daily_climo(data, var, scheme='mg'):\n    \"\"\"Create a daily climatology plot for environmental variable 'var'\n    from 'data'.\n    \n    Inputs:\n        data: xarray containing climatological stats\n        var: str, one of the available environmental variables in 'data'\n        scheme: str, either 'mg' or 'bm' specifying whether to use M. Grossi's\n            color scheme or B. McNoldy's\n        show: Bool, display the plot to screen instead of saving to file\n    \"\"\"\n\n    # Dates for x axis\n    xdates = pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D')\n    df = data.sel(variable=var)\n    \n    # Color dictionary\n    colors = dict(\n        mg=dict({\n            'Record High Year': 'white',\n            'Record High': '#d26c6c',\n            'Average High': '#dc8d8d',\n            'Daily Average': '#F5F5F5',\n            'Average Low': '#a2bff4',\n            'Record Low': '#74a0ef',\n            'Record Low Year': 'white'}),\n        bm=dict({\n            'Record High Year': 'white',\n            'Record High': 'orange',\n            'Average High': 'red',\n            'Daily Average': 'grey',\n            'Average Low': 'purple',\n            'Record Low': 'white'}        \n        ))\n    \n    # Create figure\n    fig = go.Figure()\n\n    # Record highs\n    # High records this year\n    thisYear = pd.to_datetime('today').year\n    thisYearRecords = (df==thisYear).to_dataframe().drop('variable', axis=1)[['Record High Year', 'Record Low Year']].sum().sum()\n    lastYearRecords = (df==thisYear-1).to_dataframe().drop('variable', axis=1)[['Record High Year', 'Record Low Year']].sum().sum()\n    highRecords = df['Record High'].where(df['Record High Year'] == thisYear).to_dataframe()['Record High']\n    highRecords.index = pd.to_datetime(highRecords.index+'-2020')\n    lowRecords = df['Record Low'].where(df['Record Low Year'] == thisYear).to_dataframe()['Record Low']\n    lowRecords.index = pd.to_datetime(lowRecords.index+'-2020')\n    \n    first_time = dt.strptime(df.attrs[f'{var} data range'][0], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    last_time = dt.strptime(df.attrs[f'{var} data range'][1], '%Y-%m-%d').strftime('%-m/%-d/%Y')\n    fig.add_trace(\n    go.Scatter(\n        x=highRecords.index, y=highRecords.values,\n        name=f'{pd.to_datetime(\"today\").year} Record'.upper(),\n        mode='markers',\n        marker=dict(size=6, color='white'),\n        hovertext=[f'{thisYear} Record: {i}' if not pd.isnull(i) else '' for i in highRecords.values],\n        hoverinfo='text'\n    ))\n    fig.add_trace(\n    go.Scatter(\n        x=lowRecords.index, y=lowRecords.values,\n        name='Low Record',\n        mode='markers',\n        marker=dict(size=6, color='white'),\n        hoverinfo='none'\n    ))\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=df['Record High'],\n        name='Record High'.upper(),\n        mode='markers',\n        marker=dict(size=3, color=colors[scheme]['Record High'])\n    ))\n    # Average highs\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=cos_fit(df['Average High']).round(1),\n        name='Average High'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Average High'])\n    ))\n    # Daily average\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=cos_fit(df['Daily Average']).round(1),\n        name='Daily Average'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Daily Average'])\n    ))\n    # Average lows\n    fig.add_trace(\n    go.Scatter(\n        x=xdates,\n        y=cos_fit(df['Average Low']).round(1),\n        name='Average Low'.upper(),\n        marker=dict(size=3, color=colors[scheme]['Average Low'])\n    ))\n    # Record lows\n    fig.add_trace(\n    go.Scatter(\n        x=xdates, y=df['Record Low'],\n        name='Record Low'.upper(),\n        mode='markers',\n        marker=dict(size=3, color=colors[scheme]['Record Low'])\n    ))\n    # Hover box\n    fig.update_traces(\n        hoverlabel = dict(bordercolor='white')\n    )\n    # Plot settings\n    fig.update_layout(\n        template='plotly_dark',\n        paper_bgcolor='#404040',\n        plot_bgcolor='#404040',\n        height=600, width=1000,\n        title=dict(text='Daily {} records'.format(var.lower())+\n                        '&lt;br&gt;&lt;sup&gt;{}-{}&lt;/sup&gt;'.format(first_time, last_time)+\n                        '&lt;br&gt;&lt;sup&gt;As of today, &lt;b&gt;{}&lt;/b&gt; {} record highs/lows have been set. Last year, {} records were set.&lt;/sup&gt;'.format(\n                            thisYearRecords, var.lower(), lastYearRecords\n                        ),\n                  font=dict(size=20)),\n        yaxis = dict(title=f'{var} ({data.attrs[f\"{var} units\"]})',\n                     showgrid=True, gridcolor='grey'),\n        xaxis = dict(showgrid=False, showspikes=True,\n                     dtick='M1', tickformat='%b %d'),\n        hovermode='x unified',\n        legend=dict(itemsizing='constant'),\n        hoverlabel=dict(font_size=12)\n    )\n    for trace in fig['data']: \n        if trace['name'] == 'Low Record':\n            trace['showlegend'] = False\n    fig.show()\n\n\ndaily_climo(days, 'Air Temperature', scheme='mg')\n\n                                                \n\n\nThat concludes this climatology demonstration series.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Behind the Scenes",
      "Plotting Records"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Giving credit where credit is due",
    "section": "",
    "text": "This project is inspired by Brian McNoldy at the University of Miami, whose long-standing “Climatology of Virginia Key, FL” site never ceased to provide insightful weather perpectives during my time at the Rosenstiel School of Marine, Atmospheric, and Earth Science.\nClimatology dashboards are provided here for a number of locations along the east coast to which I have some degree of connection. Some are updated more regularly than others.\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Shout Out"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "What are these data?",
    "section": "",
    "text": "SAVE NOAA!\n\n\n\n\n\n \n\n The products on this page rely on data from the National Oceanic and Atmospheric Administration (NOAA). NOAA is a critical tax-funded federal agency whose data collection, modeling and science capabilities, and personnel expertise keep the country safer and more prosperous—all at a cost of 6¢ per day per taxpayer. If you are visiting this page and reading this, you have an interest in NOAA’s science, service, and stewardship to the nation. Contact your representatives in Congress today to demand that NOAA employees are restored, facilities and resources are maintained, and budget is preserved.\n\n\n\n\n\nWhat are these data?\nThe National Oceanographic and Atmospheric Administration (NOAA) National Ocean Service Center for Operational Oceanographic Products and Services (CO-OPS) operates hundreds of water level observation stations along the United States coasts and Great Lakes. This National Water Level Observation Network (NWLON), part of the Integrating Ocean Observing System (IOOS), provides the data from which official tidal predictions are generated. Most of these observation stations also observe water temperature as well as air temperature, barometric pressure, and wind. All of these data are publically available via the NOAA CO-OPS Tides and Currents data portal.\nThe historical time series vary in length among sites and environmental parameters. Water level sensors often came first, with weather stations added later. Data collected since circa 1995 are generally available in 6-minute observations; prior to that, observations are hourly. Climatology dashboards are provided here for a number of locations along the east coast to which I have some degree of connection. Data inventories are available for every site:\n\nBeaufort, North Carolina\nWoods Hole, Massachusetts\nNaples, Florida\nBay St. Louis, Mississippi\nVirginia Key, Florida\nLewes, Delaware\n\nWater level sensors are calibrated and the observations are verified. None of the other variables are verified and should be used with caution.\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "About the Data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Local Climatology and Records",
    "section": "",
    "text": "SAVE NOAA!\n\n\n\n\n\n \n\n The products on this page rely on data from the National Oceanic and Atmospheric Administration (NOAA). NOAA is a critical tax-funded federal agency whose data collection, modeling and science capabilities, and personnel expertise keep the country safer and more prosperous—all at a cost of 6¢ per day per taxpayer. If you are visiting this page and reading this, you have an interest in NOAA’s science, service, and stewardship to the nation. Contact your representatives in Congress today to demand that NOAA employees are restored, facilities and resources are maintained, and budget is preserved."
  },
  {
    "objectID": "index.html#active-sites-updated-daily",
    "href": "index.html#active-sites-updated-daily",
    "title": "Local Climatology and Records",
    "section": "Active Sites (updated daily)",
    "text": "Active Sites (updated daily)\n\n\n\n\n\n\n\n\n\n\nBeaufort, NC\n\n\n\n\n\n\n\n\n\n\n\n\nVirginia Key, FL\n\n\n\n\n\n\n\n\n\n\n\n\nWoods Hole, MA\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#quasi-active-sites-updated-less-frequently",
    "href": "index.html#quasi-active-sites-updated-less-frequently",
    "title": "Local Climatology and Records",
    "section": "Quasi-active Sites (updated less frequently)",
    "text": "Quasi-active Sites (updated less frequently)\n\n\n\n\n\n\n\n\n\n\nBay St. Louis, MS\n\n\n\n\n\n\n\n\n\n\n\n\nLewes, DE\n\n\n\n\n\n\n\n\n\n\n\n\nNaples, FL\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "How are these records calculated?",
    "section": "",
    "text": "SAVE NOAA!\n\n\n\n\n\n \n\n The products on this page rely on data from the National Oceanic and Atmospheric Administration (NOAA). NOAA is a critical tax-funded federal agency whose data collection, modeling and science capabilities, and personnel expertise keep the country safer and more prosperous—all at a cost of 6¢ per day per taxpayer. If you are visiting this page and reading this, you have an interest in NOAA’s science, service, and stewardship to the nation. Contact your representatives in Congress today to demand that NOAA employees are restored, facilities and resources are maintained, and budget is preserved.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#daily-climatology-and-records",
    "href": "methods.html#daily-climatology-and-records",
    "title": "How are these records calculated?",
    "section": "Daily Climatology and Records",
    "text": "Daily Climatology and Records\nDaily climatology and records are calculated for each day-of-year (DOY), where\n\nJan 1 \\(\\longrightarrow\\) Day 1\nJan 2 \\(\\longrightarrow\\) Day 2\n…\nFeb 28 \\(\\longrightarrow\\) Day 59\nFeb 29 \\(\\longrightarrow\\) Day 60\n…\nDec 30 \\(\\longrightarrow\\) Day 365\nDec 31 \\(\\longrightarrow\\) Day 366\n\nInstead of eliminating February 29 on leap years, Day 60 is skipped in years that are not leap years. Thus, December 31 is always Day 366. Days start at midnight (00:00) and go until 23:59 (11:59 PM) local time.\n\nDOY Daily Average\nThe DOY daily average is the average of all daily averages for any given DOY. It is calculated by taking the daily averages from Equation 3, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{A}\\) be a matrix of daily averages from Equation 3 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{A} = (a_{yd}) = \\left( \\begin{array}{cccc}\na_{1,1} & a_{1,2} & ... & a_{1,366} \\\\\na_{2,1} & a_{2,2} & ... & a_{2,366} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\na_{y,1} & a_{y,2} & ... & a_{y,366} \\end{array} \\right) \\tag{5}\\]\nThe DOY daily average is the average over each column:\n\\[\\text{DOY daily average} = \\frac{1}{Y}\\sum_{y=1}^Y a_{yd} \\tag{6}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\n\n\n\n\n\n\nNote\n\n\n\nThe Daily Average reported in the statistics dashboard are DOY daily averages from Equation 6, not to be confused with Equation 3 or 4. For the sake of visualization, a cosine regression is fit to these data and shown on the plots.\n\n\n\n\nRecord High Daily Average\nThe record high daily average is the maximum daily average for any given DOY. It is determined by taking the daily averages from Equation 3, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record high daily average} = \\max\\{|a_{yd}|: d=1,2,...,366\\} \\tag{7}\\]\n\n\nRecord Low Daily Average\nThe record low daily average is the minimum daily average for any given DOY. It is determined by taking the daily averages from Equation 3, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{A}\\) from Equation 5 above:\n\\[\\text{record low daily average} = \\min\\{|a_{yd}|: d=1,2,...,366\\} \\tag{8}\\]\n\n\nAverage High\nThe average high is the average of all daily highs for any given DOY. It is determined by taking the daily highs from Equation 1, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{H}\\) be a matrix of daily highs from Equation 1 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{H} = (h_{yd}) = \\left( \\begin{array}{cccc}\nh_{1,1} & h_{1,2} & ... & h_{1,366} \\\\\nh_{2,1} & h_{2,2} & ... & h_{2,366} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nh_{y,1} & h_{y,2} & ... & h_{y,366} \\end{array} \\right) \\tag{9}\\]\nThe average high is the average over each column:\n\\[\\text{average high} = \\frac{1}{Y}\\sum_{y=1}^Y h_{yd} \\tag{10}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nPlots illustrate a cosine regression fit to these data for the sake of visualization.\n\n\nRecord High\nThe record high is the maximum daily high for any given DOY. It is determined by taking the daily highs from Equation 1, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{record high} = \\max\\{|h_{yd}|: d=1,2,...,366\\} \\tag{11}\\]\n\n\nLowest High\nThe lowest high is the minimum daily high for any given DOY. It is determined by taking the daily highs from Equation 1, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{H}\\) from Equation 9 above:\n\\[\\text{lowest high} = \\min\\{|h_{yd}|: d=1,2,...,366\\} \\tag{12}\\]\n\n\nAverage Low\nThe average low is the average of all daily lows for any given DOY. It is determined by taking the daily lows from Equation 2, grouping them by DOY, and calculating the average for each DOY.\nLet \\(\\textbf{L}\\) be a matrix of daily lows from Equation 2 arranged with years in rows and DOY in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(d\\) indicate DOY:\n\\[\\textbf{L} = (l_{yd}) = \\left( \\begin{array}{cccc}\nl_{1,1} & l_{1,2} & ... & l_{1,366} \\\\\nl_{2,1} & l_{2,2} & ... & l_{2,366} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nl_{y,1} & l_{y,2} & ... & l_{y,366} \\end{array} \\right) \\tag{13}\\]\nThe average low is the average over each column:\n\\[\\text{average low} = \\frac{1}{Y}\\sum_{y=1}^Y l_{yd} \\tag{14}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nPlots illustrate a cosine regression fit to these data for the sake of visualization.\n\n\nHighest Low\nThe highest low is the maximum daily low for any given DOY. It is determined by taking the daily lows from Equation 2, grouping them by DOY, and finding the maximum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{highest low} = \\max\\{|l_{yd}|: d=1,2,...,366\\} \\tag{15}\\]\n\n\nRecord Low\nThe record low is the minimum daily low for any given DOY. It is determined by taking the daily lows from Equation 2, grouping them by DOY, and finding the minimum value for each DOY. Given \\(\\textbf{L}\\) from Equation 13 above:\n\\[\\text{record low} = \\min\\{|l_{yd}|: d=1,2,...,366\\} \\tag{16}\\]\n\n\nNumber of Years in Record\nThe number of years of data available varies from day to day and between variables due to sensor availability, gaps in the observational record, or bad data being filtered out. Years are tallied by grouping the entire time series by DOY and counting the number of years for each day. For example, given \\(\\textbf{A}\\) from Equation 5 above, the number of years available for each DOY is the total number of unique years in each column.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#monthly-climatology-and-records",
    "href": "methods.html#monthly-climatology-and-records",
    "title": "How are these records calculated?",
    "section": "Monthly Climatology and Records",
    "text": "Monthly Climatology and Records\nMonthly climatology and records are calculated in the same way as daily climatology and records except that daily highs, lows, and averages are grouped by calendar month instead of DOY.\n\nMonthly Average\nThe monthly average is the average of all daily averages for any given month. It is calculated by taking the daily averages from Equation 3, grouping them by calendar month, and calculating the average for each month.\nLet \\(\\textbf{A}\\) now be a matrix of daily averages from Equation 3 arranged with years in rows and months in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(m\\) indicate month:\n\\[\\textbf{A} = (a_{ym}) = \\left( \\begin{array}{cccc}\na_{1,1} & a_{1,2} & ... & a_{1,12} \\\\\na_{2,1} & a_{2,2} & ... & a_{2,12} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\na_{y,1} & a_{y,2} & ... & a_{y,12} \\end{array} \\right) \\tag{17}\\]\nThe monthly average is the average over each column:\n\\[\\text{monthly average} = \\frac{1}{Y}\\sum_{y=1}^Y a_{ym} \\tag{18}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nPlots illustrate a cosine regression fit to these data for the sake of visualization.\n\n\nRecord High Monthly Average\nThe record high monthly average is the maximum daily average for any given calendar month. It is determined by taking the daily averages from Equation 3, grouping them by calendar month, and finding the maximum value for each month. Given \\(\\textbf{A}\\) from Equation 17 above:\n\\[\\text{record high monthly average} = \\max\\{|a_{ym}|: m=1,2,...,12\\} \\tag{19}\\]\n\n\nRecord Low Monthly Average\nThe record low monthly average is the minimum daily average for any given calendar month. It is determined by taking the daily averages from Equation 3, grouping them by calendar month, and finding the minimum value for each month. Given \\(\\textbf{A}\\) from Equation 17 above:\n\\[\\text{record low monthly average} = \\min\\{|a_{ym}|: m=1,2,...,12\\} \\tag{20}\\]\n\n\nAverage High\nThe average high is the average of all daily highs for any given calendar month. It is determined by taking the daily highs from Equation 1, grouping them by calendar month, and calculating the average for each month.\nLet \\(\\textbf{H}\\) now be a matrix of daily highs from Equation 1 arranged with years in rows and months in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(m\\) indicate month:\n\\[\\textbf{H} = (h_{ym}) = \\left( \\begin{array}{cccc}\nh_{1,1} & h_{1,2} & ... & h_{1,12} \\\\\nh_{2,1} & h_{2,2} & ... & h_{2,12} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nh_{y,1} & h_{y,2} & ... & h_{y,12} \\end{array} \\right) \\tag{21}\\]\nThe average high is the average over each column:\n\\[\\text{average high} = \\frac{1}{Y}\\sum_{y=1}^Y h_{ym} \\tag{22}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nPlots illustrate a cosine regression fit to these data for the sake of visualization.\n\n\nRecord High\nThe record high is the maximum daily high for any given calendar month. It is determined by taking the daily highs from Equation 1, grouping them by calendar month, and finding the maximum value for each month. Given \\(\\textbf{H}\\) from Equation 21 above:\n\\[\\text{record high} = {\\max}_m |h_{ym}| = \\max\\{|h_{ym}|: m=1,2,...,12\\} \\tag{23}\\]\n\n\nLowest High\nThe lowest high is the minimum daily high for any given calendar month. It is determined by taking the daily highs from Equation 1, grouping them by calendar month, and finding the minimum value for each month. Given \\(\\textbf{H}\\) from Equation 21 above:\n\\[\\text{lowest high} = {\\min}_m |h_{ym}| = \\min\\{|h_{ym}|: m=1,2,...,12\\} \\tag{24}\\]\n\n\nAverage Low\nThe average low is the average of all daily lows for any given calendar month. It is determined by taking the daily lows from Equation 2, grouping them by calendar month, and calculating the average for each month.\nLet \\(\\textbf{L}\\) now be a matrix of daily lows from Equation 2 arranged with years in rows and months in columns, and for simplicity, let subscript \\(y\\) indicate year and \\(m\\) indicate month:\n\\[\\textbf{L} = (l_{ym}) = \\left( \\begin{array}{cccc}\nl_{1,1} & l_{1,2} & ... & l_{1,12} \\\\\nl_{2,1} & l_{2,2} & ... & l_{2,12} \\\\\n\\vdotswithin{=} & \\vdotswithin{=} &  & \\vdotswithin{=} \\\\\nl_{y,1} & l_{y,2} & ... & l_{y,12} \\end{array} \\right) \\tag{25}\\]\nThe average low is the average over each column:\n\\[\\text{average low} = \\frac{1}{Y}\\sum_{y=1}^Y l_{ym} \\tag{26}\\]\nwhere \\(Y\\) is the number of years in the observational time series.\nPlots illustrate a cosine regression fit to these data for the sake of visualization.\n\n\nHighest Low\nThe highest low is the maximum daily low for any given calendar month. It is determined by taking the daily lows from Equation 2, grouping them by calendar month, and finding the maximum value for each month. Given \\(\\textbf{L}\\) from Equation 25 above:\n\\[\\text{highest low} = \\max\\{|l_{ym}|: m=1,2,...,12\\} \\tag{27}\\]\n\n\nRecord Low\nThe record low is the minimum daily low for any given calendar month. It is determined by taking the daily lows from Equation 2, grouping them by calendar month, and finding the minimum value for each month. Given \\(\\textbf{L}\\) from Equation 25 above:\n\\[\\text{record low} = \\min\\{|l_{ym}|: m=1,2,...,12\\} \\tag{28}\\]\n\n\nNumber of Years in Record\nThe number of years of data available varies from month to month and between variables due to sensor availability, gaps in the observational record, or bad data being filtered out. Years are tallied by grouping the entire time series by calendar month and counting the number of years for each month. For example, given \\(\\textbf{A}\\) from Equation 17 above, the number of years available for each month is the total number of unique years in each column.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#record-counts",
    "href": "methods.html#record-counts",
    "title": "How are these records calculated?",
    "section": "Record Counts",
    "text": "Record Counts\n\nDaily Records Set By Year\nThe total number of the daily records set each year are tallied up by year. Daily records include all of the following:\n\nRecord high daily average\nRecord low daily average\nLowest high\nRecord high\nHighest low\nRecord low\n\n\n\nMonthly Records Set By Year\nThe total number of the monthly records set each year are tallied up by year. Monthly records include all of the following:\n\nRecord high monthly average\nRecord low monthly average\nLowest high\nRecord high\nHighest low\nRecord low",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "methods.html#water-level-trend",
    "href": "methods.html#water-level-trend",
    "title": "How are these records calculated?",
    "section": "Water Level Trend",
    "text": "Water Level Trend\nThis plot shows the full water level time series with any long term trend observed at the site. Water level data are the only data that are quality controlled and, in many locations, the time series span several decades, making it possible to discern trends. Let \\(L\\) be the full time series of water levels observed at a given site, sampled either hourly or every six minutes, containing a total of \\(n\\) observations:\n\\[L = \\{l_1, l_2,...,l_n\\}\\]\nMonthly average water levels are calculated from daily averaged calculated from Equation 4 over the entire time series and a simple linear interpretation model is applied to fill missing data. The time series is then normalized to the interval \\([0,1]\\):\n\\[D = \\frac{L - \\min(L)}{\\max(L) - \\min(L)} \\tag{29}\\]\nwhere \\(\\min(L)\\) and \\(\\max(L)\\) are the minimum and maximum of the entire time series, respectively. The seasonal signal is then removed from the normalized time series using an additive model from the Python package statsmodels with a quarterly period (4 seasons per year.) The de-seasonalized time series is then un-normalized using the inverse of Equation 30:\n\\[D * \\big(\\max(L) - \\min(L)\\big) + \\min(L) \\tag{30}\\]\nFinally, a linear regression is applied to the de-seasonalized time series to discern any long term trend.\n\n\n\n\n\n\nNote\n\n\n\nThis plot is only available for sites containing full time series of water level obervations. Some time series have been interrupted by storms or other logistical challenges, making it either impossible or uninstructive to make this plot.",
    "crumbs": [
      "Home",
      "Methodology"
    ]
  },
  {
    "objectID": "demos/NOAA-CO-OPS-data.html",
    "href": "demos/NOAA-CO-OPS-data.html",
    "title": "Downloading NOAA CO-OPS Data",
    "section": "",
    "text": "This notebook demonstrates downloading atmospheric and water observations from the National Oceanic and Atmospheric Administration (NOAA) Center for Operational Oceanographic Products and Services (CO-OPS) data portal. The objective is to replicate the Climatology for Virginia Key, FL page created and maintained by Brian McNoldy at the University of Miami Rosenstiel School of Marine, Atmospheric, and Earth Science.\nWe will retrieve water level, water temperature, and air temperature data from Virginia Key, FL. Ultimately, however, there are several variables that could also be retrieved:\n\nWater level (i.e., tides)\nWater temperature\nAir temperature\nBarometric pressure\nWind speed\n\nIn this notebook we will download the data, store the metadata, and write these to file. The second notebook, NOAA-CO-OPS-records, will filter these data and calculate a set of statistics and records. Part 3, NOAA-CO-OPS-plots, will plot and display the data.\n\nPackages and configurations\nFirst we import the packages we need.\n\nfrom datetime import datetime as dt\nfrom noaa_coops import Station\nimport pandas as pd\nimport numpy as np\nimport yaml\nimport os\n\nBy default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes some trial and error to resolve the issue being warned about. So, for diagnostic purposes, we’ll set the kernel to always display warnings.\n\nimport warnings\nwarnings.filterwarnings('always')\n\n\n\nFunctions\nNext, we define a number of functions that will come in handy later:\n\ncamel: This will use the site location to create a directory name in camelCase (e.g., “virginiaKeyFl”) so that we do not have to do it manually\nget_units: Quick tool for retrieving the units for a desired variable\nformat_date: Formats a timestamp in YYYYMMDD for noaa_coops utility\nload_atemp: Fetch air temperature data\nload_water_temp: Fetch water temperature data\nload_water_level: Fetch water level (tide) data\nload_hourly_height: Fetch hourly water level height data, the precurser to the 6-minute water level product\ndownload_data: Wrapper function that downloads all of the desired data.\n\n\nHelper functions\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',', '').replace('.', '').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef get_units(variable, unit_system):\n    \"\"\"Return the desired units for 'variable'\"\"\"\n    deg = u'\\N{DEGREE SIGN}'\n    unit_options = dict({\n        'Air Temperature': {'metric': deg+'C', 'english': deg+'F'},\n        'Barometric Pressure': {'metric': 'mb', 'english': 'mb'},\n        'Wind Speed': {'metric': 'm/s', 'english': 'kn'},\n        'Wind Gust': {'metric': 'm/s', 'english': 'kn'},\n        'Wind Direction': {'metric': 'deg', 'english': 'deg'},\n        'Water Temperature': {'metric': deg+'C', 'english': deg+'F'},\n        'Water Level': {'metric': 'm', 'english': 'ft'}\n    })\n    return unit_options[variable][unit_system]\n\ndef format_date(datestr):\n    \"\"\"Format date strings into YYYYMMDD format\"\"\"\n    dtdt = pd.to_datetime(datestr)\n    return dt.strftime(dtdt, '%Y%m%d')\n\n\n\nDownloading data\n\ndef load_atemp(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download air temperature data from NOAA CO-OPS between 'start_date'\n    and 'end_date' for 'stationid', 'unit_system', and timezone 'tz'\n    provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving air temperature data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Air Temperature']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    air_temp = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='air_temperature',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    air_temp.columns = ['atemp', 'atemp_flag']\n    return air_temp\n\ndef load_water_temp(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download water temperature data from NOAA CO-OPS between\n    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n    timezone 'tz' provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving water temperature data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Water Temperature']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    water_temp = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='water_temperature',\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    water_temp.columns = ['wtemp', 'wtemp_flag']\n    return water_temp\n\ndef load_water_level(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download water level data from NOAA CO-OPS between 'start_date' and\n    'end_date' for 'stationid', 'unit_system', 'datum', and timezone 'tz'\n    provided in 'metadata' dictionary.\n    \"\"\"\n    if verbose:\n        print('Retrieving water level tide data')\n    station = Station(id=metadata['stationid'])\n    if not start_date:\n        start_date = format_date(station.data_inventory['Verified 6-Minute Water Level']['start_date'])\n    if not end_date:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    water_levels = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='water_level',\n        datum=metadata['datum'],\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    water_levels.columns = ['wlevel', 's', 'wlevel_flag', 'wlevel_qc']\n    return water_levels\n\ndef load_hourly_height(metadata, start_date, end_date, verbose=True):\n    \"\"\"Download verified hourly height data, the predecessor to the water level product, from NOAA CO-OPS from 'start_date' through 'end_date'.\"\"\"\n    if verbose:\n        print('Retrieving hourly height data')\n    station = Station(id=metadata['stationid'])\n    hourly_heights = station.get_data(\n        begin_date=start_date,\n        end_date=end_date,\n        product='hourly_height',\n        datum=metadata['datum'],\n        units=metadata['unit_system'],\n        time_zone=metadata['tz'])\n    hourly_heights.columns = ['wlevel', 's', 'wlevel_flag']\n    # Add QC column for comparing to water level product\n    hourly_heights['wlevel_qc'] = 'v'\n    return hourly_heights\n\ndef download_data(metadata, start_date=None, end_date=None, verbose=True):\n    \"\"\"Download data from NOAA CO-OPS\"\"\"\n    if verbose:\n        print('Downloading data')\n    \n    # NOAA CO-OPS API\n    station = Station(id=metadata['stationid'])\n    \n    # List of data variables to combine at the end\n    datasets = []\n            \n    # If no 'end_date' is passed, download through end of current date\n    if end_date is None:\n        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n    else:\n        end_date = format_date(end_date)\n    \n    # Air temperature\n    if 'Air Temperature' in station.data_inventory:\n        if start_date is None:\n            start_date = format_date(station.data_inventory['Air Temperature']['start_date'])\n        else:\n            start_date = format_date(start_date)\n        air_temp = load_atemp(metadata=metadata, start_date=start_date,\n                              end_date=end_date, verbose=verbose)\n        air_temp['atemp_flag'] = air_temp['atemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        air_temp.loc[air_temp['atemp_flag'] &gt; 0, 'atemp'] = np.nan\n        datasets.append(air_temp['atemp'])\n\n    # Water temperature\n    if 'Water Temperature' in station.data_inventory:\n        if start_date is None:\n            start_date = format_date(station.data_inventory['Water Temperature']['start_date'])\n        else:\n            start_date = format_date(start_date)\n        water_temp = load_water_temp(metadata=metadata, start_date=start_date,\n                                     end_date=end_date, verbose=verbose)\n        water_temp['wtemp_flag'] = water_temp['wtemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        water_temp.loc[water_temp['wtemp_flag'] &gt; 0, 'wtemp'] = np.nan\n        datasets.append(water_temp['wtemp'])\n\n    # Water level (tides)\n    if 'Verified 6-Minute Water Level' in station.data_inventory:\n        if start_date is None:\n            start_date = format_date(station.data_inventory['Verified 6-Minute Water Level']['start_date'])\n        else:\n            start_date = format_date(start_date)\n        water_levels = load_water_level(metadata=metadata, start_date=start_date,\n                                        end_date=end_date, verbose=verbose)\n        water_levels['wlevel_flag'] = water_levels['wlevel_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n        water_levels.loc[water_levels['wlevel_flag'] &gt; 0, 'wlevel'] = np.nan\n        \n        # Hourly water heights (historical product)\n        if start_date is None:\n            if 'Verified Hourly Height Water Level' in station.data_inventory:\n                start = format_date(station.data_inventory['Verified Hourly Height Water Level']['start_date'])\n                end = format_date(water_levels.index[0] + pd.Timedelta(days=1))\n                hourly_heights = load_hourly_height(metadata=metadata, \n                                                    start_date=start, end_date=end, verbose=verbose)\n                hourly_heights['wlevel_flag'] = \\\n                        hourly_heights['wlevel_flag'].str\\\n                            .split(',', expand=True).astype(int).sum(axis=1)\n                hourly_heights.loc[hourly_heights['wlevel_flag'] &gt; 0] = np.nan\n                water_levels = pd.concat(\n                    (hourly_heights[['wlevel', 'wlevel_flag', 'wlevel_qc']][:-1], \n                    water_levels[['wlevel', 'wlevel_flag', 'wlevel_qc']]), axis=0\n                )\n                water_levels = water_levels[~water_levels.index.duplicated(keep='first')]\n        datasets.append(water_levels[['wlevel', 'wlevel_qc']])\n\n    # Merge into single dataframe and rename columns\n    if verbose:\n        print('Compiling data')\n    newdata = pd.concat(datasets, axis=1)\n    newdata.index.name = f'time_{metadata[\"tz\"]}'\n    newdata.columns = [i for i in metadata['variables']+['Water Level QC']]\n    return newdata\n\n\n\n\nLoad / download data\nNow it’s time to load the data. First, specify the station we want to load. This will be used to load saved data or download all data from a new station, if we have not yet retrieved data from this particular stationname.\nstationname is a custom human-readable “City, ST” string for the station, while id is the NOAA-COOPS station ID number.\nWe also need to specify other settings such as datum, timezone (tz), and unit system.\nFinally, we indicate hr_threshold, the maximum number of hours of missing data allowed before a day is not counted in the records, and day_threshold, the maximum number of days of missing data allowed before a month is not counted.\n\nstationname = 'Virginia Key, FL'\nid = '8723214'\ndatum = 'MHHW'\ntz = 'lst'\nunit_system = 'english'\nhr_threshold = 4\nday_threshold = 2\n\nDerive the directory name containing for data from the station name. This is where the data are or will be saved locally.\n\ndirname = camel(stationname)\noutdir = os.path.join(os.getcwd(), dirname)\noutdir = f'../{dirname}'\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: ../virginiaKeyFl\n\n\nFlag for printing statuses\n\nverbose = True\n\nLet’s see if we already have data from this station saved locally. This will be true if a directory already exists for the station.\nIf the directory outdir does not exist, then no data have been downloaded for this station, so we need to download everything through the present. This requires a few steps:\n\nCreate outdir\nDownload the data and record the timestamp of the last observation for each variable in the metadata. This will be used later when updating the data.\nWrite the data and metadata to file.\n\nOn the other hand, if data already exist locally, we will load it from file and download new data we do not yet have:\n\nLoad the data and metadata from file\nRetrieve new data\nCombine new data to existing data, update the ‘last_obs’ metadata entries, and write data and metadata to file\n\nThe noaa-coops tool only accepts dates without times, so it is possible to download data we already have. We therefore have to check what we download against what we already have to avoid duplicating data.\nThe most likely (and perhaps only) scenerio for encountering duplicated data is if the data we have for the most recent day is incomplete. For example, assume today is May 5, 2025 and we download data at noon. Also assume the start date is some earlier day, the last time we retrieved data, and this will be automatically determined from the metadata. Specifying an end date 2025-05-05 will retrieve all data available through noon on May 5. In this case, we do not yet have these data, so we concatenate what we do not have to what we do have. However, if we then run the download function again (say, for diagnostic purposes) with the new start date of 2025-05-01 and the end date 2025-05-05, it will again download the data through noon on May 5. But since we already have those data, we do not want to re-concatenate them.\nThis cell may take several seconds or minutes to run, depending on how much data are downloaded.\n\nif not os.path.exists(outdir):\n    if verbose:\n        print('Creating new directory for this station.')\n    os.makedirs(outdir)\n\n    # Save metadata to file\n    meta = dict({\n        'stationname': stationname,\n        'stationid': stationid,\n        'dirname': dirname,\n        'unit_system': unit_system,\n        'tz': tz,\n        'datum': datum,\n        'hr_threshold': hr_threshold,\n        'day_threshold': day_threshold,\n        'variables': ['Air Temperature', 'Water Temperature', 'Water Level']})\n    meta['units'] = [get_units(var, meta['unit_system']) for var in meta['variables']]\n    with open(os.path.join(outdir, 'metadata.yml'), 'w') as fp:\n        yaml.dump(meta, fp)\n\n    # Download all data (set start and end date to None to get all data)\n    if verbose:\n        print('Downloading all data for this station.')\n    data = download_data(metadata=meta, start_date=None, end_date=None)\n    outFile = os.path.join(outDir, 'observational_data_record.csv.gz')\n    data.to_csv(outDir, compression='infer')\n    meta['last_obs'] = {i:data[i].last_valid_index().strftime('%Y-%m-%d %X') \\\n                        for i in meta['variables']}\n    print(f\"Observational data written to file '{outFile}'.\")\n    \nelse:\n    # Load the metadata\n    if verbose:\n        print('Loading metadata from file')\n    with open(os.path.join(outdir, 'metadata.yml')) as m:\n        meta = yaml.safe_load(m)\n    \n    # Load the historical data\n    if verbose:\n        print('Loading historical data from file')\n    dataInFile = os.path.join(outdir, 'observational_data_record.csv.gz')\n    dtypeDict = {k: float for k in meta['variables']}\n    dtypeDict['Water Level QC'] = str\n    data = pd.read_csv(dataInFile, index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n                       compression='infer', dtype=dtypeDict)\n    start_date = format_date(data.index.max())\n\n    # Retrieve new data\n    newdata = download_data(metadata=meta, start_date=start_date)\n    if sum(~newdata.index.isin(data.index)) == 0:\n        print('No new data available.')\n    else:\n        newdata.index.name = f\"time_{meta['tz']}\"\n        newdata.columns = [i for i in data.columns]\n        data = pd.concat([data,\n                          newdata[newdata.index.isin(data.index) == False]], axis=0)\n        data.to_csv(dataInFile, compression='infer')\n        meta['last_obs'] = {i:data[i].last_valid_index().strftime('%Y-%m-%d %X') \\\n                            for i in meta['variables']}\n        print(\"Updated observational data written to file 'observational_data_record.csv'.\")\n\nLoading metadata from file\nLoading historical data from file\nDownloading data\nRetrieving air temperature data\nRetrieving water temperature data\nRetrieving water level tide data\nCompiling data\nUpdated observational data written to file 'observational_data_record.csv'.\n\n\nCheck the data and metadata for sanity:\n\ndata\n\n\n\n\n\n\n\n\nAir Temperature\nWater Temperature\nWater Level\nWater Level QC\n\n\ntime_lst\n\n\n\n\n\n\n\n\n1994-01-28 00:00:00\nNaN\nNaN\nNaN\nNaN\n\n\n1994-01-28 00:06:00\nNaN\nNaN\nNaN\nNaN\n\n\n1994-01-28 00:12:00\nNaN\nNaN\nNaN\nNaN\n\n\n1994-01-28 00:18:00\nNaN\nNaN\nNaN\nNaN\n\n\n1994-01-28 00:24:00\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n\n\n2025-05-30 19:36:00\n86.7\n88.2\n-1.657\np\n\n\n2025-05-30 19:42:00\n86.5\n88.2\nNaN\np\n\n\n2025-05-30 19:48:00\n86.5\n88.2\n-1.552\np\n\n\n2025-05-30 19:54:00\n86.4\n88.2\nNaN\np\n\n\n2025-05-30 20:00:00\n86.4\n88.2\nNaN\np\n\n\n\n\n2745205 rows × 4 columns\n\n\n\n\nmeta\n\n{'datum': 'MHHW',\n 'day_threshold': 2,\n 'dirname': 'virginiaKeyFl',\n 'hr_threshold': 4,\n 'stationid': '8723214',\n 'stationname': 'Virginia Key, FL',\n 'tz': 'lst',\n 'unit_system': 'english',\n 'units': {'Air Temperature': '°F',\n  'Water Level': 'ft',\n  'Water Temperature': '°F'},\n 'variables': ['Air Temperature', 'Water Temperature', 'Water Level'],\n 'last_obs': {'Air Temperature': '2025-05-30 20:00:00',\n  'Water Temperature': '2025-05-30 20:00:00',\n  'Water Level': '2025-05-30 19:48:00'}}\n\n\n\nlen(data.index.unique()) == data.shape[0]\n\nTrue\n\n\nThe ‘last_obs’ metadata values matches the last observation in the data record and corresponds to the most recently available observation. Also, every observation time is unique, so there are no duplicated entries. So, everything checks out.\nIn the next part, we will filter these data and calculate statistics and records.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Behind the Scenes",
      "Downloading NOAA CO-OPS Data"
    ]
  },
  {
    "objectID": "demos/NOAA-CO-OPS-records.html",
    "href": "demos/NOAA-CO-OPS-records.html",
    "title": "Data Cleansing and Records Calculations",
    "section": "",
    "text": "This notebook follows sequentially from NOAA-CO-OPS-data in which we downloaded the latest data for a particular NOAA CO-OPS weather and tide station. The data record and corresponding metadata were written to file. Here we use those data to calculate several daily and monthly statistics and records. This is done in two steps:\n\nFilter the data: We do not perform any quality assurance or quality control checks, but we do remove from the records any days missing a specified amount of data and any months missing a specified number of days of data.\nCalculate records:\n\nDaily and monthly averages\nRecord high daily and monthly averages*\nRecord low daily and monthly averages*\nAverage daily and monthly high\nLowest daily and monthly high*\nRecord daily and monthly high*\nAverage daily and monthly low\nHighest daily and monthly low*\nRecord daily and monthly low*\n\n\nYears are also noted for those records marked by an asterisk (*).\n\nPackages and configurations\nFirst we import the packages we need.\n\nimport pandas as pd\nimport xarray as xr\nimport numpy as np\nimport calendar\nimport yaml\nimport os\n\n\n\nFunctions\nNext, we define a number of functions that will come in handy later:\n\ncamel: This will use the site location to create a directory name in camelCase (e.g., “virginiaKeyFl”) so that we do not have to do it manually\nDOY: Determine day of year (DOY) out of 366 for each day in the data record\ncount_missing_hours: Return the number of hours of missing data for a given day\ncount_missing_days: Return the number of days of missing data for a given month\nfilter_hours: Filter out days with too many hours of missing data\nfilter_days: Filter out months with too many days of missing data\nFunctions for all of the highs, lows, and averages (see their docstrings for more information)\n\n\nHelper functions\n\ndef camel(text):\n    \"\"\"Convert 'text' to camel case\"\"\"\n    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n    s = s.split()\n    if len(text) == 0:\n        return text\n    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n\ndef DOY(df):\n    \"\"\"Determine year day out of 366\"\"\"\n    # Day of year as integer\n    df['YearDay'] = df.index.day_of_year.astype(int)\n    # Years that are NOT leap years\n    leapInd = [not calendar.isleap(i) for i in df.index.year]\n    mask = (leapInd) & (df.index.month &gt; 2)\n    # Advance by one day everything after February 28 \n    df.loc[mask, 'YearDay'] += 1\n    return df\n\n\n\nFiltering data\n\ndef count_missing_hours(group, threshold=4):\n    \"\"\"Return True if the number of hours in a day with good data is \n    greater than or equal to 24-'threshold' (i.e., a 'good' day) and False \n    otherwise.\n    \"\"\"\n    num_obs = (~group.resample('1h').mean().isna()).sum()\n    good_threshold = 24 - threshold\n    return num_obs &gt;= good_threshold\n\ndef count_missing_days(group, threshold=2):\n    \"\"\"Return True if the number of days in a month with good data \n    is greater than or equal to the number of days in the month minus 'theshold' (i.e., a 'good' month) and False\n    otherwise.\n    \"\"\"\n    try:\n        days_in_month = pd.Period(group.index[0].strftime(format='%Y-%m-%d')).days_in_month\n        good_days = (~group.resample('1D').mean().isna()).sum()\n        good_threshold = days_in_month - threshold\n        missing_days_flag = good_days &gt; good_threshold\n        return good_days &gt;= good_threshold\n    except IndexError:\n        pass\n\ndef filter_hours(data, hr_threshold=4):\n    \"\"\"Filter data to remove days with more than 'hr_threshold' missing\n    hours of data.\n    \"\"\"\n    # Filter out fillVals==31.8\n    filtered = data.replace(31.8, np.nan)\n    # Filter out days missing more than &lt;hr_threshold&gt; hours\n    filtered = filtered.groupby(pd.Grouper(freq='1D')).filter(\n        lambda x: count_missing_hours(group=x, threshold=hr_threshold))\n    return filtered\n\ndef filter_days(data, hr_threshold=4, day_threshold=2):\n    \"\"\"Filter months with more than 'day_threshold' days of missing\n    data by first filtering data to remove days with more than \n    'hr_threshold' missing hours of data.\n    \"\"\"\n    # Filter out fillVals==31.8\n    filtered = data.replace(31.8, np.nan)\n    # Filter out days missing more than &lt;hr_threshold&gt; hours\n    filtered = filter_hours(filtered, hr_threshold=hr_threshold)\n    # Filter out months missing more than &lt;day_threshold&gt; days\n    filtered = filtered.groupby(pd.Grouper(freq='1M')).filter(\n        lambda x: count_missing_days(group=x, threshold=day_threshold))\n    return filtered\n\n\n\nCalculate records\n\ndef daily_highs(df):\n    \"\"\"Daily highs\"\"\"\n    return df.groupby(pd.Grouper(freq='1D', closed='left', label='left', dropna=True)).max(numeric_only=True)\n              \ndef daily_lows(df):\n    \"\"\"Daily lows\"\"\"\n    return df.groupby(pd.Grouper(freq='1D', closed='left', label='left', dropna=True)).min(numeric_only=True)\n\ndef daily_avgs(df, true_average=False):\n    \"\"\"Daily averages by calendar day. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    if true_average:\n        results = df.groupby(pd.Grouper(freq='1D', closed='left', label='left', dropna=True)).mean(numeric_only=True)\n    else:\n        dailyHighs = daily_highs(df)\n        dailyLows = daily_lows(df)\n        results = (dailyHighs + dailyLows) / 2\n    return results\n\ndef mon_daily_highs(df):\n    \"\"\"Daily highs using data filtered by days\"\"\"\n    return df.groupby(pd.Grouper(freq='1D', closed='left', label='left', dropna=True)).max(numeric_only=True)\n\ndef mon_daily_lows(df):\n    \"\"\"Daily lows using data filtered by days\"\"\"\n    return df.groupby(pd.Grouper(freq='1D', closed='left', label='left', dropna=True)).min(numeric_only=True)\n\ndef mon_daily_avgs(df, true_average=False):\n    \"\"\"Daily averages by calendar day using data filtered by day. If\n    'true_average' is True, all measurements from each 24-hour day will be\n    used to calculate the average. Otherwise, only the maximum and minimum\n    observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    if true_average:\n        return df.groupby(pd.Grouper(freq='1D', closed='left', label='left', dropna=True)).mean(numeric_only=True)\n    else:\n        dailyHighs = mon_daily_highs(df)\n        dailyLows = mon_daily_lows(df)\n        results = (dailyHighs + dailyLows) / 2\n        return results\n\ndef daily_avg(df, true_average=False):\n    \"\"\"Daily averages. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, true_average=true_average)\n    dailyAvg = dailyAvgs.groupby('YearDay').mean(numeric_only=True)\n    dailyAvg.index = dailyAvg.index.astype(int)\n    results = xr.DataArray(dailyAvg, dims=['yearday', 'variable'])\n    results.name = 'Daily Average'\n    return results\n\ndef monthly_highs(df, true_average=False):\n    \"\"\"Monthly highs. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, true_average=true_average)\n    monthHighs = dailyAvgs.groupby(pd.Grouper(freq='M')).max(numeric_only=True)\n    return monthHighs\n  \ndef monthly_lows(df, true_average=False):\n    \"\"\"Monthly lows. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    dailyAvgs = daily_avgs(df, true_average=true_average)\n    monthLows = dailyAvgs.groupby(pd.Grouper(freq='M')).min(numeric_only=True)\n    return monthLows\n    \ndef monthly_avg(df, true_average=False):\n    \"\"\"Monthly averages. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological\n    standard).\n    \"\"\"\n    dailyAvgs = mon_daily_avgs(df, true_average=true_average)\n    monthlyMeans = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\n    monthlyMeans.drop('YearDay', axis=1, inplace=True)\n    monthlyAvg = monthlyMeans.groupby(monthlyMeans.index.month).mean(numeric_only=True)\n    monthlyAvg.index = monthlyAvg.index.astype(int)\n    results = xr.DataArray(monthlyAvg, dims=['month', 'variable'])\n    results.name = 'Monthly Average'\n    return results\n\ndef record_high_daily_avg(df, true_average=False):\n    \"\"\"Record high daily averages. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df=df, true_average=true_average)\n    recordHighDailyAvg = dailyAvgs.groupby('YearDay').max(numeric_only=True)\n    recordHighDailyAvg.index = recordHighDailyAvg.index.astype(int)\n    # Record years\n    recordHighDailyAvgYear = dailyAvgs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n    recordHighDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n    recordHighDailyAvgYear.index = recordHighDailyAvgYear.index.astype(int)\n    recordHighDailyAvgYear.columns = [i+' Year' for i in recordHighDailyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordHighDailyAvg, recordHighDailyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record High Daily Average'\n    return results\n    \ndef record_high_monthly_avg(df, true_average=False):\n    \"\"\"Record high monthly averages. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = mon_daily_avgs(df, true_average=true_average)\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\n    monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n    recordHighMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month).max(numeric_only=True)\n    recordHighMonthlyAvg.index = recordHighMonthlyAvg.index.astype(int)\n    # Record years\n    recordHighMonthlyAvgYear = monthlyAvgs.groupby(monthlyAvgs.index.month).apply(\n                lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n    recordHighMonthlyAvgYear.index = recordHighMonthlyAvgYear.index.astype(int)\n    recordHighMonthlyAvgYear.columns = [i+' Year' for i in recordHighMonthlyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordHighMonthlyAvg, recordHighMonthlyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record High Monthly Average'\n    return results\n\ndef record_low_daily_avg(df, true_average=False):\n    \"\"\"Record low daily averages.  If 'true_average' True, all measurements from each 24-hour day will be used to calculate the average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\"\"\"\n    # Calculate the records\n    dailyAvgs = daily_avgs(df=df, true_average=true_average)\n    recordLowDailyAvg = dailyAvgs.groupby('YearDay').min(numeric_only=True)\n    recordLowDailyAvg.index = recordLowDailyAvg.index.astype(int)\n    # Record years\n    recordLowDailyAvgYear = dailyAvgs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n    recordLowDailyAvgYear.drop('YearDay', axis=1, inplace=True)\n    recordLowDailyAvgYear.index = recordLowDailyAvgYear.index.astype(int)\n    recordLowDailyAvgYear.columns = [i+' Year' for i in recordLowDailyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordLowDailyAvg, recordLowDailyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Low Daily Average'\n    return results\n\ndef record_low_monthly_avg(df, true_average=False):\n    \"\"\"Record low monthly averages. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the records\n    dailyAvgs = mon_daily_avgs(df, true_average=true_average)\n    monthlyAvgs = dailyAvgs.groupby(pd.Grouper(freq='M')).mean(numeric_only=True)\n    monthlyAvgs.drop('YearDay', axis=1, inplace=True)\n    recordLowMonthlyAvg = monthlyAvgs.groupby(monthlyAvgs.index.month).min(numeric_only=True)\n    recordLowMonthlyAvg.index = recordLowMonthlyAvg.index.astype(int)\n    # Record years\n    recordLowMonthlyAvgYear = \\\n            monthlyAvgs.groupby(monthlyAvgs.index.month).apply(\n                lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n    recordLowMonthlyAvgYear.index = recordLowMonthlyAvgYear.index.astype(int)\n    recordLowMonthlyAvgYear.columns = [i+' Year' for i in recordLowMonthlyAvgYear.columns]\n    # Create xarray\n    results = pd.concat((recordLowMonthlyAvg, recordLowMonthlyAvgYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Low Monthly Average'\n    return results\n\ndef avg_daily_high(df):\n    \"\"\"Average daily highs.\"\"\"        \n    dailyHighs = daily_highs(df)\n    results = dailyHighs.groupby('YearDay').mean(numeric_only=True)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Average Daily High'\n    return results\n\ndef avg_monthly_high(df, true_average=False):\n    \"\"\"Average monthly highs. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    monthlyHighs = monthly_highs(df, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    avgMonthlyHighs = monthlyHighs.groupby(monthlyHighs.index.month).mean(numeric_only=True)\n    results = xr.DataArray(avgMonthlyHighs, dims=['month', 'variable'])\n    results.name = 'Average Monthly High'\n    return results\n\ndef lowest_daily_high(df):\n    \"\"\"Lowest daily highs.\"\"\"\n    # Calculate the record\n    dailyHighs = daily_highs(df)\n    lowestHigh = dailyHighs.groupby('YearDay').min(numeric_only=True)\n    lowestHigh.index = lowestHigh.index.astype(int)\n    # Record years\n    lowestHighYear = dailyHighs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n    lowestHighYear.drop('YearDay', axis=1, inplace=True)\n    lowestHighYear.index = lowestHighYear.index.astype(int)\n    lowestHighYear.columns = [i+' Year' for i in lowestHighYear.columns]\n    # Create xarray\n    results = pd.concat((lowestHigh, lowestHighYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Lowest Daily High'\n    return results\n    \ndef lowest_monthly_high(df, true_average=False):\n    \"\"\"Lowest monthly highs. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyHighs = monthly_highs(df, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    lowMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month).min(numeric_only=True)\n    lowMonthlyHigh.index = lowMonthlyHigh.index.astype(int)\n    # Record years\n    lowMonthlyHighYear = \\\n            monthlyHighs.groupby(monthlyHighs.index.month).apply(\n                lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n    lowMonthlyHighYear.index = lowMonthlyHighYear.index.astype(int)\n    lowMonthlyHighYear.columns = [i+' Year' for i in lowMonthlyHighYear.columns]\n    # Create xarray\n    results = pd.concat((lowMonthlyHigh, lowMonthlyHighYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Lowest Monthly High'\n    return results\n\ndef record_daily_high(df):\n    \"\"\"Record daily highs.\"\"\"\n    # Calculate the record\n    dailyHighs = daily_highs(df)\n    recordHigh = dailyHighs.groupby('YearDay').max(numeric_only=True)\n    recordHigh.index = recordHigh.index.astype(int)\n    # Record years\n    recordHighYear = dailyHighs.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n    recordHighYear.drop('YearDay', axis=1, inplace=True)\n    recordHighYear.index = recordHighYear.index.astype(int)\n    recordHighYear.columns = [i+' Year' for i in recordHighYear.columns]\n    # Create xarray\n    results = pd.concat((recordHigh, recordHighYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Daily High'\n    return results\n\ndef record_monthly_high(df, true_average=False):\n    \"\"\"Record monthly highs. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyHighs = monthly_highs(df, true_average=true_average)\n    monthlyHighs.drop('YearDay', axis=1, inplace=True)\n    recordMonthlyHigh = monthlyHighs.groupby(monthlyHighs.index.month).max(numeric_only=True)\n    recordMonthlyHigh.index = recordMonthlyHigh.index.astype(int)\n    # Record years\n    recordMonthlyHighYear = \\\n            monthlyHighs.groupby(monthlyHighs.index.month).apply(\n                lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n    recordMonthlyHighYear.index = recordMonthlyHighYear.index.astype(int)\n    recordMonthlyHighYear.columns = [i+' Year' for i in recordMonthlyHighYear.columns]\n    # Create xarray\n    results = pd.concat((recordMonthlyHigh, recordMonthlyHighYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Monthly High'\n    return results\n\ndef avg_daily_low(df):\n    \"\"\"Average daily lows.\"\"\"        \n    dailyLows = daily_lows(df)\n    results = dailyLows.groupby('YearDay').mean(numeric_only=True)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Average Daily Low'\n    return results\n\ndef avg_monthly_low(df, true_average=False):\n    \"\"\"Average monthly lows. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    monthlyLows = monthly_lows(df, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    avgMonthlyLows = monthlyLows.groupby(monthlyLows.index.month).mean(numeric_only=True)\n    results = xr.DataArray(avgMonthlyLows, dims=['month', 'variable'])\n    results.name = 'Average Monthly Low'\n    return results\n\ndef highest_daily_low(df):\n    \"\"\"Highest daily lows.\"\"\"\n    # Calculate the record\n    dailyLows = daily_lows(df)\n    highestLow = dailyLows.groupby('YearDay').max(numeric_only=True)\n    highestLow.index = highestLow.index.astype(int)\n    # Record years\n    highestLowYear = dailyLows.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n    highestLowYear.drop('YearDay', axis=1, inplace=True)\n    highestLowYear.index = highestLowYear.index.astype(int)\n    highestLowYear.columns = [i+' Year' for i in highestLowYear.columns]\n    # Create xarray\n    results = pd.concat((highestLow, highestLowYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Highest Daily Low'\n    return results\n    \ndef highest_monthly_low(df, true_average=False):\n    \"\"\"Highest monthly lows. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyLows = monthly_lows(df, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    highestMonthlyLow = monthlyLows.groupby(monthlyLows.index.month).max(numeric_only=True)\n    highestMonthlyLow.index = highestMonthlyLow.index.astype(int)\n    # Record years\n    highestMonthlyLowYear = \\\n            monthlyLows.groupby(monthlyLows.index.month).apply(\n                lambda x: x.sort_index().idxmax(numeric_only=True).dt.year)\n    highestMonthlyLowYear.index = highestMonthlyLowYear.index.astype(int)\n    highestMonthlyLowYear.columns = [i+' Year' for i in highestMonthlyLowYear.columns]\n    # Create xarray\n    results = pd.concat((highestMonthlyLow, highestMonthlyLowYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Highest Monthly Low'\n    return results\n\ndef record_daily_low(df):\n    \"\"\"Record daily lows.\"\"\"\n    # Calculate the record\n    dailyLows = daily_lows(df)\n    recordLow = dailyLows.groupby('YearDay').min(numeric_only=True)\n    recordLow.index = recordLow.index.astype(int)\n    # Record years\n    recordLowYear = dailyLows.groupby('YearDay').apply(\n            lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n    recordLowYear.drop('YearDay', axis=1, inplace=True)\n    recordLowYear.index = recordLowYear.index.astype(int)\n    recordLowYear.columns = [i+' Year' for i in recordLowYear.columns]\n    # Create xarray\n    results = pd.concat((recordLow, recordLowYear), axis=1)\n    results = xr.DataArray(results, dims=['yearday', 'variable'])\n    results.name = 'Record Daily Low'\n    return results\n\ndef record_monthly_low(df, true_average=False):\n    \"\"\"Record monthly lows. If 'true_average' is True, all measurements from each 24-hour day will be used to calculate the daily average. Otherwise, only the maximum and minimum observations are used. Defaults to False (meteorological standard).\n    \"\"\"\n    # Calculate the record\n    monthlyLows = monthly_lows(df, true_average=true_average)\n    monthlyLows.drop('YearDay', axis=1, inplace=True)\n    recordMonthlyLow = monthlyLows.groupby(monthlyLows.index.month).min(numeric_only=True)\n    recordMonthlyLow.index = recordMonthlyLow.index.astype(int)\n    # Record years\n    recordMonthlyLowYear = \\\n            monthlyLows.groupby(monthlyLows.index.month).apply(\n                lambda x: x.sort_index().idxmin(numeric_only=True).dt.year)\n    recordMonthlyLowYear.index = recordMonthlyLowYear.index.astype(int)\n    recordMonthlyLowYear.columns = [i+' Year' for i in recordMonthlyLowYear.columns]\n    # Create xarray\n    results = pd.concat((recordMonthlyLow, recordMonthlyLowYear), axis=1)\n    results = xr.DataArray(results, dims=['month', 'variable'])\n    results.name = 'Record Monthly Low'\n    return results\n\ndef number_of_years_byday(df):\n    \"\"\"Number of years in the historical data records by day of year.\"\"\"\n    numYears = pd.concat([df[[v, 'YearDay']].dropna().groupby('YearDay')\\\n                                        .apply(lambda x: len(x.index.year.unique())) \\\n                         for v in filtered_hours.columns if v != 'YearDay'], axis=1)\n    numYears.columns = [v for v in df.columns if v != 'YearDay']\n    results = xr.DataArray(numYears, dims=['yearday', 'variable'])\n    results.name = 'Number of Years'\n    return results\n\ndef number_of_years_bymonth(df):\n    \"\"\"Number of years in the historical data records by month.\"\"\"\n    numYears = pd.concat([df[v].dropna().groupby(df[v].dropna().index.month)\\\n                                        .apply(lambda x: len(x.index.year.unique())) \\\n                         for v in filtered_hours.columns if v != 'YearDay'], axis=1)\n    numYears.columns = [v for v in df.columns if v != 'YearDay']\n    results = xr.DataArray(numYears, dims=['month', 'variable'])\n    results.name = 'Number of Years'\n    return results\n\ndef generate_yeardays():\n    return pd.date_range(start='2020-01-01',end='2020-12-31', freq='1D').strftime('%d-%b')\n\n\n\n\nData cleaning\nFirst we need to load in the data and metadata for the desired station. As before, stationname is the custom human-readable “City, ST” string for the station. This will be used to determine the directory from which to load the data. Since we are not downloading data, we do not need the NOAA-COOPS station ID number.\n\nstationname = 'Virginia Key, FL'\n\nDerive the local directory name containing the data from the station name. This is the same way the directory was created when the data were downloaded.\n\ndirname = camel(stationname)\noutdir = f'../{dirname}'\n\nprint(f\"Station folder: {dirname}\")\nprint(f\"Full directory: {outdir}\")\n\nStation folder: virginiaKeyFl\nFull directory: ../virginiaKeyFl\n\n\nNext, load the data and metadata.\n\n# Metadata\nwith open(os.path.join(outdir, 'metadata.yml')) as m:\n    meta = yaml.safe_load(m)\n\n# Data types\ndtypeDict = {k: float for k in meta['variables']}\ndtypeDict['Water Level QC'] = str\n\n# Observational data\ndata = pd.read_csv(os.path.join(outdir, 'observational_data_record.csv.gz'),\n                   index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n                   compression='infer', dtype=dtypeDict)\n\nNow we filter the data to remove days with more than 4 hours of missing data and months with more than 2 days of missing data. These thresholds are stored in meta and can easily be changed. We have to do this one variable at a time because this is sensor-dependent, so it takes a short while to run.\n\nfiltered_hours = pd.concat([filter_hours(data[var],\n                                       hr_threshold=meta['hr_threshold'])\n                                       for var in meta['variables']], axis=1)\n\nfiltered_days = pd.concat([filter_days(data[var],\n                                       hr_threshold=meta['hr_threshold'],\n                                       day_threshold=meta['day_threshold'])\n                                       for var in meta['variables']], axis=1)\n\nConfirm that the data were filtered:\n\nprint(data.shape)\nprint(filtered_hours.shape)\nprint(filtered_days.shape)\n\n(2745205, 4)\n(2720854, 3)\n(2657974, 3)\n\n\n\n\nCalculate records\nNow we’re ready to determine the records using all of the functions above. We’ll store these in an xarray dataset and add the appropriate metadata for convenience. But first, we need to add a day of year (DOY) column so that we can calculate daily records. We’ve used a function to do this because accounting for leap years is not trivial.\n\nfiltered_hours = DOY(filtered_hours)\nfiltered_days = DOY(filtered_days)\n\n\ndaily_records = \\\n    xr.Dataset({'Daily Average': daily_avg(filtered_hours),\n                'Record High Daily Average': record_high_daily_avg(filtered_hours),\n                'Record Low Daily Average': record_low_daily_avg(filtered_hours),\n                'Average High': avg_daily_high(filtered_hours),\n                'Lowest High': lowest_daily_high(filtered_hours),\n                'Record High': record_daily_high(filtered_hours),\n                'Average Low': avg_daily_low(filtered_hours),\n                'Highest Low': highest_daily_low(filtered_hours),\n                'Record Low': record_daily_low(filtered_hours),\n                'Years': number_of_years_byday(filtered_hours)},\n               attrs={k:v for k, v in meta.items() if k not in ['outdir', 'variables', 'units']})\n\n\nmonthly_records = \\\n    xr.Dataset({'Monthly Average': monthly_avg(filtered_days),\n                'Record High Monthly Average': record_high_monthly_avg(filtered_days),\n                'Record Low Monthly Average': record_low_monthly_avg(filtered_days),\n                'Average High': avg_monthly_high(filtered_days),\n                'Lowest High': lowest_monthly_high(filtered_days),\n                'Record High': record_monthly_high(filtered_days),\n                'Average Low': avg_monthly_low(filtered_days),\n                'Highest Low': highest_monthly_low(filtered_days),\n                'Record Low': record_monthly_low(filtered_days),\n                'Years': number_of_years_bymonth(filtered_days)},\n               attrs={k:v for k, v in meta.items() if k not in ['outdir', 'variables', 'units']})\n\nAdd data units and time series ranges for each variable to the arrays as metadata attributes.\n\nfor k, v in meta['units'].items():\n    daily_records.attrs[k+' units'] = v\n\nfor var in daily_records.coords['variable'].values:\n    if 'Year' not in var:\n        daily_records.attrs[var+' data range'] = \\\n            (filtered_hours[var].first_valid_index().strftime('%Y-%m-%d'),\n             filtered_hours[var].last_valid_index().strftime('%Y-%m-%d'))\n\n\nfor k, v in meta['units'].items():\n    monthly_records.attrs[k+' units'] = v\n\nfor var in monthly_records.coords['variable'].values:\n    if 'Year' not in var:\n        monthly_records.attrs[var+' data range'] = \\\n            (filtered_days[var].first_valid_index().strftime('%Y-%m-%d'),\n             filtered_days[var].last_valid_index().strftime('%Y-%m-%d'))\n\nWhat do we have now? Let’s take a look:\n\ndaily_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 179kB\nDimensions:                    (yearday: 366, variable: 6)\nCoordinates:\n  * yearday                    (yearday) int64 3kB 1 2 3 4 5 ... 363 364 365 366\n  * variable                   (variable) object 48B 'Air Temperature' ... 'W...\nData variables:\n    Daily Average              (yearday, variable) float64 18kB 72.06 ... nan\n    Record High Daily Average  (yearday, variable) float64 18kB 78.7 ... 2.02...\n    Record Low Daily Average   (yearday, variable) float64 18kB 54.4 ... 2.01...\n    Average High               (yearday, variable) float64 18kB 75.49 ... nan\n    Lowest High                (yearday, variable) float64 18kB 63.3 ... 2.01...\n    Record High                (yearday, variable) float64 18kB 80.8 ... 2.02...\n    Average Low                (yearday, variable) float64 18kB 68.64 ... nan\n    Highest Low                (yearday, variable) float64 18kB 77.2 ... 2.02...\n    Record Low                 (yearday, variable) float64 18kB 45.5 ... 2.01...\n    Years                      (yearday, variable) float64 18kB 27.0 nan ... nan\nAttributes: (12/14)\n    datum:                         MHHW\n    day_threshold:                 2\n    dirname:                       virginiaKeyFl\n    hr_threshold:                  4\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    ...                            ...\n    Air Temperature units:         °F\n    Water Level units:             ft\n    Water Temperature units:       °F\n    Air Temperature data range:    ('1994-01-29', '2025-05-30')\n    Water Level data range:        ('1994-01-29', '2025-05-29')\n    Water Temperature data range:  ('1994-01-29', '2025-05-30')xarray.DatasetDimensions:yearday: 366variable: 6Coordinates: (2)yearday(yearday)int641 2 3 4 5 6 ... 362 363 364 365 366array([  1,   2,   3, ..., 364, 365, 366])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype=object)Data variables: (10)Daily Average(yearday, variable)float6472.06 nan -1.108 ... nan 72.48 nanarray([[72.06481481,         nan, -1.10846774,         nan, 72.78392857,\n                nan],\n       [72.12222222,         nan, -1.13256452,         nan, 73.23214286,\n                nan],\n       [70.36296296,         nan, -1.11587097,         nan, 73.35      ,\n                nan],\n       ...,\n       [70.63076923,         nan, -0.97168333,         nan, 72.45      ,\n                nan],\n       [69.73653846,         nan, -1.03998387,         nan, 72.47777778,\n                nan],\n       [70.84038462,         nan, -1.05217742,         nan, 72.48333333,\n                nan]])Record High Daily Average(yearday, variable)float6478.7 2.016e+03 ... 80.5 2.021e+03array([[ 7.870e+01,  2.016e+03, -6.695e-01,  2.022e+03,  8.040e+01,\n         2.022e+03],\n       [ 7.780e+01,  2.022e+03, -6.775e-01,  2.022e+03,  8.025e+01,\n         2.022e+03],\n       [ 7.800e+01,  2.015e+03, -3.575e-01,  2.018e+03,  8.070e+01,\n         2.017e+03],\n       ...,\n       [ 7.945e+01,  2.015e+03, -3.900e-01,  1.994e+03,  8.260e+01,\n         2.016e+03],\n       [ 7.950e+01,  2.015e+03, -4.400e-01,  1.994e+03,  8.195e+01,\n         2.016e+03],\n       [ 7.920e+01,  2.015e+03, -6.525e-01,  2.022e+03,  8.050e+01,\n         2.021e+03]])Record Low Daily Average(yearday, variable)float6454.4 2.001e+03 ... 66.1 2.01e+03array([[ 5.4400e+01,  2.0010e+03, -1.7765e+00,  1.9980e+03,  6.6450e+01,\n         2.0110e+03],\n       [ 5.6650e+01,  2.0100e+03, -1.5780e+00,  2.0110e+03,  6.6850e+01,\n         2.0110e+03],\n       [ 5.1700e+01,  2.0120e+03, -1.7915e+00,  2.0110e+03,  6.7300e+01,\n         2.0110e+03],\n       ...,\n       [ 5.8700e+01,  2.0090e+03, -1.6585e+00,  2.0080e+03,  6.6550e+01,\n         1.9950e+03],\n       [ 5.4750e+01,  2.0000e+03, -1.5370e+00,  1.9960e+03,  6.6400e+01,\n         2.0100e+03],\n       [ 4.9900e+01,  2.0000e+03, -1.5765e+00,  1.9970e+03,  6.6100e+01,\n         2.0100e+03]])Average High(yearday, variable)float6475.49 nan 0.04435 ... nan 73.71 nanarray([[7.54925926e+01,            nan, 4.43548387e-02,            nan,\n        7.40178571e+01,            nan],\n       [7.53962963e+01,            nan, 3.09677419e-03,            nan,\n        7.44607143e+01,            nan],\n       [7.44370370e+01,            nan, 1.67419355e-02,            nan,\n        7.46000000e+01,            nan],\n       ...,\n       [7.44307692e+01,            nan, 1.53700000e-01,            nan,\n        7.38444444e+01,            nan],\n       [7.33230769e+01,            nan, 9.42903226e-02,            nan,\n        7.37962963e+01,            nan],\n       [7.44500000e+01,            nan, 7.68709677e-02,            nan,\n        7.37074074e+01,            nan]])Lowest High(yearday, variable)float6463.3 2.001e+03 ... 67.8 2.01e+03array([[ 6.330e+01,  2.001e+03, -6.460e-01,  2.004e+03,  6.780e+01,\n         2.011e+03],\n       [ 6.420e+01,  2.010e+03, -6.430e-01,  2.012e+03,  6.800e+01,\n         2.011e+03],\n       [ 5.700e+01,  2.012e+03, -7.780e-01,  2.012e+03,  6.890e+01,\n         2.011e+03],\n       ...,\n       [ 6.710e+01,  2.010e+03, -6.690e-01,  2.008e+03,  6.940e+01,\n         2.003e+03],\n       [ 5.950e+01,  2.000e+03, -6.100e-01,  1.996e+03,  6.840e+01,\n         2.010e+03],\n       [ 5.560e+01,  2.000e+03, -6.070e-01,  1.996e+03,  6.780e+01,\n         2.010e+03]])Record High(yearday, variable)float6480.8 2.025e+03 ... 81.7 2.021e+03array([[8.080e+01, 2.025e+03, 8.100e-01, 2.022e+03, 8.110e+01, 2.022e+03],\n       [7.970e+01, 2.016e+03, 9.020e-01, 2.018e+03, 8.100e+01, 2.022e+03],\n       [7.920e+01, 2.019e+03, 1.198e+00, 2.018e+03, 8.150e+01, 2.017e+03],\n       ...,\n       [8.060e+01, 2.015e+03, 9.060e-01, 1.994e+03, 8.330e+01, 2.016e+03],\n       [8.060e+01, 2.013e+03, 9.150e-01, 1.994e+03, 8.310e+01, 2.016e+03],\n       [8.010e+01, 2.015e+03, 7.250e-01, 1.994e+03, 8.170e+01, 2.021e+03]])Average Low(yearday, variable)float6468.64 nan -2.261 ... nan 71.26 nanarray([[68.63703704,         nan, -2.26129032,         nan, 71.55      ,\n                nan],\n       [68.84814815,         nan, -2.26822581,         nan, 72.00357143,\n                nan],\n       [66.28888889,         nan, -2.24848387,         nan, 72.1       ,\n                nan],\n       ...,\n       [66.83076923,         nan, -2.09706667,         nan, 71.05555556,\n                nan],\n       [66.15      ,         nan, -2.17425806,         nan, 71.15925926,\n                nan],\n       [67.23076923,         nan, -2.18122581,         nan, 71.25925926,\n                nan]])Highest Low(yearday, variable)float6477.2 2.016e+03 ... 79.3 2.021e+03array([[ 7.720e+01,  2.016e+03, -1.791e+00,  2.024e+03,  7.970e+01,\n         2.022e+03],\n       [ 7.630e+01,  2.017e+03, -1.516e+00,  2.024e+03,  7.950e+01,\n         2.022e+03],\n       [ 7.700e+01,  2.015e+03, -1.339e+00,  2.024e+03,  7.990e+01,\n         2.017e+03],\n       ...,\n       [ 7.830e+01,  2.015e+03, -1.594e+00,  2.019e+03,  8.190e+01,\n         2.016e+03],\n       [ 7.840e+01,  2.015e+03, -1.519e+00,  2.019e+03,  8.080e+01,\n         2.016e+03],\n       [ 7.830e+01,  2.015e+03, -1.677e+00,  2.019e+03,  7.930e+01,\n         2.021e+03]])Record Low(yearday, variable)float6445.5 2.001e+03 ... 64.4 2.01e+03array([[  45.5  , 2001.   ,   -3.159, 1998.   ,   63.9  , 2001.   ],\n       [  49.1  , 2010.   ,   -2.835, 2006.   ,   64.4  , 2001.   ],\n       [  46.4  , 2012.   ,   -3.035, 2011.   ,   65.5  , 2001.   ],\n       ...,\n       [  50.1  , 2009.   ,   -2.648, 2005.   ,   62.2  , 2010.   ],\n       [  50.   , 2000.   ,   -2.766, 2005.   ,   64.4  , 2010.   ],\n       [  44.2  , 2000.   ,   -2.822, 1997.   ,   64.4  , 2010.   ]])Years(yearday, variable)float6427.0 nan 31.0 nan ... nan 27.0 nanarray([[27., nan, 31., nan, 28., nan],\n       [27., nan, 31., nan, 28., nan],\n       [27., nan, 31., nan, 28., nan],\n       ...,\n       [26., nan, 30., nan, 27., nan],\n       [26., nan, 31., nan, 27., nan],\n       [26., nan, 31., nan, 27., nan]])Indexes: (2)yeardayPandasIndexPandasIndex(Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n            ...\n            357, 358, 359, 360, 361, 362, 363, 364, 365, 366],\n           dtype='int64', name='yearday', length=366))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (14)datum :MHHWday_threshold :2dirname :virginiaKeyFlhr_threshold :4stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :°FWater Level units :ftWater Temperature units :°FAir Temperature data range :('1994-01-29', '2025-05-30')Water Level data range :('1994-01-29', '2025-05-29')Water Temperature data range :('1994-01-29', '2025-05-30')\n\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6kB\nDimensions:                      (month: 12, variable: 6)\nCoordinates:\n  * month                        (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * variable                     (variable) object 48B 'Air Temperature' ... ...\nData variables:\n    Monthly Average              (month, variable) float64 576B 68.66 ... nan\n    Record High Monthly Average  (month, variable) float64 576B 72.57 ... 2.0...\n    Record Low Monthly Average   (month, variable) float64 576B 63.04 ... 2.0...\n    Average High                 (month, variable) float64 576B 76.05 ... nan\n    Lowest High                  (month, variable) float64 576B 72.95 ... 2.0...\n    Record High                  (month, variable) float64 576B 78.05 ... 2.0...\n    Average Low                  (month, variable) float64 576B 55.55 ... nan\n    Highest Low                  (month, variable) float64 576B 63.5 ... 2.01...\n    Record Low                   (month, variable) float64 576B 48.3 ... 2.01...\n    Years                        (month, variable) float64 576B 23.0 nan ... nan\nAttributes: (12/14)\n    datum:                         MHHW\n    day_threshold:                 2\n    dirname:                       virginiaKeyFl\n    hr_threshold:                  4\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    ...                            ...\n    Air Temperature units:         °F\n    Water Level units:             ft\n    Water Temperature units:       °F\n    Air Temperature data range:    ('1994-02-01', '2025-05-30')\n    Water Level data range:        ('1994-02-01', '2025-04-30')\n    Water Temperature data range:  ('1994-02-01', '2025-05-30')xarray.DatasetDimensions:month: 12variable: 6Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype=object)Data variables: (10)Monthly Average(month, variable)float6468.66 nan -1.124 ... nan 74.04 nanarray([[68.65629476,         nan, -1.12401237,         nan, 71.62517419,\n                nan],\n       [70.89272269,         nan, -1.18149129,         nan, 73.14671022,\n                nan],\n       [72.27276989,         nan, -1.07706229,         nan, 75.15274624,\n                nan],\n       [75.63306437,         nan, -1.02213989,         nan, 78.47779399,\n                nan],\n       [78.72849056,         nan, -0.95087643,         nan, 82.13263705,\n                nan],\n       [81.53800571,         nan, -0.98853085,         nan, 85.23606117,\n                nan],\n       [82.90998167,         nan, -1.02524941,         nan, 87.13986958,\n                nan],\n       [83.29827764,         nan, -0.88312497,         nan, 87.34393222,\n                nan],\n       [82.09382299,         nan, -0.5381523 ,         nan, 85.7543954 ,\n                nan],\n       [79.63475582,         nan, -0.36203893,         nan, 82.04959733,\n                nan],\n       [75.04279933,         nan, -0.52922935,         nan, 77.38016782,\n                nan],\n       [71.4254462 ,         nan, -0.91394324,         nan, 74.03937634,\n                nan]])Record High Monthly Average(month, variable)float6472.57 2.013e+03 ... 82.55 2.016e+03array([[ 7.25709677e+01,  2.01300000e+03, -5.27451613e-01,\n         2.02200000e+03,  7.88870968e+01,  2.01700000e+03],\n       [ 7.49000000e+01,  2.01800000e+03, -6.95672414e-01,\n         2.02400000e+03,  7.63017857e+01,  2.02100000e+03],\n       [ 7.76166667e+01,  2.00300000e+03, -5.01596774e-01,\n         2.01900000e+03,  7.99854839e+01,  2.00300000e+03],\n       [ 7.93833333e+01,  2.02000000e+03, -5.01650000e-01,\n         2.02300000e+03,  8.33933333e+01,  2.02000000e+03],\n       [ 8.19306452e+01,  2.02400000e+03, -5.12403226e-01,\n         2.02200000e+03,  8.48129032e+01,  2.02400000e+03],\n       [ 8.36133333e+01,  2.01000000e+03, -5.02616667e-01,\n         2.02300000e+03,  8.76333333e+01,  2.01000000e+03],\n       [ 8.49967742e+01,  2.02300000e+03, -6.88129032e-01,\n         2.01900000e+03,  8.94919355e+01,  2.02300000e+03],\n       [ 8.59064516e+01,  2.02200000e+03, -4.23822581e-01,\n         2.01900000e+03,  9.01096774e+01,  2.02100000e+03],\n       [ 8.37400000e+01,  2.02400000e+03, -2.12833333e-02,\n         2.01900000e+03,  8.94866667e+01,  2.02100000e+03],\n       [ 8.12387097e+01,  2.02000000e+03,  1.75935484e-01,\n         2.02300000e+03,  8.59064516e+01,  2.02100000e+03],\n       [ 7.86233333e+01,  2.01500000e+03,  9.05500000e-02,\n         2.02300000e+03,  8.14666667e+01,  2.01600000e+03],\n       [ 7.68709677e+01,  2.01500000e+03, -2.97661290e-01,\n         2.02200000e+03,  8.25467742e+01,  2.01600000e+03]])Record Low Monthly Average(month, variable)float6463.04 2.001e+03 ... 68.2 2.01e+03array([[ 6.30387097e+01,  2.00100000e+03, -1.55930645e+00,\n         2.00200000e+03,  6.75096774e+01,  2.00100000e+03],\n       [ 6.54655172e+01,  1.99600000e+03, -1.64225000e+00,\n         1.99500000e+03,  6.77392857e+01,  2.00500000e+03],\n       [ 6.60790323e+01,  2.01000000e+03, -1.47172581e+00,\n         1.99600000e+03,  6.92209677e+01,  2.01000000e+03],\n       [ 7.28133333e+01,  2.00400000e+03, -1.48520000e+00,\n         1.99400000e+03,  7.50883333e+01,  2.00400000e+03],\n       [ 7.69741379e+01,  2.00700000e+03, -1.32648276e+00,\n         1.99600000e+03,  7.86403226e+01,  2.00100000e+03],\n       [ 7.98400000e+01,  2.01400000e+03, -1.41310000e+00,\n         1.99600000e+03,  8.32568966e+01,  2.00200000e+03],\n       [ 8.09806452e+01,  2.01300000e+03, -1.42170968e+00,\n         1.99400000e+03,  8.45145161e+01,  2.01300000e+03],\n       [ 8.18209677e+01,  1.99400000e+03, -1.27498387e+00,\n         1.99600000e+03,  8.54354839e+01,  1.99500000e+03],\n       [ 8.05716667e+01,  2.00100000e+03, -1.05141667e+00,\n         1.99600000e+03,  8.27333333e+01,  2.00400000e+03],\n       [ 7.75516129e+01,  2.00000000e+03, -8.86080645e-01,\n         1.99800000e+03,  7.95629032e+01,  2.00000000e+03],\n       [ 7.13733333e+01,  2.01200000e+03, -1.11588333e+00,\n         1.99800000e+03,  7.45900000e+01,  2.01200000e+03],\n       [ 6.20966667e+01,  2.01000000e+03, -1.34004839e+00,\n         2.00800000e+03,  6.82016129e+01,  2.01000000e+03]])Average High(month, variable)float6476.05 nan -0.7102 ... nan 77.61 nanarray([[ 7.60500000e+01,             nan, -7.10209677e-01,\n                    nan,  7.54460000e+01,             nan],\n       [ 7.64854167e+01,             nan, -7.48650000e-01,\n                    nan,  7.70181818e+01,             nan],\n       [ 7.84900000e+01,             nan, -6.95586207e-01,\n                    nan,  7.92420000e+01,             nan],\n       [ 8.07400000e+01,             nan, -6.88650000e-01,\n                    nan,  8.18076923e+01,             nan],\n       [ 8.24807692e+01,             nan, -6.04620690e-01,\n                    nan,  8.52923077e+01,             nan],\n       [ 8.47547619e+01,             nan, -6.88844828e-01,\n                    nan,  8.79041667e+01,             nan],\n       [ 8.57903846e+01,             nan, -6.96016667e-01,\n                    nan,  8.91807692e+01,             nan],\n       [ 8.58458333e+01,             nan, -4.56645161e-01,\n                    nan,  8.94750000e+01,             nan],\n       [ 8.51660000e+01,             nan, -1.05483871e-02,\n                    nan,  8.80340000e+01,             nan],\n       [ 8.38125000e+01,             nan,  1.30224138e-01,\n                    nan,  8.56300000e+01,             nan],\n       [ 7.98416667e+01,             nan,  1.90666667e-02,\n                    nan,  8.06300000e+01,             nan],\n       [ 7.74700000e+01,             nan, -4.77350000e-01,\n                    nan,  7.76060000e+01,             nan]])Lowest High(month, variable)float6472.95 2.011e+03 ... 72.95 2.003e+03array([[ 7.2950e+01,  2.0110e+03, -1.3290e+00,  2.0090e+03,  7.0500e+01,\n         2.0110e+03],\n       [ 7.4200e+01,  2.0000e+03, -1.4140e+00,  1.9950e+03,  7.3700e+01,\n         2.0160e+03],\n       [ 7.4150e+01,  2.0100e+03, -1.1480e+00,  2.0080e+03,  7.3300e+01,\n         2.0100e+03],\n       [ 7.7300e+01,  2.0040e+03, -1.1860e+00,  2.0010e+03,  7.8450e+01,\n         2.0100e+03],\n       [ 7.9350e+01,  2.0070e+03, -1.1025e+00,  2.0040e+03,  8.2500e+01,\n         2.0180e+03],\n       [ 8.2750e+01,  2.0140e+03, -1.1155e+00,  2.0030e+03,  8.5300e+01,\n         1.9960e+03],\n       [ 8.4200e+01,  2.0120e+03, -1.1500e+00,  1.9940e+03,  8.6450e+01,\n         2.0130e+03],\n       [ 8.4050e+01,  2.0030e+03, -9.8900e-01,  2.0010e+03,  8.7250e+01,\n         2.0000e+03],\n       [ 8.3900e+01,  2.0000e+03, -6.6800e-01,  1.9960e+03,  8.5200e+01,\n         1.9970e+03],\n       [ 8.0950e+01,  2.0100e+03, -5.2650e-01,  1.9980e+03,  8.2700e+01,\n         2.0040e+03],\n       [ 7.6900e+01,  2.0120e+03, -6.2000e-01,  1.9950e+03,  7.6750e+01,\n         2.0010e+03],\n       [ 7.2500e+01,  2.0100e+03, -1.0285e+00,  2.0080e+03,  7.2950e+01,\n         2.0030e+03]])Record High(month, variable)float6478.05 2.022e+03 ... 84.55 2.016e+03array([[ 7.8050e+01,  2.0220e+03,  1.5000e-02,  2.0200e+03,  8.1700e+01,\n         2.0170e+03],\n       [ 7.8550e+01,  2.0210e+03, -1.5250e-01,  2.0240e+03,  8.1500e+01,\n         2.0210e+03],\n       [ 8.2850e+01,  2.0030e+03, -5.6000e-02,  2.0190e+03,  8.3200e+01,\n         2.0210e+03],\n       [ 8.5800e+01,  2.0200e+03, -8.0000e-03,  2.0230e+03,  8.5750e+01,\n         2.0200e+03],\n       [ 8.7250e+01,  2.0240e+03,  4.3150e-01,  2.0220e+03,  8.8600e+01,\n         2.0240e+03],\n       [ 8.7650e+01,  2.0090e+03, -4.1000e-02,  2.0230e+03,  9.0400e+01,\n         2.0100e+03],\n       [ 8.8700e+01,  2.0180e+03, -1.9200e-01,  2.0190e+03,  9.2000e+01,\n         2.0210e+03],\n       [ 8.8500e+01,  2.0220e+03,  1.4500e-02,  2.0140e+03,  9.2200e+01,\n         2.0210e+03],\n       [ 8.6700e+01,  2.0210e+03,  1.8965e+00,  2.0170e+03,  9.1150e+01,\n         2.0210e+03],\n       [ 8.6750e+01,  2.0230e+03,  7.2000e-01,  2.0170e+03,  8.9050e+01,\n         2.0160e+03],\n       [ 8.2050e+01,  2.0200e+03,  8.7900e-01,  2.0220e+03,  8.5000e+01,\n         2.0200e+03],\n       [ 7.9650e+01,  1.9940e+03,  4.8100e-01,  2.0230e+03,  8.4550e+01,\n         2.0160e+03]])Average Low(month, variable)float6455.55 nan -1.507 ... nan 70.24 nanarray([[55.55      ,         nan, -1.5068871 ,         nan, 67.71      ,\n                nan],\n       [59.3625    ,         nan, -1.5467    ,         nan, 69.18863636,\n                nan],\n       [63.334     ,         nan, -1.44827586,         nan, 71.098     ,\n                nan],\n       [68.398     ,         nan, -1.3832    ,         nan, 74.68461538,\n                nan],\n       [73.95192308,         nan, -1.26675862,         nan, 78.20192308,\n                nan],\n       [77.63571429,         nan, -1.29075862,         nan, 82.23958333,\n                nan],\n       [79.01923077,         nan, -1.36201667,         nan, 84.58076923,\n                nan],\n       [79.51041667,         nan, -1.25251613,         nan, 84.41346154,\n                nan],\n       [78.336     ,         nan, -0.97132258,         nan, 83.102     ,\n                nan],\n       [72.88333333,         nan, -0.82972414,         nan, 77.872     ,\n                nan],\n       [65.97291667,         nan, -0.99663333,         nan, 74.172     ,\n                nan],\n       [59.406     ,         nan, -1.29768333,         nan, 70.244     ,\n                nan]])Highest Low(month, variable)float6463.5 2.013e+03 ... 79.65 2.016e+03array([[ 6.350e+01,  2.013e+03, -7.970e-01,  2.022e+03,  7.590e+01,\n         2.017e+03],\n       [ 7.000e+01,  2.018e+03, -1.127e+00,  2.019e+03,  7.340e+01,\n         2.023e+03],\n       [ 7.200e+01,  1.997e+03, -9.550e-01,  2.019e+03,  7.540e+01,\n         1.997e+03],\n       [ 7.260e+01,  2.015e+03, -9.910e-01,  2.024e+03,  8.105e+01,\n         2.020e+03],\n       [ 7.710e+01,  2.003e+03, -7.855e-01,  2.024e+03,  8.035e+01,\n         1.994e+03],\n       [ 8.075e+01,  2.004e+03, -8.070e-01,  2.024e+03,  8.520e+01,\n         2.004e+03],\n       [ 8.230e+01,  2.022e+03, -1.091e+00,  2.019e+03,  8.715e+01,\n         2.023e+03],\n       [ 8.355e+01,  2.022e+03, -7.610e-01,  2.019e+03,  8.725e+01,\n         2.021e+03],\n       [ 8.160e+01,  2.024e+03, -5.235e-01,  2.008e+03,  8.710e+01,\n         2.021e+03],\n       [ 7.780e+01,  2.020e+03, -1.020e-01,  2.023e+03,  8.340e+01,\n         2.021e+03],\n       [ 7.445e+01,  2.020e+03, -2.755e-01,  2.022e+03,  8.005e+01,\n         2.016e+03],\n       [ 7.050e+01,  2.015e+03, -6.525e-01,  2.022e+03,  7.965e+01,\n         2.016e+03]])Record Low(month, variable)float6448.3 1.997e+03 ... 63.7 2.01e+03array([[ 4.8300e+01,  1.9970e+03, -2.0160e+00,  2.0010e+03,  6.3950e+01,\n         2.0030e+03],\n       [ 4.7900e+01,  1.9960e+03, -2.0225e+00,  2.0080e+03,  6.3150e+01,\n         2.0050e+03],\n       [ 5.5100e+01,  1.9960e+03, -2.0045e+00,  1.9960e+03,  6.4850e+01,\n         2.0100e+03],\n       [ 6.1200e+01,  2.0090e+03, -1.9000e+00,  1.9940e+03,  6.9400e+01,\n         2.0030e+03],\n       [ 6.7950e+01,  1.9990e+03, -1.6075e+00,  2.0110e+03,  7.4100e+01,\n         2.0010e+03],\n       [ 7.5100e+01,  1.9950e+03, -1.8310e+00,  2.0060e+03,  7.9950e+01,\n         2.0140e+03],\n       [ 7.6100e+01,  2.0130e+03, -1.8160e+00,  1.9940e+03,  8.0950e+01,\n         2.0130e+03],\n       [ 7.7000e+01,  1.9940e+03, -1.6095e+00,  1.9960e+03,  8.1050e+01,\n         2.0120e+03],\n       [ 7.4300e+01,  2.0010e+03, -1.3995e+00,  2.0040e+03,  7.9500e+01,\n         2.0040e+03],\n       [ 6.4600e+01,  2.0050e+03, -1.5915e+00,  2.0100e+03,  7.3200e+01,\n         2.0050e+03],\n       [ 5.7350e+01,  2.0060e+03, -1.5830e+00,  1.9980e+03,  7.0800e+01,\n         2.0000e+03],\n       [ 4.8750e+01,  2.0100e+03, -1.7110e+00,  2.0040e+03,  6.3700e+01,\n         2.0100e+03]])Years(month, variable)float6423.0 nan 31.0 nan ... nan 25.0 nanarray([[23., nan, 31., nan, 25., nan],\n       [24., nan, 30., nan, 22., nan],\n       [25., nan, 29., nan, 25., nan],\n       [25., nan, 30., nan, 26., nan],\n       [26., nan, 29., nan, 26., nan],\n       [21., nan, 29., nan, 24., nan],\n       [26., nan, 30., nan, 26., nan],\n       [24., nan, 31., nan, 26., nan],\n       [25., nan, 31., nan, 25., nan],\n       [24., nan, 29., nan, 25., nan],\n       [24., nan, 30., nan, 25., nan],\n       [25., nan, 30., nan, 25., nan]])Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (14)datum :MHHWday_threshold :2dirname :virginiaKeyFlhr_threshold :4stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :°FWater Level units :ftWater Temperature units :°FAir Temperature data range :('1994-02-01', '2025-05-30')Water Level data range :('1994-02-01', '2025-04-30')Water Temperature data range :('1994-02-01', '2025-05-30')\n\n\nHow are these stored? Let’s consider the monthly stats. Each statistic is its own variable within the dataset. Take Record High for example:\n\nmonthly_records['Record High']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'Record High' (month: 12, variable: 6)&gt; Size: 576B\narray([[ 7.8050e+01,  2.0220e+03,  1.5000e-02,  2.0200e+03,  8.1700e+01,\n         2.0170e+03],\n       [ 7.8550e+01,  2.0210e+03, -1.5250e-01,  2.0240e+03,  8.1500e+01,\n         2.0210e+03],\n       [ 8.2850e+01,  2.0030e+03, -5.6000e-02,  2.0190e+03,  8.3200e+01,\n         2.0210e+03],\n       [ 8.5800e+01,  2.0200e+03, -8.0000e-03,  2.0230e+03,  8.5750e+01,\n         2.0200e+03],\n       [ 8.7250e+01,  2.0240e+03,  4.3150e-01,  2.0220e+03,  8.8600e+01,\n         2.0240e+03],\n       [ 8.7650e+01,  2.0090e+03, -4.1000e-02,  2.0230e+03,  9.0400e+01,\n         2.0100e+03],\n       [ 8.8700e+01,  2.0180e+03, -1.9200e-01,  2.0190e+03,  9.2000e+01,\n         2.0210e+03],\n       [ 8.8500e+01,  2.0220e+03,  1.4500e-02,  2.0140e+03,  9.2200e+01,\n         2.0210e+03],\n       [ 8.6700e+01,  2.0210e+03,  1.8965e+00,  2.0170e+03,  9.1150e+01,\n         2.0210e+03],\n       [ 8.6750e+01,  2.0230e+03,  7.2000e-01,  2.0170e+03,  8.9050e+01,\n         2.0160e+03],\n       [ 8.2050e+01,  2.0200e+03,  8.7900e-01,  2.0220e+03,  8.5000e+01,\n         2.0200e+03],\n       [ 7.9650e+01,  1.9940e+03,  4.8100e-01,  2.0230e+03,  8.4550e+01,\n         2.0160e+03]])\nCoordinates:\n  * month     (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\n  * variable  (variable) object 48B 'Air Temperature' ... 'Water Temperature ...xarray.DataArray'Record High'month: 12variable: 678.05 2.022e+03 0.015 2.02e+03 ... 0.481 2.023e+03 84.55 2.016e+03array([[ 7.8050e+01,  2.0220e+03,  1.5000e-02,  2.0200e+03,  8.1700e+01,\n         2.0170e+03],\n       [ 7.8550e+01,  2.0210e+03, -1.5250e-01,  2.0240e+03,  8.1500e+01,\n         2.0210e+03],\n       [ 8.2850e+01,  2.0030e+03, -5.6000e-02,  2.0190e+03,  8.3200e+01,\n         2.0210e+03],\n       [ 8.5800e+01,  2.0200e+03, -8.0000e-03,  2.0230e+03,  8.5750e+01,\n         2.0200e+03],\n       [ 8.7250e+01,  2.0240e+03,  4.3150e-01,  2.0220e+03,  8.8600e+01,\n         2.0240e+03],\n       [ 8.7650e+01,  2.0090e+03, -4.1000e-02,  2.0230e+03,  9.0400e+01,\n         2.0100e+03],\n       [ 8.8700e+01,  2.0180e+03, -1.9200e-01,  2.0190e+03,  9.2000e+01,\n         2.0210e+03],\n       [ 8.8500e+01,  2.0220e+03,  1.4500e-02,  2.0140e+03,  9.2200e+01,\n         2.0210e+03],\n       [ 8.6700e+01,  2.0210e+03,  1.8965e+00,  2.0170e+03,  9.1150e+01,\n         2.0210e+03],\n       [ 8.6750e+01,  2.0230e+03,  7.2000e-01,  2.0170e+03,  8.9050e+01,\n         2.0160e+03],\n       [ 8.2050e+01,  2.0200e+03,  8.7900e-01,  2.0220e+03,  8.5000e+01,\n         2.0200e+03],\n       [ 7.9650e+01,  1.9940e+03,  4.8100e-01,  2.0230e+03,  8.4550e+01,\n         2.0160e+03]])Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype=object)Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (0)\n\n\nHere, the rows are months and the columns are the records or corresponding year. Let’s see what the variables are:\n\nmonthly_records['Record High'].coords['variable']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'variable' (variable: 6)&gt; Size: 48B\narray(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype=object)\nCoordinates:\n  * variable  (variable) object 48B 'Air Temperature' ... 'Water Temperature ...xarray.DataArray'variable'variable: 6'Air Temperature' 'Air Temperature Year' ... 'Water Temperature Year'array(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype=object)Coordinates: (1)variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype=object)Indexes: (1)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Air Temperature Year', 'Water Level',\n       'Water Level Year', 'Water Temperature', 'Water Temperature Year'],\n      dtype='object', name='variable'))Attributes: (0)\n\n\nAlternatively, we can select a specific variable and see all of its stats (converting to a dataframe makes it easier to see):\n\nmonthly_records.sel(variable='Air Temperature').to_dataframe().drop('variable', axis=1)\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord Low Monthly Average\nAverage High\nLowest High\nRecord High\nAverage Low\nHighest Low\nRecord Low\nYears\n\n\nmonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n68.656295\n72.570968\n63.038710\n76.050000\n72.95\n78.05\n55.550000\n63.50\n48.30\n23.0\n\n\n2\n70.892723\n74.900000\n65.465517\n76.485417\n74.20\n78.55\n59.362500\n70.00\n47.90\n24.0\n\n\n3\n72.272770\n77.616667\n66.079032\n78.490000\n74.15\n82.85\n63.334000\n72.00\n55.10\n25.0\n\n\n4\n75.633064\n79.383333\n72.813333\n80.740000\n77.30\n85.80\n68.398000\n72.60\n61.20\n25.0\n\n\n5\n78.728491\n81.930645\n76.974138\n82.480769\n79.35\n87.25\n73.951923\n77.10\n67.95\n26.0\n\n\n6\n81.538006\n83.613333\n79.840000\n84.754762\n82.75\n87.65\n77.635714\n80.75\n75.10\n21.0\n\n\n7\n82.909982\n84.996774\n80.980645\n85.790385\n84.20\n88.70\n79.019231\n82.30\n76.10\n26.0\n\n\n8\n83.298278\n85.906452\n81.820968\n85.845833\n84.05\n88.50\n79.510417\n83.55\n77.00\n24.0\n\n\n9\n82.093823\n83.740000\n80.571667\n85.166000\n83.90\n86.70\n78.336000\n81.60\n74.30\n25.0\n\n\n10\n79.634756\n81.238710\n77.551613\n83.812500\n80.95\n86.75\n72.883333\n77.80\n64.60\n24.0\n\n\n11\n75.042799\n78.623333\n71.373333\n79.841667\n76.90\n82.05\n65.972917\n74.45\n57.35\n24.0\n\n\n12\n71.425446\n76.870968\n62.096667\n77.470000\n72.50\n79.65\n59.406000\n70.50\n48.75\n25.0\n\n\n\n\n\n\n\n\n\nReorganize\nFor the sake of convenience later, let’s rearrange these data arrays before saving them. It will be more useful to have records and years as data variables instead of a dimension, but we have to do some renaming in order to pull this off.\nFirst, separate the records and years into smaller xarrays:\n\nday_records = daily_records.sel(variable=[i for i in daily_records.coords['variable'].values if 'Year' not in i])\nday_years = daily_records.sel(variable=[i for i in daily_records.coords['variable'].values if 'Year' in i])\n\nmon_records = monthly_records.sel(variable=[i for i in monthly_records.coords['variable'].values if 'Year' not in i])\nmon_years = monthly_records.sel(variable=[i for i in monthly_records.coords['variable'].values if 'Year' in i])\n\nNext, add “Year” to all of the variable names and remove it from the coordinate name:\n\nday_years = day_years.rename_vars({i:i+' Year' for i in day_years.data_vars})\nday_years.coords['variable'] = [i.removesuffix(' Year') for i in day_years.coords['variable'].values]\n\nmon_years = mon_years.rename_vars({i:i+' Year' for i in mon_years.data_vars})\nmon_years.coords['variable'] = [i.removesuffix(' Year') for i in mon_years.coords['variable'].values]\n\nNow we can merge these two xarrays together, rearrange the order of the variables, and drop those that do not contain a year, such as daily average.\n\ndaily_records = xr.merge([day_records, day_years])\ndaily_records = daily_records[[item for items in zip(day_records.data_vars, day_years.data_vars) for item in items]]\ndaily_records = daily_records.drop_vars([x for x in daily_records.data_vars if daily_records[x].isnull().all()])\n\nmonthly_records = xr.merge([mon_records, mon_years])\nmonthly_records = monthly_records[[item for items in zip(mon_records.data_vars, mon_years.data_vars) for item in items]]\nmonthly_records = monthly_records.drop_vars([x for x in monthly_records.data_vars if monthly_records[x].isnull().all()])\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5kB\nDimensions:                           (month: 12, variable: 3)\nCoordinates:\n  * month                             (month) int64 96B 1 2 3 4 5 ... 9 10 11 12\n  * variable                          (variable) object 24B 'Air Temperature'...\nData variables: (12/16)\n    Monthly Average                   (month, variable) float64 288B 68.66 .....\n    Record High Monthly Average       (month, variable) float64 288B 72.57 .....\n    Record High Monthly Average Year  (month, variable) float64 288B 2.013e+0...\n    Record Low Monthly Average        (month, variable) float64 288B 63.04 .....\n    Record Low Monthly Average Year   (month, variable) float64 288B 2.001e+0...\n    Average High                      (month, variable) float64 288B 76.05 .....\n    ...                                ...\n    Average Low                       (month, variable) float64 288B 55.55 .....\n    Highest Low                       (month, variable) float64 288B 63.5 ......\n    Highest Low Year                  (month, variable) float64 288B 2.013e+0...\n    Record Low                        (month, variable) float64 288B 48.3 ......\n    Record Low Year                   (month, variable) float64 288B 1.997e+0...\n    Years                             (month, variable) float64 288B 23.0 ......\nAttributes: (12/14)\n    datum:                         MHHW\n    day_threshold:                 2\n    dirname:                       virginiaKeyFl\n    hr_threshold:                  4\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    ...                            ...\n    Air Temperature units:         °F\n    Water Level units:             ft\n    Water Temperature units:       °F\n    Air Temperature data range:    ('1994-02-01', '2025-05-30')\n    Water Level data range:        ('1994-02-01', '2025-04-30')\n    Water Temperature data range:  ('1994-02-01', '2025-05-30')xarray.DatasetDimensions:month: 12variable: 3Coordinates: (2)month(month)int641 2 3 4 5 6 7 8 9 10 11 12array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Water Level', 'Water Temperature'], dtype=object)Data variables: (16)Monthly Average(month, variable)float6468.66 -1.124 ... -0.9139 74.04array([[68.65629476, -1.12401237, 71.62517419],\n       [70.89272269, -1.18149129, 73.14671022],\n       [72.27276989, -1.07706229, 75.15274624],\n       [75.63306437, -1.02213989, 78.47779399],\n       [78.72849056, -0.95087643, 82.13263705],\n       [81.53800571, -0.98853085, 85.23606117],\n       [82.90998167, -1.02524941, 87.13986958],\n       [83.29827764, -0.88312497, 87.34393222],\n       [82.09382299, -0.5381523 , 85.7543954 ],\n       [79.63475582, -0.36203893, 82.04959733],\n       [75.04279933, -0.52922935, 77.38016782],\n       [71.4254462 , -0.91394324, 74.03937634]])Record High Monthly Average(month, variable)float6472.57 -0.5275 ... -0.2977 82.55array([[ 7.25709677e+01, -5.27451613e-01,  7.88870968e+01],\n       [ 7.49000000e+01, -6.95672414e-01,  7.63017857e+01],\n       [ 7.76166667e+01, -5.01596774e-01,  7.99854839e+01],\n       [ 7.93833333e+01, -5.01650000e-01,  8.33933333e+01],\n       [ 8.19306452e+01, -5.12403226e-01,  8.48129032e+01],\n       [ 8.36133333e+01, -5.02616667e-01,  8.76333333e+01],\n       [ 8.49967742e+01, -6.88129032e-01,  8.94919355e+01],\n       [ 8.59064516e+01, -4.23822581e-01,  9.01096774e+01],\n       [ 8.37400000e+01, -2.12833333e-02,  8.94866667e+01],\n       [ 8.12387097e+01,  1.75935484e-01,  8.59064516e+01],\n       [ 7.86233333e+01,  9.05500000e-02,  8.14666667e+01],\n       [ 7.68709677e+01, -2.97661290e-01,  8.25467742e+01]])Record High Monthly Average Year(month, variable)float642.013e+03 2.022e+03 ... 2.016e+03array([[2013., 2022., 2017.],\n       [2018., 2024., 2021.],\n       [2003., 2019., 2003.],\n       [2020., 2023., 2020.],\n       [2024., 2022., 2024.],\n       [2010., 2023., 2010.],\n       [2023., 2019., 2023.],\n       [2022., 2019., 2021.],\n       [2024., 2019., 2021.],\n       [2020., 2023., 2021.],\n       [2015., 2023., 2016.],\n       [2015., 2022., 2016.]])Record Low Monthly Average(month, variable)float6463.04 -1.559 67.51 ... -1.34 68.2array([[63.03870968, -1.55930645, 67.50967742],\n       [65.46551724, -1.64225   , 67.73928571],\n       [66.07903226, -1.47172581, 69.22096774],\n       [72.81333333, -1.4852    , 75.08833333],\n       [76.97413793, -1.32648276, 78.64032258],\n       [79.84      , -1.4131    , 83.25689655],\n       [80.98064516, -1.42170968, 84.51451613],\n       [81.82096774, -1.27498387, 85.43548387],\n       [80.57166667, -1.05141667, 82.73333333],\n       [77.5516129 , -0.88608065, 79.56290323],\n       [71.37333333, -1.11588333, 74.59      ],\n       [62.09666667, -1.34004839, 68.2016129 ]])Record Low Monthly Average Year(month, variable)float642.001e+03 2.002e+03 ... 2.01e+03array([[2001., 2002., 2001.],\n       [1996., 1995., 2005.],\n       [2010., 1996., 2010.],\n       [2004., 1994., 2004.],\n       [2007., 1996., 2001.],\n       [2014., 1996., 2002.],\n       [2013., 1994., 2013.],\n       [1994., 1996., 1995.],\n       [2001., 1996., 2004.],\n       [2000., 1998., 2000.],\n       [2012., 1998., 2012.],\n       [2010., 2008., 2010.]])Average High(month, variable)float6476.05 -0.7102 ... -0.4773 77.61array([[ 7.60500000e+01, -7.10209677e-01,  7.54460000e+01],\n       [ 7.64854167e+01, -7.48650000e-01,  7.70181818e+01],\n       [ 7.84900000e+01, -6.95586207e-01,  7.92420000e+01],\n       [ 8.07400000e+01, -6.88650000e-01,  8.18076923e+01],\n       [ 8.24807692e+01, -6.04620690e-01,  8.52923077e+01],\n       [ 8.47547619e+01, -6.88844828e-01,  8.79041667e+01],\n       [ 8.57903846e+01, -6.96016667e-01,  8.91807692e+01],\n       [ 8.58458333e+01, -4.56645161e-01,  8.94750000e+01],\n       [ 8.51660000e+01, -1.05483871e-02,  8.80340000e+01],\n       [ 8.38125000e+01,  1.30224138e-01,  8.56300000e+01],\n       [ 7.98416667e+01,  1.90666667e-02,  8.06300000e+01],\n       [ 7.74700000e+01, -4.77350000e-01,  7.76060000e+01]])Lowest High(month, variable)float6472.95 -1.329 70.5 ... -1.028 72.95array([[72.95  , -1.329 , 70.5   ],\n       [74.2   , -1.414 , 73.7   ],\n       [74.15  , -1.148 , 73.3   ],\n       [77.3   , -1.186 , 78.45  ],\n       [79.35  , -1.1025, 82.5   ],\n       [82.75  , -1.1155, 85.3   ],\n       [84.2   , -1.15  , 86.45  ],\n       [84.05  , -0.989 , 87.25  ],\n       [83.9   , -0.668 , 85.2   ],\n       [80.95  , -0.5265, 82.7   ],\n       [76.9   , -0.62  , 76.75  ],\n       [72.5   , -1.0285, 72.95  ]])Lowest High Year(month, variable)float642.011e+03 2.009e+03 ... 2.003e+03array([[2011., 2009., 2011.],\n       [2000., 1995., 2016.],\n       [2010., 2008., 2010.],\n       [2004., 2001., 2010.],\n       [2007., 2004., 2018.],\n       [2014., 2003., 1996.],\n       [2012., 1994., 2013.],\n       [2003., 2001., 2000.],\n       [2000., 1996., 1997.],\n       [2010., 1998., 2004.],\n       [2012., 1995., 2001.],\n       [2010., 2008., 2003.]])Record High(month, variable)float6478.05 0.015 81.7 ... 0.481 84.55array([[ 7.8050e+01,  1.5000e-02,  8.1700e+01],\n       [ 7.8550e+01, -1.5250e-01,  8.1500e+01],\n       [ 8.2850e+01, -5.6000e-02,  8.3200e+01],\n       [ 8.5800e+01, -8.0000e-03,  8.5750e+01],\n       [ 8.7250e+01,  4.3150e-01,  8.8600e+01],\n       [ 8.7650e+01, -4.1000e-02,  9.0400e+01],\n       [ 8.8700e+01, -1.9200e-01,  9.2000e+01],\n       [ 8.8500e+01,  1.4500e-02,  9.2200e+01],\n       [ 8.6700e+01,  1.8965e+00,  9.1150e+01],\n       [ 8.6750e+01,  7.2000e-01,  8.9050e+01],\n       [ 8.2050e+01,  8.7900e-01,  8.5000e+01],\n       [ 7.9650e+01,  4.8100e-01,  8.4550e+01]])Record High Year(month, variable)float642.022e+03 2.02e+03 ... 2.016e+03array([[2022., 2020., 2017.],\n       [2021., 2024., 2021.],\n       [2003., 2019., 2021.],\n       [2020., 2023., 2020.],\n       [2024., 2022., 2024.],\n       [2009., 2023., 2010.],\n       [2018., 2019., 2021.],\n       [2022., 2014., 2021.],\n       [2021., 2017., 2021.],\n       [2023., 2017., 2016.],\n       [2020., 2022., 2020.],\n       [1994., 2023., 2016.]])Average Low(month, variable)float6455.55 -1.507 67.71 ... -1.298 70.24array([[55.55      , -1.5068871 , 67.71      ],\n       [59.3625    , -1.5467    , 69.18863636],\n       [63.334     , -1.44827586, 71.098     ],\n       [68.398     , -1.3832    , 74.68461538],\n       [73.95192308, -1.26675862, 78.20192308],\n       [77.63571429, -1.29075862, 82.23958333],\n       [79.01923077, -1.36201667, 84.58076923],\n       [79.51041667, -1.25251613, 84.41346154],\n       [78.336     , -0.97132258, 83.102     ],\n       [72.88333333, -0.82972414, 77.872     ],\n       [65.97291667, -0.99663333, 74.172     ],\n       [59.406     , -1.29768333, 70.244     ]])Highest Low(month, variable)float6463.5 -0.797 75.9 ... -0.6525 79.65array([[63.5   , -0.797 , 75.9   ],\n       [70.    , -1.127 , 73.4   ],\n       [72.    , -0.955 , 75.4   ],\n       [72.6   , -0.991 , 81.05  ],\n       [77.1   , -0.7855, 80.35  ],\n       [80.75  , -0.807 , 85.2   ],\n       [82.3   , -1.091 , 87.15  ],\n       [83.55  , -0.761 , 87.25  ],\n       [81.6   , -0.5235, 87.1   ],\n       [77.8   , -0.102 , 83.4   ],\n       [74.45  , -0.2755, 80.05  ],\n       [70.5   , -0.6525, 79.65  ]])Highest Low Year(month, variable)float642.013e+03 2.022e+03 ... 2.016e+03array([[2013., 2022., 2017.],\n       [2018., 2019., 2023.],\n       [1997., 2019., 1997.],\n       [2015., 2024., 2020.],\n       [2003., 2024., 1994.],\n       [2004., 2024., 2004.],\n       [2022., 2019., 2023.],\n       [2022., 2019., 2021.],\n       [2024., 2008., 2021.],\n       [2020., 2023., 2021.],\n       [2020., 2022., 2016.],\n       [2015., 2022., 2016.]])Record Low(month, variable)float6448.3 -2.016 63.95 ... -1.711 63.7array([[48.3   , -2.016 , 63.95  ],\n       [47.9   , -2.0225, 63.15  ],\n       [55.1   , -2.0045, 64.85  ],\n       [61.2   , -1.9   , 69.4   ],\n       [67.95  , -1.6075, 74.1   ],\n       [75.1   , -1.831 , 79.95  ],\n       [76.1   , -1.816 , 80.95  ],\n       [77.    , -1.6095, 81.05  ],\n       [74.3   , -1.3995, 79.5   ],\n       [64.6   , -1.5915, 73.2   ],\n       [57.35  , -1.583 , 70.8   ],\n       [48.75  , -1.711 , 63.7   ]])Record Low Year(month, variable)float641.997e+03 2.001e+03 ... 2.01e+03array([[1997., 2001., 2003.],\n       [1996., 2008., 2005.],\n       [1996., 1996., 2010.],\n       [2009., 1994., 2003.],\n       [1999., 2011., 2001.],\n       [1995., 2006., 2014.],\n       [2013., 1994., 2013.],\n       [1994., 1996., 2012.],\n       [2001., 2004., 2004.],\n       [2005., 2010., 2005.],\n       [2006., 1998., 2000.],\n       [2010., 2004., 2010.]])Years(month, variable)float6423.0 31.0 25.0 ... 25.0 30.0 25.0array([[23., 31., 25.],\n       [24., 30., 22.],\n       [25., 29., 25.],\n       [25., 30., 26.],\n       [26., 29., 26.],\n       [21., 29., 24.],\n       [26., 30., 26.],\n       [24., 31., 26.],\n       [25., 31., 25.],\n       [24., 29., 25.],\n       [24., 30., 25.],\n       [25., 30., 25.]])Indexes: (2)monthPandasIndexPandasIndex(Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Level', 'Water Temperature'], dtype='object', name='variable'))Attributes: (14)datum :MHHWday_threshold :2dirname :virginiaKeyFlhr_threshold :4stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :°FWater Level units :ftWater Temperature units :°FAir Temperature data range :('1994-02-01', '2025-05-30')Water Level data range :('1994-02-01', '2025-04-30')Water Temperature data range :('1994-02-01', '2025-05-30')\n\n\nFinally, let’s convert years to integers since we do not need decimal years.\n\ndaily_records[[i for i in daily_records.data_vars if \"Year\" in i]] = \\\n    daily_records[[i for i in daily_records.data_vars if \"Year\" in i]].astype(int)\n\nmonthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]] = \\\n    monthly_records[[i for i in monthly_records.data_vars if \"Year\" in i]].astype(int)\n\n‘yearday’ is not intuitive, so we can change it to calendar day instead and rename the coordinate. Similarly, we can use month names instead of numbers for the sake of clarity.\n\ndaily_records.coords['yearday'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1D').strftime('%d-%b')\ndaily_records = daily_records.rename({'yearday':'Date'})\n\nmonthly_records.coords['month'] = pd.date_range(start='2020-01-01', end='2020-12-31', freq='1m').strftime('%b')\nmonthly_records = monthly_records.rename({'month': 'Month'})\n\nNow take a look at the final products\n\ndaily_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 143kB\nDimensions:                         (Date: 366, variable: 3)\nCoordinates:\n  * variable                        (variable) object 24B 'Air Temperature' ....\n  * Date                            (Date) object 3kB '01-Jan' ... '31-Dec'\nData variables: (12/16)\n    Daily Average                   (Date, variable) float64 9kB 72.06 ... 72.48\n    Record High Daily Average       (Date, variable) float64 9kB 78.7 ... 80.5\n    Record High Daily Average Year  (Date, variable) int64 9kB 2016 ... 2021\n    Record Low Daily Average        (Date, variable) float64 9kB 54.4 ... 66.1\n    Record Low Daily Average Year   (Date, variable) int64 9kB 2001 ... 2010\n    Average High                    (Date, variable) float64 9kB 75.49 ... 73.71\n    ...                              ...\n    Average Low                     (Date, variable) float64 9kB 68.64 ... 71.26\n    Highest Low                     (Date, variable) float64 9kB 77.2 ... 79.3\n    Highest Low Year                (Date, variable) int64 9kB 2016 ... 2021\n    Record Low                      (Date, variable) float64 9kB 45.5 ... 64.4\n    Record Low Year                 (Date, variable) int64 9kB 2001 ... 2010\n    Years                           (Date, variable) int64 9kB 27 31 ... 31 27\nAttributes: (12/14)\n    datum:                         MHHW\n    day_threshold:                 2\n    dirname:                       virginiaKeyFl\n    hr_threshold:                  4\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    ...                            ...\n    Air Temperature units:         °F\n    Water Level units:             ft\n    Water Temperature units:       °F\n    Air Temperature data range:    ('1994-01-29', '2025-05-30')\n    Water Level data range:        ('1994-01-29', '2025-05-29')\n    Water Temperature data range:  ('1994-01-29', '2025-05-30')xarray.DatasetDimensions:Date: 366variable: 3Coordinates: (2)variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Water Level', 'Water Temperature'], dtype=object)Date(Date)object'01-Jan' '02-Jan' ... '31-Dec'array(['01-Jan', '02-Jan', '03-Jan', ..., '29-Dec', '30-Dec', '31-Dec'],\n      dtype=object)Data variables: (16)Daily Average(Date, variable)float6472.06 -1.108 72.78 ... -1.052 72.48array([[72.06481481, -1.10846774, 72.78392857],\n       [72.12222222, -1.13256452, 73.23214286],\n       [70.36296296, -1.11587097, 73.35      ],\n       ...,\n       [70.63076923, -0.97168333, 72.45      ],\n       [69.73653846, -1.03998387, 72.47777778],\n       [70.84038462, -1.05217742, 72.48333333]])Record High Daily Average(Date, variable)float6478.7 -0.6695 80.4 ... -0.6525 80.5array([[78.7   , -0.6695, 80.4   ],\n       [77.8   , -0.6775, 80.25  ],\n       [78.    , -0.3575, 80.7   ],\n       ...,\n       [79.45  , -0.39  , 82.6   ],\n       [79.5   , -0.44  , 81.95  ],\n       [79.2   , -0.6525, 80.5   ]])Record High Daily Average Year(Date, variable)int642016 2022 2022 ... 2015 2022 2021array([[2016, 2022, 2022],\n       [2022, 2022, 2022],\n       [2015, 2018, 2017],\n       ...,\n       [2015, 1994, 2016],\n       [2015, 1994, 2016],\n       [2015, 2022, 2021]])Record Low Daily Average(Date, variable)float6454.4 -1.776 66.45 ... -1.577 66.1array([[54.4   , -1.7765, 66.45  ],\n       [56.65  , -1.578 , 66.85  ],\n       [51.7   , -1.7915, 67.3   ],\n       ...,\n       [58.7   , -1.6585, 66.55  ],\n       [54.75  , -1.537 , 66.4   ],\n       [49.9   , -1.5765, 66.1   ]])Record Low Daily Average Year(Date, variable)int642001 1998 2011 ... 2000 1997 2010array([[2001, 1998, 2011],\n       [2010, 2011, 2011],\n       [2012, 2011, 2011],\n       ...,\n       [2009, 2008, 1995],\n       [2000, 1996, 2010],\n       [2000, 1997, 2010]])Average High(Date, variable)float6475.49 0.04435 ... 0.07687 73.71array([[7.54925926e+01, 4.43548387e-02, 7.40178571e+01],\n       [7.53962963e+01, 3.09677419e-03, 7.44607143e+01],\n       [7.44370370e+01, 1.67419355e-02, 7.46000000e+01],\n       ...,\n       [7.44307692e+01, 1.53700000e-01, 7.38444444e+01],\n       [7.33230769e+01, 9.42903226e-02, 7.37962963e+01],\n       [7.44500000e+01, 7.68709677e-02, 7.37074074e+01]])Lowest High(Date, variable)float6463.3 -0.646 67.8 ... -0.607 67.8array([[63.3  , -0.646, 67.8  ],\n       [64.2  , -0.643, 68.   ],\n       [57.   , -0.778, 68.9  ],\n       ...,\n       [67.1  , -0.669, 69.4  ],\n       [59.5  , -0.61 , 68.4  ],\n       [55.6  , -0.607, 67.8  ]])Lowest High Year(Date, variable)int642001 2004 2011 ... 2000 1996 2010array([[2001, 2004, 2011],\n       [2010, 2012, 2011],\n       [2012, 2012, 2011],\n       ...,\n       [2010, 2008, 2003],\n       [2000, 1996, 2010],\n       [2000, 1996, 2010]])Record High(Date, variable)float6480.8 0.81 81.1 ... 80.1 0.725 81.7array([[80.8  ,  0.81 , 81.1  ],\n       [79.7  ,  0.902, 81.   ],\n       [79.2  ,  1.198, 81.5  ],\n       ...,\n       [80.6  ,  0.906, 83.3  ],\n       [80.6  ,  0.915, 83.1  ],\n       [80.1  ,  0.725, 81.7  ]])Record High Year(Date, variable)int642025 2022 2022 ... 2015 1994 2021array([[2025, 2022, 2022],\n       [2016, 2018, 2022],\n       [2019, 2018, 2017],\n       ...,\n       [2015, 1994, 2016],\n       [2013, 1994, 2016],\n       [2015, 1994, 2021]])Average Low(Date, variable)float6468.64 -2.261 71.55 ... -2.181 71.26array([[68.63703704, -2.26129032, 71.55      ],\n       [68.84814815, -2.26822581, 72.00357143],\n       [66.28888889, -2.24848387, 72.1       ],\n       ...,\n       [66.83076923, -2.09706667, 71.05555556],\n       [66.15      , -2.17425806, 71.15925926],\n       [67.23076923, -2.18122581, 71.25925926]])Highest Low(Date, variable)float6477.2 -1.791 79.7 ... -1.677 79.3array([[77.2  , -1.791, 79.7  ],\n       [76.3  , -1.516, 79.5  ],\n       [77.   , -1.339, 79.9  ],\n       ...,\n       [78.3  , -1.594, 81.9  ],\n       [78.4  , -1.519, 80.8  ],\n       [78.3  , -1.677, 79.3  ]])Highest Low Year(Date, variable)int642016 2024 2022 ... 2015 2019 2021array([[2016, 2024, 2022],\n       [2017, 2024, 2022],\n       [2015, 2024, 2017],\n       ...,\n       [2015, 2019, 2016],\n       [2015, 2019, 2016],\n       [2015, 2019, 2021]])Record Low(Date, variable)float6445.5 -3.159 63.9 ... -2.822 64.4array([[45.5  , -3.159, 63.9  ],\n       [49.1  , -2.835, 64.4  ],\n       [46.4  , -3.035, 65.5  ],\n       ...,\n       [50.1  , -2.648, 62.2  ],\n       [50.   , -2.766, 64.4  ],\n       [44.2  , -2.822, 64.4  ]])Record Low Year(Date, variable)int642001 1998 2001 ... 2000 1997 2010array([[2001, 1998, 2001],\n       [2010, 2006, 2001],\n       [2012, 2011, 2001],\n       ...,\n       [2009, 2005, 2010],\n       [2000, 2005, 2010],\n       [2000, 1997, 2010]])Years(Date, variable)int6427 31 28 27 31 ... 31 27 26 31 27array([[27, 31, 28],\n       [27, 31, 28],\n       [27, 31, 28],\n       ...,\n       [26, 30, 27],\n       [26, 31, 27],\n       [26, 31, 27]])Indexes: (2)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Level', 'Water Temperature'], dtype='object', name='variable'))DatePandasIndexPandasIndex(Index(['01-Jan', '02-Jan', '03-Jan', '04-Jan', '05-Jan', '06-Jan', '07-Jan',\n       '08-Jan', '09-Jan', '10-Jan',\n       ...\n       '22-Dec', '23-Dec', '24-Dec', '25-Dec', '26-Dec', '27-Dec', '28-Dec',\n       '29-Dec', '30-Dec', '31-Dec'],\n      dtype='object', name='Date', length=366))Attributes: (14)datum :MHHWday_threshold :2dirname :virginiaKeyFlhr_threshold :4stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :°FWater Level units :ftWater Temperature units :°FAir Temperature data range :('1994-01-29', '2025-05-30')Water Level data range :('1994-01-29', '2025-05-29')Water Temperature data range :('1994-01-29', '2025-05-30')\n\n\n\nmonthly_records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5kB\nDimensions:                           (Month: 12, variable: 3)\nCoordinates:\n  * variable                          (variable) object 24B 'Air Temperature'...\n  * Month                             (Month) object 96B 'Jan' 'Feb' ... 'Dec'\nData variables: (12/16)\n    Monthly Average                   (Month, variable) float64 288B 68.66 .....\n    Record High Monthly Average       (Month, variable) float64 288B 72.57 .....\n    Record High Monthly Average Year  (Month, variable) int64 288B 2013 ... 2016\n    Record Low Monthly Average        (Month, variable) float64 288B 63.04 .....\n    Record Low Monthly Average Year   (Month, variable) int64 288B 2001 ... 2010\n    Average High                      (Month, variable) float64 288B 76.05 .....\n    ...                                ...\n    Average Low                       (Month, variable) float64 288B 55.55 .....\n    Highest Low                       (Month, variable) float64 288B 63.5 ......\n    Highest Low Year                  (Month, variable) int64 288B 2013 ... 2016\n    Record Low                        (Month, variable) float64 288B 48.3 ......\n    Record Low Year                   (Month, variable) int64 288B 1997 ... 2010\n    Years                             (Month, variable) int64 288B 23 31 ... 25\nAttributes: (12/14)\n    datum:                         MHHW\n    day_threshold:                 2\n    dirname:                       virginiaKeyFl\n    hr_threshold:                  4\n    stationid:                     8723214\n    stationname:                   Virginia Key, FL\n    ...                            ...\n    Air Temperature units:         °F\n    Water Level units:             ft\n    Water Temperature units:       °F\n    Air Temperature data range:    ('1994-02-01', '2025-05-30')\n    Water Level data range:        ('1994-02-01', '2025-04-30')\n    Water Temperature data range:  ('1994-02-01', '2025-05-30')xarray.DatasetDimensions:Month: 12variable: 3Coordinates: (2)variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Water Level', 'Water Temperature'], dtype=object)Month(Month)object'Jan' 'Feb' 'Mar' ... 'Nov' 'Dec'array(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct',\n       'Nov', 'Dec'], dtype=object)Data variables: (16)Monthly Average(Month, variable)float6468.66 -1.124 ... -0.9139 74.04array([[68.65629476, -1.12401237, 71.62517419],\n       [70.89272269, -1.18149129, 73.14671022],\n       [72.27276989, -1.07706229, 75.15274624],\n       [75.63306437, -1.02213989, 78.47779399],\n       [78.72849056, -0.95087643, 82.13263705],\n       [81.53800571, -0.98853085, 85.23606117],\n       [82.90998167, -1.02524941, 87.13986958],\n       [83.29827764, -0.88312497, 87.34393222],\n       [82.09382299, -0.5381523 , 85.7543954 ],\n       [79.63475582, -0.36203893, 82.04959733],\n       [75.04279933, -0.52922935, 77.38016782],\n       [71.4254462 , -0.91394324, 74.03937634]])Record High Monthly Average(Month, variable)float6472.57 -0.5275 ... -0.2977 82.55array([[ 7.25709677e+01, -5.27451613e-01,  7.88870968e+01],\n       [ 7.49000000e+01, -6.95672414e-01,  7.63017857e+01],\n       [ 7.76166667e+01, -5.01596774e-01,  7.99854839e+01],\n       [ 7.93833333e+01, -5.01650000e-01,  8.33933333e+01],\n       [ 8.19306452e+01, -5.12403226e-01,  8.48129032e+01],\n       [ 8.36133333e+01, -5.02616667e-01,  8.76333333e+01],\n       [ 8.49967742e+01, -6.88129032e-01,  8.94919355e+01],\n       [ 8.59064516e+01, -4.23822581e-01,  9.01096774e+01],\n       [ 8.37400000e+01, -2.12833333e-02,  8.94866667e+01],\n       [ 8.12387097e+01,  1.75935484e-01,  8.59064516e+01],\n       [ 7.86233333e+01,  9.05500000e-02,  8.14666667e+01],\n       [ 7.68709677e+01, -2.97661290e-01,  8.25467742e+01]])Record High Monthly Average Year(Month, variable)int642013 2022 2017 ... 2015 2022 2016array([[2013, 2022, 2017],\n       [2018, 2024, 2021],\n       [2003, 2019, 2003],\n       [2020, 2023, 2020],\n       [2024, 2022, 2024],\n       [2010, 2023, 2010],\n       [2023, 2019, 2023],\n       [2022, 2019, 2021],\n       [2024, 2019, 2021],\n       [2020, 2023, 2021],\n       [2015, 2023, 2016],\n       [2015, 2022, 2016]])Record Low Monthly Average(Month, variable)float6463.04 -1.559 67.51 ... -1.34 68.2array([[63.03870968, -1.55930645, 67.50967742],\n       [65.46551724, -1.64225   , 67.73928571],\n       [66.07903226, -1.47172581, 69.22096774],\n       [72.81333333, -1.4852    , 75.08833333],\n       [76.97413793, -1.32648276, 78.64032258],\n       [79.84      , -1.4131    , 83.25689655],\n       [80.98064516, -1.42170968, 84.51451613],\n       [81.82096774, -1.27498387, 85.43548387],\n       [80.57166667, -1.05141667, 82.73333333],\n       [77.5516129 , -0.88608065, 79.56290323],\n       [71.37333333, -1.11588333, 74.59      ],\n       [62.09666667, -1.34004839, 68.2016129 ]])Record Low Monthly Average Year(Month, variable)int642001 2002 2001 ... 2010 2008 2010array([[2001, 2002, 2001],\n       [1996, 1995, 2005],\n       [2010, 1996, 2010],\n       [2004, 1994, 2004],\n       [2007, 1996, 2001],\n       [2014, 1996, 2002],\n       [2013, 1994, 2013],\n       [1994, 1996, 1995],\n       [2001, 1996, 2004],\n       [2000, 1998, 2000],\n       [2012, 1998, 2012],\n       [2010, 2008, 2010]])Average High(Month, variable)float6476.05 -0.7102 ... -0.4773 77.61array([[ 7.60500000e+01, -7.10209677e-01,  7.54460000e+01],\n       [ 7.64854167e+01, -7.48650000e-01,  7.70181818e+01],\n       [ 7.84900000e+01, -6.95586207e-01,  7.92420000e+01],\n       [ 8.07400000e+01, -6.88650000e-01,  8.18076923e+01],\n       [ 8.24807692e+01, -6.04620690e-01,  8.52923077e+01],\n       [ 8.47547619e+01, -6.88844828e-01,  8.79041667e+01],\n       [ 8.57903846e+01, -6.96016667e-01,  8.91807692e+01],\n       [ 8.58458333e+01, -4.56645161e-01,  8.94750000e+01],\n       [ 8.51660000e+01, -1.05483871e-02,  8.80340000e+01],\n       [ 8.38125000e+01,  1.30224138e-01,  8.56300000e+01],\n       [ 7.98416667e+01,  1.90666667e-02,  8.06300000e+01],\n       [ 7.74700000e+01, -4.77350000e-01,  7.76060000e+01]])Lowest High(Month, variable)float6472.95 -1.329 70.5 ... -1.028 72.95array([[72.95  , -1.329 , 70.5   ],\n       [74.2   , -1.414 , 73.7   ],\n       [74.15  , -1.148 , 73.3   ],\n       [77.3   , -1.186 , 78.45  ],\n       [79.35  , -1.1025, 82.5   ],\n       [82.75  , -1.1155, 85.3   ],\n       [84.2   , -1.15  , 86.45  ],\n       [84.05  , -0.989 , 87.25  ],\n       [83.9   , -0.668 , 85.2   ],\n       [80.95  , -0.5265, 82.7   ],\n       [76.9   , -0.62  , 76.75  ],\n       [72.5   , -1.0285, 72.95  ]])Lowest High Year(Month, variable)int642011 2009 2011 ... 2010 2008 2003array([[2011, 2009, 2011],\n       [2000, 1995, 2016],\n       [2010, 2008, 2010],\n       [2004, 2001, 2010],\n       [2007, 2004, 2018],\n       [2014, 2003, 1996],\n       [2012, 1994, 2013],\n       [2003, 2001, 2000],\n       [2000, 1996, 1997],\n       [2010, 1998, 2004],\n       [2012, 1995, 2001],\n       [2010, 2008, 2003]])Record High(Month, variable)float6478.05 0.015 81.7 ... 0.481 84.55array([[ 7.8050e+01,  1.5000e-02,  8.1700e+01],\n       [ 7.8550e+01, -1.5250e-01,  8.1500e+01],\n       [ 8.2850e+01, -5.6000e-02,  8.3200e+01],\n       [ 8.5800e+01, -8.0000e-03,  8.5750e+01],\n       [ 8.7250e+01,  4.3150e-01,  8.8600e+01],\n       [ 8.7650e+01, -4.1000e-02,  9.0400e+01],\n       [ 8.8700e+01, -1.9200e-01,  9.2000e+01],\n       [ 8.8500e+01,  1.4500e-02,  9.2200e+01],\n       [ 8.6700e+01,  1.8965e+00,  9.1150e+01],\n       [ 8.6750e+01,  7.2000e-01,  8.9050e+01],\n       [ 8.2050e+01,  8.7900e-01,  8.5000e+01],\n       [ 7.9650e+01,  4.8100e-01,  8.4550e+01]])Record High Year(Month, variable)int642022 2020 2017 ... 1994 2023 2016array([[2022, 2020, 2017],\n       [2021, 2024, 2021],\n       [2003, 2019, 2021],\n       [2020, 2023, 2020],\n       [2024, 2022, 2024],\n       [2009, 2023, 2010],\n       [2018, 2019, 2021],\n       [2022, 2014, 2021],\n       [2021, 2017, 2021],\n       [2023, 2017, 2016],\n       [2020, 2022, 2020],\n       [1994, 2023, 2016]])Average Low(Month, variable)float6455.55 -1.507 67.71 ... -1.298 70.24array([[55.55      , -1.5068871 , 67.71      ],\n       [59.3625    , -1.5467    , 69.18863636],\n       [63.334     , -1.44827586, 71.098     ],\n       [68.398     , -1.3832    , 74.68461538],\n       [73.95192308, -1.26675862, 78.20192308],\n       [77.63571429, -1.29075862, 82.23958333],\n       [79.01923077, -1.36201667, 84.58076923],\n       [79.51041667, -1.25251613, 84.41346154],\n       [78.336     , -0.97132258, 83.102     ],\n       [72.88333333, -0.82972414, 77.872     ],\n       [65.97291667, -0.99663333, 74.172     ],\n       [59.406     , -1.29768333, 70.244     ]])Highest Low(Month, variable)float6463.5 -0.797 75.9 ... -0.6525 79.65array([[63.5   , -0.797 , 75.9   ],\n       [70.    , -1.127 , 73.4   ],\n       [72.    , -0.955 , 75.4   ],\n       [72.6   , -0.991 , 81.05  ],\n       [77.1   , -0.7855, 80.35  ],\n       [80.75  , -0.807 , 85.2   ],\n       [82.3   , -1.091 , 87.15  ],\n       [83.55  , -0.761 , 87.25  ],\n       [81.6   , -0.5235, 87.1   ],\n       [77.8   , -0.102 , 83.4   ],\n       [74.45  , -0.2755, 80.05  ],\n       [70.5   , -0.6525, 79.65  ]])Highest Low Year(Month, variable)int642013 2022 2017 ... 2015 2022 2016array([[2013, 2022, 2017],\n       [2018, 2019, 2023],\n       [1997, 2019, 1997],\n       [2015, 2024, 2020],\n       [2003, 2024, 1994],\n       [2004, 2024, 2004],\n       [2022, 2019, 2023],\n       [2022, 2019, 2021],\n       [2024, 2008, 2021],\n       [2020, 2023, 2021],\n       [2020, 2022, 2016],\n       [2015, 2022, 2016]])Record Low(Month, variable)float6448.3 -2.016 63.95 ... -1.711 63.7array([[48.3   , -2.016 , 63.95  ],\n       [47.9   , -2.0225, 63.15  ],\n       [55.1   , -2.0045, 64.85  ],\n       [61.2   , -1.9   , 69.4   ],\n       [67.95  , -1.6075, 74.1   ],\n       [75.1   , -1.831 , 79.95  ],\n       [76.1   , -1.816 , 80.95  ],\n       [77.    , -1.6095, 81.05  ],\n       [74.3   , -1.3995, 79.5   ],\n       [64.6   , -1.5915, 73.2   ],\n       [57.35  , -1.583 , 70.8   ],\n       [48.75  , -1.711 , 63.7   ]])Record Low Year(Month, variable)int641997 2001 2003 ... 2010 2004 2010array([[1997, 2001, 2003],\n       [1996, 2008, 2005],\n       [1996, 1996, 2010],\n       [2009, 1994, 2003],\n       [1999, 2011, 2001],\n       [1995, 2006, 2014],\n       [2013, 1994, 2013],\n       [1994, 1996, 2012],\n       [2001, 2004, 2004],\n       [2005, 2010, 2005],\n       [2006, 1998, 2000],\n       [2010, 2004, 2010]])Years(Month, variable)int6423 31 25 24 30 ... 30 25 25 30 25array([[23, 31, 25],\n       [24, 30, 22],\n       [25, 29, 25],\n       [25, 30, 26],\n       [26, 29, 26],\n       [21, 29, 24],\n       [26, 30, 26],\n       [24, 31, 26],\n       [25, 31, 25],\n       [24, 29, 25],\n       [24, 30, 25],\n       [25, 30, 25]])Indexes: (2)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Level', 'Water Temperature'], dtype='object', name='variable'))MonthPandasIndexPandasIndex(Index(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct',\n       'Nov', 'Dec'],\n      dtype='object', name='Month'))Attributes: (14)datum :MHHWday_threshold :2dirname :virginiaKeyFlhr_threshold :4stationid :8723214stationname :Virginia Key, FLtz :lstunit_system :englishAir Temperature units :°FWater Level units :ftWater Temperature units :°FAir Temperature data range :('1994-02-01', '2025-05-30')Water Level data range :('1994-02-01', '2025-04-30')Water Temperature data range :('1994-02-01', '2025-05-30')\n\n\n\nmonthly_records.coords['variable']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'variable' (variable: 3)&gt; Size: 24B\narray(['Air Temperature', 'Water Level', 'Water Temperature'], dtype=object)\nCoordinates:\n  * variable  (variable) object 24B 'Air Temperature' ... 'Water Temperature'xarray.DataArray'variable'variable: 3'Air Temperature' 'Water Level' 'Water Temperature'array(['Air Temperature', 'Water Level', 'Water Temperature'], dtype=object)Coordinates: (1)variable(variable)object'Air Temperature' ... 'Water Tem...array(['Air Temperature', 'Water Level', 'Water Temperature'], dtype=object)Indexes: (1)variablePandasIndexPandasIndex(Index(['Air Temperature', 'Water Level', 'Water Temperature'], dtype='object', name='variable'))Attributes: (0)\n\n\nWe can still choose one environmental variable at a time, but now we get all of the records and corresponding years:\n\nmonthly_records.sel(variable='Air Temperature').to_dataframe().drop('variable', axis=1)\n\n\n\n\n\n\n\n\nMonthly Average\nRecord High Monthly Average\nRecord High Monthly Average Year\nRecord Low Monthly Average\nRecord Low Monthly Average Year\nAverage High\nLowest High\nLowest High Year\nRecord High\nRecord High Year\nAverage Low\nHighest Low\nHighest Low Year\nRecord Low\nRecord Low Year\nYears\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan\n68.656295\n72.570968\n2013\n63.038710\n2001\n76.050000\n72.95\n2011\n78.05\n2022\n55.550000\n63.50\n2013\n48.30\n1997\n23\n\n\nFeb\n70.892723\n74.900000\n2018\n65.465517\n1996\n76.485417\n74.20\n2000\n78.55\n2021\n59.362500\n70.00\n2018\n47.90\n1996\n24\n\n\nMar\n72.272770\n77.616667\n2003\n66.079032\n2010\n78.490000\n74.15\n2010\n82.85\n2003\n63.334000\n72.00\n1997\n55.10\n1996\n25\n\n\nApr\n75.633064\n79.383333\n2020\n72.813333\n2004\n80.740000\n77.30\n2004\n85.80\n2020\n68.398000\n72.60\n2015\n61.20\n2009\n25\n\n\nMay\n78.728491\n81.930645\n2024\n76.974138\n2007\n82.480769\n79.35\n2007\n87.25\n2024\n73.951923\n77.10\n2003\n67.95\n1999\n26\n\n\nJun\n81.538006\n83.613333\n2010\n79.840000\n2014\n84.754762\n82.75\n2014\n87.65\n2009\n77.635714\n80.75\n2004\n75.10\n1995\n21\n\n\nJul\n82.909982\n84.996774\n2023\n80.980645\n2013\n85.790385\n84.20\n2012\n88.70\n2018\n79.019231\n82.30\n2022\n76.10\n2013\n26\n\n\nAug\n83.298278\n85.906452\n2022\n81.820968\n1994\n85.845833\n84.05\n2003\n88.50\n2022\n79.510417\n83.55\n2022\n77.00\n1994\n24\n\n\nSep\n82.093823\n83.740000\n2024\n80.571667\n2001\n85.166000\n83.90\n2000\n86.70\n2021\n78.336000\n81.60\n2024\n74.30\n2001\n25\n\n\nOct\n79.634756\n81.238710\n2020\n77.551613\n2000\n83.812500\n80.95\n2010\n86.75\n2023\n72.883333\n77.80\n2020\n64.60\n2005\n24\n\n\nNov\n75.042799\n78.623333\n2015\n71.373333\n2012\n79.841667\n76.90\n2012\n82.05\n2020\n65.972917\n74.45\n2020\n57.35\n2006\n24\n\n\nDec\n71.425446\n76.870968\n2015\n62.096667\n2010\n77.470000\n72.50\n2010\n79.65\n1994\n59.406000\n70.50\n2015\n48.75\n2010\n25\n\n\n\n\n\n\n\nFinally, write these to file for safe keeping.\n\ndaily_records.to_netcdf(os.path.join(outdir, 'statistics-daily.nc'), mode='w')\nmonthly_records.to_netcdf(os.path.join(outdir, 'statistics-monthly.nc'), mode='w')\n\nWe will plot these results in Part 3.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Behind the Scenes",
      "Data Cleansing and Records Calculations"
    ]
  }
]